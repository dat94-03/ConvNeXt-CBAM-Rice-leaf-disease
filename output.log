✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: ConvNeXt+3cbam+norm+dataset1]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
🕒 Epoch 1/100 | Time: 74.19s | Train Loss: 0.8288 | Val Loss: 0.5507 | Val Acc: 0.9629 | LR: 0.000100 
💾 Saving best val acc: 0.9629
🕒 Epoch 2/100 | Time: 74.05s | Train Loss: 0.5193 | Val Loss: 0.4932 | Val Acc: 0.9759 | LR: 0.000100 
💾 Saving best val acc: 0.9759
🕒 Epoch 3/100 | Time: 74.20s | Train Loss: 0.4722 | Val Loss: 0.4772 | Val Acc: 0.9796 | LR: 0.000100 
💾 Saving best val acc: 0.9796
🕒 Epoch 4/100 | Time: 73.70s | Train Loss: 0.4599 | Val Loss: 0.5030 | Val Acc: 0.9703 | LR: 0.000099 
🕒 Epoch 5/100 | Time: 74.19s | Train Loss: 0.4609 | Val Loss: 0.4696 | Val Acc: 0.9796 | LR: 0.000098 
💾 Saving best val acc: 0.9796
🕒 Epoch 6/100 | Time: 74.44s | Train Loss: 0.4482 | Val Loss: 0.4770 | Val Acc: 0.9777 | LR: 0.000098 
🕒 Epoch 7/100 | Time: 74.30s | Train Loss: 0.4415 | Val Loss: 0.4564 | Val Acc: 0.9833 | LR: 0.000097 
💾 Saving best val acc: 0.9833
🕒 Epoch 8/100 | Time: 74.44s | Train Loss: 0.4328 | Val Loss: 0.4801 | Val Acc: 0.9740 | LR: 0.000095 
🕒 Epoch 9/100 | Time: 74.47s | Train Loss: 0.4721 | Val Loss: 0.4795 | Val Acc: 0.9777 | LR: 0.000094 
🕒 Epoch 10/100 | Time: 74.02s | Train Loss: 0.4377 | Val Loss: 0.4789 | Val Acc: 0.9833 | LR: 0.000092 
🕒 Epoch 11/100 | Time: 74.68s | Train Loss: 0.4317 | Val Loss: 0.4711 | Val Acc: 0.9833 | LR: 0.000091 
🕒 Epoch 12/100 | Time: 74.76s | Train Loss: 0.4328 | Val Loss: 0.4643 | Val Acc: 0.9814 | LR: 0.000089 
🕒 Epoch 13/100 | Time: 74.62s | Train Loss: 0.4315 | Val Loss: 0.4634 | Val Acc: 0.9852 | LR: 0.000087 
🕒 Epoch 14/100 | Time: 74.77s | Train Loss: 0.4355 | Val Loss: 0.4788 | Val Acc: 0.9814 | LR: 0.000084 
🕒 Epoch 15/100 | Time: 75.28s | Train Loss: 0.4357 | Val Loss: 0.4824 | Val Acc: 0.9814 | LR: 0.000082 
🕒 Epoch 16/100 | Time: 74.63s | Train Loss: 0.4335 | Val Loss: 0.4985 | Val Acc: 0.9722 | LR: 0.000080 
🕒 Epoch 17/100 | Time: 74.88s | Train Loss: 0.4305 | Val Loss: 0.4638 | Val Acc: 0.9833 | LR: 0.000077 
⏹️ Early stopping triggered.
✅ Training complete in 1265.72 seconds. Best model loaded.
📁 Model saved to ./output/models/ConvNeXt+3cbam+norm+dataset1+dataset1.pth
📂 Training metrics plot saved to: output/test/ConvNeXt+3cbam+norm+dataset1/training metric.png

Evaluate model:ConvNeXt+3cbam+norm+dataset1

🔥 Test Accuracy: 97.99%

📌 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    0.9775    0.9886        89
           brown_spot     0.9775    0.9255    0.9508        94
              healthy     0.9792    1.0000    0.9895        94
           leaf_blast     0.9278    0.9783    0.9524        92
           leaf_scald     1.0000    1.0000    1.0000        91
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9799       548
            macro avg     0.9808    0.9802    0.9802       548
         weighted avg     0.9805    0.9799    0.9799       548

📂 Confusion matrix saved to: output/test/ConvNeXt+3cbam+norm+dataset1/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+3cbam+norm+dataset1/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+3cbam+norm+dataset1/misclassified_images.png
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: ConvNeXt+dataset1]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
🕒 Epoch 1/100 | Time: 73.84s | Train Loss: 0.7870 | Val Loss: 0.5196 | Val Acc: 0.9666 | LR: 0.000100 
💾 Saving best val acc: 0.9666
🕒 Epoch 2/100 | Time: 74.33s | Train Loss: 0.5057 | Val Loss: 0.5590 | Val Acc: 0.9703 | LR: 0.000100 
🕒 Epoch 3/100 | Time: 74.16s | Train Loss: 0.4852 | Val Loss: 0.4982 | Val Acc: 0.9722 | LR: 0.000100 
💾 Saving best val acc: 0.9722
🕒 Epoch 4/100 | Time: 74.25s | Train Loss: 0.4643 | Val Loss: 0.4728 | Val Acc: 0.9814 | LR: 0.000099 
💾 Saving best val acc: 0.9814
🕒 Epoch 5/100 | Time: 74.46s | Train Loss: 0.4486 | Val Loss: 0.4796 | Val Acc: 0.9759 | LR: 0.000098 
🕒 Epoch 6/100 | Time: 73.96s | Train Loss: 0.4468 | Val Loss: 0.4765 | Val Acc: 0.9777 | LR: 0.000098 
🕒 Epoch 7/100 | Time: 75.54s | Train Loss: 0.4447 | Val Loss: 0.4871 | Val Acc: 0.9759 | LR: 0.000097 
🕒 Epoch 8/100 | Time: 74.62s | Train Loss: 0.4480 | Val Loss: 0.4914 | Val Acc: 0.9722 | LR: 0.000095 
🕒 Epoch 9/100 | Time: 75.40s | Train Loss: 0.4426 | Val Loss: 0.4652 | Val Acc: 0.9852 | LR: 0.000094 
💾 Saving best val acc: 0.9852
🕒 Epoch 10/100 | Time: 75.88s | Train Loss: 0.4340 | Val Loss: 0.4625 | Val Acc: 0.9833 | LR: 0.000092 
💾 Saving best val acc: 0.9833
🕒 Epoch 11/100 | Time: 74.76s | Train Loss: 0.4340 | Val Loss: 0.4649 | Val Acc: 0.9870 | LR: 0.000091 
🕒 Epoch 12/100 | Time: 74.81s | Train Loss: 0.4303 | Val Loss: 0.4562 | Val Acc: 0.9870 | LR: 0.000089 
💾 Saving best val acc: 0.9870
🕒 Epoch 13/100 | Time: 74.29s | Train Loss: 0.4275 | Val Loss: 0.4609 | Val Acc: 0.9889 | LR: 0.000087 
🕒 Epoch 14/100 | Time: 74.81s | Train Loss: 0.4251 | Val Loss: 0.4421 | Val Acc: 0.9926 | LR: 0.000084 
💾 Saving best val acc: 0.9926
🕒 Epoch 15/100 | Time: 74.63s | Train Loss: 0.4276 | Val Loss: 0.4647 | Val Acc: 0.9852 | LR: 0.000082 
🕒 Epoch 16/100 | Time: 74.27s | Train Loss: 0.4268 | Val Loss: 0.4508 | Val Acc: 0.9907 | LR: 0.000080 
🕒 Epoch 17/100 | Time: 73.58s | Train Loss: 0.4253 | Val Loss: 0.4701 | Val Acc: 0.9814 | LR: 0.000077 
🕒 Epoch 18/100 | Time: 73.78s | Train Loss: 0.4276 | Val Loss: 0.4542 | Val Acc: 0.9870 | LR: 0.000074 
🕒 Epoch 19/100 | Time: 74.25s | Train Loss: 0.4257 | Val Loss: 0.4605 | Val Acc: 0.9889 | LR: 0.000072 
🕒 Epoch 20/100 | Time: 74.33s | Train Loss: 0.4263 | Val Loss: 0.4458 | Val Acc: 0.9889 | LR: 0.000069 
🕒 Epoch 21/100 | Time: 74.65s | Train Loss: 0.4307 | Val Loss: 0.4590 | Val Acc: 0.9889 | LR: 0.000066 
🕒 Epoch 22/100 | Time: 73.70s | Train Loss: 0.4283 | Val Loss: 0.4547 | Val Acc: 0.9889 | LR: 0.000063 
🕒 Epoch 23/100 | Time: 74.05s | Train Loss: 0.4367 | Val Loss: 0.4554 | Val Acc: 0.9870 | LR: 0.000060 
🕒 Epoch 24/100 | Time: 74.80s | Train Loss: 0.4323 | Val Loss: 0.4545 | Val Acc: 0.9889 | LR: 0.000057 
⏹️ Early stopping triggered.
✅ Training complete in 1787.29 seconds. Best model loaded.
📁 Model saved to ./output/models/ConvNeXt+dataset1+dataset1.pth
📂 Training metrics plot saved to: output/test/ConvNeXt+dataset1/training metric.png
Evaluate model:ConvNeXt+dataset1

🔥 Test Accuracy: 98.36%

📌 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    1.0000    1.0000        89
           brown_spot     0.9474    0.9574    0.9524        94
              healthy     1.0000    1.0000    1.0000        94
           leaf_blast     0.9560    0.9457    0.9508        92
           leaf_scald     1.0000    1.0000    1.0000        91
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9836       548
            macro avg     0.9839    0.9838    0.9839       548
         weighted avg     0.9836    0.9836    0.9836       548

📂 Confusion matrix saved to: output/test/ConvNeXt+dataset1/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+dataset1/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+dataset1/misclassified_images.png

✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: ConvNeXt+3cbam+norn+dataset21]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
🕒 Epoch 1/100 | Time: 70.12s | Train Loss: 0.7757 | Val Loss: 0.5315 | Val Acc: 0.9540 | LR: 0.000100 
💾 Saving best val acc: 0.9540
🕒 Epoch 2/100 | Time: 70.85s | Train Loss: 0.5146 | Val Loss: 0.5034 | Val Acc: 0.9761 | LR: 0.000100 
💾 Saving best val acc: 0.9761
🕒 Epoch 3/100 | Time: 70.38s | Train Loss: 0.4625 | Val Loss: 0.4770 | Val Acc: 0.9761 | LR: 0.000100 
💾 Saving best val acc: 0.9761
🕒 Epoch 4/100 | Time: 70.65s | Train Loss: 0.4528 | Val Loss: 0.4786 | Val Acc: 0.9798 | LR: 0.000099 
🕒 Epoch 5/100 | Time: 69.93s | Train Loss: 0.4649 | Val Loss: 0.4843 | Val Acc: 0.9761 | LR: 0.000098 
🕒 Epoch 6/100 | Time: 70.88s | Train Loss: 0.4613 | Val Loss: 0.4827 | Val Acc: 0.9779 | LR: 0.000098 
🕒 Epoch 7/100 | Time: 70.00s | Train Loss: 0.4640 | Val Loss: 0.5023 | Val Acc: 0.9596 | LR: 0.000097 
🕒 Epoch 8/100 | Time: 71.23s | Train Loss: 0.4462 | Val Loss: 0.4746 | Val Acc: 0.9798 | LR: 0.000095 
💾 Saving best val acc: 0.9798
🕒 Epoch 9/100 | Time: 70.39s | Train Loss: 0.4391 | Val Loss: 0.4815 | Val Acc: 0.9761 | LR: 0.000094 
🕒 Epoch 10/100 | Time: 70.96s | Train Loss: 0.4336 | Val Loss: 0.4793 | Val Acc: 0.9798 | LR: 0.000092 
🕒 Epoch 11/100 | Time: 70.38s | Train Loss: 0.4289 | Val Loss: 0.4661 | Val Acc: 0.9816 | LR: 0.000091 
💾 Saving best val acc: 0.9816
🕒 Epoch 12/100 | Time: 97.33s | Train Loss: 0.4269 | Val Loss: 0.4729 | Val Acc: 0.9835 | LR: 0.000089 
🕒 Epoch 13/100 | Time: 88.32s | Train Loss: 0.4306 | Val Loss: 0.4780 | Val Acc: 0.9798 | LR: 0.000087 
🕒 Epoch 14/100 | Time: 71.94s | Train Loss: 0.4280 | Val Loss: 0.4692 | Val Acc: 0.9835 | LR: 0.000084 
🕒 Epoch 15/100 | Time: 71.08s | Train Loss: 0.4256 | Val Loss: 0.4732 | Val Acc: 0.9816 | LR: 0.000082 
🕒 Epoch 16/100 | Time: 71.11s | Train Loss: 0.4269 | Val Loss: 0.4802 | Val Acc: 0.9798 | LR: 0.000080 
🕒 Epoch 17/100 | Time: 71.08s | Train Loss: 0.4349 | Val Loss: 0.4859 | Val Acc: 0.9761 | LR: 0.000077 
🕒 Epoch 18/100 | Time: 71.80s | Train Loss: 0.4447 | Val Loss: 0.5840 | Val Acc: 0.9467 | LR: 0.000074 
🕒 Epoch 19/100 | Time: 71.03s | Train Loss: 0.4704 | Val Loss: 0.4755 | Val Acc: 0.9798 | LR: 0.000072 
🕒 Epoch 20/100 | Time: 71.01s | Train Loss: 0.4338 | Val Loss: 0.4752 | Val Acc: 0.9798 | LR: 0.000069 
🕒 Epoch 21/100 | Time: 71.59s | Train Loss: 0.4291 | Val Loss: 0.4615 | Val Acc: 0.9853 | LR: 0.000066 
💾 Saving best val acc: 0.9853
🕒 Epoch 22/100 | Time: 71.42s | Train Loss: 0.4290 | Val Loss: 0.4604 | Val Acc: 0.9890 | LR: 0.000063 
💾 Saving best val acc: 0.9890
🕒 Epoch 23/100 | Time: 71.13s | Train Loss: 0.4269 | Val Loss: 0.4594 | Val Acc: 0.9871 | LR: 0.000060 
💾 Saving best val acc: 0.9871
🕒 Epoch 24/100 | Time: 70.17s | Train Loss: 0.4262 | Val Loss: 0.4880 | Val Acc: 0.9798 | LR: 0.000057 
🕒 Epoch 25/100 | Time: 71.17s | Train Loss: 0.4231 | Val Loss: 0.4806 | Val Acc: 0.9816 | LR: 0.000054 
🕒 Epoch 26/100 | Time: 70.73s | Train Loss: 0.4236 | Val Loss: 0.4792 | Val Acc: 0.9816 | LR: 0.000050 
🕒 Epoch 27/100 | Time: 71.48s | Train Loss: 0.4232 | Val Loss: 0.4720 | Val Acc: 0.9779 | LR: 0.000047 
🕒 Epoch 28/100 | Time: 70.82s | Train Loss: 0.4258 | Val Loss: 0.4595 | Val Acc: 0.9871 | LR: 0.000044 
🕒 Epoch 29/100 | Time: 71.72s | Train Loss: 0.4226 | Val Loss: 0.4609 | Val Acc: 0.9871 | LR: 0.000041 
🕒 Epoch 30/100 | Time: 72.55s | Train Loss: 0.4228 | Val Loss: 0.4609 | Val Acc: 0.9871 | LR: 0.000038 
🕒 Epoch 31/100 | Time: 70.84s | Train Loss: 0.4225 | Val Loss: 0.4655 | Val Acc: 0.9871 | LR: 0.000035 
🕒 Epoch 32/100 | Time: 70.95s | Train Loss: 0.4220 | Val Loss: 0.4638 | Val Acc: 0.9871 | LR: 0.000032 
🕒 Epoch 33/100 | Time: 70.75s | Train Loss: 0.4217 | Val Loss: 0.4641 | Val Acc: 0.9853 | LR: 0.000029 
⏹️ Early stopping triggered.
✅ Training complete in 2385.95 seconds. Best model loaded.
📁 Model saved to ./output/models/ConvNeXt+3cbam+norn+dataset21+dataset21.pth
📂 Training metrics plot saved to: output/test/ConvNeXt+3cbam+norn+dataset21/training metric.png
Evaluate model:ConvNeXt+3cbam+norn+dataset21

🔥 Test Accuracy: 98.53%

📌 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    1.0000    1.0000        88
           brown_spot     0.9474    0.9677    0.9574        93
              healthy     0.9894    1.0000    0.9947        93
           leaf_blast     0.9773    0.9451    0.9609        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9853       543
            macro avg     0.9857    0.9855    0.9855       543
         weighted avg     0.9854    0.9853    0.9852       543

📂 Confusion matrix saved to: output/test/ConvNeXt+3cbam+norn+dataset21/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+3cbam+norn+dataset21/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+3cbam+norn+dataset21/misclassified_images.png
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: ConvNeXt+dataset21]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
🕒 Epoch 1/100 | Time: 79.92s | Train Loss: 0.7694 | Val Loss: 0.5436 | Val Acc: 0.9596 | LR: 0.000100 
💾 Saving best val acc: 0.9596
🕒 Epoch 2/100 | Time: 69.36s | Train Loss: 0.4981 | Val Loss: 0.5127 | Val Acc: 0.9724 | LR: 0.000100 
💾 Saving best val acc: 0.9724
🕒 Epoch 3/100 | Time: 69.61s | Train Loss: 0.4783 | Val Loss: 0.4962 | Val Acc: 0.9706 | LR: 0.000100 
💾 Saving best val acc: 0.9706
🕒 Epoch 4/100 | Time: 69.99s | Train Loss: 0.4643 | Val Loss: 0.4940 | Val Acc: 0.9706 | LR: 0.000099 
💾 Saving best val acc: 0.9706
🕒 Epoch 5/100 | Time: 69.81s | Train Loss: 0.4489 | Val Loss: 0.4843 | Val Acc: 0.9798 | LR: 0.000098 
💾 Saving best val acc: 0.9798
🕒 Epoch 6/100 | Time: 70.70s | Train Loss: 0.4463 | Val Loss: 0.4610 | Val Acc: 0.9871 | LR: 0.000098 
💾 Saving best val acc: 0.9871
🕒 Epoch 7/100 | Time: 70.98s | Train Loss: 0.4421 | Val Loss: 0.4706 | Val Acc: 0.9779 | LR: 0.000097 
🕒 Epoch 8/100 | Time: 70.11s | Train Loss: 0.4311 | Val Loss: 0.4648 | Val Acc: 0.9871 | LR: 0.000095 
🕒 Epoch 9/100 | Time: 69.94s | Train Loss: 0.4333 | Val Loss: 0.4582 | Val Acc: 0.9890 | LR: 0.000094 
💾 Saving best val acc: 0.9890
🕒 Epoch 10/100 | Time: 70.45s | Train Loss: 0.4300 | Val Loss: 0.4680 | Val Acc: 0.9835 | LR: 0.000092 
🕒 Epoch 11/100 | Time: 69.07s | Train Loss: 0.4299 | Val Loss: 0.4756 | Val Acc: 0.9761 | LR: 0.000091 
🕒 Epoch 12/100 | Time: 70.38s | Train Loss: 0.4412 | Val Loss: 0.4787 | Val Acc: 0.9743 | LR: 0.000089 
🕒 Epoch 13/100 | Time: 69.82s | Train Loss: 0.4485 | Val Loss: 0.4665 | Val Acc: 0.9871 | LR: 0.000087 
🕒 Epoch 14/100 | Time: 70.11s | Train Loss: 0.4280 | Val Loss: 0.4611 | Val Acc: 0.9871 | LR: 0.000084 
🕒 Epoch 15/100 | Time: 69.68s | Train Loss: 0.4322 | Val Loss: 0.5030 | Val Acc: 0.9669 | LR: 0.000082 
🕒 Epoch 16/100 | Time: 70.87s | Train Loss: 0.4439 | Val Loss: 0.5460 | Val Acc: 0.9577 | LR: 0.000080 
🕒 Epoch 17/100 | Time: 69.83s | Train Loss: 0.4581 | Val Loss: 0.4589 | Val Acc: 0.9816 | LR: 0.000077 
🕒 Epoch 18/100 | Time: 70.68s | Train Loss: 0.4315 | Val Loss: 0.4705 | Val Acc: 0.9816 | LR: 0.000074 
🕒 Epoch 19/100 | Time: 69.90s | Train Loss: 0.4233 | Val Loss: 0.4515 | Val Acc: 0.9853 | LR: 0.000072 
💾 Saving best val acc: 0.9853
🕒 Epoch 20/100 | Time: 70.68s | Train Loss: 0.4309 | Val Loss: 0.4887 | Val Acc: 0.9779 | LR: 0.000069 
🕒 Epoch 21/100 | Time: 70.12s | Train Loss: 0.4573 | Val Loss: 0.4671 | Val Acc: 0.9871 | LR: 0.000066 
🕒 Epoch 22/100 | Time: 70.14s | Train Loss: 0.4263 | Val Loss: 0.4556 | Val Acc: 0.9853 | LR: 0.000063 
🕒 Epoch 23/100 | Time: 69.61s | Train Loss: 0.4242 | Val Loss: 0.4538 | Val Acc: 0.9871 | LR: 0.000060 
🕒 Epoch 24/100 | Time: 70.83s | Train Loss: 0.4248 | Val Loss: 0.4562 | Val Acc: 0.9853 | LR: 0.000057 
🕒 Epoch 25/100 | Time: 69.98s | Train Loss: 0.4228 | Val Loss: 0.4586 | Val Acc: 0.9816 | LR: 0.000054 
🕒 Epoch 26/100 | Time: 70.64s | Train Loss: 0.4237 | Val Loss: 0.4528 | Val Acc: 0.9835 | LR: 0.000050 
🕒 Epoch 27/100 | Time: 70.08s | Train Loss: 0.4220 | Val Loss: 0.4504 | Val Acc: 0.9871 | LR: 0.000047 
💾 Saving best val acc: 0.9871
🕒 Epoch 28/100 | Time: 70.56s | Train Loss: 0.4227 | Val Loss: 0.4825 | Val Acc: 0.9706 | LR: 0.000044 
🕒 Epoch 29/100 | Time: 69.64s | Train Loss: 0.4258 | Val Loss: 0.4492 | Val Acc: 0.9871 | LR: 0.000041 
💾 Saving best val acc: 0.9871
🕒 Epoch 30/100 | Time: 70.41s | Train Loss: 0.4221 | Val Loss: 0.4514 | Val Acc: 0.9871 | LR: 0.000038 
🕒 Epoch 31/100 | Time: 69.54s | Train Loss: 0.4216 | Val Loss: 0.4524 | Val Acc: 0.9871 | LR: 0.000035 
🕒 Epoch 32/100 | Time: 69.11s | Train Loss: 0.4255 | Val Loss: 0.4622 | Val Acc: 0.9798 | LR: 0.000032 
🕒 Epoch 33/100 | Time: 70.07s | Train Loss: 0.4221 | Val Loss: 0.4498 | Val Acc: 0.9871 | LR: 0.000029 
🕒 Epoch 34/100 | Time: 69.92s | Train Loss: 0.4219 | Val Loss: 0.4546 | Val Acc: 0.9853 | LR: 0.000027 
🕒 Epoch 35/100 | Time: 69.83s | Train Loss: 0.4215 | Val Loss: 0.4556 | Val Acc: 0.9853 | LR: 0.000024 
🕒 Epoch 36/100 | Time: 69.27s | Train Loss: 0.4222 | Val Loss: 0.4482 | Val Acc: 0.9871 | LR: 0.000021 
💾 Saving best val acc: 0.9871
🕒 Epoch 37/100 | Time: 70.97s | Train Loss: 0.4214 | Val Loss: 0.4479 | Val Acc: 0.9890 | LR: 0.000019 
💾 Saving best val acc: 0.9890
🕒 Epoch 38/100 | Time: 70.77s | Train Loss: 0.4229 | Val Loss: 0.4562 | Val Acc: 0.9871 | LR: 0.000017 
🕒 Epoch 39/100 | Time: 70.89s | Train Loss: 0.4218 | Val Loss: 0.4558 | Val Acc: 0.9871 | LR: 0.000014 
🕒 Epoch 40/100 | Time: 70.32s | Train Loss: 0.4214 | Val Loss: 0.4555 | Val Acc: 0.9871 | LR: 0.000012 
🕒 Epoch 41/100 | Time: 71.13s | Train Loss: 0.4213 | Val Loss: 0.4553 | Val Acc: 0.9871 | LR: 0.000010 
🕒 Epoch 42/100 | Time: 71.45s | Train Loss: 0.4213 | Val Loss: 0.4548 | Val Acc: 0.9871 | LR: 0.000009 
🕒 Epoch 43/100 | Time: 70.45s | Train Loss: 0.4213 | Val Loss: 0.4546 | Val Acc: 0.9871 | LR: 0.000007 
🕒 Epoch 44/100 | Time: 71.29s | Train Loss: 0.4216 | Val Loss: 0.4548 | Val Acc: 0.9871 | LR: 0.000006 
🕒 Epoch 45/100 | Time: 70.07s | Train Loss: 0.4213 | Val Loss: 0.4545 | Val Acc: 0.9871 | LR: 0.000004 
🕒 Epoch 46/100 | Time: 71.20s | Train Loss: 0.4213 | Val Loss: 0.4546 | Val Acc: 0.9871 | LR: 0.000003 
🕒 Epoch 47/100 | Time: 70.86s | Train Loss: 0.4226 | Val Loss: 0.4547 | Val Acc: 0.9871 | LR: 0.000003 
⏹️ Early stopping triggered.
✅ Training complete in 3311.26 seconds. Best model loaded.
📁 Model saved to ./output/models/ConvNeXt+dataset21+dataset21.pth
📂 Training metrics plot saved to: output/test/ConvNeXt+dataset21/training metric.png
Evaluate model:ConvNeXt+dataset21

🔥 Test Accuracy: 98.53%

📌 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    0.9886    0.9943        88
           brown_spot     0.9677    0.9677    0.9677        93
              healthy     0.9787    0.9892    0.9840        93
           leaf_blast     0.9670    0.9670    0.9670        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9853       543
            macro avg     0.9856    0.9854    0.9855       543
         weighted avg     0.9853    0.9853    0.9853       543

📂 Confusion matrix saved to: output/test/ConvNeXt+dataset21/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+dataset21/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+dataset21/misclassified_images.png

✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: ConvNeXt+dataset21]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
🕒 Epoch 1/100 | Time: 150.91s | Train Loss: 0.7430 | Val Loss: 0.5240 | Val Acc: 0.9577 | LR: 0.000100 
💾 Saving best val acc: 0.9577
🕒 Epoch 2/100 | Time: 108.86s | Train Loss: 0.5114 | Val Loss: 0.5314 | Val Acc: 0.9430 | LR: 0.000100 
🕒 Epoch 3/100 | Time: 112.93s | Train Loss: 0.4781 | Val Loss: 0.4912 | Val Acc: 0.9743 | LR: 0.000100 
💾 Saving best val acc: 0.9743
🕒 Epoch 4/100 | Time: 109.01s | Train Loss: 0.4844 | Val Loss: 0.5197 | Val Acc: 0.9706 | LR: 0.000099 
🕒 Epoch 5/100 | Time: 108.21s | Train Loss: 0.4582 | Val Loss: 0.5042 | Val Acc: 0.9614 | LR: 0.000098 
🕒 Epoch 6/100 | Time: 108.60s | Train Loss: 0.4533 | Val Loss: 0.4682 | Val Acc: 0.9816 | LR: 0.000098 
💾 Saving best val acc: 0.9816
🕒 Epoch 7/100 | Time: 108.67s | Train Loss: 0.4454 | Val Loss: 0.4903 | Val Acc: 0.9651 | LR: 0.000097 
🕒 Epoch 8/100 | Time: 109.50s | Train Loss: 0.4409 | Val Loss: 0.4841 | Val Acc: 0.9724 | LR: 0.000095 
🕒 Epoch 9/100 | Time: 107.47s | Train Loss: 0.4481 | Val Loss: 0.4693 | Val Acc: 0.9816 | LR: 0.000094 
🕒 Epoch 10/100 | Time: 109.57s | Train Loss: 0.4440 | Val Loss: 0.4927 | Val Acc: 0.9743 | LR: 0.000092 
🕒 Epoch 11/100 | Time: 111.26s | Train Loss: 0.4335 | Val Loss: 0.4928 | Val Acc: 0.9706 | LR: 0.000091 
🕒 Epoch 12/100 | Time: 108.98s | Train Loss: 0.4383 | Val Loss: 0.4778 | Val Acc: 0.9798 | LR: 0.000089 
🕒 Epoch 13/100 | Time: 109.50s | Train Loss: 0.4313 | Val Loss: 0.4959 | Val Acc: 0.9724 | LR: 0.000087 
🕒 Epoch 14/100 | Time: 108.74s | Train Loss: 0.4310 | Val Loss: 0.4733 | Val Acc: 0.9816 | LR: 0.000084 
🕒 Epoch 15/100 | Time: 110.42s | Train Loss: 0.4285 | Val Loss: 0.4657 | Val Acc: 0.9853 | LR: 0.000082 
💾 Saving best val acc: 0.9853
🕒 Epoch 16/100 | Time: 110.32s | Train Loss: 0.4247 | Val Loss: 0.5092 | Val Acc: 0.9688 | LR: 0.000080 
🕒 Epoch 17/100 | Time: 109.55s | Train Loss: 0.4338 | Val Loss: 0.4740 | Val Acc: 0.9798 | LR: 0.000077 
🕒 Epoch 18/100 | Time: 109.42s | Train Loss: 0.4311 | Val Loss: 0.5308 | Val Acc: 0.9632 | LR: 0.000074 
🕒 Epoch 19/100 | Time: 108.74s | Train Loss: 0.4442 | Val Loss: 0.4714 | Val Acc: 0.9835 | LR: 0.000072 
🕒 Epoch 20/100 | Time: 107.72s | Train Loss: 0.4274 | Val Loss: 0.4583 | Val Acc: 0.9890 | LR: 0.000069 
💾 Saving best val acc: 0.9890
🕒 Epoch 21/100 | Time: 108.19s | Train Loss: 0.4342 | Val Loss: 0.4682 | Val Acc: 0.9835 | LR: 0.000066 
🕒 Epoch 22/100 | Time: 98.69s | Train Loss: 0.4305 | Val Loss: 0.4723 | Val Acc: 0.9835 | LR: 0.000063 
🕒 Epoch 23/100 | Time: 71.80s | Train Loss: 0.4350 | Val Loss: 0.4649 | Val Acc: 0.9798 | LR: 0.000060 
🕒 Epoch 24/100 | Time: 72.65s | Train Loss: 0.4223 | Val Loss: 0.4605 | Val Acc: 0.9835 | LR: 0.000057 
🕒 Epoch 25/100 | Time: 72.34s | Train Loss: 0.4222 | Val Loss: 0.4638 | Val Acc: 0.9816 | LR: 0.000054 
🕒 Epoch 26/100 | Time: 70.86s | Train Loss: 0.4226 | Val Loss: 0.4631 | Val Acc: 0.9853 | LR: 0.000050 
🕒 Epoch 27/100 | Time: 71.02s | Train Loss: 0.4224 | Val Loss: 0.4617 | Val Acc: 0.9853 | LR: 0.000047 
🕒 Epoch 28/100 | Time: 70.66s | Train Loss: 0.4230 | Val Loss: 0.4526 | Val Acc: 0.9908 | LR: 0.000044 
💾 Saving best val acc: 0.9908
🕒 Epoch 29/100 | Time: 71.86s | Train Loss: 0.4243 | Val Loss: 0.4593 | Val Acc: 0.9890 | LR: 0.000041 
🕒 Epoch 30/100 | Time: 71.36s | Train Loss: 0.4225 | Val Loss: 0.4845 | Val Acc: 0.9798 | LR: 0.000038 
🕒 Epoch 31/100 | Time: 71.45s | Train Loss: 0.4281 | Val Loss: 0.4570 | Val Acc: 0.9890 | LR: 0.000035 
🕒 Epoch 32/100 | Time: 71.89s | Train Loss: 0.4223 | Val Loss: 0.4614 | Val Acc: 0.9890 | LR: 0.000032 
🕒 Epoch 33/100 | Time: 71.88s | Train Loss: 0.4255 | Val Loss: 0.4615 | Val Acc: 0.9871 | LR: 0.000029 
🕒 Epoch 34/100 | Time: 71.55s | Train Loss: 0.4224 | Val Loss: 0.4649 | Val Acc: 0.9835 | LR: 0.000027 
🕒 Epoch 35/100 | Time: 71.57s | Train Loss: 0.4217 | Val Loss: 0.4647 | Val Acc: 0.9835 | LR: 0.000024 
🕒 Epoch 36/100 | Time: 71.17s | Train Loss: 0.4215 | Val Loss: 0.4636 | Val Acc: 0.9853 | LR: 0.000021 
🕒 Epoch 37/100 | Time: 71.33s | Train Loss: 0.4213 | Val Loss: 0.4632 | Val Acc: 0.9853 | LR: 0.000019 
🕒 Epoch 38/100 | Time: 71.90s | Train Loss: 0.4222 | Val Loss: 0.4601 | Val Acc: 0.9853 | LR: 0.000017 
⏹️ Early stopping triggered.
✅ Training complete in 3580.80 seconds. Best model loaded.
📁 Model saved to ./output/models/ConvNeXt+dataset21+dataset21.pth
📂 Training metrics plot saved to: output/test/ConvNeXt+dataset21/training metric.png
Evaluate model:ConvNeXt+dataset21

🔥 Test Accuracy: 99.26%

📌 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     0.9888    1.0000    0.9944        88
           brown_spot     0.9787    0.9892    0.9840        93
              healthy     1.0000    1.0000    1.0000        93
           leaf_blast     0.9888    0.9670    0.9778        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9926       543
            macro avg     0.9927    0.9927    0.9927       543
         weighted avg     0.9927    0.9926    0.9926       543

📂 Confusion matrix saved to: output/test/ConvNeXt+dataset21/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+dataset21/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+dataset21/misclassified_images.png
✅ Saved fold class distribution plot to: output/fold_class_distribution.png

📂 Fold 1/5
🕒 Epoch 1/100 | Train Loss: 0.6968 | Val Loss: 0.5083 | Val Acc: 0.9631
💾 Best model updated (val acc: 0.9631)
🕒 Epoch 2/100 | Train Loss: 0.4836 | Val Loss: 0.4973 | Val Acc: 0.9631
💾 Best model updated (val acc: 0.9631)
🕒 Epoch 3/100 | Train Loss: 0.4608 | Val Loss: 0.4766 | Val Acc: 0.9700
💾 Best model updated (val acc: 0.9700)
🕒 Epoch 4/100 | Train Loss: 0.4311 | Val Loss: 0.4515 | Val Acc: 0.9885
💾 Best model updated (val acc: 0.9885)
🕒 Epoch 5/100 | Train Loss: 0.4286 | Val Loss: 0.4443 | Val Acc: 0.9862
💾 Best model updated (val acc: 0.9862)
🕒 Epoch 6/100 | Train Loss: 0.4233 | Val Loss: 0.4485 | Val Acc: 0.9839
🕒 Epoch 7/100 | Train Loss: 0.4220 | Val Loss: 0.4420 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 8/100 | Train Loss: 0.4216 | Val Loss: 0.4426 | Val Acc: 0.9931
🕒 Epoch 9/100 | Train Loss: 0.4214 | Val Loss: 0.4429 | Val Acc: 0.9839
🕒 Epoch 10/100 | Train Loss: 0.4214 | Val Loss: 0.4431 | Val Acc: 0.9839
🕒 Epoch 11/100 | Train Loss: 0.4214 | Val Loss: 0.4431 | Val Acc: 0.9839
🕒 Epoch 12/100 | Train Loss: 0.4213 | Val Loss: 0.4433 | Val Acc: 0.9862
🕒 Epoch 13/100 | Train Loss: 0.4213 | Val Loss: 0.4433 | Val Acc: 0.9839
🕒 Epoch 14/100 | Train Loss: 0.4213 | Val Loss: 0.4433 | Val Acc: 0.9839
🕒 Epoch 15/100 | Train Loss: 0.4213 | Val Loss: 0.4433 | Val Acc: 0.9885
🕒 Epoch 16/100 | Train Loss: 0.4212 | Val Loss: 0.4434 | Val Acc: 0.9839
🕒 Epoch 17/100 | Train Loss: 0.4212 | Val Loss: 0.4434 | Val Acc: 0.9839
⏹️ Early stopping.
✅ Fold 1 complete. Saved: ./output/models/kfold/ConvNeXt+4cbam+kfold+dataset22+dataset22_fold1.pth

📂 Fold 2/5
🕒 Epoch 1/100 | Train Loss: 0.7119 | Val Loss: 0.5069 | Val Acc: 0.9631
💾 Best model updated (val acc: 0.9631)
🕒 Epoch 2/100 | Train Loss: 0.4677 | Val Loss: 0.5047 | Val Acc: 0.9654
💾 Best model updated (val acc: 0.9654)
🕒 Epoch 3/100 | Train Loss: 0.4604 | Val Loss: 0.4640 | Val Acc: 0.9862
💾 Best model updated (val acc: 0.9862)
🕒 Epoch 4/100 | Train Loss: 0.4389 | Val Loss: 0.4681 | Val Acc: 0.9816
🕒 Epoch 5/100 | Train Loss: 0.4296 | Val Loss: 0.4658 | Val Acc: 0.9793
🕒 Epoch 6/100 | Train Loss: 0.4223 | Val Loss: 0.4592 | Val Acc: 0.9816
💾 Best model updated (val acc: 0.9816)
🕒 Epoch 7/100 | Train Loss: 0.4217 | Val Loss: 0.4584 | Val Acc: 0.9816
💾 Best model updated (val acc: 0.9816)
🕒 Epoch 8/100 | Train Loss: 0.4216 | Val Loss: 0.4581 | Val Acc: 0.9816
💾 Best model updated (val acc: 0.9816)
🕒 Epoch 9/100 | Train Loss: 0.4214 | Val Loss: 0.4577 | Val Acc: 0.9816
💾 Best model updated (val acc: 0.9816)
🕒 Epoch 10/100 | Train Loss: 0.4214 | Val Loss: 0.4578 | Val Acc: 0.9816
🕒 Epoch 11/100 | Train Loss: 0.4213 | Val Loss: 0.4579 | Val Acc: 0.9816
🕒 Epoch 12/100 | Train Loss: 0.4213 | Val Loss: 0.4578 | Val Acc: 0.9816
🕒 Epoch 13/100 | Train Loss: 0.4213 | Val Loss: 0.4577 | Val Acc: 0.9839
💾 Best model updated (val acc: 0.9839)
🕒 Epoch 14/100 | Train Loss: 0.4213 | Val Loss: 0.4577 | Val Acc: 0.9839
💾 Best model updated (val acc: 0.9839)
🕒 Epoch 15/100 | Train Loss: 0.4213 | Val Loss: 0.4577 | Val Acc: 0.9839
🕒 Epoch 16/100 | Train Loss: 0.4213 | Val Loss: 0.4578 | Val Acc: 0.9839
🕒 Epoch 17/100 | Train Loss: 0.4213 | Val Loss: 0.4578 | Val Acc: 0.9839
🕒 Epoch 18/100 | Train Loss: 0.4212 | Val Loss: 0.4578 | Val Acc: 0.9839
🕒 Epoch 19/100 | Train Loss: 0.4212 | Val Loss: 0.4577 | Val Acc: 0.9839
🕒 Epoch 20/100 | Train Loss: 0.4212 | Val Loss: 0.4579 | Val Acc: 0.9839
🕒 Epoch 21/100 | Train Loss: 0.4212 | Val Loss: 0.4578 | Val Acc: 0.9839
🕒 Epoch 22/100 | Train Loss: 0.4212 | Val Loss: 0.4578 | Val Acc: 0.9839
🕒 Epoch 23/100 | Train Loss: 0.4212 | Val Loss: 0.4579 | Val Acc: 0.9839
🕒 Epoch 24/100 | Train Loss: 0.4212 | Val Loss: 0.4579 | Val Acc: 0.9839
⏹️ Early stopping.
✅ Fold 2 complete. Saved: ./output/models/kfold/ConvNeXt+4cbam+kfold+dataset22+dataset22_fold2.pth

📂 Fold 3/5
🕒 Epoch 1/100 | Train Loss: 0.6849 | Val Loss: 0.4943 | Val Acc: 0.9654
💾 Best model updated (val acc: 0.9654)
🕒 Epoch 2/100 | Train Loss: 0.4761 | Val Loss: 0.5573 | Val Acc: 0.9330
🕒 Epoch 3/100 | Train Loss: 0.4496 | Val Loss: 0.4641 | Val Acc: 0.9746
💾 Best model updated (val acc: 0.9746)
🕒 Epoch 4/100 | Train Loss: 0.4372 | Val Loss: 0.4510 | Val Acc: 0.9838
💾 Best model updated (val acc: 0.9838)
🕒 Epoch 5/100 | Train Loss: 0.4340 | Val Loss: 0.4581 | Val Acc: 0.9861
🕒 Epoch 6/100 | Train Loss: 0.4398 | Val Loss: 0.5184 | Val Acc: 0.9584
🕒 Epoch 7/100 | Train Loss: 0.4305 | Val Loss: 0.4476 | Val Acc: 0.9838
💾 Best model updated (val acc: 0.9838)
🕒 Epoch 8/100 | Train Loss: 0.4222 | Val Loss: 0.4442 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 9/100 | Train Loss: 0.4216 | Val Loss: 0.4407 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 10/100 | Train Loss: 0.4215 | Val Loss: 0.4396 | Val Acc: 0.9931
💾 Best model updated (val acc: 0.9931)
🕒 Epoch 11/100 | Train Loss: 0.4214 | Val Loss: 0.4393 | Val Acc: 0.9931
💾 Best model updated (val acc: 0.9931)
🕒 Epoch 12/100 | Train Loss: 0.4214 | Val Loss: 0.4391 | Val Acc: 0.9931
💾 Best model updated (val acc: 0.9931)
🕒 Epoch 13/100 | Train Loss: 0.4213 | Val Loss: 0.4388 | Val Acc: 0.9931
💾 Best model updated (val acc: 0.9931)
🕒 Epoch 14/100 | Train Loss: 0.4213 | Val Loss: 0.4387 | Val Acc: 0.9931
💾 Best model updated (val acc: 0.9931)
🕒 Epoch 15/100 | Train Loss: 0.4213 | Val Loss: 0.4387 | Val Acc: 0.9931
💾 Best model updated (val acc: 0.9931)
🕒 Epoch 16/100 | Train Loss: 0.4213 | Val Loss: 0.4387 | Val Acc: 0.9931
💾 Best model updated (val acc: 0.9931)
🕒 Epoch 17/100 | Train Loss: 0.4213 | Val Loss: 0.4385 | Val Acc: 0.9931
💾 Best model updated (val acc: 0.9931)
🕒 Epoch 18/100 | Train Loss: 0.4212 | Val Loss: 0.4386 | Val Acc: 0.9931
🕒 Epoch 19/100 | Train Loss: 0.4212 | Val Loss: 0.4385 | Val Acc: 0.9931
💾 Best model updated (val acc: 0.9931)
🕒 Epoch 20/100 | Train Loss: 0.4212 | Val Loss: 0.4384 | Val Acc: 0.9931
💾 Best model updated (val acc: 0.9931)
🕒 Epoch 21/100 | Train Loss: 0.4212 | Val Loss: 0.4384 | Val Acc: 0.9931
🕒 Epoch 22/100 | Train Loss: 0.4212 | Val Loss: 0.4384 | Val Acc: 0.9908
🕒 Epoch 23/100 | Train Loss: 0.4212 | Val Loss: 0.4384 | Val Acc: 0.9908
🕒 Epoch 24/100 | Train Loss: 0.4212 | Val Loss: 0.4384 | Val Acc: 0.9908
🕒 Epoch 25/100 | Train Loss: 0.4212 | Val Loss: 0.4384 | Val Acc: 0.9908
🕒 Epoch 26/100 | Train Loss: 0.4212 | Val Loss: 0.4384 | Val Acc: 0.9908
🕒 Epoch 27/100 | Train Loss: 0.4212 | Val Loss: 0.4385 | Val Acc: 0.9908
🕒 Epoch 28/100 | Train Loss: 0.4212 | Val Loss: 0.4384 | Val Acc: 0.9908
🕒 Epoch 29/100 | Train Loss: 0.4212 | Val Loss: 0.4385 | Val Acc: 0.9908
🕒 Epoch 30/100 | Train Loss: 0.4212 | Val Loss: 0.4385 | Val Acc: 0.9908
⏹️ Early stopping.
✅ Fold 3 complete. Saved: ./output/models/kfold/ConvNeXt+4cbam+kfold+dataset22+dataset22_fold3.pth

📂 Fold 4/5
🕒 Epoch 1/100 | Train Loss: 0.6810 | Val Loss: 0.5507 | Val Acc: 0.9376
💾 Best model updated (val acc: 0.9376)
🕒 Epoch 2/100 | Train Loss: 0.4843 | Val Loss: 0.5742 | Val Acc: 0.9446
🕒 Epoch 3/100 | Train Loss: 0.4484 | Val Loss: 0.4592 | Val Acc: 0.9838
💾 Best model updated (val acc: 0.9838)
🕒 Epoch 4/100 | Train Loss: 0.4282 | Val Loss: 0.4635 | Val Acc: 0.9815
🕒 Epoch 5/100 | Train Loss: 0.4251 | Val Loss: 0.4568 | Val Acc: 0.9861
💾 Best model updated (val acc: 0.9861)
🕒 Epoch 6/100 | Train Loss: 0.4218 | Val Loss: 0.4571 | Val Acc: 0.9861
🕒 Epoch 7/100 | Train Loss: 0.4215 | Val Loss: 0.4572 | Val Acc: 0.9861
🕒 Epoch 8/100 | Train Loss: 0.4214 | Val Loss: 0.4575 | Val Acc: 0.9861
🕒 Epoch 9/100 | Train Loss: 0.4214 | Val Loss: 0.4582 | Val Acc: 0.9861
🕒 Epoch 10/100 | Train Loss: 0.4213 | Val Loss: 0.4582 | Val Acc: 0.9861
🕒 Epoch 11/100 | Train Loss: 0.4213 | Val Loss: 0.4584 | Val Acc: 0.9861
🕒 Epoch 12/100 | Train Loss: 0.4212 | Val Loss: 0.4587 | Val Acc: 0.9861
🕒 Epoch 13/100 | Train Loss: 0.4213 | Val Loss: 0.4589 | Val Acc: 0.9861
🕒 Epoch 14/100 | Train Loss: 0.4213 | Val Loss: 0.4591 | Val Acc: 0.9861
🕒 Epoch 15/100 | Train Loss: 0.4213 | Val Loss: 0.4593 | Val Acc: 0.9861
⏹️ Early stopping.
✅ Fold 4 complete. Saved: ./output/models/kfold/ConvNeXt+4cbam+kfold+dataset22+dataset22_fold4.pth

📂 Fold 5/5
🕒 Epoch 1/100 | Train Loss: 0.7047 | Val Loss: 0.5009 | Val Acc: 0.9654
💾 Best model updated (val acc: 0.9654)
🕒 Epoch 2/100 | Train Loss: 0.4821 | Val Loss: 0.5170 | Val Acc: 0.9584
🕒 Epoch 3/100 | Train Loss: 0.4368 | Val Loss: 0.4567 | Val Acc: 0.9815
💾 Best model updated (val acc: 0.9815)
🕒 Epoch 4/100 | Train Loss: 0.4245 | Val Loss: 0.4529 | Val Acc: 0.9861
💾 Best model updated (val acc: 0.9861)
🕒 Epoch 5/100 | Train Loss: 0.4226 | Val Loss: 0.4552 | Val Acc: 0.9838
🕒 Epoch 6/100 | Train Loss: 0.4218 | Val Loss: 0.4544 | Val Acc: 0.9861
🕒 Epoch 7/100 | Train Loss: 0.4216 | Val Loss: 0.4550 | Val Acc: 0.9838
🕒 Epoch 8/100 | Train Loss: 0.4215 | Val Loss: 0.4554 | Val Acc: 0.9838
🕒 Epoch 9/100 | Train Loss: 0.4214 | Val Loss: 0.4557 | Val Acc: 0.9838
🕒 Epoch 10/100 | Train Loss: 0.4213 | Val Loss: 0.4560 | Val Acc: 0.9838
🕒 Epoch 11/100 | Train Loss: 0.4214 | Val Loss: 0.4563 | Val Acc: 0.9838
🕒 Epoch 12/100 | Train Loss: 0.4213 | Val Loss: 0.4565 | Val Acc: 0.9838
🕒 Epoch 13/100 | Train Loss: 0.4213 | Val Loss: 0.4567 | Val Acc: 0.9838
🕒 Epoch 14/100 | Train Loss: 0.4213 | Val Loss: 0.4569 | Val Acc: 0.9838
⏹️ Early stopping.
✅ Fold 5 complete. Saved: ./output/models/kfold/ConvNeXt+4cbam+kfold+dataset22+dataset22_fold5.pth

🚀 Evaluating 5 fold models on test set

📂 Evaluating Fold 1
📊 Fold 1 Metrics:
   - Accuracy: 0.9853
   - Precision: 0.9854
   - Recall: 0.9855
   - F1 Score: 0.9854

📂 Evaluating Fold 2
📊 Fold 2 Metrics:
   - Accuracy: 0.9834
   - Precision: 0.9838
   - Recall: 0.9837
   - F1 Score: 0.9837

📂 Evaluating Fold 3
📊 Fold 3 Metrics:
   - Accuracy: 0.9890
   - Precision: 0.9891
   - Recall: 0.9892
   - F1 Score: 0.9891

📂 Evaluating Fold 4
📊 Fold 4 Metrics:
   - Accuracy: 0.9816
   - Precision: 0.9819
   - Recall: 0.9819
   - F1 Score: 0.9818

📂 Evaluating Fold 5
📊 Fold 5 Metrics:
   - Accuracy: 0.9871
   - Precision: 0.9873
   - Recall: 0.9873
   - F1 Score: 0.9873

🧾 Classification Report for ConvNeXt+4cbam+kfold+dataset22 (Majority Vote from 5 folds):

                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    1.0000    1.0000        88
           brown_spot     0.9674    0.9570    0.9622        93
              healthy     0.9894    1.0000    0.9947        93
           leaf_blast     0.9670    0.9670    0.9670        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9871       543
            macro avg     0.9873    0.9873    0.9873       543
         weighted avg     0.9871    0.9871    0.9871       543

🔢 Confusion Matrix:
 [[88  0  0  0  0  0]
 [ 0 89  1  3  0  0]
 [ 0  0 93  0  0  0]
 [ 0  3  0 88  0  0]
 [ 0  0  0  0 90  0]
 [ 0  0  0  0  0 88]]

📊 Average Metrics Across All Folds:
   - Accuracy: 0.9853
   - Precision: 0.9855
   - Recall: 0.9855
   - F1 Score: 0.9855
-----------------------------------------------------------------------------------------------------------------------Traceback (most recent call last):

✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: ConvNeXt+4cbam+dataset1]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
🕒 Epoch 1/100 | Time: 99.94s | Train Loss: 0.7424 | Val Loss: 0.5265 | Val Acc: 0.9577 | LR: 0.000100 
💾 Saving best val acc: 0.9577
🕒 Epoch 2/100 | Time: 70.56s | Train Loss: 0.5106 | Val Loss: 0.5265 | Val Acc: 0.9540 | LR: 0.000100 
💾 Saving best val acc: 0.9540
🕒 Epoch 3/100 | Time: 71.17s | Train Loss: 0.4799 | Val Loss: 0.4995 | Val Acc: 0.9669 | LR: 0.000100 
💾 Saving best val acc: 0.9669
🕒 Epoch 4/100 | Time: 71.09s | Train Loss: 0.4699 | Val Loss: 0.5269 | Val Acc: 0.9485 | LR: 0.000099 
🕒 Epoch 5/100 | Time: 71.09s | Train Loss: 0.4763 | Val Loss: 0.5152 | Val Acc: 0.9632 | LR: 0.000098 
🕒 Epoch 6/100 | Time: 71.88s | Train Loss: 0.4603 | Val Loss: 0.4885 | Val Acc: 0.9706 | LR: 0.000098 
💾 Saving best val acc: 0.9706
🕒 Epoch 7/100 | Time: 71.30s | Train Loss: 0.4375 | Val Loss: 0.5256 | Val Acc: 0.9522 | LR: 0.000097 
🕒 Epoch 8/100 | Time: 71.06s | Train Loss: 0.4481 | Val Loss: 0.4602 | Val Acc: 0.9798 | LR: 0.000095 
💾 Saving best val acc: 0.9798
🕒 Epoch 9/100 | Time: 70.90s | Train Loss: 0.4370 | Val Loss: 0.4767 | Val Acc: 0.9743 | LR: 0.000094 
🕒 Epoch 10/100 | Time: 71.40s | Train Loss: 0.4549 | Val Loss: 0.4915 | Val Acc: 0.9743 | LR: 0.000092 
🕒 Epoch 11/100 | Time: 71.46s | Train Loss: 0.4309 | Val Loss: 0.4754 | Val Acc: 0.9798 | LR: 0.000091 
🕒 Epoch 12/100 | Time: 71.13s | Train Loss: 0.4412 | Val Loss: 0.4532 | Val Acc: 0.9890 | LR: 0.000089 
💾 Saving best val acc: 0.9890
🕒 Epoch 13/100 | Time: 71.58s | Train Loss: 0.4354 | Val Loss: 0.4502 | Val Acc: 0.9853 | LR: 0.000087 
💾 Saving best val acc: 0.9853
🕒 Epoch 14/100 | Time: 71.31s | Train Loss: 0.4295 | Val Loss: 0.4583 | Val Acc: 0.9871 | LR: 0.000084 
🕒 Epoch 15/100 | Time: 70.55s | Train Loss: 0.4300 | Val Loss: 0.4587 | Val Acc: 0.9871 | LR: 0.000082 
🕒 Epoch 16/100 | Time: 71.36s | Train Loss: 0.4231 | Val Loss: 0.4577 | Val Acc: 0.9853 | LR: 0.000080 
🕒 Epoch 17/100 | Time: 70.71s | Train Loss: 0.4260 | Val Loss: 0.4843 | Val Acc: 0.9779 | LR: 0.000077 
🕒 Epoch 18/100 | Time: 71.12s | Train Loss: 0.4417 | Val Loss: 0.4864 | Val Acc: 0.9761 | LR: 0.000074 
🕒 Epoch 19/100 | Time: 71.89s | Train Loss: 0.4296 | Val Loss: 0.4698 | Val Acc: 0.9816 | LR: 0.000072 
🕒 Epoch 20/100 | Time: 71.76s | Train Loss: 0.4248 | Val Loss: 0.4731 | Val Acc: 0.9816 | LR: 0.000069 
🕒 Epoch 21/100 | Time: 71.49s | Train Loss: 0.4273 | Val Loss: 0.4759 | Val Acc: 0.9798 | LR: 0.000066 
🕒 Epoch 22/100 | Time: 71.64s | Train Loss: 0.4339 | Val Loss: 0.4837 | Val Acc: 0.9743 | LR: 0.000063 
🕒 Epoch 23/100 | Time: 71.51s | Train Loss: 0.4260 | Val Loss: 0.4543 | Val Acc: 0.9871 | LR: 0.000060 
⏹️ Early stopping triggered.
✅ Training complete in 1668.05 seconds. Best model loaded.
📁 Model saved to ./output/models/ConvNeXt+4cbam+dataset1+dataset1.pth
📂 Training metrics plot saved to: output/test/ConvNeXt+4cbam+dataset1/training metric.png

Evaluate model:ConvNeXt+4cbam+dataset1

🔥 Test Accuracy: 99.08%

📌 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    1.0000    1.0000        88
           brown_spot     0.9783    0.9677    0.9730        93
              healthy     1.0000    1.0000    1.0000        93
           leaf_blast     0.9677    0.9890    0.9783        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    0.9886    0.9943        88

             accuracy                         0.9908       543
            macro avg     0.9910    0.9909    0.9909       543
         weighted avg     0.9909    0.9908    0.9908       543

📂 Confusion matrix saved to: output/test/ConvNeXt+4cbam+dataset1/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+4cbam+dataset1/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+4cbam+dataset1/misclassified_images.png
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: ConvNeXt+dataset1]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
🕒 Epoch 1/100 | Time: 68.84s | Train Loss: 0.7694 | Val Loss: 0.5436 | Val Acc: 0.9596 | LR: 0.000100 
💾 Saving best val acc: 0.9596
🕒 Epoch 2/100 | Time: 68.55s | Train Loss: 0.4981 | Val Loss: 0.5127 | Val Acc: 0.9724 | LR: 0.000100 
💾 Saving best val acc: 0.9724
🕒 Epoch 3/100 | Time: 69.02s | Train Loss: 0.4783 | Val Loss: 0.4962 | Val Acc: 0.9706 | LR: 0.000100 
💾 Saving best val acc: 0.9706
🕒 Epoch 4/100 | Time: 68.78s | Train Loss: 0.4644 | Val Loss: 0.4942 | Val Acc: 0.9706 | LR: 0.000099 
💾 Saving best val acc: 0.9706
🕒 Epoch 5/100 | Time: 68.91s | Train Loss: 0.4490 | Val Loss: 0.4853 | Val Acc: 0.9779 | LR: 0.000098 
💾 Saving best val acc: 0.9779
🕒 Epoch 6/100 | Time: 69.52s | Train Loss: 0.4476 | Val Loss: 0.4618 | Val Acc: 0.9853 | LR: 0.000098 
💾 Saving best val acc: 0.9853
🕒 Epoch 7/100 | Time: 70.39s | Train Loss: 0.4423 | Val Loss: 0.4734 | Val Acc: 0.9816 | LR: 0.000097 
🕒 Epoch 8/100 | Time: 70.70s | Train Loss: 0.4345 | Val Loss: 0.4557 | Val Acc: 0.9890 | LR: 0.000095 
💾 Saving best val acc: 0.9890
🕒 Epoch 9/100 | Time: 70.62s | Train Loss: 0.4310 | Val Loss: 0.4621 | Val Acc: 0.9871 | LR: 0.000094 
🕒 Epoch 10/100 | Time: 70.74s | Train Loss: 0.4311 | Val Loss: 0.4737 | Val Acc: 0.9798 | LR: 0.000092 
🕒 Epoch 11/100 | Time: 70.27s | Train Loss: 0.4442 | Val Loss: 0.5675 | Val Acc: 0.9577 | LR: 0.000091 
🕒 Epoch 12/100 | Time: 71.04s | Train Loss: 0.4685 | Val Loss: 0.5239 | Val Acc: 0.9596 | LR: 0.000089 
🕒 Epoch 13/100 | Time: 71.08s | Train Loss: 0.4651 | Val Loss: 0.4721 | Val Acc: 0.9798 | LR: 0.000087 
🕒 Epoch 14/100 | Time: 70.15s | Train Loss: 0.4395 | Val Loss: 0.4712 | Val Acc: 0.9835 | LR: 0.000084 
🕒 Epoch 15/100 | Time: 70.50s | Train Loss: 0.4387 | Val Loss: 0.4701 | Val Acc: 0.9779 | LR: 0.000082 
🕒 Epoch 16/100 | Time: 70.78s | Train Loss: 0.4371 | Val Loss: 0.4825 | Val Acc: 0.9743 | LR: 0.000080 
🕒 Epoch 17/100 | Time: 70.31s | Train Loss: 0.4304 | Val Loss: 0.4705 | Val Acc: 0.9835 | LR: 0.000077 
🕒 Epoch 18/100 | Time: 69.96s | Train Loss: 0.4301 | Val Loss: 0.4649 | Val Acc: 0.9871 | LR: 0.000074 
⏹️ Early stopping triggered.
✅ Training complete in 1260.25 seconds. Best model loaded.
📁 Model saved to ./output/models/ConvNeXt+dataset1+dataset1.pth
📂 Training metrics plot saved to: output/test/ConvNeXt+dataset1/training metric.png
Evaluate model:ConvNeXt+dataset1

🔥 Test Accuracy: 98.34%

📌 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    1.0000    1.0000        88
           brown_spot     0.9474    0.9677    0.9574        93
              healthy     0.9688    1.0000    0.9841        93
           leaf_blast     0.9884    0.9341    0.9605        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9834       543
            macro avg     0.9841    0.9836    0.9837       543
         weighted avg     0.9837    0.9834    0.9834       543

📂 Confusion matrix saved to: output/test/ConvNeXt+dataset1/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+dataset1/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+dataset1/misclassified_images.png
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: ConvNeXt+1cbam_last+dataset1]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
🕒 Epoch 1/100 | Time: 69.14s | Train Loss: 0.7864 | Val Loss: 0.5911 | Val Acc: 0.9357 | LR: 0.000100 
💾 Saving best val acc: 0.9357
🕒 Epoch 2/100 | Time: 69.85s | Train Loss: 0.4980 | Val Loss: 0.5033 | Val Acc: 0.9743 | LR: 0.000100 
💾 Saving best val acc: 0.9743
🕒 Epoch 3/100 | Time: 69.78s | Train Loss: 0.4666 | Val Loss: 0.4981 | Val Acc: 0.9761 | LR: 0.000100 
💾 Saving best val acc: 0.9761
🕒 Epoch 4/100 | Time: 70.01s | Train Loss: 0.4593 | Val Loss: 0.4716 | Val Acc: 0.9798 | LR: 0.000099 
💾 Saving best val acc: 0.9798
🕒 Epoch 5/100 | Time: 69.21s | Train Loss: 0.4428 | Val Loss: 0.4882 | Val Acc: 0.9688 | LR: 0.000098 
🕒 Epoch 6/100 | Time: 69.43s | Train Loss: 0.4555 | Val Loss: 0.4771 | Val Acc: 0.9798 | LR: 0.000098 
🕒 Epoch 7/100 | Time: 70.13s | Train Loss: 0.4430 | Val Loss: 0.4748 | Val Acc: 0.9835 | LR: 0.000097 
🕒 Epoch 8/100 | Time: 71.08s | Train Loss: 0.4397 | Val Loss: 0.5016 | Val Acc: 0.9706 | LR: 0.000095 
🕒 Epoch 9/100 | Time: 71.35s | Train Loss: 0.4411 | Val Loss: 0.5249 | Val Acc: 0.9651 | LR: 0.000094 
🕒 Epoch 10/100 | Time: 70.68s | Train Loss: 0.4581 | Val Loss: 0.4803 | Val Acc: 0.9779 | LR: 0.000092 
🕒 Epoch 11/100 | Time: 70.85s | Train Loss: 0.4370 | Val Loss: 0.4726 | Val Acc: 0.9853 | LR: 0.000091 
🕒 Epoch 12/100 | Time: 70.61s | Train Loss: 0.4305 | Val Loss: 0.5043 | Val Acc: 0.9688 | LR: 0.000089 
🕒 Epoch 13/100 | Time: 70.73s | Train Loss: 0.4301 | Val Loss: 0.4945 | Val Acc: 0.9724 | LR: 0.000087 
🕒 Epoch 14/100 | Time: 71.44s | Train Loss: 0.4319 | Val Loss: 0.4663 | Val Acc: 0.9871 | LR: 0.000084 
💾 Saving best val acc: 0.9871
🕒 Epoch 15/100 | Time: 70.99s | Train Loss: 0.4251 | Val Loss: 0.4670 | Val Acc: 0.9853 | LR: 0.000082 
🕒 Epoch 16/100 | Time: 70.80s | Train Loss: 0.4305 | Val Loss: 0.4661 | Val Acc: 0.9853 | LR: 0.000080 
💾 Saving best val acc: 0.9853
🕒 Epoch 17/100 | Time: 71.03s | Train Loss: 0.4246 | Val Loss: 0.4665 | Val Acc: 0.9853 | LR: 0.000077 
🕒 Epoch 18/100 | Time: 71.21s | Train Loss: 0.4231 | Val Loss: 0.4683 | Val Acc: 0.9853 | LR: 0.000074 
🕒 Epoch 19/100 | Time: 71.24s | Train Loss: 0.4230 | Val Loss: 0.4660 | Val Acc: 0.9871 | LR: 0.000072 
💾 Saving best val acc: 0.9871
🕒 Epoch 20/100 | Time: 71.19s | Train Loss: 0.4222 | Val Loss: 0.4652 | Val Acc: 0.9871 | LR: 0.000069 
💾 Saving best val acc: 0.9871
🕒 Epoch 21/100 | Time: 70.34s | Train Loss: 0.4248 | Val Loss: 0.4724 | Val Acc: 0.9871 | LR: 0.000066 
🕒 Epoch 22/100 | Time: 71.34s | Train Loss: 0.4277 | Val Loss: 0.4725 | Val Acc: 0.9816 | LR: 0.000063 
🕒 Epoch 23/100 | Time: 70.77s | Train Loss: 0.4258 | Val Loss: 0.4651 | Val Acc: 0.9835 | LR: 0.000060 
💾 Saving best val acc: 0.9835
🕒 Epoch 24/100 | Time: 70.69s | Train Loss: 0.4229 | Val Loss: 0.4631 | Val Acc: 0.9853 | LR: 0.000057 
💾 Saving best val acc: 0.9853
🕒 Epoch 25/100 | Time: 70.80s | Train Loss: 0.4222 | Val Loss: 0.4696 | Val Acc: 0.9798 | LR: 0.000054 
🕒 Epoch 26/100 | Time: 70.56s | Train Loss: 0.4229 | Val Loss: 0.4627 | Val Acc: 0.9871 | LR: 0.000050 
💾 Saving best val acc: 0.9871
🕒 Epoch 27/100 | Time: 70.76s | Train Loss: 0.4236 | Val Loss: 0.4664 | Val Acc: 0.9798 | LR: 0.000047 
🕒 Epoch 28/100 | Time: 70.04s | Train Loss: 0.4221 | Val Loss: 0.4611 | Val Acc: 0.9816 | LR: 0.000044 
💾 Saving best val acc: 0.9816
🕒 Epoch 29/100 | Time: 69.26s | Train Loss: 0.4221 | Val Loss: 0.4607 | Val Acc: 0.9890 | LR: 0.000041 
💾 Saving best val acc: 0.9890
🕒 Epoch 30/100 | Time: 70.07s | Train Loss: 0.4251 | Val Loss: 0.4581 | Val Acc: 0.9890 | LR: 0.000038 
💾 Saving best val acc: 0.9890
🕒 Epoch 31/100 | Time: 69.98s | Train Loss: 0.4221 | Val Loss: 0.4563 | Val Acc: 0.9890 | LR: 0.000035 
💾 Saving best val acc: 0.9890
🕒 Epoch 32/100 | Time: 69.72s | Train Loss: 0.4223 | Val Loss: 0.4570 | Val Acc: 0.9871 | LR: 0.000032 
🕒 Epoch 33/100 | Time: 69.14s | Train Loss: 0.4222 | Val Loss: 0.4559 | Val Acc: 0.9890 | LR: 0.000029 
💾 Saving best val acc: 0.9890
🕒 Epoch 34/100 | Time: 71.05s | Train Loss: 0.4216 | Val Loss: 0.4547 | Val Acc: 0.9890 | LR: 0.000027 
💾 Saving best val acc: 0.9890
🕒 Epoch 35/100 | Time: 69.66s | Train Loss: 0.4214 | Val Loss: 0.4546 | Val Acc: 0.9890 | LR: 0.000024 
💾 Saving best val acc: 0.9890
🕒 Epoch 36/100 | Time: 70.54s | Train Loss: 0.4213 | Val Loss: 0.4545 | Val Acc: 0.9890 | LR: 0.000021 
💾 Saving best val acc: 0.9890
🕒 Epoch 37/100 | Time: 69.69s | Train Loss: 0.4212 | Val Loss: 0.4548 | Val Acc: 0.9890 | LR: 0.000019 
🕒 Epoch 38/100 | Time: 70.14s | Train Loss: 0.4213 | Val Loss: 0.4548 | Val Acc: 0.9853 | LR: 0.000017 
🕒 Epoch 39/100 | Time: 69.57s | Train Loss: 0.4212 | Val Loss: 0.4578 | Val Acc: 0.9871 | LR: 0.000014 
🕒 Epoch 40/100 | Time: 69.39s | Train Loss: 0.4213 | Val Loss: 0.4562 | Val Acc: 0.9871 | LR: 0.000012 
🕒 Epoch 41/100 | Time: 70.00s | Train Loss: 0.4224 | Val Loss: 0.4571 | Val Acc: 0.9890 | LR: 0.000010 
🕒 Epoch 42/100 | Time: 69.82s | Train Loss: 0.4212 | Val Loss: 0.4562 | Val Acc: 0.9890 | LR: 0.000009 
🕒 Epoch 43/100 | Time: 69.46s | Train Loss: 0.4212 | Val Loss: 0.4560 | Val Acc: 0.9890 | LR: 0.000007 
🕒 Epoch 44/100 | Time: 69.42s | Train Loss: 0.4212 | Val Loss: 0.4557 | Val Acc: 0.9890 | LR: 0.000006 
🕒 Epoch 45/100 | Time: 69.84s | Train Loss: 0.4213 | Val Loss: 0.4567 | Val Acc: 0.9890 | LR: 0.000004 
🕒 Epoch 46/100 | Time: 70.53s | Train Loss: 0.4212 | Val Loss: 0.4567 | Val Acc: 0.9890 | LR: 0.000003 
⏹️ Early stopping triggered.
✅ Training complete in 3233.68 seconds. Best model loaded.
📁 Model saved to ./output/models/ConvNeXt+1cbam_last+dataset1+dataset1.pth
📂 Training metrics plot saved to: output/test/ConvNeXt+1cbam_last+dataset1/training metric.png
Evaluate model:ConvNeXt+1cbam_last+dataset1

🔥 Test Accuracy: 98.90%

📌 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    1.0000    1.0000        88
           brown_spot     0.9677    0.9677    0.9677        93
              healthy     0.9789    1.0000    0.9894        93
           leaf_blast     0.9888    0.9670    0.9778        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9890       543
            macro avg     0.9892    0.9891    0.9891       543
         weighted avg     0.9890    0.9890    0.9889       543

📂 Confusion matrix saved to: output/test/ConvNeXt+1cbam_last+dataset1/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+1cbam_last+dataset1/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+1cbam_last+dataset1/misclassified_images.png
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: ConvNeXt+3cbam+no-res+no-norm+dataset1]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
🕒 Epoch 1/100 | Time: 69.77s | Train Loss: 0.9778 | Val Loss: 0.6641 | Val Acc: 0.9099 | LR: 0.000100 
💾 Saving best val acc: 0.9099
🕒 Epoch 2/100 | Time: 69.45s | Train Loss: 0.5950 | Val Loss: 0.6455 | Val Acc: 0.9154 | LR: 0.000100 
💾 Saving best val acc: 0.9154
🕒 Epoch 3/100 | Time: 68.92s | Train Loss: 0.5300 | Val Loss: 0.5217 | Val Acc: 0.9669 | LR: 0.000100 
💾 Saving best val acc: 0.9669
🕒 Epoch 4/100 | Time: 69.72s | Train Loss: 0.5006 | Val Loss: 0.5034 | Val Acc: 0.9688 | LR: 0.000099 
💾 Saving best val acc: 0.9688
🕒 Epoch 5/100 | Time: 69.92s | Train Loss: 0.4673 | Val Loss: 0.5094 | Val Acc: 0.9596 | LR: 0.000098 
🕒 Epoch 6/100 | Time: 69.75s | Train Loss: 0.4743 | Val Loss: 0.5074 | Val Acc: 0.9706 | LR: 0.000098 
🕒 Epoch 7/100 | Time: 69.85s | Train Loss: 0.4660 | Val Loss: 0.4781 | Val Acc: 0.9779 | LR: 0.000097 
💾 Saving best val acc: 0.9779
🕒 Epoch 8/100 | Time: 69.21s | Train Loss: 0.4376 | Val Loss: 0.4729 | Val Acc: 0.9835 | LR: 0.000095 
💾 Saving best val acc: 0.9835
🕒 Epoch 9/100 | Time: 69.14s | Train Loss: 0.4392 | Val Loss: 0.4853 | Val Acc: 0.9798 | LR: 0.000094 
🕒 Epoch 10/100 | Time: 69.14s | Train Loss: 0.4809 | Val Loss: 0.4970 | Val Acc: 0.9669 | LR: 0.000092 
🕒 Epoch 11/100 | Time: 70.24s | Train Loss: 0.4694 | Val Loss: 0.5442 | Val Acc: 0.9504 | LR: 0.000091 
🕒 Epoch 12/100 | Time: 70.30s | Train Loss: 0.4629 | Val Loss: 0.4654 | Val Acc: 0.9871 | LR: 0.000089 
💾 Saving best val acc: 0.9871
🕒 Epoch 13/100 | Time: 70.58s | Train Loss: 0.4492 | Val Loss: 0.4950 | Val Acc: 0.9706 | LR: 0.000087 
🕒 Epoch 14/100 | Time: 70.66s | Train Loss: 0.4390 | Val Loss: 0.4744 | Val Acc: 0.9835 | LR: 0.000084 
🕒 Epoch 15/100 | Time: 70.69s | Train Loss: 0.4521 | Val Loss: 0.5079 | Val Acc: 0.9614 | LR: 0.000082 
🕒 Epoch 16/100 | Time: 70.25s | Train Loss: 0.4380 | Val Loss: 0.4888 | Val Acc: 0.9743 | LR: 0.000080 
🕒 Epoch 17/100 | Time: 70.99s | Train Loss: 0.4408 | Val Loss: 0.4897 | Val Acc: 0.9724 | LR: 0.000077 
🕒 Epoch 18/100 | Time: 70.09s | Train Loss: 0.4362 | Val Loss: 0.4833 | Val Acc: 0.9816 | LR: 0.000074 
🕒 Epoch 19/100 | Time: 74.07s | Train Loss: 0.4447 | Val Loss: 0.5115 | Val Acc: 0.9669 | LR: 0.000072 
🕒 Epoch 20/100 | Time: 94.35s | Train Loss: 0.4336 | Val Loss: 0.4584 | Val Acc: 0.9853 | LR: 0.000069 
💾 Saving best val acc: 0.9853
🕒 Epoch 21/100 | Time: 94.08s | Train Loss: 0.4327 | Val Loss: 0.4539 | Val Acc: 0.9890 | LR: 0.000066 
💾 Saving best val acc: 0.9890
🕒 Epoch 22/100 | Time: 95.07s | Train Loss: 0.4253 | Val Loss: 0.4594 | Val Acc: 0.9871 | LR: 0.000063 
🕒 Epoch 23/100 | Time: 88.86s | Train Loss: 0.4291 | Val Loss: 0.4582 | Val Acc: 0.9871 | LR: 0.000060 
🕒 Epoch 24/100 | Time: 71.38s | Train Loss: 0.4244 | Val Loss: 0.4574 | Val Acc: 0.9871 | LR: 0.000057 
🕒 Epoch 25/100 | Time: 70.54s | Train Loss: 0.4263 | Val Loss: 0.4572 | Val Acc: 0.9871 | LR: 0.000054 
🕒 Epoch 26/100 | Time: 70.69s | Train Loss: 0.4243 | Val Loss: 0.4552 | Val Acc: 0.9890 | LR: 0.000050 
🕒 Epoch 27/100 | Time: 70.68s | Train Loss: 0.4227 | Val Loss: 0.4534 | Val Acc: 0.9890 | LR: 0.000047 
💾 Saving best val acc: 0.9890
🕒 Epoch 28/100 | Time: 71.23s | Train Loss: 0.4223 | Val Loss: 0.4519 | Val Acc: 0.9890 | LR: 0.000044 
💾 Saving best val acc: 0.9890
🕒 Epoch 29/100 | Time: 70.90s | Train Loss: 0.4242 | Val Loss: 0.4565 | Val Acc: 0.9890 | LR: 0.000041 
🕒 Epoch 30/100 | Time: 70.11s | Train Loss: 0.4250 | Val Loss: 0.4531 | Val Acc: 0.9871 | LR: 0.000038 
🕒 Epoch 31/100 | Time: 70.64s | Train Loss: 0.4227 | Val Loss: 0.4542 | Val Acc: 0.9871 | LR: 0.000035 
🕒 Epoch 32/100 | Time: 71.22s | Train Loss: 0.4225 | Val Loss: 0.4520 | Val Acc: 0.9908 | LR: 0.000032 
🕒 Epoch 33/100 | Time: 71.46s | Train Loss: 0.4227 | Val Loss: 0.4720 | Val Acc: 0.9835 | LR: 0.000029 
🕒 Epoch 34/100 | Time: 70.11s | Train Loss: 0.4225 | Val Loss: 0.4608 | Val Acc: 0.9871 | LR: 0.000027 
🕒 Epoch 35/100 | Time: 71.17s | Train Loss: 0.4220 | Val Loss: 0.4618 | Val Acc: 0.9853 | LR: 0.000024 
🕒 Epoch 36/100 | Time: 71.21s | Train Loss: 0.4219 | Val Loss: 0.4593 | Val Acc: 0.9871 | LR: 0.000021 
🕒 Epoch 37/100 | Time: 71.31s | Train Loss: 0.4219 | Val Loss: 0.4643 | Val Acc: 0.9835 | LR: 0.000019 
🕒 Epoch 38/100 | Time: 71.17s | Train Loss: 0.4215 | Val Loss: 0.4629 | Val Acc: 0.9835 | LR: 0.000017 
⏹️ Early stopping triggered.
✅ Training complete in 2769.07 seconds. Best model loaded.
📁 Model saved to ./output/models/ConvNeXt+3cbam+no-res+no-norm+dataset1+dataset1.pth
📂 Training metrics plot saved to: output/test/ConvNeXt+3cbam+no-res+no-norm+dataset1/training metric.png
Evaluate model:ConvNeXt+3cbam+no-res+no-norm+dataset1

🔥 Test Accuracy: 98.90%

📌 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    0.9886    0.9943        88
           brown_spot     0.9889    0.9570    0.9727        93
              healthy     0.9789    1.0000    0.9894        93
           leaf_blast     0.9677    0.9890    0.9783        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9890       543
            macro avg     0.9893    0.9891    0.9891       543
         weighted avg     0.9891    0.9890    0.9889       543

📂 Confusion matrix saved to: output/test/ConvNeXt+3cbam+no-res+no-norm+dataset1/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+3cbam+no-res+no-norm+dataset1/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+3cbam+no-res+no-norm+dataset1/misclassified_images.png
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: ConvNeXt+last_cbam+res+norm+dataset1]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
🕒 Epoch 1/100 | Time: 68.85s | Train Loss: 0.8027 | Val Loss: 0.5549 | Val Acc: 0.9449 | LR: 0.000100 
💾 Saving best val acc: 0.9449
🕒 Epoch 2/100 | Time: 69.52s | Train Loss: 0.5002 | Val Loss: 0.4923 | Val Acc: 0.9724 | LR: 0.000100 
💾 Saving best val acc: 0.9724
🕒 Epoch 3/100 | Time: 69.50s | Train Loss: 0.4830 | Val Loss: 0.4783 | Val Acc: 0.9779 | LR: 0.000100 
💾 Saving best val acc: 0.9779
🕒 Epoch 4/100 | Time: 69.27s | Train Loss: 0.4561 | Val Loss: 0.4715 | Val Acc: 0.9835 | LR: 0.000099 
💾 Saving best val acc: 0.9835
🕒 Epoch 5/100 | Time: 69.04s | Train Loss: 0.4585 | Val Loss: 0.4793 | Val Acc: 0.9816 | LR: 0.000098 
🕒 Epoch 6/100 | Time: 68.72s | Train Loss: 0.4462 | Val Loss: 0.5216 | Val Acc: 0.9577 | LR: 0.000098 
🕒 Epoch 7/100 | Time: 68.90s | Train Loss: 0.4461 | Val Loss: 0.4710 | Val Acc: 0.9853 | LR: 0.000097 
💾 Saving best val acc: 0.9853
🕒 Epoch 8/100 | Time: 70.37s | Train Loss: 0.4456 | Val Loss: 0.4711 | Val Acc: 0.9798 | LR: 0.000095 
🕒 Epoch 9/100 | Time: 69.07s | Train Loss: 0.4453 | Val Loss: 0.4646 | Val Acc: 0.9798 | LR: 0.000094 
💾 Saving best val acc: 0.9798
🕒 Epoch 10/100 | Time: 70.86s | Train Loss: 0.4333 | Val Loss: 0.4669 | Val Acc: 0.9816 | LR: 0.000092 
🕒 Epoch 11/100 | Time: 70.20s | Train Loss: 0.4345 | Val Loss: 0.4671 | Val Acc: 0.9853 | LR: 0.000091 
🕒 Epoch 12/100 | Time: 70.31s | Train Loss: 0.4563 | Val Loss: 0.5003 | Val Acc: 0.9743 | LR: 0.000089 
🕒 Epoch 13/100 | Time: 69.52s | Train Loss: 0.4481 | Val Loss: 0.4767 | Val Acc: 0.9743 | LR: 0.000087 
🕒 Epoch 14/100 | Time: 69.38s | Train Loss: 0.4390 | Val Loss: 0.4720 | Val Acc: 0.9779 | LR: 0.000084 
🕒 Epoch 15/100 | Time: 70.20s | Train Loss: 0.4329 | Val Loss: 0.4742 | Val Acc: 0.9798 | LR: 0.000082 
🕒 Epoch 16/100 | Time: 69.90s | Train Loss: 0.4315 | Val Loss: 0.4651 | Val Acc: 0.9853 | LR: 0.000080 
🕒 Epoch 17/100 | Time: 69.98s | Train Loss: 0.4281 | Val Loss: 0.4526 | Val Acc: 0.9871 | LR: 0.000077 
💾 Saving best val acc: 0.9871
🕒 Epoch 18/100 | Time: 69.58s | Train Loss: 0.4229 | Val Loss: 0.4512 | Val Acc: 0.9871 | LR: 0.000074 
💾 Saving best val acc: 0.9871
🕒 Epoch 19/100 | Time: 70.57s | Train Loss: 0.4228 | Val Loss: 0.4516 | Val Acc: 0.9890 | LR: 0.000072 
🕒 Epoch 20/100 | Time: 69.81s | Train Loss: 0.4255 | Val Loss: 0.4858 | Val Acc: 0.9743 | LR: 0.000069 
🕒 Epoch 21/100 | Time: 69.69s | Train Loss: 0.4290 | Val Loss: 0.4601 | Val Acc: 0.9835 | LR: 0.000066 
🕒 Epoch 22/100 | Time: 70.55s | Train Loss: 0.4390 | Val Loss: 0.4812 | Val Acc: 0.9724 | LR: 0.000063 
🕒 Epoch 23/100 | Time: 69.54s | Train Loss: 0.4262 | Val Loss: 0.4537 | Val Acc: 0.9853 | LR: 0.000060 
🕒 Epoch 24/100 | Time: 70.43s | Train Loss: 0.4224 | Val Loss: 0.4619 | Val Acc: 0.9835 | LR: 0.000057 
🕒 Epoch 25/100 | Time: 69.08s | Train Loss: 0.4229 | Val Loss: 0.4573 | Val Acc: 0.9835 | LR: 0.000054 
🕒 Epoch 26/100 | Time: 68.82s | Train Loss: 0.4225 | Val Loss: 0.4528 | Val Acc: 0.9890 | LR: 0.000050 
🕒 Epoch 27/100 | Time: 70.01s | Train Loss: 0.4242 | Val Loss: 0.4716 | Val Acc: 0.9761 | LR: 0.000047 
🕒 Epoch 28/100 | Time: 70.46s | Train Loss: 0.4222 | Val Loss: 0.4668 | Val Acc: 0.9798 | LR: 0.000044 
⏹️ Early stopping triggered.
✅ Training complete in 1952.29 seconds. Best model loaded.
📁 Model saved to ./output/models/ConvNeXt+last_cbam+res+norm+dataset1+dataset1.pth
📂 Training metrics plot saved to: output/test/ConvNeXt+last_cbam+res+norm+dataset1/training metric.png
Evaluate model:ConvNeXt+last_cbam+res+norm+dataset1

🔥 Test Accuracy: 98.71%

📌 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    1.0000    1.0000        88
           brown_spot     0.9674    0.9570    0.9622        93
              healthy     0.9789    1.0000    0.9894        93
           leaf_blast     0.9778    0.9670    0.9724        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9871       543
            macro avg     0.9874    0.9873    0.9873       543
         weighted avg     0.9871    0.9871    0.9871       543

📂 Confusion matrix saved to: output/test/ConvNeXt+last_cbam+res+norm+dataset1/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+last_cbam+res+norm+dataset1/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+last_cbam+res+norm+dataset1/misclassified_images.png
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: ConvNeXt+4cbam+res+dataset1]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
🕒 Epoch 1/100 | Time: 70.64s | Train Loss: 0.7993 | Val Loss: 0.5322 | Val Acc: 0.9540 | LR: 0.000100 
💾 Saving best val acc: 0.9540
🕒 Epoch 2/100 | Time: 70.17s | Train Loss: 0.5219 | Val Loss: 0.5522 | Val Acc: 0.9540 | LR: 0.000100 
🕒 Epoch 3/100 | Time: 69.48s | Train Loss: 0.4736 | Val Loss: 0.4975 | Val Acc: 0.9779 | LR: 0.000100 
💾 Saving best val acc: 0.9779
🕒 Epoch 4/100 | Time: 71.01s | Train Loss: 0.4651 | Val Loss: 0.4802 | Val Acc: 0.9743 | LR: 0.000099 
💾 Saving best val acc: 0.9743
🕒 Epoch 5/100 | Time: 70.41s | Train Loss: 0.4462 | Val Loss: 0.4748 | Val Acc: 0.9798 | LR: 0.000098 
💾 Saving best val acc: 0.9798
🕒 Epoch 6/100 | Time: 71.28s | Train Loss: 0.4521 | Val Loss: 0.4738 | Val Acc: 0.9853 | LR: 0.000098 
💾 Saving best val acc: 0.9853
🕒 Epoch 7/100 | Time: 70.88s | Train Loss: 0.4392 | Val Loss: 0.4733 | Val Acc: 0.9798 | LR: 0.000097 
💾 Saving best val acc: 0.9798
🕒 Epoch 8/100 | Time: 70.58s | Train Loss: 0.4345 | Val Loss: 0.4765 | Val Acc: 0.9798 | LR: 0.000095 
🕒 Epoch 9/100 | Time: 71.34s | Train Loss: 0.4493 | Val Loss: 0.4913 | Val Acc: 0.9706 | LR: 0.000094 
🕒 Epoch 10/100 | Time: 70.09s | Train Loss: 0.4661 | Val Loss: 0.5047 | Val Acc: 0.9669 | LR: 0.000092 
🕒 Epoch 11/100 | Time: 70.89s | Train Loss: 0.4629 | Val Loss: 0.4681 | Val Acc: 0.9871 | LR: 0.000091 
💾 Saving best val acc: 0.9871
🕒 Epoch 12/100 | Time: 71.60s | Train Loss: 0.4532 | Val Loss: 0.4811 | Val Acc: 0.9835 | LR: 0.000089 
🕒 Epoch 13/100 | Time: 70.68s | Train Loss: 0.4383 | Val Loss: 0.4817 | Val Acc: 0.9724 | LR: 0.000087 
🕒 Epoch 14/100 | Time: 70.79s | Train Loss: 0.4318 | Val Loss: 0.4590 | Val Acc: 0.9871 | LR: 0.000084 
💾 Saving best val acc: 0.9871
🕒 Epoch 15/100 | Time: 70.95s | Train Loss: 0.4334 | Val Loss: 0.4769 | Val Acc: 0.9779 | LR: 0.000082 
🕒 Epoch 16/100 | Time: 70.43s | Train Loss: 0.4267 | Val Loss: 0.4693 | Val Acc: 0.9816 | LR: 0.000080 
🕒 Epoch 17/100 | Time: 70.79s | Train Loss: 0.4299 | Val Loss: 0.4860 | Val Acc: 0.9761 | LR: 0.000077 
🕒 Epoch 18/100 | Time: 70.94s | Train Loss: 0.4260 | Val Loss: 0.4670 | Val Acc: 0.9835 | LR: 0.000074 
🕒 Epoch 19/100 | Time: 70.38s | Train Loss: 0.4378 | Val Loss: 0.5161 | Val Acc: 0.9651 | LR: 0.000072 
🕒 Epoch 20/100 | Time: 70.79s | Train Loss: 0.4300 | Val Loss: 0.4686 | Val Acc: 0.9853 | LR: 0.000069 
🕒 Epoch 21/100 | Time: 70.84s | Train Loss: 0.4262 | Val Loss: 0.4624 | Val Acc: 0.9853 | LR: 0.000066 
🕒 Epoch 22/100 | Time: 71.19s | Train Loss: 0.4321 | Val Loss: 0.4641 | Val Acc: 0.9835 | LR: 0.000063 
🕒 Epoch 23/100 | Time: 71.87s | Train Loss: 0.4260 | Val Loss: 0.4600 | Val Acc: 0.9853 | LR: 0.000060 
🕒 Epoch 24/100 | Time: 71.13s | Train Loss: 0.4225 | Val Loss: 0.4604 | Val Acc: 0.9853 | LR: 0.000057 
⏹️ Early stopping triggered.
✅ Training complete in 1699.28 seconds. Best model loaded.
📁 Model saved to ./output/models/ConvNeXt+4cbam+res+dataset1+dataset1.pth
📂 Training metrics plot saved to: output/test/ConvNeXt+4cbam+res+dataset1/training metric.png
Evaluate model:ConvNeXt+4cbam+res+dataset1

🔥 Test Accuracy: 98.16%

📌 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    0.9886    0.9943        88
           brown_spot     0.9884    0.9140    0.9497        93
              healthy     0.9688    1.0000    0.9841        93
           leaf_blast     0.9375    0.9890    0.9626        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9816       543
            macro avg     0.9824    0.9819    0.9818       543
         weighted avg     0.9822    0.9816    0.9815       543

📂 Confusion matrix saved to: output/test/ConvNeXt+4cbam+res+dataset1/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+4cbam+res+dataset1/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+4cbam+res+dataset1/misclassified_images.png
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: ConvNeXt+4cbam+res+last-norm+dataset1]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
🕒 Epoch 1/100 | Time: 69.38s | Train Loss: 0.7487 | Val Loss: 0.5258 | Val Acc: 0.9632 | LR: 0.000100 
💾 Saving best val acc: 0.9632
🕒 Epoch 2/100 | Time: 69.63s | Train Loss: 0.5181 | Val Loss: 0.5511 | Val Acc: 0.9449 | LR: 0.000100 
🕒 Epoch 3/100 | Time: 71.42s | Train Loss: 0.4903 | Val Loss: 0.4744 | Val Acc: 0.9779 | LR: 0.000100 
💾 Saving best val acc: 0.9779
🕒 Epoch 4/100 | Time: 71.28s | Train Loss: 0.4713 | Val Loss: 0.4723 | Val Acc: 0.9816 | LR: 0.000099 
💾 Saving best val acc: 0.9816
🕒 Epoch 5/100 | Time: 71.17s | Train Loss: 0.4456 | Val Loss: 0.5064 | Val Acc: 0.9614 | LR: 0.000098 
🕒 Epoch 6/100 | Time: 69.91s | Train Loss: 0.4448 | Val Loss: 0.4747 | Val Acc: 0.9798 | LR: 0.000098 
🕒 Epoch 7/100 | Time: 70.75s | Train Loss: 0.4405 | Val Loss: 0.4663 | Val Acc: 0.9835 | LR: 0.000097 
💾 Saving best val acc: 0.9835
🕒 Epoch 8/100 | Time: 70.51s | Train Loss: 0.4304 | Val Loss: 0.4604 | Val Acc: 0.9835 | LR: 0.000095 
💾 Saving best val acc: 0.9835
🕒 Epoch 9/100 | Time: 70.62s | Train Loss: 0.4509 | Val Loss: 0.4752 | Val Acc: 0.9724 | LR: 0.000094 
🕒 Epoch 10/100 | Time: 70.84s | Train Loss: 0.4344 | Val Loss: 0.4769 | Val Acc: 0.9798 | LR: 0.000092 
🕒 Epoch 11/100 | Time: 70.50s | Train Loss: 0.4380 | Val Loss: 0.4845 | Val Acc: 0.9779 | LR: 0.000091 
🕒 Epoch 12/100 | Time: 71.65s | Train Loss: 0.4379 | Val Loss: 0.4747 | Val Acc: 0.9798 | LR: 0.000089 
🕒 Epoch 13/100 | Time: 72.11s | Train Loss: 0.4417 | Val Loss: 0.4884 | Val Acc: 0.9706 | LR: 0.000087 
🕒 Epoch 14/100 | Time: 70.31s | Train Loss: 0.4592 | Val Loss: 0.5189 | Val Acc: 0.9596 | LR: 0.000084 
🕒 Epoch 15/100 | Time: 71.55s | Train Loss: 0.4409 | Val Loss: 0.4650 | Val Acc: 0.9816 | LR: 0.000082 
🕒 Epoch 16/100 | Time: 71.81s | Train Loss: 0.4348 | Val Loss: 0.4628 | Val Acc: 0.9853 | LR: 0.000080 
🕒 Epoch 17/100 | Time: 70.94s | Train Loss: 0.4255 | Val Loss: 0.4614 | Val Acc: 0.9853 | LR: 0.000077 
🕒 Epoch 18/100 | Time: 70.80s | Train Loss: 0.4236 | Val Loss: 0.4571 | Val Acc: 0.9853 | LR: 0.000074 
💾 Saving best val acc: 0.9853
🕒 Epoch 19/100 | Time: 71.73s | Train Loss: 0.4273 | Val Loss: 0.4661 | Val Acc: 0.9835 | LR: 0.000072 
🕒 Epoch 20/100 | Time: 70.92s | Train Loss: 0.4223 | Val Loss: 0.4652 | Val Acc: 0.9835 | LR: 0.000069 
🕒 Epoch 21/100 | Time: 70.97s | Train Loss: 0.4233 | Val Loss: 0.4636 | Val Acc: 0.9835 | LR: 0.000066 
🕒 Epoch 22/100 | Time: 70.20s | Train Loss: 0.4237 | Val Loss: 0.4583 | Val Acc: 0.9853 | LR: 0.000063 
🕒 Epoch 23/100 | Time: 69.32s | Train Loss: 0.4314 | Val Loss: 0.4663 | Val Acc: 0.9816 | LR: 0.000060 
🕒 Epoch 24/100 | Time: 70.44s | Train Loss: 0.4254 | Val Loss: 0.4630 | Val Acc: 0.9871 | LR: 0.000057 
🕒 Epoch 25/100 | Time: 70.24s | Train Loss: 0.4252 | Val Loss: 0.4563 | Val Acc: 0.9890 | LR: 0.000054 
💾 Saving best val acc: 0.9890
🕒 Epoch 26/100 | Time: 71.01s | Train Loss: 0.4247 | Val Loss: 0.4603 | Val Acc: 0.9871 | LR: 0.000050 
🕒 Epoch 27/100 | Time: 70.17s | Train Loss: 0.4225 | Val Loss: 0.4636 | Val Acc: 0.9871 | LR: 0.000047 
🕒 Epoch 28/100 | Time: 71.20s | Train Loss: 0.4313 | Val Loss: 0.4736 | Val Acc: 0.9835 | LR: 0.000044 
🕒 Epoch 29/100 | Time: 70.87s | Train Loss: 0.4236 | Val Loss: 0.4618 | Val Acc: 0.9871 | LR: 0.000041 
🕒 Epoch 30/100 | Time: 71.32s | Train Loss: 0.4220 | Val Loss: 0.4573 | Val Acc: 0.9871 | LR: 0.000038 
🕒 Epoch 31/100 | Time: 71.69s | Train Loss: 0.4214 | Val Loss: 0.4558 | Val Acc: 0.9890 | LR: 0.000035 
💾 Saving best val acc: 0.9890
🕒 Epoch 32/100 | Time: 71.17s | Train Loss: 0.4231 | Val Loss: 0.4562 | Val Acc: 0.9890 | LR: 0.000032 
🕒 Epoch 33/100 | Time: 70.95s | Train Loss: 0.4225 | Val Loss: 0.4607 | Val Acc: 0.9853 | LR: 0.000029 
🕒 Epoch 34/100 | Time: 71.21s | Train Loss: 0.4308 | Val Loss: 0.4631 | Val Acc: 0.9798 | LR: 0.000027 
🕒 Epoch 35/100 | Time: 71.10s | Train Loss: 0.4234 | Val Loss: 0.4634 | Val Acc: 0.9816 | LR: 0.000024 
🕒 Epoch 36/100 | Time: 71.00s | Train Loss: 0.4233 | Val Loss: 0.4565 | Val Acc: 0.9853 | LR: 0.000021 
🕒 Epoch 37/100 | Time: 70.92s | Train Loss: 0.4231 | Val Loss: 0.4564 | Val Acc: 0.9890 | LR: 0.000019 
🕒 Epoch 38/100 | Time: 70.87s | Train Loss: 0.4233 | Val Loss: 0.4648 | Val Acc: 0.9835 | LR: 0.000017 
🕒 Epoch 39/100 | Time: 71.32s | Train Loss: 0.4216 | Val Loss: 0.4607 | Val Acc: 0.9871 | LR: 0.000014 
🕒 Epoch 40/100 | Time: 70.10s | Train Loss: 0.4220 | Val Loss: 0.4584 | Val Acc: 0.9835 | LR: 0.000012 
🕒 Epoch 41/100 | Time: 70.47s | Train Loss: 0.4219 | Val Loss: 0.4685 | Val Acc: 0.9798 | LR: 0.000010 
⏹️ Early stopping triggered.
✅ Training complete in 2904.49 seconds. Best model loaded.
📁 Model saved to ./output/models/ConvNeXt+4cbam+res+last-norm+dataset1+dataset1.pth
📂 Training metrics plot saved to: output/test/ConvNeXt+4cbam+res+last-norm+dataset1/training metric.png
Evaluate model:ConvNeXt+4cbam+res+last-norm+dataset1

🔥 Test Accuracy: 98.53%

📌 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    0.9886    0.9943        88
           brown_spot     0.9674    0.9570    0.9622        93
              healthy     0.9688    1.0000    0.9841        93
           leaf_blast     0.9778    0.9670    0.9724        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9853       543
            macro avg     0.9857    0.9854    0.9855       543
         weighted avg     0.9853    0.9853    0.9852       543

📂 Confusion matrix saved to: output/test/ConvNeXt+4cbam+res+last-norm+dataset1/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+4cbam+res+last-norm+dataset1/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+4cbam+res+last-norm+dataset1/misclassified_images.png


Traceback (most recent call last):
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/train.py", line 11, in <module>
    from load_data import get_kfold_loaders, num_classes  # ✅ using new loader function
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ImportError: cannot import name 'get_kfold_loaders' from 'load_data' (/media/data3/users/datlht/Rice_leaf_disease_detection/load_data.py)
🚀 Starting training with 5-Fold Cross-Validation for model: ConvNeXt+4cbam+dataset1
/media/data3/users/datlht/Rice_leaf_disease_detection/load_data.py:78: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/media/data3/users/datlht/Rice_leaf_disease_detection/load_data.py:81: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from font(s) DejaVu Sans.
  plt.savefig(plot_path)
✅ Saved fold class distribution plot to: output/fold_class_distribution.png

📂 Fold 1/5
🕒 Epoch 1/100 | Train Loss: 0.7662 | Val Loss: 0.5814 | Val Acc: 0.9385
💾 Best model updated (val acc: 0.9385)
🕒 Epoch 2/100 | Train Loss: 0.4880 | Val Loss: 0.5168 | Val Acc: 0.9446
💾 Best model updated (val acc: 0.9446)
🕒 Epoch 3/100 | Train Loss: 0.4353 | Val Loss: 0.4679 | Val Acc: 0.9815
💾 Best model updated (val acc: 0.9815)
🕒 Epoch 4/100 | Train Loss: 0.4326 | Val Loss: 0.4380 | Val Acc: 0.9969
💾 Best model updated (val acc: 0.9969)
🕒 Epoch 5/100 | Train Loss: 0.4230 | Val Loss: 0.4484 | Val Acc: 0.9846
🕒 Epoch 6/100 | Train Loss: 0.4219 | Val Loss: 0.4477 | Val Acc: 0.9877
🕒 Epoch 7/100 | Train Loss: 0.4217 | Val Loss: 0.4481 | Val Acc: 0.9877
🕒 Epoch 8/100 | Train Loss: 0.4217 | Val Loss: 0.4491 | Val Acc: 0.9877
🕒 Epoch 9/100 | Train Loss: 0.4214 | Val Loss: 0.4492 | Val Acc: 0.9846
🕒 Epoch 10/100 | Train Loss: 0.4214 | Val Loss: 0.4499 | Val Acc: 0.9846
🕒 Epoch 11/100 | Train Loss: 0.4215 | Val Loss: 0.4509 | Val Acc: 0.9846
🕒 Epoch 12/100 | Train Loss: 0.4213 | Val Loss: 0.4519 | Val Acc: 0.9846
🕒 Epoch 13/100 | Train Loss: 0.4214 | Val Loss: 0.4522 | Val Acc: 0.9846
🕒 Epoch 14/100 | Train Loss: 0.4212 | Val Loss: 0.4527 | Val Acc: 0.9846
⏹️ Early stopping.
✅ Fold 1 complete. Saved: ./output/models/ConvNeXt+4cbam+dataset1+dataset1_fold1.pth

📂 Fold 2/5
🕒 Epoch 1/100 | Train Loss: 0.7506 | Val Loss: 0.5050 | Val Acc: 0.9723
💾 Best model updated (val acc: 0.9723)
🕒 Epoch 2/100 | Train Loss: 0.4821 | Val Loss: 0.5232 | Val Acc: 0.9538
🕒 Epoch 3/100 | Train Loss: 0.4651 | Val Loss: 0.5118 | Val Acc: 0.9569
🕒 Epoch 4/100 | Train Loss: 0.4371 | Val Loss: 0.4761 | Val Acc: 0.9815
💾 Best model updated (val acc: 0.9815)
🕒 Epoch 5/100 | Train Loss: 0.4326 | Val Loss: 0.4543 | Val Acc: 0.9877
💾 Best model updated (val acc: 0.9877)
🕒 Epoch 6/100 | Train Loss: 0.4265 | Val Loss: 0.5085 | Val Acc: 0.9631
🕒 Epoch 7/100 | Train Loss: 0.4390 | Val Loss: 0.4640 | Val Acc: 0.9815
🕒 Epoch 8/100 | Train Loss: 0.4342 | Val Loss: 0.5517 | Val Acc: 0.9415
🕒 Epoch 9/100 | Train Loss: 0.4534 | Val Loss: 0.4557 | Val Acc: 0.9815
🕒 Epoch 10/100 | Train Loss: 0.4250 | Val Loss: 0.4488 | Val Acc: 0.9846
💾 Best model updated (val acc: 0.9846)
🕒 Epoch 11/100 | Train Loss: 0.4229 | Val Loss: 0.4569 | Val Acc: 0.9846
🕒 Epoch 12/100 | Train Loss: 0.4218 | Val Loss: 0.4563 | Val Acc: 0.9846
🕒 Epoch 13/100 | Train Loss: 0.4215 | Val Loss: 0.4558 | Val Acc: 0.9846
🕒 Epoch 14/100 | Train Loss: 0.4216 | Val Loss: 0.4557 | Val Acc: 0.9846
🕒 Epoch 15/100 | Train Loss: 0.4213 | Val Loss: 0.4555 | Val Acc: 0.9846
🕒 Epoch 16/100 | Train Loss: 0.4214 | Val Loss: 0.4554 | Val Acc: 0.9846
🕒 Epoch 17/100 | Train Loss: 0.4214 | Val Loss: 0.4555 | Val Acc: 0.9846
🕒 Epoch 18/100 | Train Loss: 0.4213 | Val Loss: 0.4556 | Val Acc: 0.9846
🕒 Epoch 19/100 | Train Loss: 0.4214 | Val Loss: 0.4556 | Val Acc: 0.9846
🕒 Epoch 20/100 | Train Loss: 0.4213 | Val Loss: 0.4555 | Val Acc: 0.9846
⏹️ Early stopping.
✅ Fold 2 complete. Saved: ./output/models/ConvNeXt+4cbam+dataset1+dataset1_fold2.pth

📂 Fold 3/5
🕒 Epoch 1/100 | Train Loss: 0.7834 | Val Loss: 0.6012 | Val Acc: 0.9385
💾 Best model updated (val acc: 0.9385)
🕒 Epoch 2/100 | Train Loss: 0.4840 | Val Loss: 0.4720 | Val Acc: 0.9723
💾 Best model updated (val acc: 0.9723)
🕒 Epoch 3/100 | Train Loss: 0.4476 | Val Loss: 0.5106 | Val Acc: 0.9569
🕒 Epoch 4/100 | Train Loss: 0.4361 | Val Loss: 0.4861 | Val Acc: 0.9754
🕒 Epoch 5/100 | Train Loss: 0.4349 | Val Loss: 0.4705 | Val Acc: 0.9846
💾 Best model updated (val acc: 0.9846)
🕒 Epoch 6/100 | Train Loss: 0.4270 | Val Loss: 0.4880 | Val Acc: 0.9754
🕒 Epoch 7/100 | Train Loss: 0.4231 | Val Loss: 0.4485 | Val Acc: 0.9846
💾 Best model updated (val acc: 0.9846)
🕒 Epoch 8/100 | Train Loss: 0.4219 | Val Loss: 0.4472 | Val Acc: 0.9877
💾 Best model updated (val acc: 0.9877)
🕒 Epoch 9/100 | Train Loss: 0.4214 | Val Loss: 0.4468 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 10/100 | Train Loss: 0.4214 | Val Loss: 0.4467 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 11/100 | Train Loss: 0.4214 | Val Loss: 0.4466 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 12/100 | Train Loss: 0.4214 | Val Loss: 0.4465 | Val Acc: 0.9877
💾 Best model updated (val acc: 0.9877)
🕒 Epoch 13/100 | Train Loss: 0.4212 | Val Loss: 0.4467 | Val Acc: 0.9877
🕒 Epoch 14/100 | Train Loss: 0.4213 | Val Loss: 0.4468 | Val Acc: 0.9877
🕒 Epoch 15/100 | Train Loss: 0.4212 | Val Loss: 0.4468 | Val Acc: 0.9877
🕒 Epoch 16/100 | Train Loss: 0.4214 | Val Loss: 0.4466 | Val Acc: 0.9877
🕒 Epoch 17/100 | Train Loss: 0.4213 | Val Loss: 0.4468 | Val Acc: 0.9877
🕒 Epoch 18/100 | Train Loss: 0.4212 | Val Loss: 0.4467 | Val Acc: 0.9877
🕒 Epoch 19/100 | Train Loss: 0.4212 | Val Loss: 0.4468 | Val Acc: 0.9877
🕒 Epoch 20/100 | Train Loss: 0.4212 | Val Loss: 0.4468 | Val Acc: 0.9877
🕒 Epoch 21/100 | Train Loss: 0.4213 | Val Loss: 0.4467 | Val Acc: 0.9877
🕒 Epoch 22/100 | Train Loss: 0.4213 | Val Loss: 0.4469 | Val Acc: 0.9877
⏹️ Early stopping.
✅ Fold 3 complete. Saved: ./output/models/ConvNeXt+4cbam+dataset1+dataset1_fold3.pth

📂 Fold 4/5
🕒 Epoch 1/100 | Train Loss: 0.7433 | Val Loss: 0.5066 | Val Acc: 0.9660
💾 Best model updated (val acc: 0.9660)
🕒 Epoch 2/100 | Train Loss: 0.5082 | Val Loss: 0.4852 | Val Acc: 0.9691
💾 Best model updated (val acc: 0.9691)
🕒 Epoch 3/100 | Train Loss: 0.4329 | Val Loss: 0.4686 | Val Acc: 0.9784
💾 Best model updated (val acc: 0.9784)
🕒 Epoch 4/100 | Train Loss: 0.4234 | Val Loss: 0.4604 | Val Acc: 0.9815
💾 Best model updated (val acc: 0.9815)
🕒 Epoch 5/100 | Train Loss: 0.4223 | Val Loss: 0.4621 | Val Acc: 0.9815
🕒 Epoch 6/100 | Train Loss: 0.4218 | Val Loss: 0.4619 | Val Acc: 0.9815
🕒 Epoch 7/100 | Train Loss: 0.4216 | Val Loss: 0.4617 | Val Acc: 0.9815
🕒 Epoch 8/100 | Train Loss: 0.4215 | Val Loss: 0.4621 | Val Acc: 0.9815
🕒 Epoch 9/100 | Train Loss: 0.4214 | Val Loss: 0.4618 | Val Acc: 0.9815
🕒 Epoch 10/100 | Train Loss: 0.4213 | Val Loss: 0.4618 | Val Acc: 0.9815
🕒 Epoch 11/100 | Train Loss: 0.4213 | Val Loss: 0.4619 | Val Acc: 0.9815
🕒 Epoch 12/100 | Train Loss: 0.4213 | Val Loss: 0.4621 | Val Acc: 0.9815
🕒 Epoch 13/100 | Train Loss: 0.4213 | Val Loss: 0.4622 | Val Acc: 0.9815
🕒 Epoch 14/100 | Train Loss: 0.4214 | Val Loss: 0.4619 | Val Acc: 0.9815
⏹️ Early stopping.
✅ Fold 4 complete. Saved: ./output/models/ConvNeXt+4cbam+dataset1+dataset1_fold4.pth

📂 Fold 5/5
🕒 Epoch 1/100 | Train Loss: 0.7716 | Val Loss: 0.5519 | Val Acc: 0.9414
💾 Best model updated (val acc: 0.9414)
🕒 Epoch 2/100 | Train Loss: 0.4771 | Val Loss: 0.4836 | Val Acc: 0.9660
💾 Best model updated (val acc: 0.9660)
🕒 Epoch 3/100 | Train Loss: 0.4357 | Val Loss: 0.5182 | Val Acc: 0.9537
🕒 Epoch 4/100 | Train Loss: 0.4290 | Val Loss: 0.4799 | Val Acc: 0.9784
💾 Best model updated (val acc: 0.9784)
🕒 Epoch 5/100 | Train Loss: 0.4236 | Val Loss: 0.4763 | Val Acc: 0.9815
💾 Best model updated (val acc: 0.9815)
🕒 Epoch 6/100 | Train Loss: 0.4243 | Val Loss: 0.5285 | Val Acc: 0.9568
🕒 Epoch 7/100 | Train Loss: 0.4457 | Val Loss: 0.5004 | Val Acc: 0.9691
🕒 Epoch 8/100 | Train Loss: 0.4911 | Val Loss: 0.7285 | Val Acc: 0.8673
🕒 Epoch 9/100 | Train Loss: 0.4637 | Val Loss: 0.5166 | Val Acc: 0.9537
🕒 Epoch 10/100 | Train Loss: 0.4375 | Val Loss: 0.4784 | Val Acc: 0.9784
🕒 Epoch 11/100 | Train Loss: 0.4245 | Val Loss: 0.4935 | Val Acc: 0.9722
🕒 Epoch 12/100 | Train Loss: 0.4221 | Val Loss: 0.4789 | Val Acc: 0.9784
🕒 Epoch 13/100 | Train Loss: 0.4216 | Val Loss: 0.4784 | Val Acc: 0.9784
🕒 Epoch 14/100 | Train Loss: 0.4215 | Val Loss: 0.4780 | Val Acc: 0.9784
🕒 Epoch 15/100 | Train Loss: 0.4215 | Val Loss: 0.4779 | Val Acc: 0.9784
⏹️ Early stopping.
✅ Fold 5 complete. Saved: ./output/models/ConvNeXt+4cbam+dataset1+dataset1_fold5.pth
Traceback (most recent call last):
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/train.py", line 114, in <module>
    plot_training_metrics(all_fold_train_losses, all_fold_val_losses, all_fold_train_accs, all_fold_val_accs, kfold=KFOLD_SPLITS)
TypeError: plot_training_metrics() got an unexpected keyword argument 'kfold'
🚀 Evaluating 5 fold models on test set

📂 Evaluating Fold 1
📊 Fold 1 Metrics:
   - Accuracy: 0.9797
   - Precision: 0.9799
   - Recall: 0.9801
   - F1 Score: 0.9799

📂 Evaluating Fold 2
📊 Fold 2 Metrics:
   - Accuracy: 0.9705
   - Precision: 0.9709
   - Recall: 0.9710
   - F1 Score: 0.9708

📂 Evaluating Fold 3
📊 Fold 3 Metrics:
   - Accuracy: 0.9816
   - Precision: 0.9821
   - Recall: 0.9818
   - F1 Score: 0.9818

📂 Evaluating Fold 4
📊 Fold 4 Metrics:
   - Accuracy: 0.9761
   - Precision: 0.9765
   - Recall: 0.9764
   - F1 Score: 0.9764

📂 Evaluating Fold 5
📊 Fold 5 Metrics:
   - Accuracy: 0.9816
   - Precision: 0.9821
   - Recall: 0.9818
   - F1 Score: 0.9818

🧾 Classification Report for ConvNeXt+4cbam+dataset1 (Majority Vote from 5 folds):

                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    1.0000    1.0000        88
           brown_spot     0.9778    0.9462    0.9617        93
              healthy     0.9688    1.0000    0.9841        93
           leaf_blast     0.9778    0.9670    0.9724        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     0.9888    1.0000    0.9944        88

             accuracy                         0.9853       543
            macro avg     0.9855    0.9855    0.9854       543
         weighted avg     0.9853    0.9853    0.9852       543

🔢 Confusion Matrix:
 [[88  0  0  0  0  0]
 [ 0 88  2  2  0  1]
 [ 0  0 93  0  0  0]
 [ 0  2  1 88  0  0]
 [ 0  0  0  0 90  0]
 [ 0  0  0  0  0 88]]

📊 Average Metrics Across All Folds:
   - Accuracy: 0.9779
   - Precision: 0.9783
   - Recall: 0.9782
   - F1 Score: 0.9781
🚀 Starting training with 5-Fold Cross-Validation for model: ConvNeXt+4cbam+dataset1_kfold
/media/data3/users/datlht/Rice_leaf_disease_detection/load_data.py:78: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/media/data3/users/datlht/Rice_leaf_disease_detection/load_data.py:81: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from font(s) DejaVu Sans.
  plt.savefig(plot_path)
✅ Saved fold class distribution plot to: output/fold_class_distribution.png

📂 Fold 1/5
🕒 Epoch 1/100 | Train Loss: 0.6968 | Val Loss: 0.5085 | Val Acc: 0.9631
💾 Best model updated (val acc: 0.9631)
🕒 Epoch 2/100 | Train Loss: 0.4840 | Val Loss: 0.4917 | Val Acc: 0.9677
💾 Best model updated (val acc: 0.9677)
🕒 Epoch 3/100 | Train Loss: 0.4389 | Val Loss: 0.4561 | Val Acc: 0.9862
💾 Best model updated (val acc: 0.9862)
🕒 Epoch 4/100 | Train Loss: 0.4562 | Val Loss: 0.5424 | Val Acc: 0.9493
🕒 Epoch 5/100 | Train Loss: 0.4374 | Val Loss: 0.4908 | Val Acc: 0.9770
🕒 Epoch 6/100 | Train Loss: 0.4323 | Val Loss: 0.4460 | Val Acc: 0.9839
💾 Best model updated (val acc: 0.9839)
🕒 Epoch 7/100 | Train Loss: 0.4228 | Val Loss: 0.4454 | Val Acc: 0.9839
💾 Best model updated (val acc: 0.9839)
🕒 Epoch 8/100 | Train Loss: 0.4217 | Val Loss: 0.4471 | Val Acc: 0.9839
🕒 Epoch 9/100 | Train Loss: 0.4215 | Val Loss: 0.4481 | Val Acc: 0.9862
🕒 Epoch 10/100 | Train Loss: 0.4214 | Val Loss: 0.4479 | Val Acc: 0.9862
🕒 Epoch 11/100 | Train Loss: 0.4214 | Val Loss: 0.4484 | Val Acc: 0.9862
🕒 Epoch 12/100 | Train Loss: 0.4213 | Val Loss: 0.4487 | Val Acc: 0.9862
🕒 Epoch 13/100 | Train Loss: 0.4213 | Val Loss: 0.4492 | Val Acc: 0.9862
🕒 Epoch 14/100 | Train Loss: 0.4213 | Val Loss: 0.4493 | Val Acc: 0.9862
🕒 Epoch 15/100 | Train Loss: 0.4213 | Val Loss: 0.4494 | Val Acc: 0.9862
🕒 Epoch 16/100 | Train Loss: 0.4212 | Val Loss: 0.4500 | Val Acc: 0.9862
🕒 Epoch 17/100 | Train Loss: 0.4212 | Val Loss: 0.4504 | Val Acc: 0.9862
⏹️ Early stopping.
✅ Fold 1 complete. Saved: ./output/models/ConvNeXt+4cbam+dataset1_kfold+dataset1_kfold_fold1.pth

📂 Fold 2/5
🕒 Epoch 1/100 | Train Loss: 0.7128 | Val Loss: 0.5068 | Val Acc: 0.9654
💾 Best model updated (val acc: 0.9654)
🕒 Epoch 2/100 | Train Loss: 0.4719 | Val Loss: 0.4915 | Val Acc: 0.9724
💾 Best model updated (val acc: 0.9724)
🕒 Epoch 3/100 | Train Loss: 0.4407 | Val Loss: 0.4982 | Val Acc: 0.9677
🕒 Epoch 4/100 | Train Loss: 0.4387 | Val Loss: 0.4729 | Val Acc: 0.9770
💾 Best model updated (val acc: 0.9770)
🕒 Epoch 5/100 | Train Loss: 0.4226 | Val Loss: 0.4627 | Val Acc: 0.9793
💾 Best model updated (val acc: 0.9793)
🕒 Epoch 6/100 | Train Loss: 0.4218 | Val Loss: 0.4635 | Val Acc: 0.9793
🕒 Epoch 7/100 | Train Loss: 0.4216 | Val Loss: 0.4643 | Val Acc: 0.9793
🕒 Epoch 8/100 | Train Loss: 0.4215 | Val Loss: 0.4646 | Val Acc: 0.9793
🕒 Epoch 9/100 | Train Loss: 0.4214 | Val Loss: 0.4646 | Val Acc: 0.9793
🕒 Epoch 10/100 | Train Loss: 0.4214 | Val Loss: 0.4652 | Val Acc: 0.9793
🕒 Epoch 11/100 | Train Loss: 0.4213 | Val Loss: 0.4653 | Val Acc: 0.9793
🕒 Epoch 12/100 | Train Loss: 0.4213 | Val Loss: 0.4657 | Val Acc: 0.9793
🕒 Epoch 13/100 | Train Loss: 0.4213 | Val Loss: 0.4658 | Val Acc: 0.9793
🕒 Epoch 14/100 | Train Loss: 0.4213 | Val Loss: 0.4659 | Val Acc: 0.9793
🕒 Epoch 15/100 | Train Loss: 0.4213 | Val Loss: 0.4661 | Val Acc: 0.9793
⏹️ Early stopping.
✅ Fold 2 complete. Saved: ./output/models/ConvNeXt+4cbam+dataset1_kfold+dataset1_kfold_fold2.pth

📂 Fold 3/5
🕒 Epoch 1/100 | Train Loss: 0.7021 | Val Loss: 0.5188 | Val Acc: 0.9515
💾 Best model updated (val acc: 0.9515)
🕒 Epoch 2/100 | Train Loss: 0.4756 | Val Loss: 0.4716 | Val Acc: 0.9815
💾 Best model updated (val acc: 0.9815)
🕒 Epoch 3/100 | Train Loss: 0.4516 | Val Loss: 0.4630 | Val Acc: 0.9838
💾 Best model updated (val acc: 0.9838)
🕒 Epoch 4/100 | Train Loss: 0.4322 | Val Loss: 0.4698 | Val Acc: 0.9792
🕒 Epoch 5/100 | Train Loss: 0.4277 | Val Loss: 0.4461 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 6/100 | Train Loss: 0.4276 | Val Loss: 0.4614 | Val Acc: 0.9861
🕒 Epoch 7/100 | Train Loss: 0.4234 | Val Loss: 0.4581 | Val Acc: 0.9838
🕒 Epoch 8/100 | Train Loss: 0.4452 | Val Loss: 0.4974 | Val Acc: 0.9746
🕒 Epoch 9/100 | Train Loss: 0.4636 | Val Loss: 0.5135 | Val Acc: 0.9607
🕒 Epoch 10/100 | Train Loss: 0.4599 | Val Loss: 0.4481 | Val Acc: 0.9908
🕒 Epoch 11/100 | Train Loss: 0.4227 | Val Loss: 0.4452 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 12/100 | Train Loss: 0.4217 | Val Loss: 0.4422 | Val Acc: 0.9931
💾 Best model updated (val acc: 0.9931)
🕒 Epoch 13/100 | Train Loss: 0.4215 | Val Loss: 0.4424 | Val Acc: 0.9931
🕒 Epoch 14/100 | Train Loss: 0.4215 | Val Loss: 0.4424 | Val Acc: 0.9931
🕒 Epoch 15/100 | Train Loss: 0.4214 | Val Loss: 0.4424 | Val Acc: 0.9931
🕒 Epoch 16/100 | Train Loss: 0.4214 | Val Loss: 0.4425 | Val Acc: 0.9931
🕒 Epoch 17/100 | Train Loss: 0.4213 | Val Loss: 0.4423 | Val Acc: 0.9931
🕒 Epoch 18/100 | Train Loss: 0.4213 | Val Loss: 0.4424 | Val Acc: 0.9931
🕒 Epoch 19/100 | Train Loss: 0.4213 | Val Loss: 0.4424 | Val Acc: 0.9931
🕒 Epoch 20/100 | Train Loss: 0.4212 | Val Loss: 0.4424 | Val Acc: 0.9931
🕒 Epoch 21/100 | Train Loss: 0.4213 | Val Loss: 0.4424 | Val Acc: 0.9931
🕒 Epoch 22/100 | Train Loss: 0.4213 | Val Loss: 0.4425 | Val Acc: 0.9931
⏹️ Early stopping.
✅ Fold 3 complete. Saved: ./output/models/ConvNeXt+4cbam+dataset1_kfold+dataset1_kfold_fold3.pth

📂 Fold 4/5
🕒 Epoch 1/100 | Train Loss: 0.7113 | Val Loss: 0.5148 | Val Acc: 0.9538
💾 Best model updated (val acc: 0.9538)
🕒 Epoch 2/100 | Train Loss: 0.4632 | Val Loss: 0.4810 | Val Acc: 0.9746
💾 Best model updated (val acc: 0.9746)
🕒 Epoch 3/100 | Train Loss: 0.4344 | Val Loss: 0.5072 | Val Acc: 0.9607
🕒 Epoch 4/100 | Train Loss: 0.4503 | Val Loss: 0.5079 | Val Acc: 0.9630
🕒 Epoch 5/100 | Train Loss: 0.4398 | Val Loss: 0.4835 | Val Acc: 0.9723
🕒 Epoch 6/100 | Train Loss: 0.4368 | Val Loss: 0.4918 | Val Acc: 0.9746
🕒 Epoch 7/100 | Train Loss: 0.4307 | Val Loss: 0.4587 | Val Acc: 0.9769
💾 Best model updated (val acc: 0.9769)
🕒 Epoch 8/100 | Train Loss: 0.4228 | Val Loss: 0.4600 | Val Acc: 0.9815
🕒 Epoch 9/100 | Train Loss: 0.4287 | Val Loss: 0.4733 | Val Acc: 0.9769
🕒 Epoch 10/100 | Train Loss: 0.4282 | Val Loss: 0.4611 | Val Acc: 0.9861
🕒 Epoch 11/100 | Train Loss: 0.4541 | Val Loss: 0.4762 | Val Acc: 0.9769
🕒 Epoch 12/100 | Train Loss: 0.4250 | Val Loss: 0.6612 | Val Acc: 0.9122
🕒 Epoch 13/100 | Train Loss: 0.4585 | Val Loss: 0.4750 | Val Acc: 0.9815
🕒 Epoch 14/100 | Train Loss: 0.4240 | Val Loss: 0.4678 | Val Acc: 0.9792
🕒 Epoch 15/100 | Train Loss: 0.4217 | Val Loss: 0.4663 | Val Acc: 0.9792
🕒 Epoch 16/100 | Train Loss: 0.4214 | Val Loss: 0.4667 | Val Acc: 0.9792
🕒 Epoch 17/100 | Train Loss: 0.4214 | Val Loss: 0.4676 | Val Acc: 0.9792
⏹️ Early stopping.
✅ Fold 4 complete. Saved: ./output/models/ConvNeXt+4cbam+dataset1_kfold+dataset1_kfold_fold4.pth

📂 Fold 5/5
🕒 Epoch 1/100 | Train Loss: 0.7164 | Val Loss: 0.5222 | Val Acc: 0.9584
💾 Best model updated (val acc: 0.9584)
🕒 Epoch 2/100 | Train Loss: 0.4828 | Val Loss: 0.4694 | Val Acc: 0.9792
💾 Best model updated (val acc: 0.9792)
🕒 Epoch 3/100 | Train Loss: 0.4440 | Val Loss: 0.4601 | Val Acc: 0.9838
💾 Best model updated (val acc: 0.9838)
🕒 Epoch 4/100 | Train Loss: 0.4293 | Val Loss: 0.4543 | Val Acc: 0.9838
💾 Best model updated (val acc: 0.9838)
🕒 Epoch 5/100 | Train Loss: 0.4322 | Val Loss: 0.4599 | Val Acc: 0.9792
🕒 Epoch 6/100 | Train Loss: 0.4259 | Val Loss: 0.4541 | Val Acc: 0.9861
💾 Best model updated (val acc: 0.9861)
🕒 Epoch 7/100 | Train Loss: 0.4219 | Val Loss: 0.4496 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 8/100 | Train Loss: 0.4215 | Val Loss: 0.4497 | Val Acc: 0.9908
🕒 Epoch 9/100 | Train Loss: 0.4214 | Val Loss: 0.4500 | Val Acc: 0.9908
🕒 Epoch 10/100 | Train Loss: 0.4214 | Val Loss: 0.4503 | Val Acc: 0.9908
🕒 Epoch 11/100 | Train Loss: 0.4213 | Val Loss: 0.4503 | Val Acc: 0.9908
🕒 Epoch 12/100 | Train Loss: 0.4213 | Val Loss: 0.4505 | Val Acc: 0.9885
🕒 Epoch 13/100 | Train Loss: 0.4213 | Val Loss: 0.4506 | Val Acc: 0.9885
🕒 Epoch 14/100 | Train Loss: 0.4212 | Val Loss: 0.4508 | Val Acc: 0.9885
🕒 Epoch 15/100 | Train Loss: 0.4212 | Val Loss: 0.4508 | Val Acc: 0.9885
🕒 Epoch 16/100 | Train Loss: 0.4213 | Val Loss: 0.4507 | Val Acc: 0.9908
🕒 Epoch 17/100 | Train Loss: 0.4212 | Val Loss: 0.4509 | Val Acc: 0.9885
⏹️ Early stopping.
✅ Fold 5 complete. Saved: ./output/models/ConvNeXt+4cbam+dataset1_kfold+dataset1_kfold_fold5.pth
📂 Training metrics plot saved for Fold 1: output/test/fold_1/training_metrics.png
📂 Training metrics plot saved for Fold 2: output/test/fold_2/training_metrics.png
📂 Training metrics plot saved for Fold 3: output/test/fold_3/training_metrics.png
📂 Training metrics plot saved for Fold 4: output/test/fold_4/training_metrics.png
📂 Training metrics plot saved for Fold 5: output/test/fold_5/training_metrics.png
🎉 All folds completed.
🚀 Evaluating 5 fold models on test set

📂 Evaluating Fold 1
📊 Fold 1 Metrics:
   - Accuracy: 0.9834
   - Precision: 0.9837
   - Recall: 0.9837
   - F1 Score: 0.9837

📂 Evaluating Fold 2
📊 Fold 2 Metrics:
   - Accuracy: 0.9853
   - Precision: 0.9856
   - Recall: 0.9855
   - F1 Score: 0.9855

📂 Evaluating Fold 3
📊 Fold 3 Metrics:
   - Accuracy: 0.9871
   - Precision: 0.9873
   - Recall: 0.9873
   - F1 Score: 0.9873

📂 Evaluating Fold 4
📊 Fold 4 Metrics:
   - Accuracy: 0.9797
   - Precision: 0.9805
   - Recall: 0.9800
   - F1 Score: 0.9799

📂 Evaluating Fold 5
📊 Fold 5 Metrics:
   - Accuracy: 0.9853
   - Precision: 0.9856
   - Recall: 0.9855
   - F1 Score: 0.9855

🧾 Classification Report for ConvNeXt+4cbam+dataset1_kfold (Majority Vote from 5 folds):

                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    1.0000    1.0000        88
           brown_spot     0.9783    0.9677    0.9730        93
              healthy     0.9789    1.0000    0.9894        93
           leaf_blast     0.9778    0.9670    0.9724        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9890       543
            macro avg     0.9892    0.9891    0.9891       543
         weighted avg     0.9889    0.9890    0.9889       543

🔢 Confusion Matrix:
 [[88  0  0  0  0  0]
 [ 0 90  1  2  0  0]
 [ 0  0 93  0  0  0]
 [ 0  2  1 88  0  0]
 [ 0  0  0  0 90  0]
 [ 0  0  0  0  0 88]]

📊 Average Metrics Across All Folds:
   - Accuracy: 0.9842
   - Precision: 0.9845
   - Recall: 0.9844
   - F1 Score: 0.9844
🚀 Starting training with 5-Fold Cross-Validation for model: ConvNeXt+4cbam+v2+dataset1_kfold
/media/data3/users/datlht/Rice_leaf_disease_detection/load_data.py:81: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/media/data3/users/datlht/Rice_leaf_disease_detection/load_data.py:84: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from font(s) DejaVu Sans.
  plt.savefig(plot_path)
✅ Saved fold class distribution plot to: output/fold_class_distribution.png

📂 Fold 1/5
🕒 Epoch 1/100 | Train Loss: 0.7753 | Val Loss: 0.5237 | Val Acc: 0.9700
💾 Best model updated (val acc: 0.9700)
🕒 Epoch 2/100 | Train Loss: 0.5046 | Val Loss: 0.4690 | Val Acc: 0.9862
💾 Best model updated (val acc: 0.9862)
🕒 Epoch 3/100 | Train Loss: 0.4951 | Val Loss: 0.4747 | Val Acc: 0.9816
🕒 Epoch 4/100 | Train Loss: 0.4643 | Val Loss: 0.4901 | Val Acc: 0.9654
🕒 Epoch 5/100 | Train Loss: 0.4503 | Val Loss: 0.4591 | Val Acc: 0.9862
💾 Best model updated (val acc: 0.9862)
🕒 Epoch 6/100 | Train Loss: 0.4702 | Val Loss: 0.4678 | Val Acc: 0.9816
🕒 Epoch 7/100 | Train Loss: 0.4431 | Val Loss: 0.4761 | Val Acc: 0.9747
🕒 Epoch 8/100 | Train Loss: 0.4458 | Val Loss: 0.4500 | Val Acc: 0.9816
💾 Best model updated (val acc: 0.9816)
🕒 Epoch 9/100 | Train Loss: 0.4411 | Val Loss: 0.4404 | Val Acc: 0.9954
💾 Best model updated (val acc: 0.9954)
🕒 Epoch 10/100 | Train Loss: 0.4400 | Val Loss: 0.4553 | Val Acc: 0.9908
🕒 Epoch 11/100 | Train Loss: 0.4392 | Val Loss: 0.4441 | Val Acc: 0.9885
🕒 Epoch 12/100 | Train Loss: 0.4277 | Val Loss: 0.4443 | Val Acc: 0.9885
🕒 Epoch 13/100 | Train Loss: 0.4281 | Val Loss: 0.4492 | Val Acc: 0.9862
🕒 Epoch 14/100 | Train Loss: 0.4298 | Val Loss: 0.4420 | Val Acc: 0.9885
🕒 Epoch 15/100 | Train Loss: 0.4706 | Val Loss: 0.4863 | Val Acc: 0.9724
🕒 Epoch 16/100 | Train Loss: 0.4540 | Val Loss: 0.4460 | Val Acc: 0.9908
🕒 Epoch 17/100 | Train Loss: 0.4319 | Val Loss: 0.4628 | Val Acc: 0.9816
🕒 Epoch 18/100 | Train Loss: 0.4306 | Val Loss: 0.4529 | Val Acc: 0.9839
🕒 Epoch 19/100 | Train Loss: 0.4319 | Val Loss: 0.4491 | Val Acc: 0.9839
⏹️ Early stopping.
✅ Fold 1 complete. Saved: ./output/models/ConvNeXt+4cbam+v2+dataset1_kfold+dataset1_kfold_fold1.pth

📂 Fold 2/5
🕒 Epoch 1/100 | Train Loss: 0.7279 | Val Loss: 0.5524 | Val Acc: 0.9401
💾 Best model updated (val acc: 0.9401)
🕒 Epoch 2/100 | Train Loss: 0.5063 | Val Loss: 0.4851 | Val Acc: 0.9700
💾 Best model updated (val acc: 0.9700)
🕒 Epoch 3/100 | Train Loss: 0.4946 | Val Loss: 0.5126 | Val Acc: 0.9631
🕒 Epoch 4/100 | Train Loss: 0.4840 | Val Loss: 0.4732 | Val Acc: 0.9816
💾 Best model updated (val acc: 0.9816)
🕒 Epoch 5/100 | Train Loss: 0.4662 | Val Loss: 0.4565 | Val Acc: 0.9816
💾 Best model updated (val acc: 0.9816)
🕒 Epoch 6/100 | Train Loss: 0.4442 | Val Loss: 0.4665 | Val Acc: 0.9747
🕒 Epoch 7/100 | Train Loss: 0.4450 | Val Loss: 0.4512 | Val Acc: 0.9885
💾 Best model updated (val acc: 0.9885)
🕒 Epoch 8/100 | Train Loss: 0.4498 | Val Loss: 0.4546 | Val Acc: 0.9885
🕒 Epoch 9/100 | Train Loss: 0.4380 | Val Loss: 0.5055 | Val Acc: 0.9700
🕒 Epoch 10/100 | Train Loss: 0.4633 | Val Loss: 0.4692 | Val Acc: 0.9793
🕒 Epoch 11/100 | Train Loss: 0.4356 | Val Loss: 0.4469 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 12/100 | Train Loss: 0.4346 | Val Loss: 0.4527 | Val Acc: 0.9885
🕒 Epoch 13/100 | Train Loss: 0.4403 | Val Loss: 0.4703 | Val Acc: 0.9816
🕒 Epoch 14/100 | Train Loss: 0.4361 | Val Loss: 0.4442 | Val Acc: 0.9885
💾 Best model updated (val acc: 0.9885)
🕒 Epoch 15/100 | Train Loss: 0.4271 | Val Loss: 0.4485 | Val Acc: 0.9839
🕒 Epoch 16/100 | Train Loss: 0.4353 | Val Loss: 0.4504 | Val Acc: 0.9885
🕒 Epoch 17/100 | Train Loss: 0.4274 | Val Loss: 0.4408 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 18/100 | Train Loss: 0.4284 | Val Loss: 0.4581 | Val Acc: 0.9862
🕒 Epoch 19/100 | Train Loss: 0.4280 | Val Loss: 0.4606 | Val Acc: 0.9816
🕒 Epoch 20/100 | Train Loss: 0.4258 | Val Loss: 0.4497 | Val Acc: 0.9862
🕒 Epoch 21/100 | Train Loss: 0.4274 | Val Loss: 0.4425 | Val Acc: 0.9931
🕒 Epoch 22/100 | Train Loss: 0.4332 | Val Loss: 0.4571 | Val Acc: 0.9862
🕒 Epoch 23/100 | Train Loss: 0.4293 | Val Loss: 0.4561 | Val Acc: 0.9839
🕒 Epoch 24/100 | Train Loss: 0.4285 | Val Loss: 0.4555 | Val Acc: 0.9885
🕒 Epoch 25/100 | Train Loss: 0.4246 | Val Loss: 0.4455 | Val Acc: 0.9885
🕒 Epoch 26/100 | Train Loss: 0.4236 | Val Loss: 0.4446 | Val Acc: 0.9885
🕒 Epoch 27/100 | Train Loss: 0.4228 | Val Loss: 0.4451 | Val Acc: 0.9908
⏹️ Early stopping.
✅ Fold 2 complete. Saved: ./output/models/ConvNeXt+4cbam+v2+dataset1_kfold+dataset1_kfold_fold2.pth

📂 Fold 3/5
🕒 Epoch 1/100 | Train Loss: 0.7776 | Val Loss: 0.5093 | Val Acc: 0.9654
💾 Best model updated (val acc: 0.9654)
🕒 Epoch 2/100 | Train Loss: 0.5205 | Val Loss: 0.4892 | Val Acc: 0.9630
💾 Best model updated (val acc: 0.9630)
🕒 Epoch 3/100 | Train Loss: 0.4816 | Val Loss: 0.4818 | Val Acc: 0.9746
💾 Best model updated (val acc: 0.9746)
🕒 Epoch 4/100 | Train Loss: 0.4526 | Val Loss: 0.4541 | Val Acc: 0.9861
💾 Best model updated (val acc: 0.9861)
🕒 Epoch 5/100 | Train Loss: 0.4659 | Val Loss: 0.4508 | Val Acc: 0.9885
💾 Best model updated (val acc: 0.9885)
🕒 Epoch 6/100 | Train Loss: 0.4448 | Val Loss: 0.4529 | Val Acc: 0.9815
🕒 Epoch 7/100 | Train Loss: 0.4592 | Val Loss: 0.4664 | Val Acc: 0.9792
🕒 Epoch 8/100 | Train Loss: 0.4635 | Val Loss: 0.4573 | Val Acc: 0.9885
🕒 Epoch 9/100 | Train Loss: 0.4478 | Val Loss: 0.4694 | Val Acc: 0.9815
🕒 Epoch 10/100 | Train Loss: 0.4463 | Val Loss: 0.4561 | Val Acc: 0.9861
🕒 Epoch 11/100 | Train Loss: 0.4357 | Val Loss: 0.4653 | Val Acc: 0.9792
🕒 Epoch 12/100 | Train Loss: 0.4325 | Val Loss: 0.4579 | Val Acc: 0.9861
🕒 Epoch 13/100 | Train Loss: 0.4288 | Val Loss: 0.4613 | Val Acc: 0.9792
🕒 Epoch 14/100 | Train Loss: 0.4362 | Val Loss: 0.4454 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 15/100 | Train Loss: 0.4370 | Val Loss: 0.4557 | Val Acc: 0.9885
🕒 Epoch 16/100 | Train Loss: 0.4303 | Val Loss: 0.4549 | Val Acc: 0.9861
🕒 Epoch 17/100 | Train Loss: 0.4277 | Val Loss: 0.4452 | Val Acc: 0.9861
💾 Best model updated (val acc: 0.9861)
🕒 Epoch 18/100 | Train Loss: 0.4328 | Val Loss: 0.4362 | Val Acc: 0.9954
💾 Best model updated (val acc: 0.9954)
🕒 Epoch 19/100 | Train Loss: 0.4251 | Val Loss: 0.4439 | Val Acc: 0.9908
🕒 Epoch 20/100 | Train Loss: 0.4346 | Val Loss: 0.4464 | Val Acc: 0.9908
🕒 Epoch 21/100 | Train Loss: 0.4261 | Val Loss: 0.4604 | Val Acc: 0.9885
🕒 Epoch 22/100 | Train Loss: 0.4339 | Val Loss: 0.4412 | Val Acc: 0.9885
🕒 Epoch 23/100 | Train Loss: 0.4228 | Val Loss: 0.4433 | Val Acc: 0.9931
🕒 Epoch 24/100 | Train Loss: 0.4256 | Val Loss: 0.4407 | Val Acc: 0.9885
🕒 Epoch 25/100 | Train Loss: 0.4244 | Val Loss: 0.4517 | Val Acc: 0.9885
🕒 Epoch 26/100 | Train Loss: 0.4226 | Val Loss: 0.4475 | Val Acc: 0.9908
🕒 Epoch 27/100 | Train Loss: 0.4231 | Val Loss: 0.4478 | Val Acc: 0.9885
🕒 Epoch 28/100 | Train Loss: 0.4344 | Val Loss: 0.4446 | Val Acc: 0.9885
⏹️ Early stopping.
✅ Fold 3 complete. Saved: ./output/models/ConvNeXt+4cbam+v2+dataset1_kfold+dataset1_kfold_fold3.pth

📂 Fold 4/5
🕒 Epoch 1/100 | Train Loss: 0.7668 | Val Loss: 0.5465 | Val Acc: 0.9515
💾 Best model updated (val acc: 0.9515)
🕒 Epoch 2/100 | Train Loss: 0.5095 | Val Loss: 0.4986 | Val Acc: 0.9746
💾 Best model updated (val acc: 0.9746)
🕒 Epoch 3/100 | Train Loss: 0.4829 | Val Loss: 0.4968 | Val Acc: 0.9654
💾 Best model updated (val acc: 0.9654)
🕒 Epoch 4/100 | Train Loss: 0.4699 | Val Loss: 0.4782 | Val Acc: 0.9769
💾 Best model updated (val acc: 0.9769)
🕒 Epoch 5/100 | Train Loss: 0.4673 | Val Loss: 0.5663 | Val Acc: 0.9215
🕒 Epoch 6/100 | Train Loss: 0.4695 | Val Loss: 0.5366 | Val Acc: 0.9469
🕒 Epoch 7/100 | Train Loss: 0.4545 | Val Loss: 0.4983 | Val Acc: 0.9607
🕒 Epoch 8/100 | Train Loss: 0.4396 | Val Loss: 0.4704 | Val Acc: 0.9815
💾 Best model updated (val acc: 0.9815)
🕒 Epoch 9/100 | Train Loss: 0.4381 | Val Loss: 0.4799 | Val Acc: 0.9746
🕒 Epoch 10/100 | Train Loss: 0.4551 | Val Loss: 0.4667 | Val Acc: 0.9861
💾 Best model updated (val acc: 0.9861)
🕒 Epoch 11/100 | Train Loss: 0.4493 | Val Loss: 0.4794 | Val Acc: 0.9746
🕒 Epoch 12/100 | Train Loss: 0.4302 | Val Loss: 0.4580 | Val Acc: 0.9838
💾 Best model updated (val acc: 0.9838)
🕒 Epoch 13/100 | Train Loss: 0.4283 | Val Loss: 0.4687 | Val Acc: 0.9838
🕒 Epoch 14/100 | Train Loss: 0.4339 | Val Loss: 0.4625 | Val Acc: 0.9815
🕒 Epoch 15/100 | Train Loss: 0.4234 | Val Loss: 0.4501 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 16/100 | Train Loss: 0.4311 | Val Loss: 0.4460 | Val Acc: 0.9931
💾 Best model updated (val acc: 0.9931)
🕒 Epoch 17/100 | Train Loss: 0.4259 | Val Loss: 0.4508 | Val Acc: 0.9908
🕒 Epoch 18/100 | Train Loss: 0.4243 | Val Loss: 0.4520 | Val Acc: 0.9885
🕒 Epoch 19/100 | Train Loss: 0.4233 | Val Loss: 0.4527 | Val Acc: 0.9908
🕒 Epoch 20/100 | Train Loss: 0.4326 | Val Loss: 0.4817 | Val Acc: 0.9746
🕒 Epoch 21/100 | Train Loss: 0.4299 | Val Loss: 0.4484 | Val Acc: 0.9885
🕒 Epoch 22/100 | Train Loss: 0.4240 | Val Loss: 0.4606 | Val Acc: 0.9815
🕒 Epoch 23/100 | Train Loss: 0.4238 | Val Loss: 0.4493 | Val Acc: 0.9861
🕒 Epoch 24/100 | Train Loss: 0.4333 | Val Loss: 0.4506 | Val Acc: 0.9908
🕒 Epoch 25/100 | Train Loss: 0.4287 | Val Loss: 0.4520 | Val Acc: 0.9861
🕒 Epoch 26/100 | Train Loss: 0.4231 | Val Loss: 0.4680 | Val Acc: 0.9815
⏹️ Early stopping.
✅ Fold 4 complete. Saved: ./output/models/ConvNeXt+4cbam+v2+dataset1_kfold+dataset1_kfold_fold4.pth

📂 Fold 5/5
🕒 Epoch 1/100 | Train Loss: 0.7677 | Val Loss: 0.5462 | Val Acc: 0.9307
💾 Best model updated (val acc: 0.9307)
🕒 Epoch 2/100 | Train Loss: 0.5110 | Val Loss: 0.5266 | Val Acc: 0.9515
💾 Best model updated (val acc: 0.9515)
🕒 Epoch 3/100 | Train Loss: 0.4791 | Val Loss: 0.4649 | Val Acc: 0.9838
💾 Best model updated (val acc: 0.9838)
🕒 Epoch 4/100 | Train Loss: 0.4811 | Val Loss: 0.4690 | Val Acc: 0.9792
🕒 Epoch 5/100 | Train Loss: 0.4525 | Val Loss: 0.4635 | Val Acc: 0.9792
💾 Best model updated (val acc: 0.9792)
🕒 Epoch 6/100 | Train Loss: 0.4395 | Val Loss: 0.4728 | Val Acc: 0.9769
🕒 Epoch 7/100 | Train Loss: 0.4417 | Val Loss: 0.4709 | Val Acc: 0.9769
🕒 Epoch 8/100 | Train Loss: 0.4598 | Val Loss: 0.4930 | Val Acc: 0.9723
🕒 Epoch 9/100 | Train Loss: 0.4501 | Val Loss: 0.4921 | Val Acc: 0.9746
🕒 Epoch 10/100 | Train Loss: 0.4577 | Val Loss: 0.4574 | Val Acc: 0.9838
💾 Best model updated (val acc: 0.9838)
🕒 Epoch 11/100 | Train Loss: 0.4333 | Val Loss: 0.4633 | Val Acc: 0.9838
🕒 Epoch 12/100 | Train Loss: 0.4299 | Val Loss: 0.4573 | Val Acc: 0.9861
💾 Best model updated (val acc: 0.9861)
🕒 Epoch 13/100 | Train Loss: 0.4254 | Val Loss: 0.4613 | Val Acc: 0.9861
🕒 Epoch 14/100 | Train Loss: 0.4272 | Val Loss: 0.4500 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 15/100 | Train Loss: 0.4233 | Val Loss: 0.4568 | Val Acc: 0.9861
🕒 Epoch 16/100 | Train Loss: 0.4247 | Val Loss: 0.4524 | Val Acc: 0.9885
🕒 Epoch 17/100 | Train Loss: 0.4606 | Val Loss: 0.4560 | Val Acc: 0.9885
🕒 Epoch 18/100 | Train Loss: 0.4322 | Val Loss: 0.4514 | Val Acc: 0.9885
🕒 Epoch 19/100 | Train Loss: 0.4445 | Val Loss: 0.4667 | Val Acc: 0.9792
🕒 Epoch 20/100 | Train Loss: 0.4373 | Val Loss: 0.4666 | Val Acc: 0.9815
🕒 Epoch 21/100 | Train Loss: 0.4263 | Val Loss: 0.4540 | Val Acc: 0.9838
🕒 Epoch 22/100 | Train Loss: 0.4299 | Val Loss: 0.4539 | Val Acc: 0.9861
🕒 Epoch 23/100 | Train Loss: 0.4236 | Val Loss: 0.4542 | Val Acc: 0.9861
🕒 Epoch 24/100 | Train Loss: 0.4232 | Val Loss: 0.4681 | Val Acc: 0.9746
⏹️ Early stopping.
✅ Fold 5 complete. Saved: ./output/models/ConvNeXt+4cbam+v2+dataset1_kfold+dataset1_kfold_fold5.pth
📂 Training metrics plot saved for Fold 1: output/test/fold_1/training_metrics.png
📂 Training metrics plot saved for Fold 2: output/test/fold_2/training_metrics.png
📂 Training metrics plot saved for Fold 3: output/test/fold_3/training_metrics.png
📂 Training metrics plot saved for Fold 4: output/test/fold_4/training_metrics.png
📂 Training metrics plot saved for Fold 5: output/test/fold_5/training_metrics.png
🎉 All folds completed.
🚀 Evaluating 5 fold models on test set

📂 Evaluating Fold 1
📊 Fold 1 Metrics:
   - Accuracy: 0.9853
   - Precision: 0.9859
   - Recall: 0.9856
   - F1 Score: 0.9856

📂 Evaluating Fold 2
📊 Fold 2 Metrics:
   - Accuracy: 0.9834
   - Precision: 0.9838
   - Recall: 0.9835
   - F1 Score: 0.9834

📂 Evaluating Fold 3
📊 Fold 3 Metrics:
   - Accuracy: 0.9908
   - Precision: 0.9912
   - Recall: 0.9909
   - F1 Score: 0.9910

📂 Evaluating Fold 4
📊 Fold 4 Metrics:
   - Accuracy: 0.9834
   - Precision: 0.9836
   - Recall: 0.9838
   - F1 Score: 0.9836

📂 Evaluating Fold 5
📊 Fold 5 Metrics:
   - Accuracy: 0.9890
   - Precision: 0.9895
   - Recall: 0.9891
   - F1 Score: 0.9891

🧾 Classification Report for ConvNeXt+4cbam+v2+dataset1_kfold (Majority Vote from 5 folds):

                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    1.0000    1.0000        88
           brown_spot     0.9681    0.9785    0.9733        93
              healthy     0.9894    1.0000    0.9947        93
           leaf_blast     0.9888    0.9670    0.9778        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9908       543
            macro avg     0.9910    0.9909    0.9909       543
         weighted avg     0.9908    0.9908    0.9908       543

🔢 Confusion Matrix:
 [[88  0  0  0  0  0]
 [ 0 91  1  1  0  0]
 [ 0  0 93  0  0  0]
 [ 0  3  0 88  0  0]
 [ 0  0  0  0 90  0]
 [ 0  0  0  0  0 88]]

📊 Average Metrics Across All Folds:
   - Accuracy: 0.9864
   - Precision: 0.9868
   - Recall: 0.9866
   - F1 Score: 0.9865
🚀 Starting training with 5-Fold Cross-Validation for model: ConvNeXt+4cbam+res+no-norm+dataset1_kfold
/media/data3/users/datlht/Rice_leaf_disease_detection/load_data.py:81: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/media/data3/users/datlht/Rice_leaf_disease_detection/load_data.py:84: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from font(s) DejaVu Sans.
  plt.savefig(plot_path)
✅ Saved fold class distribution plot to: output/fold_class_distribution.png

📂 Fold 1/5
🕒 Epoch 1/100 | Train Loss: 0.7593 | Val Loss: 0.5166 | Val Acc: 0.9654
💾 Best model updated (val acc: 0.9654)
🕒 Epoch 2/100 | Train Loss: 0.5157 | Val Loss: 0.4883 | Val Acc: 0.9793
💾 Best model updated (val acc: 0.9793)
🕒 Epoch 3/100 | Train Loss: 0.4755 | Val Loss: 0.4691 | Val Acc: 0.9816
💾 Best model updated (val acc: 0.9816)
🕒 Epoch 4/100 | Train Loss: 0.4662 | Val Loss: 0.4894 | Val Acc: 0.9700
🕒 Epoch 5/100 | Train Loss: 0.4653 | Val Loss: 0.4539 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 6/100 | Train Loss: 0.4509 | Val Loss: 0.4696 | Val Acc: 0.9839
🕒 Epoch 7/100 | Train Loss: 0.4491 | Val Loss: 0.4694 | Val Acc: 0.9862
🕒 Epoch 8/100 | Train Loss: 0.4409 | Val Loss: 0.4428 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 9/100 | Train Loss: 0.4416 | Val Loss: 0.4651 | Val Acc: 0.9839
🕒 Epoch 10/100 | Train Loss: 0.4394 | Val Loss: 0.4767 | Val Acc: 0.9839
🕒 Epoch 11/100 | Train Loss: 0.4371 | Val Loss: 0.4436 | Val Acc: 0.9931
🕒 Epoch 12/100 | Train Loss: 0.4324 | Val Loss: 0.4459 | Val Acc: 0.9908
🕒 Epoch 13/100 | Train Loss: 0.4617 | Val Loss: 0.4547 | Val Acc: 0.9908
🕒 Epoch 14/100 | Train Loss: 0.4370 | Val Loss: 0.4468 | Val Acc: 0.9908
🕒 Epoch 15/100 | Train Loss: 0.4407 | Val Loss: 0.4587 | Val Acc: 0.9839
🕒 Epoch 16/100 | Train Loss: 0.4494 | Val Loss: 0.4749 | Val Acc: 0.9770
🕒 Epoch 17/100 | Train Loss: 0.4394 | Val Loss: 0.4404 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 18/100 | Train Loss: 0.4247 | Val Loss: 0.4328 | Val Acc: 0.9977
💾 Best model updated (val acc: 0.9977)
🕒 Epoch 19/100 | Train Loss: 0.4319 | Val Loss: 0.4413 | Val Acc: 0.9908
🕒 Epoch 20/100 | Train Loss: 0.4249 | Val Loss: 0.4522 | Val Acc: 0.9816
🕒 Epoch 21/100 | Train Loss: 0.4259 | Val Loss: 0.4396 | Val Acc: 0.9931
🕒 Epoch 22/100 | Train Loss: 0.4230 | Val Loss: 0.4435 | Val Acc: 0.9908
🕒 Epoch 23/100 | Train Loss: 0.4265 | Val Loss: 0.4356 | Val Acc: 0.9977
🕒 Epoch 24/100 | Train Loss: 0.4269 | Val Loss: 0.4831 | Val Acc: 0.9747
🕒 Epoch 25/100 | Train Loss: 0.4384 | Val Loss: 0.4631 | Val Acc: 0.9770
🕒 Epoch 26/100 | Train Loss: 0.4284 | Val Loss: 0.4486 | Val Acc: 0.9839
🕒 Epoch 27/100 | Train Loss: 0.4262 | Val Loss: 0.4534 | Val Acc: 0.9862
🕒 Epoch 28/100 | Train Loss: 0.4256 | Val Loss: 0.4391 | Val Acc: 0.9931
⏹️ Early stopping.
✅ Fold 1 complete. Saved: ./output/models/ConvNeXt+4cbam+res+no-norm+dataset1_kfold+dataset1_kfold_fold1.pth

📂 Fold 2/5
🕒 Epoch 1/100 | Train Loss: 0.7719 | Val Loss: 0.5120 | Val Acc: 0.9724
💾 Best model updated (val acc: 0.9724)
🕒 Epoch 2/100 | Train Loss: 0.5006 | Val Loss: 0.4978 | Val Acc: 0.9793
💾 Best model updated (val acc: 0.9793)
🕒 Epoch 3/100 | Train Loss: 0.4782 | Val Loss: 0.4702 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 4/100 | Train Loss: 0.4677 | Val Loss: 0.4591 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 5/100 | Train Loss: 0.4572 | Val Loss: 0.4669 | Val Acc: 0.9908
🕒 Epoch 6/100 | Train Loss: 0.4420 | Val Loss: 0.5034 | Val Acc: 0.9608
🕒 Epoch 7/100 | Train Loss: 0.4636 | Val Loss: 0.4633 | Val Acc: 0.9885
🕒 Epoch 8/100 | Train Loss: 0.4426 | Val Loss: 0.4452 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 9/100 | Train Loss: 0.4516 | Val Loss: 0.4460 | Val Acc: 0.9931
🕒 Epoch 10/100 | Train Loss: 0.4301 | Val Loss: 0.4487 | Val Acc: 0.9862
🕒 Epoch 11/100 | Train Loss: 0.4336 | Val Loss: 0.4961 | Val Acc: 0.9747
🕒 Epoch 12/100 | Train Loss: 0.4418 | Val Loss: 0.4539 | Val Acc: 0.9885
🕒 Epoch 13/100 | Train Loss: 0.4422 | Val Loss: 0.4670 | Val Acc: 0.9885
🕒 Epoch 14/100 | Train Loss: 0.4501 | Val Loss: 0.4484 | Val Acc: 0.9908
🕒 Epoch 15/100 | Train Loss: 0.4354 | Val Loss: 0.4682 | Val Acc: 0.9770
🕒 Epoch 16/100 | Train Loss: 0.4510 | Val Loss: 0.4726 | Val Acc: 0.9839
🕒 Epoch 17/100 | Train Loss: 0.4494 | Val Loss: 0.4639 | Val Acc: 0.9862
🕒 Epoch 18/100 | Train Loss: 0.4369 | Val Loss: 0.4487 | Val Acc: 0.9862
⏹️ Early stopping.
✅ Fold 2 complete. Saved: ./output/models/ConvNeXt+4cbam+res+no-norm+dataset1_kfold+dataset1_kfold_fold2.pth

📂 Fold 3/5
🕒 Epoch 1/100 | Train Loss: 0.7679 | Val Loss: 0.5199 | Val Acc: 0.9700
💾 Best model updated (val acc: 0.9700)
🕒 Epoch 2/100 | Train Loss: 0.5156 | Val Loss: 0.4833 | Val Acc: 0.9746
💾 Best model updated (val acc: 0.9746)
🕒 Epoch 3/100 | Train Loss: 0.4881 | Val Loss: 0.4802 | Val Acc: 0.9792
💾 Best model updated (val acc: 0.9792)
🕒 Epoch 4/100 | Train Loss: 0.4535 | Val Loss: 0.4927 | Val Acc: 0.9677
🕒 Epoch 5/100 | Train Loss: 0.4682 | Val Loss: 0.4666 | Val Acc: 0.9746
💾 Best model updated (val acc: 0.9746)
🕒 Epoch 6/100 | Train Loss: 0.4439 | Val Loss: 0.4553 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 7/100 | Train Loss: 0.4658 | Val Loss: 0.4752 | Val Acc: 0.9792
🕒 Epoch 8/100 | Train Loss: 0.4608 | Val Loss: 0.4979 | Val Acc: 0.9723
🕒 Epoch 9/100 | Train Loss: 0.4681 | Val Loss: 0.4786 | Val Acc: 0.9861
🕒 Epoch 10/100 | Train Loss: 0.4454 | Val Loss: 0.4527 | Val Acc: 0.9861
💾 Best model updated (val acc: 0.9861)
🕒 Epoch 11/100 | Train Loss: 0.4293 | Val Loss: 0.4485 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 12/100 | Train Loss: 0.4334 | Val Loss: 0.4546 | Val Acc: 0.9885
🕒 Epoch 13/100 | Train Loss: 0.4285 | Val Loss: 0.4518 | Val Acc: 0.9861
🕒 Epoch 14/100 | Train Loss: 0.4375 | Val Loss: 0.4462 | Val Acc: 0.9885
💾 Best model updated (val acc: 0.9885)
🕒 Epoch 15/100 | Train Loss: 0.4349 | Val Loss: 0.4717 | Val Acc: 0.9815
🕒 Epoch 16/100 | Train Loss: 0.4427 | Val Loss: 0.4744 | Val Acc: 0.9769
🕒 Epoch 17/100 | Train Loss: 0.4295 | Val Loss: 0.4510 | Val Acc: 0.9861
🕒 Epoch 18/100 | Train Loss: 0.4291 | Val Loss: 0.4495 | Val Acc: 0.9838
🕒 Epoch 19/100 | Train Loss: 0.4301 | Val Loss: 0.4493 | Val Acc: 0.9931
🕒 Epoch 20/100 | Train Loss: 0.4303 | Val Loss: 0.4365 | Val Acc: 0.9931
💾 Best model updated (val acc: 0.9931)
🕒 Epoch 21/100 | Train Loss: 0.4258 | Val Loss: 0.4549 | Val Acc: 0.9861
🕒 Epoch 22/100 | Train Loss: 0.4305 | Val Loss: 0.4525 | Val Acc: 0.9885
🕒 Epoch 23/100 | Train Loss: 0.4236 | Val Loss: 0.4503 | Val Acc: 0.9908
🕒 Epoch 24/100 | Train Loss: 0.4234 | Val Loss: 0.4666 | Val Acc: 0.9861
🕒 Epoch 25/100 | Train Loss: 0.4247 | Val Loss: 0.4372 | Val Acc: 0.9931
🕒 Epoch 26/100 | Train Loss: 0.4225 | Val Loss: 0.4406 | Val Acc: 0.9931
🕒 Epoch 27/100 | Train Loss: 0.4265 | Val Loss: 0.4700 | Val Acc: 0.9838
🕒 Epoch 28/100 | Train Loss: 0.4296 | Val Loss: 0.4558 | Val Acc: 0.9838
🕒 Epoch 29/100 | Train Loss: 0.4241 | Val Loss: 0.4441 | Val Acc: 0.9908
🕒 Epoch 30/100 | Train Loss: 0.4221 | Val Loss: 0.4488 | Val Acc: 0.9885
⏹️ Early stopping.
✅ Fold 3 complete. Saved: ./output/models/ConvNeXt+4cbam+res+no-norm+dataset1_kfold+dataset1_kfold_fold3.pth

📂 Fold 4/5
🕒 Epoch 1/100 | Train Loss: 0.7772 | Val Loss: 0.7260 | Val Acc: 0.8637
💾 Best model updated (val acc: 0.8637)
🕒 Epoch 2/100 | Train Loss: 0.5118 | Val Loss: 0.5177 | Val Acc: 0.9538
💾 Best model updated (val acc: 0.9538)
🕒 Epoch 3/100 | Train Loss: 0.4697 | Val Loss: 0.5274 | Val Acc: 0.9515
🕒 Epoch 4/100 | Train Loss: 0.4587 | Val Loss: 0.4706 | Val Acc: 0.9815
💾 Best model updated (val acc: 0.9815)
🕒 Epoch 5/100 | Train Loss: 0.4619 | Val Loss: 0.4857 | Val Acc: 0.9815
🕒 Epoch 6/100 | Train Loss: 0.4491 | Val Loss: 0.4688 | Val Acc: 0.9861
💾 Best model updated (val acc: 0.9861)
🕒 Epoch 7/100 | Train Loss: 0.4360 | Val Loss: 0.4469 | Val Acc: 0.9954
💾 Best model updated (val acc: 0.9954)
🕒 Epoch 8/100 | Train Loss: 0.4368 | Val Loss: 0.4835 | Val Acc: 0.9838
🕒 Epoch 9/100 | Train Loss: 0.4380 | Val Loss: 0.4463 | Val Acc: 0.9954
💾 Best model updated (val acc: 0.9954)
🕒 Epoch 10/100 | Train Loss: 0.4317 | Val Loss: 0.4644 | Val Acc: 0.9908
🕒 Epoch 11/100 | Train Loss: 0.4419 | Val Loss: 0.4788 | Val Acc: 0.9792
🕒 Epoch 12/100 | Train Loss: 0.4519 | Val Loss: 0.4853 | Val Acc: 0.9815
🕒 Epoch 13/100 | Train Loss: 0.4422 | Val Loss: 0.4644 | Val Acc: 0.9838
🕒 Epoch 14/100 | Train Loss: 0.4396 | Val Loss: 0.4511 | Val Acc: 0.9908
🕒 Epoch 15/100 | Train Loss: 0.4324 | Val Loss: 0.4575 | Val Acc: 0.9861
🕒 Epoch 16/100 | Train Loss: 0.4325 | Val Loss: 0.4560 | Val Acc: 0.9861
🕒 Epoch 17/100 | Train Loss: 0.4277 | Val Loss: 0.4583 | Val Acc: 0.9861
🕒 Epoch 18/100 | Train Loss: 0.4344 | Val Loss: 0.4750 | Val Acc: 0.9769
🕒 Epoch 19/100 | Train Loss: 0.4237 | Val Loss: 0.4485 | Val Acc: 0.9885
⏹️ Early stopping.
✅ Fold 4 complete. Saved: ./output/models/ConvNeXt+4cbam+res+no-norm+dataset1_kfold+dataset1_kfold_fold4.pth

📂 Fold 5/5
🕒 Epoch 1/100 | Train Loss: 0.7275 | Val Loss: 0.5698 | Val Acc: 0.9515
💾 Best model updated (val acc: 0.9515)
🕒 Epoch 2/100 | Train Loss: 0.4982 | Val Loss: 0.5975 | Val Acc: 0.9330
🕒 Epoch 3/100 | Train Loss: 0.4908 | Val Loss: 0.5165 | Val Acc: 0.9584
💾 Best model updated (val acc: 0.9584)
🕒 Epoch 4/100 | Train Loss: 0.4623 | Val Loss: 0.4800 | Val Acc: 0.9769
💾 Best model updated (val acc: 0.9769)
🕒 Epoch 5/100 | Train Loss: 0.4440 | Val Loss: 0.4612 | Val Acc: 0.9861
💾 Best model updated (val acc: 0.9861)
🕒 Epoch 6/100 | Train Loss: 0.4452 | Val Loss: 0.4850 | Val Acc: 0.9723
🕒 Epoch 7/100 | Train Loss: 0.4665 | Val Loss: 0.4707 | Val Acc: 0.9792
🕒 Epoch 8/100 | Train Loss: 0.4497 | Val Loss: 0.5129 | Val Acc: 0.9607
🕒 Epoch 9/100 | Train Loss: 0.4392 | Val Loss: 0.4584 | Val Acc: 0.9861
💾 Best model updated (val acc: 0.9861)
🕒 Epoch 10/100 | Train Loss: 0.4293 | Val Loss: 0.4538 | Val Acc: 0.9838
💾 Best model updated (val acc: 0.9838)
🕒 Epoch 11/100 | Train Loss: 0.4528 | Val Loss: 0.4598 | Val Acc: 0.9908
🕒 Epoch 12/100 | Train Loss: 0.4572 | Val Loss: 0.5046 | Val Acc: 0.9654
🕒 Epoch 13/100 | Train Loss: 0.4616 | Val Loss: 0.4754 | Val Acc: 0.9792
🕒 Epoch 14/100 | Train Loss: 0.4443 | Val Loss: 0.4654 | Val Acc: 0.9815
🕒 Epoch 15/100 | Train Loss: 0.4318 | Val Loss: 0.4581 | Val Acc: 0.9815
🕒 Epoch 16/100 | Train Loss: 0.4283 | Val Loss: 0.4587 | Val Acc: 0.9815
🕒 Epoch 17/100 | Train Loss: 0.4263 | Val Loss: 0.4594 | Val Acc: 0.9861
🕒 Epoch 18/100 | Train Loss: 0.4284 | Val Loss: 0.4600 | Val Acc: 0.9838
🕒 Epoch 19/100 | Train Loss: 0.4296 | Val Loss: 0.4574 | Val Acc: 0.9838
🕒 Epoch 20/100 | Train Loss: 0.4259 | Val Loss: 0.4602 | Val Acc: 0.9815
⏹️ Early stopping.
✅ Fold 5 complete. Saved: ./output/models/ConvNeXt+4cbam+res+no-norm+dataset1_kfold+dataset1_kfold_fold5.pth
📂 Training metrics plot saved for Fold 1: output/test/fold_1/training_metrics.png
📂 Training metrics plot saved for Fold 2: output/test/fold_2/training_metrics.png
📂 Training metrics plot saved for Fold 3: output/test/fold_3/training_metrics.png
📂 Training metrics plot saved for Fold 4: output/test/fold_4/training_metrics.png
📂 Training metrics plot saved for Fold 5: output/test/fold_5/training_metrics.png
🎉 All folds completed.
🚀 Evaluating 5 fold models on test set

📂 Evaluating Fold 1
📊 Fold 1 Metrics:
   - Accuracy: 0.9871
   - Precision: 0.9873
   - Recall: 0.9873
   - F1 Score: 0.9873

📂 Evaluating Fold 2
📊 Fold 2 Metrics:
   - Accuracy: 0.9742
   - Precision: 0.9751
   - Recall: 0.9747
   - F1 Score: 0.9745

📂 Evaluating Fold 3
📊 Fold 3 Metrics:
   - Accuracy: 0.9890
   - Precision: 0.9892
   - Recall: 0.9891
   - F1 Score: 0.9891

📂 Evaluating Fold 4
📊 Fold 4 Metrics:
   - Accuracy: 0.9871
   - Precision: 0.9875
   - Recall: 0.9873
   - F1 Score: 0.9873

📂 Evaluating Fold 5
📊 Fold 5 Metrics:
   - Accuracy: 0.9779
   - Precision: 0.9785
   - Recall: 0.9784
   - F1 Score: 0.9782

🧾 Classification Report for ConvNeXt+4cbam+res+no-norm+dataset1_kfold (Majority Vote from 5 folds):

                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    0.9886    0.9943        88
           brown_spot     0.9783    0.9677    0.9730        93
              healthy     0.9688    1.0000    0.9841        93
           leaf_blast     0.9889    0.9780    0.9834        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9890       543
            macro avg     0.9893    0.9891    0.9891       543
         weighted avg     0.9891    0.9890    0.9889       543

🔢 Confusion Matrix:
 [[87  0  1  0  0  0]
 [ 0 90  2  1  0  0]
 [ 0  0 93  0  0  0]
 [ 0  2  0 89  0  0]
 [ 0  0  0  0 90  0]
 [ 0  0  0  0  0 88]]

📊 Average Metrics Across All Folds:
   - Accuracy: 0.9831
   - Precision: 0.9835
   - Recall: 0.9833
   - F1 Score: 0.9833
🚀 Starting training with 5-Fold Cross-Validation for model: ConvNeXt+4cbam+res+last-norm+dataset1_kfold
/media/data3/users/datlht/Rice_leaf_disease_detection/load_data.py:81: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/media/data3/users/datlht/Rice_leaf_disease_detection/load_data.py:84: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from font(s) DejaVu Sans.
  plt.savefig(plot_path)
✅ Saved fold class distribution plot to: output/fold_class_distribution.png

📂 Fold 1/5
🕒 Epoch 1/100 | Train Loss: 0.7584 | Val Loss: 0.5423 | Val Acc: 0.9493
💾 Best model updated (val acc: 0.9493)
🕒 Epoch 2/100 | Train Loss: 0.5180 | Val Loss: 0.4933 | Val Acc: 0.9677
💾 Best model updated (val acc: 0.9677)
🕒 Epoch 3/100 | Train Loss: 0.5054 | Val Loss: 0.4569 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 4/100 | Train Loss: 0.4595 | Val Loss: 0.4892 | Val Acc: 0.9747
🕒 Epoch 5/100 | Train Loss: 0.4584 | Val Loss: 0.4793 | Val Acc: 0.9793
🕒 Epoch 6/100 | Train Loss: 0.4436 | Val Loss: 0.4531 | Val Acc: 0.9839
💾 Best model updated (val acc: 0.9839)
🕒 Epoch 7/100 | Train Loss: 0.4449 | Val Loss: 0.4570 | Val Acc: 0.9816
🕒 Epoch 8/100 | Train Loss: 0.4399 | Val Loss: 0.4414 | Val Acc: 0.9931
💾 Best model updated (val acc: 0.9931)
🕒 Epoch 9/100 | Train Loss: 0.4403 | Val Loss: 0.4395 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 10/100 | Train Loss: 0.4335 | Val Loss: 0.4369 | Val Acc: 0.9954
💾 Best model updated (val acc: 0.9954)
🕒 Epoch 11/100 | Train Loss: 0.4547 | Val Loss: 0.4494 | Val Acc: 0.9839
🕒 Epoch 12/100 | Train Loss: 0.4458 | Val Loss: 0.5108 | Val Acc: 0.9724
🕒 Epoch 13/100 | Train Loss: 0.4629 | Val Loss: 0.4494 | Val Acc: 0.9908
🕒 Epoch 14/100 | Train Loss: 0.4478 | Val Loss: 0.4510 | Val Acc: 0.9885
🕒 Epoch 15/100 | Train Loss: 0.4403 | Val Loss: 0.4591 | Val Acc: 0.9770
🕒 Epoch 16/100 | Train Loss: 0.4347 | Val Loss: 0.4379 | Val Acc: 0.9954
🕒 Epoch 17/100 | Train Loss: 0.4371 | Val Loss: 0.4423 | Val Acc: 0.9931
🕒 Epoch 18/100 | Train Loss: 0.4371 | Val Loss: 0.4507 | Val Acc: 0.9885
🕒 Epoch 19/100 | Train Loss: 0.4405 | Val Loss: 0.4487 | Val Acc: 0.9908
🕒 Epoch 20/100 | Train Loss: 0.4276 | Val Loss: 0.4354 | Val Acc: 0.9954
💾 Best model updated (val acc: 0.9954)
🕒 Epoch 21/100 | Train Loss: 0.4255 | Val Loss: 0.4351 | Val Acc: 0.9954
💾 Best model updated (val acc: 0.9954)
🕒 Epoch 22/100 | Train Loss: 0.4266 | Val Loss: 0.4423 | Val Acc: 0.9908
🕒 Epoch 23/100 | Train Loss: 0.4241 | Val Loss: 0.4421 | Val Acc: 0.9908
🕒 Epoch 24/100 | Train Loss: 0.4227 | Val Loss: 0.4390 | Val Acc: 0.9931
🕒 Epoch 25/100 | Train Loss: 0.4265 | Val Loss: 0.4372 | Val Acc: 0.9908
🕒 Epoch 26/100 | Train Loss: 0.4229 | Val Loss: 0.4390 | Val Acc: 0.9908
🕒 Epoch 27/100 | Train Loss: 0.4235 | Val Loss: 0.4388 | Val Acc: 0.9931
🕒 Epoch 28/100 | Train Loss: 0.4223 | Val Loss: 0.4411 | Val Acc: 0.9908
🕒 Epoch 29/100 | Train Loss: 0.4223 | Val Loss: 0.4336 | Val Acc: 0.9954
💾 Best model updated (val acc: 0.9954)
🕒 Epoch 30/100 | Train Loss: 0.4224 | Val Loss: 0.4357 | Val Acc: 0.9931
🕒 Epoch 31/100 | Train Loss: 0.4218 | Val Loss: 0.4359 | Val Acc: 0.9908
🕒 Epoch 32/100 | Train Loss: 0.4225 | Val Loss: 0.4362 | Val Acc: 0.9908
🕒 Epoch 33/100 | Train Loss: 0.4216 | Val Loss: 0.4380 | Val Acc: 0.9908
🕒 Epoch 34/100 | Train Loss: 0.4217 | Val Loss: 0.4347 | Val Acc: 0.9954
🕒 Epoch 35/100 | Train Loss: 0.4218 | Val Loss: 0.4351 | Val Acc: 0.9931
🕒 Epoch 36/100 | Train Loss: 0.4216 | Val Loss: 0.4342 | Val Acc: 0.9954
🕒 Epoch 37/100 | Train Loss: 0.4214 | Val Loss: 0.4343 | Val Acc: 0.9954
🕒 Epoch 38/100 | Train Loss: 0.4222 | Val Loss: 0.4338 | Val Acc: 0.9954
🕒 Epoch 39/100 | Train Loss: 0.4214 | Val Loss: 0.4338 | Val Acc: 0.9954
⏹️ Early stopping.
✅ Fold 1 complete. Saved: ./output/models/ConvNeXt+4cbam+res+last-norm+dataset1_kfold+dataset1_kfold_fold1.pth

📂 Fold 2/5
🕒 Epoch 1/100 | Train Loss: 0.7541 | Val Loss: 0.5487 | Val Acc: 0.9447
💾 Best model updated (val acc: 0.9447)
🕒 Epoch 2/100 | Train Loss: 0.5223 | Val Loss: 0.5040 | Val Acc: 0.9654
💾 Best model updated (val acc: 0.9654)
🕒 Epoch 3/100 | Train Loss: 0.4905 | Val Loss: 0.5081 | Val Acc: 0.9562
🕒 Epoch 4/100 | Train Loss: 0.4546 | Val Loss: 0.4749 | Val Acc: 0.9770
💾 Best model updated (val acc: 0.9770)
🕒 Epoch 5/100 | Train Loss: 0.4496 | Val Loss: 0.4543 | Val Acc: 0.9862
💾 Best model updated (val acc: 0.9862)
🕒 Epoch 6/100 | Train Loss: 0.4507 | Val Loss: 0.4541 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 7/100 | Train Loss: 0.4487 | Val Loss: 0.4559 | Val Acc: 0.9816
🕒 Epoch 8/100 | Train Loss: 0.4448 | Val Loss: 0.4529 | Val Acc: 0.9862
💾 Best model updated (val acc: 0.9862)
🕒 Epoch 9/100 | Train Loss: 0.4472 | Val Loss: 0.4902 | Val Acc: 0.9654
🕒 Epoch 10/100 | Train Loss: 0.4341 | Val Loss: 0.4668 | Val Acc: 0.9793
🕒 Epoch 11/100 | Train Loss: 0.4420 | Val Loss: 0.5036 | Val Acc: 0.9700
🕒 Epoch 12/100 | Train Loss: 0.4438 | Val Loss: 0.4585 | Val Acc: 0.9862
🕒 Epoch 13/100 | Train Loss: 0.4396 | Val Loss: 0.4491 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 14/100 | Train Loss: 0.4293 | Val Loss: 0.4623 | Val Acc: 0.9816
🕒 Epoch 15/100 | Train Loss: 0.4284 | Val Loss: 0.4448 | Val Acc: 0.9931
💾 Best model updated (val acc: 0.9931)
🕒 Epoch 16/100 | Train Loss: 0.4373 | Val Loss: 0.4651 | Val Acc: 0.9862
🕒 Epoch 17/100 | Train Loss: 0.4297 | Val Loss: 0.4624 | Val Acc: 0.9816
🕒 Epoch 18/100 | Train Loss: 0.4239 | Val Loss: 0.4470 | Val Acc: 0.9885
🕒 Epoch 19/100 | Train Loss: 0.4252 | Val Loss: 0.4506 | Val Acc: 0.9839
🕒 Epoch 20/100 | Train Loss: 0.4272 | Val Loss: 0.4683 | Val Acc: 0.9816
🕒 Epoch 21/100 | Train Loss: 0.4334 | Val Loss: 0.4684 | Val Acc: 0.9747
🕒 Epoch 22/100 | Train Loss: 0.4248 | Val Loss: 0.4544 | Val Acc: 0.9816
🕒 Epoch 23/100 | Train Loss: 0.4228 | Val Loss: 0.4687 | Val Acc: 0.9747
🕒 Epoch 24/100 | Train Loss: 0.4276 | Val Loss: 0.4600 | Val Acc: 0.9839
🕒 Epoch 25/100 | Train Loss: 0.4263 | Val Loss: 0.4372 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 26/100 | Train Loss: 0.4264 | Val Loss: 0.4492 | Val Acc: 0.9839
🕒 Epoch 27/100 | Train Loss: 0.4239 | Val Loss: 0.4443 | Val Acc: 0.9885
🕒 Epoch 28/100 | Train Loss: 0.4225 | Val Loss: 0.4495 | Val Acc: 0.9885
🕒 Epoch 29/100 | Train Loss: 0.4259 | Val Loss: 0.4507 | Val Acc: 0.9885
🕒 Epoch 30/100 | Train Loss: 0.4281 | Val Loss: 0.4419 | Val Acc: 0.9908
🕒 Epoch 31/100 | Train Loss: 0.4254 | Val Loss: 0.4499 | Val Acc: 0.9862
🕒 Epoch 32/100 | Train Loss: 0.4229 | Val Loss: 0.4396 | Val Acc: 0.9908
🕒 Epoch 33/100 | Train Loss: 0.4246 | Val Loss: 0.4602 | Val Acc: 0.9770
🕒 Epoch 34/100 | Train Loss: 0.4230 | Val Loss: 0.4476 | Val Acc: 0.9885
🕒 Epoch 35/100 | Train Loss: 0.4234 | Val Loss: 0.4440 | Val Acc: 0.9908
⏹️ Early stopping.
✅ Fold 2 complete. Saved: ./output/models/ConvNeXt+4cbam+res+last-norm+dataset1_kfold+dataset1_kfold_fold2.pth

📂 Fold 3/5
🕒 Epoch 1/100 | Train Loss: 0.7995 | Val Loss: 0.5602 | Val Acc: 0.9423
💾 Best model updated (val acc: 0.9423)
🕒 Epoch 2/100 | Train Loss: 0.5221 | Val Loss: 0.5088 | Val Acc: 0.9677
💾 Best model updated (val acc: 0.9677)
🕒 Epoch 3/100 | Train Loss: 0.4865 | Val Loss: 0.4721 | Val Acc: 0.9815
💾 Best model updated (val acc: 0.9815)
🕒 Epoch 4/100 | Train Loss: 0.4745 | Val Loss: 0.4907 | Val Acc: 0.9723
🕒 Epoch 5/100 | Train Loss: 0.4591 | Val Loss: 0.4541 | Val Acc: 0.9885
💾 Best model updated (val acc: 0.9885)
🕒 Epoch 6/100 | Train Loss: 0.4513 | Val Loss: 0.4822 | Val Acc: 0.9723
🕒 Epoch 7/100 | Train Loss: 0.4641 | Val Loss: 0.4566 | Val Acc: 0.9861
🕒 Epoch 8/100 | Train Loss: 0.4433 | Val Loss: 0.4463 | Val Acc: 0.9931
💾 Best model updated (val acc: 0.9931)
🕒 Epoch 9/100 | Train Loss: 0.4381 | Val Loss: 0.4736 | Val Acc: 0.9723
🕒 Epoch 10/100 | Train Loss: 0.4391 | Val Loss: 0.4659 | Val Acc: 0.9815
🕒 Epoch 11/100 | Train Loss: 0.4330 | Val Loss: 0.4472 | Val Acc: 0.9885
🕒 Epoch 12/100 | Train Loss: 0.4372 | Val Loss: 0.4711 | Val Acc: 0.9815
🕒 Epoch 13/100 | Train Loss: 0.4598 | Val Loss: 0.4422 | Val Acc: 0.9931
💾 Best model updated (val acc: 0.9931)
🕒 Epoch 14/100 | Train Loss: 0.4449 | Val Loss: 0.4588 | Val Acc: 0.9885
🕒 Epoch 15/100 | Train Loss: 0.4410 | Val Loss: 0.4545 | Val Acc: 0.9838
🕒 Epoch 16/100 | Train Loss: 0.4264 | Val Loss: 0.4450 | Val Acc: 0.9908
🕒 Epoch 17/100 | Train Loss: 0.4373 | Val Loss: 0.4521 | Val Acc: 0.9861
🕒 Epoch 18/100 | Train Loss: 0.4268 | Val Loss: 0.4609 | Val Acc: 0.9861
🕒 Epoch 19/100 | Train Loss: 0.4240 | Val Loss: 0.4543 | Val Acc: 0.9861
🕒 Epoch 20/100 | Train Loss: 0.4285 | Val Loss: 0.4662 | Val Acc: 0.9861
🕒 Epoch 21/100 | Train Loss: 0.4312 | Val Loss: 0.4503 | Val Acc: 0.9885
🕒 Epoch 22/100 | Train Loss: 0.4259 | Val Loss: 0.4440 | Val Acc: 0.9931
🕒 Epoch 23/100 | Train Loss: 0.4254 | Val Loss: 0.4408 | Val Acc: 0.9931
💾 Best model updated (val acc: 0.9931)
🕒 Epoch 24/100 | Train Loss: 0.4252 | Val Loss: 0.4453 | Val Acc: 0.9908
🕒 Epoch 25/100 | Train Loss: 0.4240 | Val Loss: 0.4428 | Val Acc: 0.9931
🕒 Epoch 26/100 | Train Loss: 0.4234 | Val Loss: 0.4396 | Val Acc: 0.9931
💾 Best model updated (val acc: 0.9931)
🕒 Epoch 27/100 | Train Loss: 0.4227 | Val Loss: 0.4407 | Val Acc: 0.9931
🕒 Epoch 28/100 | Train Loss: 0.4234 | Val Loss: 0.4362 | Val Acc: 0.9931
💾 Best model updated (val acc: 0.9931)
🕒 Epoch 29/100 | Train Loss: 0.4220 | Val Loss: 0.4351 | Val Acc: 0.9954
💾 Best model updated (val acc: 0.9954)
🕒 Epoch 30/100 | Train Loss: 0.4218 | Val Loss: 0.4355 | Val Acc: 0.9954
🕒 Epoch 31/100 | Train Loss: 0.4235 | Val Loss: 0.4336 | Val Acc: 0.9954
💾 Best model updated (val acc: 0.9954)
🕒 Epoch 32/100 | Train Loss: 0.4219 | Val Loss: 0.4383 | Val Acc: 0.9954
🕒 Epoch 33/100 | Train Loss: 0.4215 | Val Loss: 0.4366 | Val Acc: 0.9954
🕒 Epoch 34/100 | Train Loss: 0.4238 | Val Loss: 0.4360 | Val Acc: 0.9931
🕒 Epoch 35/100 | Train Loss: 0.4216 | Val Loss: 0.4372 | Val Acc: 0.9931
🕒 Epoch 36/100 | Train Loss: 0.4215 | Val Loss: 0.4372 | Val Acc: 0.9931
🕒 Epoch 37/100 | Train Loss: 0.4217 | Val Loss: 0.4364 | Val Acc: 0.9931
🕒 Epoch 38/100 | Train Loss: 0.4214 | Val Loss: 0.4365 | Val Acc: 0.9931
🕒 Epoch 39/100 | Train Loss: 0.4215 | Val Loss: 0.4359 | Val Acc: 0.9931
🕒 Epoch 40/100 | Train Loss: 0.4213 | Val Loss: 0.4358 | Val Acc: 0.9931
🕒 Epoch 41/100 | Train Loss: 0.4213 | Val Loss: 0.4358 | Val Acc: 0.9931
⏹️ Early stopping.
✅ Fold 3 complete. Saved: ./output/models/ConvNeXt+4cbam+res+last-norm+dataset1_kfold+dataset1_kfold_fold3.pth

📂 Fold 4/5
🕒 Epoch 1/100 | Train Loss: 0.8030 | Val Loss: 0.5304 | Val Acc: 0.9492
💾 Best model updated (val acc: 0.9492)
🕒 Epoch 2/100 | Train Loss: 0.4992 | Val Loss: 0.4983 | Val Acc: 0.9700
💾 Best model updated (val acc: 0.9700)
🕒 Epoch 3/100 | Train Loss: 0.4801 | Val Loss: 0.4774 | Val Acc: 0.9815
💾 Best model updated (val acc: 0.9815)
🕒 Epoch 4/100 | Train Loss: 0.5030 | Val Loss: 0.5154 | Val Acc: 0.9584
🕒 Epoch 5/100 | Train Loss: 0.4503 | Val Loss: 0.4619 | Val Acc: 0.9792
💾 Best model updated (val acc: 0.9792)
🕒 Epoch 6/100 | Train Loss: 0.4568 | Val Loss: 0.4845 | Val Acc: 0.9746
🕒 Epoch 7/100 | Train Loss: 0.4534 | Val Loss: 0.4629 | Val Acc: 0.9838
🕒 Epoch 8/100 | Train Loss: 0.4429 | Val Loss: 0.4518 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 9/100 | Train Loss: 0.4501 | Val Loss: 0.4701 | Val Acc: 0.9769
🕒 Epoch 10/100 | Train Loss: 0.4442 | Val Loss: 0.4628 | Val Acc: 0.9861
🕒 Epoch 11/100 | Train Loss: 0.4473 | Val Loss: 0.4640 | Val Acc: 0.9861
🕒 Epoch 12/100 | Train Loss: 0.4459 | Val Loss: 0.4658 | Val Acc: 0.9861
🕒 Epoch 13/100 | Train Loss: 0.4414 | Val Loss: 0.4508 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 14/100 | Train Loss: 0.4315 | Val Loss: 0.4522 | Val Acc: 0.9931
🕒 Epoch 15/100 | Train Loss: 0.4346 | Val Loss: 0.4609 | Val Acc: 0.9908
🕒 Epoch 16/100 | Train Loss: 0.4271 | Val Loss: 0.4452 | Val Acc: 0.9931
💾 Best model updated (val acc: 0.9931)
🕒 Epoch 17/100 | Train Loss: 0.4320 | Val Loss: 0.4465 | Val Acc: 0.9908
🕒 Epoch 18/100 | Train Loss: 0.4271 | Val Loss: 0.4417 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 19/100 | Train Loss: 0.4234 | Val Loss: 0.4621 | Val Acc: 0.9838
🕒 Epoch 20/100 | Train Loss: 0.4365 | Val Loss: 0.4534 | Val Acc: 0.9861
🕒 Epoch 21/100 | Train Loss: 0.4423 | Val Loss: 0.4561 | Val Acc: 0.9885
🕒 Epoch 22/100 | Train Loss: 0.4323 | Val Loss: 0.4599 | Val Acc: 0.9815
🕒 Epoch 23/100 | Train Loss: 0.4282 | Val Loss: 0.4467 | Val Acc: 0.9931
🕒 Epoch 24/100 | Train Loss: 0.4226 | Val Loss: 0.4361 | Val Acc: 0.9954
💾 Best model updated (val acc: 0.9954)
🕒 Epoch 25/100 | Train Loss: 0.4263 | Val Loss: 0.4522 | Val Acc: 0.9861
🕒 Epoch 26/100 | Train Loss: 0.4229 | Val Loss: 0.4495 | Val Acc: 0.9861
🕒 Epoch 27/100 | Train Loss: 0.4222 | Val Loss: 0.4365 | Val Acc: 0.9954
🕒 Epoch 28/100 | Train Loss: 0.4215 | Val Loss: 0.4357 | Val Acc: 0.9954
💾 Best model updated (val acc: 0.9954)
🕒 Epoch 29/100 | Train Loss: 0.4249 | Val Loss: 0.4400 | Val Acc: 0.9908
🕒 Epoch 30/100 | Train Loss: 0.4252 | Val Loss: 0.4368 | Val Acc: 0.9954
🕒 Epoch 31/100 | Train Loss: 0.4232 | Val Loss: 0.4392 | Val Acc: 0.9931
🕒 Epoch 32/100 | Train Loss: 0.4218 | Val Loss: 0.4379 | Val Acc: 0.9931
🕒 Epoch 33/100 | Train Loss: 0.4253 | Val Loss: 0.4441 | Val Acc: 0.9908
🕒 Epoch 34/100 | Train Loss: 0.4224 | Val Loss: 0.4430 | Val Acc: 0.9931
🕒 Epoch 35/100 | Train Loss: 0.4217 | Val Loss: 0.4402 | Val Acc: 0.9931
🕒 Epoch 36/100 | Train Loss: 0.4215 | Val Loss: 0.4396 | Val Acc: 0.9931
🕒 Epoch 37/100 | Train Loss: 0.4214 | Val Loss: 0.4394 | Val Acc: 0.9931
🕒 Epoch 38/100 | Train Loss: 0.4215 | Val Loss: 0.4388 | Val Acc: 0.9931
⏹️ Early stopping.
✅ Fold 4 complete. Saved: ./output/models/ConvNeXt+4cbam+res+last-norm+dataset1_kfold+dataset1_kfold_fold4.pth

📂 Fold 5/5
🕒 Epoch 1/100 | Train Loss: 0.7856 | Val Loss: 0.5081 | Val Acc: 0.9677
💾 Best model updated (val acc: 0.9677)
🕒 Epoch 2/100 | Train Loss: 0.5197 | Val Loss: 0.5157 | Val Acc: 0.9630
🕒 Epoch 3/100 | Train Loss: 0.4955 | Val Loss: 0.4858 | Val Acc: 0.9792
💾 Best model updated (val acc: 0.9792)
🕒 Epoch 4/100 | Train Loss: 0.4623 | Val Loss: 0.5085 | Val Acc: 0.9584
🕒 Epoch 5/100 | Train Loss: 0.4561 | Val Loss: 0.4667 | Val Acc: 0.9815
💾 Best model updated (val acc: 0.9815)
🕒 Epoch 6/100 | Train Loss: 0.4580 | Val Loss: 0.4627 | Val Acc: 0.9792
💾 Best model updated (val acc: 0.9792)
🕒 Epoch 7/100 | Train Loss: 0.4434 | Val Loss: 0.4868 | Val Acc: 0.9654
🕒 Epoch 8/100 | Train Loss: 0.4669 | Val Loss: 0.4544 | Val Acc: 0.9861
💾 Best model updated (val acc: 0.9861)
🕒 Epoch 9/100 | Train Loss: 0.4462 | Val Loss: 0.4695 | Val Acc: 0.9815
🕒 Epoch 10/100 | Train Loss: 0.4566 | Val Loss: 0.4609 | Val Acc: 0.9838
🕒 Epoch 11/100 | Train Loss: 0.4397 | Val Loss: 0.4679 | Val Acc: 0.9792
🕒 Epoch 12/100 | Train Loss: 0.4416 | Val Loss: 0.4522 | Val Acc: 0.9861
💾 Best model updated (val acc: 0.9861)
🕒 Epoch 13/100 | Train Loss: 0.4278 | Val Loss: 0.4566 | Val Acc: 0.9838
🕒 Epoch 14/100 | Train Loss: 0.4296 | Val Loss: 0.4588 | Val Acc: 0.9792
🕒 Epoch 15/100 | Train Loss: 0.4278 | Val Loss: 0.4578 | Val Acc: 0.9861
🕒 Epoch 16/100 | Train Loss: 0.4383 | Val Loss: 0.4887 | Val Acc: 0.9677
🕒 Epoch 17/100 | Train Loss: 0.4332 | Val Loss: 0.4952 | Val Acc: 0.9700
🕒 Epoch 18/100 | Train Loss: 0.4326 | Val Loss: 0.4629 | Val Acc: 0.9792
🕒 Epoch 19/100 | Train Loss: 0.4292 | Val Loss: 0.4669 | Val Acc: 0.9769
🕒 Epoch 20/100 | Train Loss: 0.4381 | Val Loss: 0.4575 | Val Acc: 0.9861
🕒 Epoch 21/100 | Train Loss: 0.4244 | Val Loss: 0.4579 | Val Acc: 0.9861
🕒 Epoch 22/100 | Train Loss: 0.4224 | Val Loss: 0.4553 | Val Acc: 0.9838
⏹️ Early stopping.
✅ Fold 5 complete. Saved: ./output/models/ConvNeXt+4cbam+res+last-norm+dataset1_kfold+dataset1_kfold_fold5.pth
📂 Training metrics plot saved for Fold 1: output/test/fold_1/training_metrics.png
📂 Training metrics plot saved for Fold 2: output/test/fold_2/training_metrics.png
📂 Training metrics plot saved for Fold 3: output/test/fold_3/training_metrics.png
📂 Training metrics plot saved for Fold 4: output/test/fold_4/training_metrics.png
📂 Training metrics plot saved for Fold 5: output/test/fold_5/training_metrics.png
🎉 All folds completed.
🚀 Evaluating 5 fold models on test set

📂 Evaluating Fold 1
📊 Fold 1 Metrics:
   - Accuracy: 0.9926
   - Precision: 0.9929
   - Recall: 0.9928
   - F1 Score: 0.9928

📂 Evaluating Fold 2
📊 Fold 2 Metrics:
   - Accuracy: 0.9890
   - Precision: 0.9892
   - Recall: 0.9892
   - F1 Score: 0.9891

📂 Evaluating Fold 3
📊 Fold 3 Metrics:
   - Accuracy: 0.9853
   - Precision: 0.9855
   - Recall: 0.9854
   - F1 Score: 0.9854

📂 Evaluating Fold 4
📊 Fold 4 Metrics:
   - Accuracy: 0.9816
   - Precision: 0.9819
   - Recall: 0.9820
   - F1 Score: 0.9819

📂 Evaluating Fold 5
📊 Fold 5 Metrics:
   - Accuracy: 0.9853
   - Precision: 0.9856
   - Recall: 0.9855
   - F1 Score: 0.9855

🧾 Classification Report for ConvNeXt+4cbam+res+last-norm+dataset1_kfold (Majority Vote from 5 folds):

                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    1.0000    1.0000        88
           brown_spot     0.9889    0.9570    0.9727        93
              healthy     0.9789    1.0000    0.9894        93
           leaf_blast     0.9783    0.9890    0.9836        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9908       543
            macro avg     0.9910    0.9910    0.9909       543
         weighted avg     0.9908    0.9908    0.9908       543

🔢 Confusion Matrix:
 [[88  0  0  0  0  0]
 [ 0 89  2  2  0  0]
 [ 0  0 93  0  0  0]
 [ 0  1  0 90  0  0]
 [ 0  0  0  0 90  0]
 [ 0  0  0  0  0 88]]

📊 Average Metrics Across All Folds:
   - Accuracy: 0.9867
   - Precision: 0.9870
   - Recall: 0.9870
   - F1 Score: 0.9869

✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: 4cbam+res+batchnormlast+dataset1]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
🕒 Epoch 1/100 | Time: 69.67s | Train Loss: 0.7302 | Val Loss: 0.5281 | Val Acc: 0.9577 | LR: 0.000100 
💾 Saving best val acc: 0.9577
🕒 Epoch 2/100 | Time: 68.88s | Train Loss: 0.5197 | Val Loss: 0.5112 | Val Acc: 0.9669 | LR: 0.000100 
💾 Saving best val acc: 0.9669
🕒 Epoch 3/100 | Time: 68.72s | Train Loss: 0.4955 | Val Loss: 0.4840 | Val Acc: 0.9743 | LR: 0.000100 
💾 Saving best val acc: 0.9743
🕒 Epoch 4/100 | Time: 68.63s | Train Loss: 0.4885 | Val Loss: 0.5000 | Val Acc: 0.9651 | LR: 0.000099 
🕒 Epoch 5/100 | Time: 69.69s | Train Loss: 0.4640 | Val Loss: 0.5023 | Val Acc: 0.9688 | LR: 0.000098 
🕒 Epoch 6/100 | Time: 70.73s | Train Loss: 0.4565 | Val Loss: 0.4693 | Val Acc: 0.9871 | LR: 0.000098 
💾 Saving best val acc: 0.9871
🕒 Epoch 7/100 | Time: 69.19s | Train Loss: 0.4577 | Val Loss: 0.4684 | Val Acc: 0.9835 | LR: 0.000097 
💾 Saving best val acc: 0.9835
🕒 Epoch 8/100 | Time: 69.48s | Train Loss: 0.4489 | Val Loss: 0.4826 | Val Acc: 0.9779 | LR: 0.000095 
🕒 Epoch 9/100 | Time: 69.57s | Train Loss: 0.4695 | Val Loss: 0.4990 | Val Acc: 0.9743 | LR: 0.000094 
🕒 Epoch 10/100 | Time: 69.82s | Train Loss: 0.4602 | Val Loss: 0.4816 | Val Acc: 0.9816 | LR: 0.000092 
🕒 Epoch 11/100 | Time: 69.58s | Train Loss: 0.4481 | Val Loss: 0.4796 | Val Acc: 0.9798 | LR: 0.000091 
🕒 Epoch 12/100 | Time: 69.91s | Train Loss: 0.4513 | Val Loss: 0.4625 | Val Acc: 0.9835 | LR: 0.000089 
💾 Saving best val acc: 0.9835
🕒 Epoch 13/100 | Time: 70.67s | Train Loss: 0.4449 | Val Loss: 0.4673 | Val Acc: 0.9835 | LR: 0.000087 
🕒 Epoch 14/100 | Time: 70.86s | Train Loss: 0.4455 | Val Loss: 0.4682 | Val Acc: 0.9835 | LR: 0.000084 
🕒 Epoch 15/100 | Time: 70.28s | Train Loss: 0.4422 | Val Loss: 0.4570 | Val Acc: 0.9871 | LR: 0.000082 
💾 Saving best val acc: 0.9871
🕒 Epoch 16/100 | Time: 71.70s | Train Loss: 0.4393 | Val Loss: 0.4661 | Val Acc: 0.9871 | LR: 0.000080 
🕒 Epoch 17/100 | Time: 72.11s | Train Loss: 0.4423 | Val Loss: 0.4648 | Val Acc: 0.9853 | LR: 0.000077 
🕒 Epoch 18/100 | Time: 71.31s | Train Loss: 0.4480 | Val Loss: 0.4742 | Val Acc: 0.9798 | LR: 0.000074 
🕒 Epoch 19/100 | Time: 71.16s | Train Loss: 0.4543 | Val Loss: 0.4778 | Val Acc: 0.9779 | LR: 0.000072 
🕒 Epoch 20/100 | Time: 71.67s | Train Loss: 0.4428 | Val Loss: 0.4757 | Val Acc: 0.9816 | LR: 0.000069 
🕒 Epoch 21/100 | Time: 71.05s | Train Loss: 0.4363 | Val Loss: 0.4666 | Val Acc: 0.9816 | LR: 0.000066 
🕒 Epoch 22/100 | Time: 71.16s | Train Loss: 0.4367 | Val Loss: 0.4983 | Val Acc: 0.9688 | LR: 0.000063 
🕒 Epoch 23/100 | Time: 71.19s | Train Loss: 0.4378 | Val Loss: 0.4728 | Val Acc: 0.9779 | LR: 0.000060 
🕒 Epoch 24/100 | Time: 70.08s | Train Loss: 0.4408 | Val Loss: 0.4704 | Val Acc: 0.9798 | LR: 0.000057 
🕒 Epoch 25/100 | Time: 71.43s | Train Loss: 0.4341 | Val Loss: 0.4662 | Val Acc: 0.9816 | LR: 0.000054 
⏹️ Early stopping triggered.
✅ Training complete in 1758.66 seconds. Best model loaded.
📁 Model saved to ./output/models/4cbam+res+batchnormlast+dataset1+dataset1.pth
📂 Training metrics plot saved to: output/test/4cbam+res+batchnormlast+dataset1/training metric.png
Evaluate model:4cbam+res+batchnormlast+dataset1

🔥 Test Accuracy: 98.90%

📌 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    0.9886    0.9943        88
           brown_spot     0.9783    0.9677    0.9730        93
              healthy     0.9894    1.0000    0.9947        93
           leaf_blast     0.9674    0.9780    0.9727        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9890       543
            macro avg     0.9892    0.9891    0.9891       543
         weighted avg     0.9890    0.9890    0.9890       543

📂 Confusion matrix saved to: output/test/4cbam+res+batchnormlast+dataset1/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/4cbam+res+batchnormlast+dataset1/grad_cam folder!
Saved misclassified images to output/test/4cbam+res+batchnormlast+dataset1/misclassified_images.png


📂 Fold 1/5
🕒 Epoch 1/100 | Train Loss: 0.7260 | Val Loss: 0.5301 | Val Acc: 0.9493
💾 Best model updated (val acc: 0.9493)
🕒 Epoch 2/100 | Train Loss: 0.5348 | Val Loss: 0.4882 | Val Acc: 0.9677
💾 Best model updated (val acc: 0.9677)
🕒 Epoch 3/100 | Train Loss: 0.5062 | Val Loss: 0.4733 | Val Acc: 0.9816
💾 Best model updated (val acc: 0.9816)
🕒 Epoch 4/100 | Train Loss: 0.4727 | Val Loss: 0.4742 | Val Acc: 0.9793
🕒 Epoch 5/100 | Train Loss: 0.4705 | Val Loss: 0.4671 | Val Acc: 0.9862
💾 Best model updated (val acc: 0.9862)
🕒 Epoch 6/100 | Train Loss: 0.5038 | Val Loss: 0.5000 | Val Acc: 0.9677
🕒 Epoch 7/100 | Train Loss: 0.4724 | Val Loss: 0.4833 | Val Acc: 0.9724
🕒 Epoch 8/100 | Train Loss: 0.4535 | Val Loss: 0.4649 | Val Acc: 0.9724
💾 Best model updated (val acc: 0.9724)
🕒 Epoch 9/100 | Train Loss: 0.4543 | Val Loss: 0.4538 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 10/100 | Train Loss: 0.4591 | Val Loss: 0.5104 | Val Acc: 0.9608
🕒 Epoch 11/100 | Train Loss: 0.4573 | Val Loss: 0.4491 | Val Acc: 0.9862
💾 Best model updated (val acc: 0.9862)
🕒 Epoch 12/100 | Train Loss: 0.4441 | Val Loss: 0.4669 | Val Acc: 0.9793
🕒 Epoch 13/100 | Train Loss: 0.4450 | Val Loss: 0.4494 | Val Acc: 0.9839
🕒 Epoch 14/100 | Train Loss: 0.4446 | Val Loss: 0.4479 | Val Acc: 0.9885
💾 Best model updated (val acc: 0.9885)
🕒 Epoch 15/100 | Train Loss: 0.4483 | Val Loss: 0.4410 | Val Acc: 0.9931
💾 Best model updated (val acc: 0.9931)
🕒 Epoch 16/100 | Train Loss: 0.4475 | Val Loss: 0.4575 | Val Acc: 0.9885
🕒 Epoch 17/100 | Train Loss: 0.4473 | Val Loss: 0.4387 | Val Acc: 0.9931
💾 Best model updated (val acc: 0.9931)
🕒 Epoch 18/100 | Train Loss: 0.4568 | Val Loss: 0.4702 | Val Acc: 0.9816
🕒 Epoch 19/100 | Train Loss: 0.4419 | Val Loss: 0.4466 | Val Acc: 0.9931
🕒 Epoch 20/100 | Train Loss: 0.4373 | Val Loss: 0.4405 | Val Acc: 0.9931
🕒 Epoch 21/100 | Train Loss: 0.4353 | Val Loss: 0.4393 | Val Acc: 0.9954
🕒 Epoch 22/100 | Train Loss: 0.4336 | Val Loss: 0.4393 | Val Acc: 0.9931
🕒 Epoch 23/100 | Train Loss: 0.4367 | Val Loss: 0.4495 | Val Acc: 0.9908
🕒 Epoch 24/100 | Train Loss: 0.4339 | Val Loss: 0.4587 | Val Acc: 0.9862
🕒 Epoch 25/100 | Train Loss: 0.4375 | Val Loss: 0.4364 | Val Acc: 0.9954
💾 Best model updated (val acc: 0.9954)
🕒 Epoch 26/100 | Train Loss: 0.4324 | Val Loss: 0.4372 | Val Acc: 0.9931
🕒 Epoch 27/100 | Train Loss: 0.4370 | Val Loss: 0.4375 | Val Acc: 0.9954
🕒 Epoch 28/100 | Train Loss: 0.4335 | Val Loss: 0.4358 | Val Acc: 0.9954
💾 Best model updated (val acc: 0.9954)
🕒 Epoch 29/100 | Train Loss: 0.4341 | Val Loss: 0.4338 | Val Acc: 0.9954
💾 Best model updated (val acc: 0.9954)
🕒 Epoch 30/100 | Train Loss: 0.4368 | Val Loss: 0.4367 | Val Acc: 0.9954
🕒 Epoch 31/100 | Train Loss: 0.4314 | Val Loss: 0.4335 | Val Acc: 0.9954
💾 Best model updated (val acc: 0.9954)
🕒 Epoch 32/100 | Train Loss: 0.4310 | Val Loss: 0.4346 | Val Acc: 0.9954
🕒 Epoch 33/100 | Train Loss: 0.4328 | Val Loss: 0.4334 | Val Acc: 0.9977
💾 Best model updated (val acc: 0.9977)
🕒 Epoch 34/100 | Train Loss: 0.4318 | Val Loss: 0.4376 | Val Acc: 0.9954
🕒 Epoch 35/100 | Train Loss: 0.4322 | Val Loss: 0.4415 | Val Acc: 0.9931
🕒 Epoch 36/100 | Train Loss: 0.4309 | Val Loss: 0.4509 | Val Acc: 0.9885
🕒 Epoch 37/100 | Train Loss: 0.4350 | Val Loss: 0.4376 | Val Acc: 0.9954
🕒 Epoch 38/100 | Train Loss: 0.4306 | Val Loss: 0.4364 | Val Acc: 0.9954
🕒 Epoch 39/100 | Train Loss: 0.4307 | Val Loss: 0.4375 | Val Acc: 0.9954
🕒 Epoch 40/100 | Train Loss: 0.4310 | Val Loss: 0.4375 | Val Acc: 0.9931
🕒 Epoch 41/100 | Train Loss: 0.4308 | Val Loss: 0.4363 | Val Acc: 0.9954
🕒 Epoch 42/100 | Train Loss: 0.4315 | Val Loss: 0.4363 | Val Acc: 0.9954
🕒 Epoch 43/100 | Train Loss: 0.4295 | Val Loss: 0.4363 | Val Acc: 0.9954
⏹️ Early stopping.
✅ Fold 1 complete. Saved: ./output/models/4cbam+res+batchnormlast+dataset1_kfold+dataset1_kfold_fold1.pth

📂 Fold 2/5
🕒 Epoch 1/100 | Train Loss: 0.7238 | Val Loss: 0.5464 | Val Acc: 0.9539
💾 Best model updated (val acc: 0.9539)
🕒 Epoch 2/100 | Train Loss: 0.5306 | Val Loss: 0.4787 | Val Acc: 0.9862
💾 Best model updated (val acc: 0.9862)
🕒 Epoch 3/100 | Train Loss: 0.4961 | Val Loss: 0.4798 | Val Acc: 0.9816
🕒 Epoch 4/100 | Train Loss: 0.4759 | Val Loss: 0.4813 | Val Acc: 0.9770
🕒 Epoch 5/100 | Train Loss: 0.4715 | Val Loss: 0.4671 | Val Acc: 0.9793
💾 Best model updated (val acc: 0.9793)
🕒 Epoch 6/100 | Train Loss: 0.4610 | Val Loss: 0.4679 | Val Acc: 0.9839
🕒 Epoch 7/100 | Train Loss: 0.4663 | Val Loss: 0.4634 | Val Acc: 0.9885
💾 Best model updated (val acc: 0.9885)
🕒 Epoch 8/100 | Train Loss: 0.4585 | Val Loss: 0.4697 | Val Acc: 0.9793
🕒 Epoch 9/100 | Train Loss: 0.4562 | Val Loss: 0.4990 | Val Acc: 0.9770
🕒 Epoch 10/100 | Train Loss: 0.4453 | Val Loss: 0.4592 | Val Acc: 0.9885
💾 Best model updated (val acc: 0.9885)
🕒 Epoch 11/100 | Train Loss: 0.4477 | Val Loss: 0.4628 | Val Acc: 0.9862
🕒 Epoch 12/100 | Train Loss: 0.4525 | Val Loss: 0.4797 | Val Acc: 0.9839
🕒 Epoch 13/100 | Train Loss: 0.4519 | Val Loss: 0.4565 | Val Acc: 0.9862
💾 Best model updated (val acc: 0.9862)
🕒 Epoch 14/100 | Train Loss: 0.4465 | Val Loss: 0.5139 | Val Acc: 0.9585
🕒 Epoch 15/100 | Train Loss: 0.4902 | Val Loss: 0.4704 | Val Acc: 0.9793
🕒 Epoch 16/100 | Train Loss: 0.4479 | Val Loss: 0.4767 | Val Acc: 0.9862
🕒 Epoch 17/100 | Train Loss: 0.4501 | Val Loss: 0.4595 | Val Acc: 0.9839
🕒 Epoch 18/100 | Train Loss: 0.4454 | Val Loss: 0.4468 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 19/100 | Train Loss: 0.4396 | Val Loss: 0.4666 | Val Acc: 0.9862
🕒 Epoch 20/100 | Train Loss: 0.4446 | Val Loss: 0.4493 | Val Acc: 0.9885
🕒 Epoch 21/100 | Train Loss: 0.4366 | Val Loss: 0.4864 | Val Acc: 0.9724
🕒 Epoch 22/100 | Train Loss: 0.4376 | Val Loss: 0.4532 | Val Acc: 0.9908
🕒 Epoch 23/100 | Train Loss: 0.4361 | Val Loss: 0.4522 | Val Acc: 0.9885
🕒 Epoch 24/100 | Train Loss: 0.4337 | Val Loss: 0.4490 | Val Acc: 0.9885
🕒 Epoch 25/100 | Train Loss: 0.4391 | Val Loss: 0.4585 | Val Acc: 0.9816
🕒 Epoch 26/100 | Train Loss: 0.4372 | Val Loss: 0.4576 | Val Acc: 0.9816
🕒 Epoch 27/100 | Train Loss: 0.4373 | Val Loss: 0.4630 | Val Acc: 0.9839
🕒 Epoch 28/100 | Train Loss: 0.4342 | Val Loss: 0.4625 | Val Acc: 0.9862
⏹️ Early stopping.
✅ Fold 2 complete. Saved: ./output/models/4cbam+res+batchnormlast+dataset1_kfold+dataset1_kfold_fold2.pth

📂 Fold 3/5
🕒 Epoch 1/100 | Train Loss: 0.7751 | Val Loss: 0.5521 | Val Acc: 0.9607
💾 Best model updated (val acc: 0.9607)
🕒 Epoch 2/100 | Train Loss: 0.5469 | Val Loss: 0.4839 | Val Acc: 0.9792
💾 Best model updated (val acc: 0.9792)
🕒 Epoch 3/100 | Train Loss: 0.5016 | Val Loss: 0.4806 | Val Acc: 0.9815
💾 Best model updated (val acc: 0.9815)
🕒 Epoch 4/100 | Train Loss: 0.4787 | Val Loss: 0.4610 | Val Acc: 0.9861
💾 Best model updated (val acc: 0.9861)
🕒 Epoch 5/100 | Train Loss: 0.4815 | Val Loss: 0.4754 | Val Acc: 0.9885
🕒 Epoch 6/100 | Train Loss: 0.4751 | Val Loss: 0.4885 | Val Acc: 0.9792
🕒 Epoch 7/100 | Train Loss: 0.4840 | Val Loss: 0.4679 | Val Acc: 0.9838
🕒 Epoch 8/100 | Train Loss: 0.4569 | Val Loss: 0.4567 | Val Acc: 0.9885
💾 Best model updated (val acc: 0.9885)
🕒 Epoch 9/100 | Train Loss: 0.4693 | Val Loss: 0.4508 | Val Acc: 0.9885
💾 Best model updated (val acc: 0.9885)
🕒 Epoch 10/100 | Train Loss: 0.4653 | Val Loss: 0.4531 | Val Acc: 0.9908
🕒 Epoch 11/100 | Train Loss: 0.4503 | Val Loss: 0.4460 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 12/100 | Train Loss: 0.4542 | Val Loss: 0.4524 | Val Acc: 0.9931
🕒 Epoch 13/100 | Train Loss: 0.4528 | Val Loss: 0.4375 | Val Acc: 0.9977
💾 Best model updated (val acc: 0.9977)
🕒 Epoch 14/100 | Train Loss: 0.4637 | Val Loss: 0.4467 | Val Acc: 0.9908
🕒 Epoch 15/100 | Train Loss: 0.4414 | Val Loss: 0.4490 | Val Acc: 0.9885
🕒 Epoch 16/100 | Train Loss: 0.4403 | Val Loss: 0.4334 | Val Acc: 0.9977
💾 Best model updated (val acc: 0.9977)
🕒 Epoch 17/100 | Train Loss: 0.4646 | Val Loss: 0.4494 | Val Acc: 0.9838
🕒 Epoch 18/100 | Train Loss: 0.4429 | Val Loss: 0.4463 | Val Acc: 0.9931
🕒 Epoch 19/100 | Train Loss: 0.4383 | Val Loss: 0.4446 | Val Acc: 0.9908
🕒 Epoch 20/100 | Train Loss: 0.4371 | Val Loss: 0.4417 | Val Acc: 0.9931
🕒 Epoch 21/100 | Train Loss: 0.4364 | Val Loss: 0.4372 | Val Acc: 0.9931
🕒 Epoch 22/100 | Train Loss: 0.4399 | Val Loss: 0.4350 | Val Acc: 0.9931
🕒 Epoch 23/100 | Train Loss: 0.4472 | Val Loss: 0.4607 | Val Acc: 0.9838
🕒 Epoch 24/100 | Train Loss: 0.4413 | Val Loss: 0.4409 | Val Acc: 0.9931
🕒 Epoch 25/100 | Train Loss: 0.4368 | Val Loss: 0.4399 | Val Acc: 0.9931
🕒 Epoch 26/100 | Train Loss: 0.4352 | Val Loss: 0.4304 | Val Acc: 0.9954
💾 Best model updated (val acc: 0.9954)
🕒 Epoch 27/100 | Train Loss: 0.4317 | Val Loss: 0.4300 | Val Acc: 0.9977
💾 Best model updated (val acc: 0.9977)
🕒 Epoch 28/100 | Train Loss: 0.4342 | Val Loss: 0.4355 | Val Acc: 0.9954
🕒 Epoch 29/100 | Train Loss: 0.4314 | Val Loss: 0.4309 | Val Acc: 0.9954
🕒 Epoch 30/100 | Train Loss: 0.4312 | Val Loss: 0.4309 | Val Acc: 0.9954
🕒 Epoch 31/100 | Train Loss: 0.4309 | Val Loss: 0.4292 | Val Acc: 0.9954
💾 Best model updated (val acc: 0.9954)
🕒 Epoch 32/100 | Train Loss: 0.4309 | Val Loss: 0.4296 | Val Acc: 0.9977
🕒 Epoch 33/100 | Train Loss: 0.4337 | Val Loss: 0.4386 | Val Acc: 0.9931
🕒 Epoch 34/100 | Train Loss: 0.4338 | Val Loss: 0.4329 | Val Acc: 0.9954
🕒 Epoch 35/100 | Train Loss: 0.4332 | Val Loss: 0.4321 | Val Acc: 0.9977
🕒 Epoch 36/100 | Train Loss: 0.4316 | Val Loss: 0.4418 | Val Acc: 0.9931
🕒 Epoch 37/100 | Train Loss: 0.4305 | Val Loss: 0.4330 | Val Acc: 0.9954
🕒 Epoch 38/100 | Train Loss: 0.4302 | Val Loss: 0.4298 | Val Acc: 0.9977
🕒 Epoch 39/100 | Train Loss: 0.4320 | Val Loss: 0.4289 | Val Acc: 0.9977
💾 Best model updated (val acc: 0.9977)
🕒 Epoch 40/100 | Train Loss: 0.4316 | Val Loss: 0.4286 | Val Acc: 0.9977
💾 Best model updated (val acc: 0.9977)
🕒 Epoch 41/100 | Train Loss: 0.4315 | Val Loss: 0.4279 | Val Acc: 0.9977
💾 Best model updated (val acc: 0.9977)
🕒 Epoch 42/100 | Train Loss: 0.4316 | Val Loss: 0.4282 | Val Acc: 0.9977
🕒 Epoch 43/100 | Train Loss: 0.4316 | Val Loss: 0.4286 | Val Acc: 0.9977
🕒 Epoch 44/100 | Train Loss: 0.4325 | Val Loss: 0.4283 | Val Acc: 0.9977
🕒 Epoch 45/100 | Train Loss: 0.4309 | Val Loss: 0.4284 | Val Acc: 0.9977
🕒 Epoch 46/100 | Train Loss: 0.4300 | Val Loss: 0.4287 | Val Acc: 0.9977
🕒 Epoch 47/100 | Train Loss: 0.4304 | Val Loss: 0.4288 | Val Acc: 0.9977
🕒 Epoch 48/100 | Train Loss: 0.4306 | Val Loss: 0.4285 | Val Acc: 0.9977
🕒 Epoch 49/100 | Train Loss: 0.4315 | Val Loss: 0.4283 | Val Acc: 0.9977
🕒 Epoch 50/100 | Train Loss: 0.4306 | Val Loss: 0.4287 | Val Acc: 0.9977
🕒 Epoch 51/100 | Train Loss: 0.4317 | Val Loss: 0.4296 | Val Acc: 0.9977
⏹️ Early stopping.
✅ Fold 3 complete. Saved: ./output/models/4cbam+res+batchnormlast+dataset1_kfold+dataset1_kfold_fold3.pth

📂 Fold 4/5
🕒 Epoch 1/100 | Train Loss: 0.7186 | Val Loss: 0.6140 | Val Acc: 0.9122
💾 Best model updated (val acc: 0.9122)
🕒 Epoch 2/100 | Train Loss: 0.5187 | Val Loss: 0.5432 | Val Acc: 0.9538
💾 Best model updated (val acc: 0.9538)
🕒 Epoch 3/100 | Train Loss: 0.4992 | Val Loss: 0.4814 | Val Acc: 0.9746
💾 Best model updated (val acc: 0.9746)
🕒 Epoch 4/100 | Train Loss: 0.4682 | Val Loss: 0.4768 | Val Acc: 0.9838
💾 Best model updated (val acc: 0.9838)
🕒 Epoch 5/100 | Train Loss: 0.4807 | Val Loss: 0.4821 | Val Acc: 0.9723
🕒 Epoch 6/100 | Train Loss: 0.4712 | Val Loss: 0.4671 | Val Acc: 0.9815
💾 Best model updated (val acc: 0.9815)
🕒 Epoch 7/100 | Train Loss: 0.4642 | Val Loss: 0.4672 | Val Acc: 0.9885
🕒 Epoch 8/100 | Train Loss: 0.4770 | Val Loss: 0.4641 | Val Acc: 0.9861
💾 Best model updated (val acc: 0.9861)
🕒 Epoch 9/100 | Train Loss: 0.4645 | Val Loss: 0.4733 | Val Acc: 0.9769
🕒 Epoch 10/100 | Train Loss: 0.4543 | Val Loss: 0.4594 | Val Acc: 0.9885
💾 Best model updated (val acc: 0.9885)
🕒 Epoch 11/100 | Train Loss: 0.4464 | Val Loss: 0.4619 | Val Acc: 0.9815
🕒 Epoch 12/100 | Train Loss: 0.4511 | Val Loss: 0.4558 | Val Acc: 0.9861
💾 Best model updated (val acc: 0.9861)
🕒 Epoch 13/100 | Train Loss: 0.4362 | Val Loss: 0.4677 | Val Acc: 0.9792
🕒 Epoch 14/100 | Train Loss: 0.4541 | Val Loss: 0.4592 | Val Acc: 0.9861
🕒 Epoch 15/100 | Train Loss: 0.4460 | Val Loss: 0.4641 | Val Acc: 0.9885
🕒 Epoch 16/100 | Train Loss: 0.4537 | Val Loss: 0.4584 | Val Acc: 0.9861
🕒 Epoch 17/100 | Train Loss: 0.4376 | Val Loss: 0.4540 | Val Acc: 0.9885
💾 Best model updated (val acc: 0.9885)
🕒 Epoch 18/100 | Train Loss: 0.4435 | Val Loss: 0.4693 | Val Acc: 0.9815
🕒 Epoch 19/100 | Train Loss: 0.4431 | Val Loss: 0.4516 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 20/100 | Train Loss: 0.4385 | Val Loss: 0.4536 | Val Acc: 0.9885
🕒 Epoch 21/100 | Train Loss: 0.4360 | Val Loss: 0.4494 | Val Acc: 0.9908
💾 Best model updated (val acc: 0.9908)
🕒 Epoch 22/100 | Train Loss: 0.4345 | Val Loss: 0.4504 | Val Acc: 0.9908
🕒 Epoch 23/100 | Train Loss: 0.4370 | Val Loss: 0.4432 | Val Acc: 0.9931
💾 Best model updated (val acc: 0.9931)
🕒 Epoch 24/100 | Train Loss: 0.4455 | Val Loss: 0.4455 | Val Acc: 0.9954
🕒 Epoch 25/100 | Train Loss: 0.4341 | Val Loss: 0.4436 | Val Acc: 0.9954
🕒 Epoch 26/100 | Train Loss: 0.4337 | Val Loss: 0.4428 | Val Acc: 0.9931
💾 Best model updated (val acc: 0.9931)
🕒 Epoch 27/100 | Train Loss: 0.4330 | Val Loss: 0.4431 | Val Acc: 0.9931
🕒 Epoch 28/100 | Train Loss: 0.4350 | Val Loss: 0.4442 | Val Acc: 0.9931
🕒 Epoch 29/100 | Train Loss: 0.4334 | Val Loss: 0.4528 | Val Acc: 0.9908
🕒 Epoch 30/100 | Train Loss: 0.4330 | Val Loss: 0.4530 | Val Acc: 0.9908
🕒 Epoch 31/100 | Train Loss: 0.4320 | Val Loss: 0.4495 | Val Acc: 0.9908
🕒 Epoch 32/100 | Train Loss: 0.4308 | Val Loss: 0.4503 | Val Acc: 0.9908
🕒 Epoch 33/100 | Train Loss: 0.4306 | Val Loss: 0.4454 | Val Acc: 0.9931
🕒 Epoch 34/100 | Train Loss: 0.4312 | Val Loss: 0.4453 | Val Acc: 0.9931
🕒 Epoch 35/100 | Train Loss: 0.4303 | Val Loss: 0.4463 | Val Acc: 0.9931
🕒 Epoch 36/100 | Train Loss: 0.4310 | Val Loss: 0.4467 | Val Acc: 0.9908
⏹️ Early stopping.
✅ Fold 4 complete. Saved: ./output/models/4cbam+res+batchnormlast+dataset1_kfold+dataset1_kfold_fold4.pth

📂 Fold 5/5
🕒 Epoch 1/100 | Train Loss: 0.7685 | Val Loss: 0.5031 | Val Acc: 0.9723
💾 Best model updated (val acc: 0.9723)
🕒 Epoch 2/100 | Train Loss: 0.5159 | Val Loss: 0.4825 | Val Acc: 0.9746
💾 Best model updated (val acc: 0.9746)
🕒 Epoch 3/100 | Train Loss: 0.4805 | Val Loss: 0.4754 | Val Acc: 0.9838
💾 Best model updated (val acc: 0.9838)
🕒 Epoch 4/100 | Train Loss: 0.4851 | Val Loss: 0.4686 | Val Acc: 0.9838
💾 Best model updated (val acc: 0.9838)
🕒 Epoch 5/100 | Train Loss: 0.4743 | Val Loss: 0.4772 | Val Acc: 0.9815
🕒 Epoch 6/100 | Train Loss: 0.4846 | Val Loss: 0.5164 | Val Acc: 0.9538
🕒 Epoch 7/100 | Train Loss: 0.4614 | Val Loss: 0.4720 | Val Acc: 0.9815
🕒 Epoch 8/100 | Train Loss: 0.4530 | Val Loss: 0.4712 | Val Acc: 0.9838
🕒 Epoch 9/100 | Train Loss: 0.4510 | Val Loss: 0.4672 | Val Acc: 0.9885
💾 Best model updated (val acc: 0.9885)
🕒 Epoch 10/100 | Train Loss: 0.4720 | Val Loss: 0.4881 | Val Acc: 0.9792
🕒 Epoch 11/100 | Train Loss: 0.4476 | Val Loss: 0.5155 | Val Acc: 0.9677
🕒 Epoch 12/100 | Train Loss: 0.4605 | Val Loss: 0.4790 | Val Acc: 0.9792
🕒 Epoch 13/100 | Train Loss: 0.4398 | Val Loss: 0.4616 | Val Acc: 0.9861
💾 Best model updated (val acc: 0.9861)
🕒 Epoch 14/100 | Train Loss: 0.4477 | Val Loss: 0.4799 | Val Acc: 0.9723
🕒 Epoch 15/100 | Train Loss: 0.4418 | Val Loss: 0.4655 | Val Acc: 0.9861
🕒 Epoch 16/100 | Train Loss: 0.4429 | Val Loss: 0.4616 | Val Acc: 0.9815
🕒 Epoch 17/100 | Train Loss: 0.4335 | Val Loss: 0.4638 | Val Acc: 0.9861
🕒 Epoch 18/100 | Train Loss: 0.4381 | Val Loss: 0.4599 | Val Acc: 0.9838
💾 Best model updated (val acc: 0.9838)
🕒 Epoch 19/100 | Train Loss: 0.4443 | Val Loss: 0.4688 | Val Acc: 0.9838
🕒 Epoch 20/100 | Train Loss: 0.4430 | Val Loss: 0.4692 | Val Acc: 0.9792
🕒 Epoch 21/100 | Train Loss: 0.4461 | Val Loss: 0.4573 | Val Acc: 0.9861
💾 Best model updated (val acc: 0.9861)
🕒 Epoch 22/100 | Train Loss: 0.4378 | Val Loss: 0.4559 | Val Acc: 0.9885
💾 Best model updated (val acc: 0.9885)
🕒 Epoch 23/100 | Train Loss: 0.4332 | Val Loss: 0.4549 | Val Acc: 0.9861
💾 Best model updated (val acc: 0.9861)
🕒 Epoch 24/100 | Train Loss: 0.4346 | Val Loss: 0.4631 | Val Acc: 0.9861
🕒 Epoch 25/100 | Train Loss: 0.4332 | Val Loss: 0.4577 | Val Acc: 0.9861
🕒 Epoch 26/100 | Train Loss: 0.4338 | Val Loss: 0.4530 | Val Acc: 0.9885
💾 Best model updated (val acc: 0.9885)
🕒 Epoch 27/100 | Train Loss: 0.4330 | Val Loss: 0.4605 | Val Acc: 0.9861
🕒 Epoch 28/100 | Train Loss: 0.4332 | Val Loss: 0.4571 | Val Acc: 0.9861
🕒 Epoch 29/100 | Train Loss: 0.4411 | Val Loss: 0.4641 | Val Acc: 0.9838
🕒 Epoch 30/100 | Train Loss: 0.4365 | Val Loss: 0.4568 | Val Acc: 0.9885
🕒 Epoch 31/100 | Train Loss: 0.4323 | Val Loss: 0.4527 | Val Acc: 0.9885
💾 Best model updated (val acc: 0.9885)
🕒 Epoch 32/100 | Train Loss: 0.4368 | Val Loss: 0.4624 | Val Acc: 0.9861
🕒 Epoch 33/100 | Train Loss: 0.4323 | Val Loss: 0.4612 | Val Acc: 0.9885
🕒 Epoch 34/100 | Train Loss: 0.4328 | Val Loss: 0.4593 | Val Acc: 0.9885
🕒 Epoch 35/100 | Train Loss: 0.4310 | Val Loss: 0.4654 | Val Acc: 0.9838
🕒 Epoch 36/100 | Train Loss: 0.4312 | Val Loss: 0.4620 | Val Acc: 0.9861
🕒 Epoch 37/100 | Train Loss: 0.4321 | Val Loss: 0.4592 | Val Acc: 0.9885
🕒 Epoch 38/100 | Train Loss: 0.4327 | Val Loss: 0.4604 | Val Acc: 0.9885
🕒 Epoch 39/100 | Train Loss: 0.4318 | Val Loss: 0.4605 | Val Acc: 0.9885
🕒 Epoch 40/100 | Train Loss: 0.4310 | Val Loss: 0.4595 | Val Acc: 0.9885
🕒 Epoch 41/100 | Train Loss: 0.4323 | Val Loss: 0.4579 | Val Acc: 0.9885
⏹️ Early stopping.
✅ Fold 5 complete. Saved: ./output/models/4cbam+res+batchnormlast+dataset1_kfold+dataset1_kfold_fold5.pth
📂 Training metrics plot saved for Fold 1: output/test/fold_1/training_metrics.png
📂 Training metrics plot saved for Fold 2: output/test/fold_2/training_metrics.png
📂 Training metrics plot saved for Fold 3: output/test/fold_3/training_metrics.png
📂 Training metrics plot saved for Fold 4: output/test/fold_4/training_metrics.png
📂 Training metrics plot saved for Fold 5: output/test/fold_5/training_metrics.png
🎉 All folds completed.
🚀 Evaluating 5 fold models on test set

📂 Evaluating Fold 1
📊 Fold 1 Metrics:
   - Accuracy: 0.9908
   - Precision: 0.9911
   - Recall: 0.9909
   - F1 Score: 0.9909

📂 Evaluating Fold 2
📊 Fold 2 Metrics:
   - Accuracy: 0.9871
   - Precision: 0.9874
   - Recall: 0.9873
   - F1 Score: 0.9873

📂 Evaluating Fold 3
📊 Fold 3 Metrics:
   - Accuracy: 0.9926
   - Precision: 0.9928
   - Recall: 0.9928
   - F1 Score: 0.9928

📂 Evaluating Fold 4
📊 Fold 4 Metrics:
   - Accuracy: 0.9834
   - Precision: 0.9837
   - Recall: 0.9838
   - F1 Score: 0.9837

📂 Evaluating Fold 5
📊 Fold 5 Metrics:
   - Accuracy: 0.9853
   - Precision: 0.9859
   - Recall: 0.9854
   - F1 Score: 0.9855

🧾 Classification Report for 4cbam+res+batchnormlast+dataset1_kfold (Majority Vote from 5 folds):

                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    1.0000    1.0000        88
           brown_spot     0.9890    0.9677    0.9783        93
              healthy     0.9789    1.0000    0.9894        93
           leaf_blast     0.9890    0.9890    0.9890        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9926       543
            macro avg     0.9928    0.9928    0.9928       543
         weighted avg     0.9927    0.9926    0.9926       543

🔢 Confusion Matrix:
 [[88  0  0  0  0  0]
 [ 0 90  2  1  0  0]
 [ 0  0 93  0  0  0]
 [ 0  1  0 90  0  0]
 [ 0  0  0  0 90  0]
 [ 0  0  0  0  0 88]]

📊 Average Metrics Across All Folds:
   - Accuracy: 0.9878
   - Precision: 0.9882
   - Recall: 0.9880
   - F1 Score: 0.9880
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: last+cbam+dataset1]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
🕒 Epoch 1/100 | Time: 73.60s | Train Loss: 0.9049 | Val Loss: 0.5937 | Val Acc: 0.9449 | LR: 0.000100 
💾 Saving best val acc: 0.9449
🕒 Epoch 2/100 | Time: 68.31s | Train Loss: 0.5595 | Val Loss: 0.5329 | Val Acc: 0.9577 | LR: 0.000100 
💾 Saving best val acc: 0.9577
🕒 Epoch 3/100 | Time: 68.75s | Train Loss: 0.5045 | Val Loss: 0.5012 | Val Acc: 0.9706 | LR: 0.000100 
💾 Saving best val acc: 0.9706
🕒 Epoch 4/100 | Time: 69.37s | Train Loss: 0.4732 | Val Loss: 0.5145 | Val Acc: 0.9651 | LR: 0.000099 
🕒 Epoch 5/100 | Time: 70.02s | Train Loss: 0.4561 | Val Loss: 0.5092 | Val Acc: 0.9614 | LR: 0.000098 
🕒 Epoch 6/100 | Time: 69.57s | Train Loss: 0.4609 | Val Loss: 0.4919 | Val Acc: 0.9761 | LR: 0.000098 
💾 Saving best val acc: 0.9761
🕒 Epoch 7/100 | Time: 70.34s | Train Loss: 0.4483 | Val Loss: 0.4838 | Val Acc: 0.9779 | LR: 0.000097 
💾 Saving best val acc: 0.9779
🕒 Epoch 8/100 | Time: 69.26s | Train Loss: 0.4411 | Val Loss: 0.4614 | Val Acc: 0.9871 | LR: 0.000095 
💾 Saving best val acc: 0.9871
🕒 Epoch 9/100 | Time: 69.97s | Train Loss: 0.4367 | Val Loss: 0.4807 | Val Acc: 0.9798 | LR: 0.000094 
🕒 Epoch 10/100 | Time: 70.36s | Train Loss: 0.4586 | Val Loss: 0.4808 | Val Acc: 0.9743 | LR: 0.000092 
🕒 Epoch 11/100 | Time: 70.47s | Train Loss: 0.4382 | Val Loss: 0.4784 | Val Acc: 0.9798 | LR: 0.000091 
🕒 Epoch 12/100 | Time: 70.00s | Train Loss: 0.4368 | Val Loss: 0.4799 | Val Acc: 0.9779 | LR: 0.000089 
🕒 Epoch 13/100 | Time: 69.58s | Train Loss: 0.4451 | Val Loss: 0.4763 | Val Acc: 0.9798 | LR: 0.000087 
🕒 Epoch 14/100 | Time: 70.10s | Train Loss: 0.4548 | Val Loss: 0.4866 | Val Acc: 0.9743 | LR: 0.000084 
🕒 Epoch 15/100 | Time: 69.21s | Train Loss: 0.4625 | Val Loss: 0.5075 | Val Acc: 0.9688 | LR: 0.000082 
🕒 Epoch 16/100 | Time: 70.38s | Train Loss: 0.4424 | Val Loss: 0.4712 | Val Acc: 0.9816 | LR: 0.000080 
🕒 Epoch 17/100 | Time: 71.00s | Train Loss: 0.4336 | Val Loss: 0.4581 | Val Acc: 0.9853 | LR: 0.000077 
💾 Saving best val acc: 0.9853
🕒 Epoch 18/100 | Time: 70.34s | Train Loss: 0.4287 | Val Loss: 0.4739 | Val Acc: 0.9835 | LR: 0.000074 
🕒 Epoch 19/100 | Time: 71.02s | Train Loss: 0.4377 | Val Loss: 0.4768 | Val Acc: 0.9761 | LR: 0.000072 
🕒 Epoch 20/100 | Time: 70.54s | Train Loss: 0.4239 | Val Loss: 0.4648 | Val Acc: 0.9871 | LR: 0.000069 
🕒 Epoch 21/100 | Time: 70.18s | Train Loss: 0.4272 | Val Loss: 0.4663 | Val Acc: 0.9853 | LR: 0.000066 
🕒 Epoch 22/100 | Time: 70.60s | Train Loss: 0.4279 | Val Loss: 0.4773 | Val Acc: 0.9798 | LR: 0.000063 
🕒 Epoch 23/100 | Time: 71.02s | Train Loss: 0.4255 | Val Loss: 0.4616 | Val Acc: 0.9871 | LR: 0.000060 
🕒 Epoch 24/100 | Time: 70.95s | Train Loss: 0.4239 | Val Loss: 0.4530 | Val Acc: 0.9890 | LR: 0.000057 
💾 Saving best val acc: 0.9890
🕒 Epoch 25/100 | Time: 70.80s | Train Loss: 0.4230 | Val Loss: 0.4655 | Val Acc: 0.9835 | LR: 0.000054 
🕒 Epoch 26/100 | Time: 70.83s | Train Loss: 0.4235 | Val Loss: 0.4646 | Val Acc: 0.9835 | LR: 0.000050 
🕒 Epoch 27/100 | Time: 71.10s | Train Loss: 0.4225 | Val Loss: 0.4683 | Val Acc: 0.9835 | LR: 0.000047 
🕒 Epoch 28/100 | Time: 70.99s | Train Loss: 0.4223 | Val Loss: 0.4602 | Val Acc: 0.9871 | LR: 0.000044 
🕒 Epoch 29/100 | Time: 70.07s | Train Loss: 0.4245 | Val Loss: 0.4665 | Val Acc: 0.9835 | LR: 0.000041 
🕒 Epoch 30/100 | Time: 71.17s | Train Loss: 0.4229 | Val Loss: 0.4631 | Val Acc: 0.9835 | LR: 0.000038 
🕒 Epoch 31/100 | Time: 69.90s | Train Loss: 0.4252 | Val Loss: 0.4535 | Val Acc: 0.9890 | LR: 0.000035 
🕒 Epoch 32/100 | Time: 71.11s | Train Loss: 0.4225 | Val Loss: 0.4539 | Val Acc: 0.9890 | LR: 0.000032 
🕒 Epoch 33/100 | Time: 71.03s | Train Loss: 0.4223 | Val Loss: 0.4542 | Val Acc: 0.9890 | LR: 0.000029 
🕒 Epoch 34/100 | Time: 71.09s | Train Loss: 0.4225 | Val Loss: 0.4532 | Val Acc: 0.9890 | LR: 0.000027 
⏹️ Early stopping triggered.
✅ Training complete in 2393.17 seconds. Best model loaded.
📁 Model saved to ./output/models/last+cbam+dataset1+dataset1.pth
📂 Training metrics plot saved to: output/test/last+cbam+dataset1/training metric.png
Evaluate model:last+cbam+dataset1

🔥 Test Accuracy: 98.53%

📌 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    0.9773    0.9885        88
           brown_spot     0.9783    0.9677    0.9730        93
              healthy     0.9892    0.9892    0.9892        93
           leaf_blast     0.9780    0.9780    0.9780        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     0.9670    1.0000    0.9832        88

             accuracy                         0.9853       543
            macro avg     0.9854    0.9854    0.9853       543
         weighted avg     0.9854    0.9853    0.9853       543

📂 Confusion matrix saved to: output/test/last+cbam+dataset1/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/last+cbam+dataset1/grad_cam folder!
Saved misclassified images to output/test/last+cbam+dataset1/misclassified_images.png

🕒 Epoch 1/100 | Time: 69.65s | Train Loss: 0.9272 | Val Loss: 0.6689 | Val Acc: 0.9044 | LR: 0.000100 
💾 Saving best val acc: 0.9044
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: between_2_stage_+dataset1]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
🕒 Epoch 1/100 | Time: 72.20s | Train Loss: 0.8581 | Val Loss: 0.5569 | Val Acc: 0.9540 | LR: 0.000100 
💾 Saving best val acc: 0.9540
🕒 Epoch 2/100 | Time: 70.89s | Train Loss: 0.5263 | Val Loss: 0.5240 | Val Acc: 0.9596 | LR: 0.000100 
💾 Saving best val acc: 0.9596
🕒 Epoch 3/100 | Time: 70.71s | Train Loss: 0.4836 | Val Loss: 0.4912 | Val Acc: 0.9743 | LR: 0.000100 
💾 Saving best val acc: 0.9743
🕒 Epoch 4/100 | Time: 70.18s | Train Loss: 0.4583 | Val Loss: 0.5176 | Val Acc: 0.9688 | LR: 0.000099 
🕒 Epoch 5/100 | Time: 70.33s | Train Loss: 0.4661 | Val Loss: 0.5018 | Val Acc: 0.9761 | LR: 0.000098 
🕒 Epoch 6/100 | Time: 70.91s | Train Loss: 0.4776 | Val Loss: 0.4815 | Val Acc: 0.9798 | LR: 0.000098 
💾 Saving best val acc: 0.9798
🕒 Epoch 7/100 | Time: 70.41s | Train Loss: 0.4712 | Val Loss: 0.4901 | Val Acc: 0.9761 | LR: 0.000097 
🕒 Epoch 8/100 | Time: 71.19s | Train Loss: 0.4536 | Val Loss: 0.4647 | Val Acc: 0.9816 | LR: 0.000095 
💾 Saving best val acc: 0.9816
🕒 Epoch 9/100 | Time: 70.79s | Train Loss: 0.4386 | Val Loss: 0.4597 | Val Acc: 0.9853 | LR: 0.000094 
💾 Saving best val acc: 0.9853
🕒 Epoch 10/100 | Time: 70.61s | Train Loss: 0.4336 | Val Loss: 0.4643 | Val Acc: 0.9816 | LR: 0.000092 
🕒 Epoch 11/100 | Time: 70.59s | Train Loss: 0.4369 | Val Loss: 0.4712 | Val Acc: 0.9835 | LR: 0.000091 
🕒 Epoch 12/100 | Time: 70.26s | Train Loss: 0.4370 | Val Loss: 0.4621 | Val Acc: 0.9835 | LR: 0.000089 
🕒 Epoch 13/100 | Time: 70.85s | Train Loss: 0.4671 | Val Loss: 0.4612 | Val Acc: 0.9853 | LR: 0.000087 
🕒 Epoch 14/100 | Time: 69.59s | Train Loss: 0.4332 | Val Loss: 0.4590 | Val Acc: 0.9871 | LR: 0.000084 
💾 Saving best val acc: 0.9871
🕒 Epoch 15/100 | Time: 72.48s | Train Loss: 0.4331 | Val Loss: 0.4570 | Val Acc: 0.9853 | LR: 0.000082 
💾 Saving best val acc: 0.9853
🕒 Epoch 16/100 | Time: 71.33s | Train Loss: 0.4420 | Val Loss: 0.4899 | Val Acc: 0.9688 | LR: 0.000080 
🕒 Epoch 17/100 | Time: 71.95s | Train Loss: 0.4490 | Val Loss: 0.4674 | Val Acc: 0.9816 | LR: 0.000077 
🕒 Epoch 18/100 | Time: 71.34s | Train Loss: 0.4375 | Val Loss: 0.4649 | Val Acc: 0.9835 | LR: 0.000074 
🕒 Epoch 19/100 | Time: 70.90s | Train Loss: 0.4293 | Val Loss: 0.4544 | Val Acc: 0.9871 | LR: 0.000072 
💾 Saving best val acc: 0.9871
🕒 Epoch 20/100 | Time: 71.04s | Train Loss: 0.4264 | Val Loss: 0.4569 | Val Acc: 0.9908 | LR: 0.000069 
🕒 Epoch 21/100 | Time: 71.17s | Train Loss: 0.4377 | Val Loss: 0.4679 | Val Acc: 0.9871 | LR: 0.000066 
🕒 Epoch 22/100 | Time: 71.41s | Train Loss: 0.4385 | Val Loss: 0.4690 | Val Acc: 0.9798 | LR: 0.000063 
🕒 Epoch 23/100 | Time: 71.25s | Train Loss: 0.4280 | Val Loss: 0.4628 | Val Acc: 0.9853 | LR: 0.000060 
🕒 Epoch 24/100 | Time: 71.01s | Train Loss: 0.4241 | Val Loss: 0.4534 | Val Acc: 0.9853 | LR: 0.000057 
💾 Saving best val acc: 0.9853
🕒 Epoch 25/100 | Time: 70.33s | Train Loss: 0.4242 | Val Loss: 0.4595 | Val Acc: 0.9835 | LR: 0.000054 
🕒 Epoch 26/100 | Time: 70.70s | Train Loss: 0.4239 | Val Loss: 0.4603 | Val Acc: 0.9853 | LR: 0.000050 
🕒 Epoch 27/100 | Time: 70.88s | Train Loss: 0.4269 | Val Loss: 0.4545 | Val Acc: 0.9853 | LR: 0.000047 
🕒 Epoch 28/100 | Time: 70.94s | Train Loss: 0.4238 | Val Loss: 0.4539 | Val Acc: 0.9853 | LR: 0.000044 
🕒 Epoch 29/100 | Time: 71.45s | Train Loss: 0.4224 | Val Loss: 0.4571 | Val Acc: 0.9853 | LR: 0.000041 
🕒 Epoch 30/100 | Time: 71.55s | Train Loss: 0.4222 | Val Loss: 0.4595 | Val Acc: 0.9835 | LR: 0.000038 
🕒 Epoch 31/100 | Time: 70.64s | Train Loss: 0.4240 | Val Loss: 0.4543 | Val Acc: 0.9871 | LR: 0.000035 
🕒 Epoch 32/100 | Time: 71.47s | Train Loss: 0.4229 | Val Loss: 0.4627 | Val Acc: 0.9835 | LR: 0.000032 
🕒 Epoch 33/100 | Time: 71.65s | Train Loss: 0.4221 | Val Loss: 0.4618 | Val Acc: 0.9853 | LR: 0.000029 
🕒 Epoch 34/100 | Time: 71.06s | Train Loss: 0.4222 | Val Loss: 0.4616 | Val Acc: 0.9853 | LR: 0.000027 
⏹️ Early stopping triggered.
✅ Training complete in 2414.24 seconds. Best model loaded.
📁 Model saved to ./output/models/between_2_stage_+dataset1+dataset1.pth
📂 Training metrics plot saved to: output/test/between_2_stage_+dataset1/training metric.png
Evaluate model:between_2_stage_+dataset1

🔥 Test Accuracy: 98.90%

📌 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    1.0000    1.0000        88
           brown_spot     0.9677    0.9677    0.9677        93
              healthy     0.9789    1.0000    0.9894        93
           leaf_blast     0.9888    0.9670    0.9778        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9890       543
            macro avg     0.9892    0.9891    0.9891       543
         weighted avg     0.9890    0.9890    0.9889       543

📂 Confusion matrix saved to: output/test/between_2_stage_+dataset1/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/between_2_stage_+dataset1/grad_cam folder!
Saved misclassified images to output/test/between_2_stage_+dataset1/misclassified_images.png
Evaluate model:ConvNeXt+dataset1

Evaluate model:4cbam+res+batchnormlast+dataset1

🔥 Test Accuracy: 98.90%

📌 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    0.9886    0.9943        88
           brown_spot     0.9783    0.9677    0.9730        93
              healthy     0.9894    1.0000    0.9947        93
           leaf_blast     0.9674    0.9780    0.9727        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9890       543
            macro avg     0.9892    0.9891    0.9891       543
         weighted avg     0.9890    0.9890    0.9890       543

📂 Confusion matrix saved to: output/test/4cbam+res+batchnormlast+dataset1/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/4cbam+res+batchnormlast+dataset1/grad_cam folder!
Saved misclassified images to output/test/4cbam+res+batchnormlast+dataset1/misclassified_images.png
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: 4cbam+res+batchnormlast+dataset3]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
🕒 Epoch 1/100 | Time: 121.88s | Train Loss: 0.4259 | Val Loss: 0.3586 | Val Acc: 1.0000 | LR: 0.000100 
💾 Saving best val acc: 1.0000
🕒 Epoch 2/100 | Time: 111.33s | Train Loss: 0.3690 | Val Loss: 0.3616 | Val Acc: 0.9966 | LR: 0.000100 
🕒 Epoch 3/100 | Time: 115.53s | Train Loss: 0.3749 | Val Loss: 0.3549 | Val Acc: 1.0000 | LR: 0.000100 
💾 Saving best val acc: 1.0000
🕒 Epoch 4/100 | Time: 117.13s | Train Loss: 0.3631 | Val Loss: 0.3526 | Val Acc: 1.0000 | LR: 0.000099 
💾 Saving best val acc: 1.0000
🕒 Epoch 5/100 | Time: 117.38s | Train Loss: 0.3617 | Val Loss: 0.3502 | Val Acc: 1.0000 | LR: 0.000098 
💾 Saving best val acc: 1.0000
🕒 Epoch 6/100 | Time: 116.23s | Train Loss: 0.3607 | Val Loss: 0.3509 | Val Acc: 1.0000 | LR: 0.000098 
🕒 Epoch 7/100 | Time: 114.37s | Train Loss: 0.3619 | Val Loss: 0.3505 | Val Acc: 1.0000 | LR: 0.000097 
🕒 Epoch 8/100 | Time: 114.32s | Train Loss: 0.3607 | Val Loss: 0.3504 | Val Acc: 1.0000 | LR: 0.000095 
🕒 Epoch 9/100 | Time: 115.07s | Train Loss: 0.3595 | Val Loss: 0.3495 | Val Acc: 1.0000 | LR: 0.000094 
💾 Saving best val acc: 1.0000
🕒 Epoch 10/100 | Time: 114.64s | Train Loss: 0.3594 | Val Loss: 0.3509 | Val Acc: 1.0000 | LR: 0.000092 
🕒 Epoch 11/100 | Time: 114.59s | Train Loss: 0.3598 | Val Loss: 0.3514 | Val Acc: 1.0000 | LR: 0.000091 
🕒 Epoch 12/100 | Time: 114.27s | Train Loss: 0.3611 | Val Loss: 0.3506 | Val Acc: 1.0000 | LR: 0.000089 
🕒 Epoch 13/100 | Time: 114.41s | Train Loss: 0.3593 | Val Loss: 0.3508 | Val Acc: 1.0000 | LR: 0.000087 
🕒 Epoch 14/100 | Time: 114.23s | Train Loss: 0.3592 | Val Loss: 0.3511 | Val Acc: 1.0000 | LR: 0.000084 
🕒 Epoch 15/100 | Time: 114.39s | Train Loss: 0.3590 | Val Loss: 0.3497 | Val Acc: 1.0000 | LR: 0.000082 
🕒 Epoch 16/100 | Time: 114.25s | Train Loss: 0.3599 | Val Loss: 0.3517 | Val Acc: 1.0000 | LR: 0.000080 
🕒 Epoch 17/100 | Time: 114.30s | Train Loss: 0.3602 | Val Loss: 0.3516 | Val Acc: 1.0000 | LR: 0.000077 
🕒 Epoch 18/100 | Time: 114.39s | Train Loss: 0.3581 | Val Loss: 0.3493 | Val Acc: 1.0000 | LR: 0.000074 
💾 Saving best val acc: 1.0000
🕒 Epoch 19/100 | Time: 114.40s | Train Loss: 0.3598 | Val Loss: 0.3496 | Val Acc: 1.0000 | LR: 0.000072 
🕒 Epoch 20/100 | Time: 114.22s | Train Loss: 0.3803 | Val Loss: 0.3509 | Val Acc: 1.0000 | LR: 0.000069 
🕒 Epoch 21/100 | Time: 114.28s | Train Loss: 0.3602 | Val Loss: 0.3517 | Val Acc: 1.0000 | LR: 0.000066 
🕒 Epoch 22/100 | Time: 114.45s | Train Loss: 0.3595 | Val Loss: 0.3492 | Val Acc: 1.0000 | LR: 0.000063 
💾 Saving best val acc: 1.0000
🕒 Epoch 23/100 | Time: 114.38s | Train Loss: 0.3595 | Val Loss: 0.3520 | Val Acc: 1.0000 | LR: 0.000060 
🕒 Epoch 24/100 | Time: 114.43s | Train Loss: 0.3597 | Val Loss: 0.3523 | Val Acc: 1.0000 | LR: 0.000057 
🕒 Epoch 25/100 | Time: 114.33s | Train Loss: 0.3598 | Val Loss: 0.3490 | Val Acc: 1.0000 | LR: 0.000054 
💾 Saving best val acc: 1.0000
🕒 Epoch 26/100 | Time: 114.36s | Train Loss: 0.3590 | Val Loss: 0.3494 | Val Acc: 1.0000 | LR: 0.000050 
🕒 Epoch 27/100 | Time: 114.43s | Train Loss: 0.3595 | Val Loss: 0.3494 | Val Acc: 1.0000 | LR: 0.000047 
🕒 Epoch 28/100 | Time: 114.31s | Train Loss: 0.3595 | Val Loss: 0.3510 | Val Acc: 1.0000 | LR: 0.000044 
🕒 Epoch 29/100 | Time: 114.14s | Train Loss: 0.3583 | Val Loss: 0.3498 | Val Acc: 1.0000 | LR: 0.000041 
🕒 Epoch 30/100 | Time: 114.55s | Train Loss: 0.3595 | Val Loss: 0.3506 | Val Acc: 1.0000 | LR: 0.000038 
🕒 Epoch 31/100 | Time: 114.48s | Train Loss: 0.3585 | Val Loss: 0.3495 | Val Acc: 1.0000 | LR: 0.000035 
🕒 Epoch 32/100 | Time: 114.43s | Train Loss: 0.3594 | Val Loss: 0.3499 | Val Acc: 1.0000 | LR: 0.000032 
🕒 Epoch 33/100 | Time: 114.29s | Train Loss: 0.3587 | Val Loss: 0.3492 | Val Acc: 1.0000 | LR: 0.000029 
🕒 Epoch 34/100 | Time: 114.22s | Train Loss: 0.3596 | Val Loss: 0.3509 | Val Acc: 1.0000 | LR: 0.000027 
🕒 Epoch 35/100 | Time: 114.28s | Train Loss: 0.3589 | Val Loss: 0.3500 | Val Acc: 1.0000 | LR: 0.000024 
⏹️ Early stopping triggered.
✅ Training complete in 4016.84 seconds. Best model loaded.
📁 Model saved to ./output/models/4cbam+res+batchnormlast+dataset3+dataset3.pth
📂 Training metrics plot saved to: output/test/4cbam+res+batchnormlast+dataset3/training metric.png
Evaluate model:4cbam+res+batchnormlast+dataset3

🔥 Test Accuracy: 100.00%

📌 Classification Report:
                 precision    recall  f1-score   support

Bacterialblight     1.0000    1.0000    1.0000       160
          Blast     1.0000    1.0000    1.0000       145
      Brownspot     1.0000    1.0000    1.0000       160
         Tungro     1.0000    1.0000    1.0000       132

       accuracy                         1.0000       597
      macro avg     1.0000    1.0000    1.0000       597
   weighted avg     1.0000    1.0000    1.0000       597

📂 Confusion matrix saved to: output/test/4cbam+res+batchnormlast+dataset3/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/4cbam+res+batchnormlast+dataset3/grad_cam folder!

✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: ConvNeXt+dataset3]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
🕒 Epoch 1/100 | Time: 127.23s | Train Loss: 0.4253 | Val Loss: 0.3522 | Val Acc: 1.0000 | LR: 0.000100 
💾 Saving best val acc: 1.0000
🕒 Epoch 2/100 | Time: 126.57s | Train Loss: 0.3510 | Val Loss: 0.3502 | Val Acc: 1.0000 | LR: 0.000100 
💾 Saving best val acc: 1.0000
🕒 Epoch 3/100 | Time: 126.24s | Train Loss: 0.3496 | Val Loss: 0.3495 | Val Acc: 1.0000 | LR: 0.000100 
💾 Saving best val acc: 1.0000
🕒 Epoch 4/100 | Time: 125.49s | Train Loss: 0.3493 | Val Loss: 0.3494 | Val Acc: 1.0000 | LR: 0.000099 
💾 Saving best val acc: 1.0000
🕒 Epoch 5/100 | Time: 124.71s | Train Loss: 0.3491 | Val Loss: 0.3492 | Val Acc: 1.0000 | LR: 0.000098 
💾 Saving best val acc: 1.0000
🕒 Epoch 6/100 | Time: 125.49s | Train Loss: 0.3491 | Val Loss: 0.3491 | Val Acc: 1.0000 | LR: 0.000098 
💾 Saving best val acc: 1.0000
🕒 Epoch 7/100 | Time: 124.13s | Train Loss: 0.3490 | Val Loss: 0.3490 | Val Acc: 1.0000 | LR: 0.000097 
💾 Saving best val acc: 1.0000
🕒 Epoch 8/100 | Time: 124.74s | Train Loss: 0.3490 | Val Loss: 0.3489 | Val Acc: 1.0000 | LR: 0.000095 
💾 Saving best val acc: 1.0000
🕒 Epoch 9/100 | Time: 125.53s | Train Loss: 0.3489 | Val Loss: 0.3489 | Val Acc: 1.0000 | LR: 0.000094 
💾 Saving best val acc: 1.0000
🕒 Epoch 10/100 | Time: 125.26s | Train Loss: 0.3489 | Val Loss: 0.3489 | Val Acc: 1.0000 | LR: 0.000092 
💾 Saving best val acc: 1.0000
🕒 Epoch 11/100 | Time: 125.52s | Train Loss: 0.3489 | Val Loss: 0.3489 | Val Acc: 1.0000 | LR: 0.000091 
💾 Saving best val acc: 1.0000
🕒 Epoch 12/100 | Time: 126.34s | Train Loss: 0.3489 | Val Loss: 0.3489 | Val Acc: 1.0000 | LR: 0.000089 
💾 Saving best val acc: 1.0000
🕒 Epoch 13/100 | Time: 125.89s | Train Loss: 0.3489 | Val Loss: 0.3489 | Val Acc: 1.0000 | LR: 0.000087 
💾 Saving best val acc: 1.0000
🕒 Epoch 14/100 | Time: 125.33s | Train Loss: 0.3489 | Val Loss: 0.3489 | Val Acc: 1.0000 | LR: 0.000084 
💾 Saving best val acc: 1.0000
🕒 Epoch 15/100 | Time: 125.94s | Train Loss: 0.3489 | Val Loss: 0.3489 | Val Acc: 1.0000 | LR: 0.000082 
💾 Saving best val acc: 1.0000
🕒 Epoch 16/100 | Time: 125.51s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000080 
💾 Saving best val acc: 1.0000
🕒 Epoch 17/100 | Time: 125.32s | Train Loss: 0.3488 | Val Loss: 0.3489 | Val Acc: 1.0000 | LR: 0.000077 
🕒 Epoch 18/100 | Time: 125.94s | Train Loss: 0.3488 | Val Loss: 0.3489 | Val Acc: 1.0000 | LR: 0.000074 
🕒 Epoch 19/100 | Time: 125.73s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000072 
💾 Saving best val acc: 1.0000
🕒 Epoch 20/100 | Time: 126.16s | Train Loss: 0.3488 | Val Loss: 0.3489 | Val Acc: 1.0000 | LR: 0.000069 
🕒 Epoch 21/100 | Time: 126.36s | Train Loss: 0.3488 | Val Loss: 0.3489 | Val Acc: 1.0000 | LR: 0.000066 
🕒 Epoch 22/100 | Time: 125.92s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000063 
💾 Saving best val acc: 1.0000
🕒 Epoch 23/100 | Time: 125.98s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000060 
🕒 Epoch 24/100 | Time: 126.58s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000057 
🕒 Epoch 25/100 | Time: 126.52s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000054 
💾 Saving best val acc: 1.0000
🕒 Epoch 26/100 | Time: 125.93s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000050 
🕒 Epoch 27/100 | Time: 126.21s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000047 
💾 Saving best val acc: 1.0000
🕒 Epoch 28/100 | Time: 126.30s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000044 
🕒 Epoch 29/100 | Time: 126.57s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000041 
💾 Saving best val acc: 1.0000
🕒 Epoch 30/100 | Time: 126.36s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000038 
💾 Saving best val acc: 1.0000
🕒 Epoch 31/100 | Time: 126.83s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000035 
🕒 Epoch 32/100 | Time: 126.25s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000032 
🕒 Epoch 33/100 | Time: 126.15s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000029 
💾 Saving best val acc: 1.0000
🕒 Epoch 34/100 | Time: 126.53s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000027 
🕒 Epoch 35/100 | Time: 126.80s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000024 
💾 Saving best val acc: 1.0000
🕒 Epoch 36/100 | Time: 126.50s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000021 
🕒 Epoch 37/100 | Time: 126.36s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000019 
🕒 Epoch 38/100 | Time: 126.17s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000017 
🕒 Epoch 39/100 | Time: 125.94s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000014 
🕒 Epoch 40/100 | Time: 126.73s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000012 
💾 Saving best val acc: 1.0000
🕒 Epoch 41/100 | Time: 126.19s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000010 
🕒 Epoch 42/100 | Time: 125.53s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000009 
💾 Saving best val acc: 1.0000
🕒 Epoch 43/100 | Time: 126.40s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000007 
💾 Saving best val acc: 1.0000
🕒 Epoch 44/100 | Time: 125.66s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000006 
🕒 Epoch 45/100 | Time: 125.55s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000004 
💾 Saving best val acc: 1.0000
🕒 Epoch 46/100 | Time: 124.70s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000003 
💾 Saving best val acc: 1.0000
🕒 Epoch 47/100 | Time: 125.31s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000003 
💾 Saving best val acc: 1.0000
🕒 Epoch 48/100 | Time: 124.92s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000002 
🕒 Epoch 49/100 | Time: 125.32s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000001 
💾 Saving best val acc: 1.0000
🕒 Epoch 50/100 | Time: 126.61s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000001 
💾 Saving best val acc: 1.0000
🕒 Epoch 51/100 | Time: 126.34s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000001 
🕒 Epoch 52/100 | Time: 126.53s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000001 
💾 Saving best val acc: 1.0000
🕒 Epoch 53/100 | Time: 125.95s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000001 
🕒 Epoch 54/100 | Time: 126.20s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000002 
🕒 Epoch 55/100 | Time: 125.99s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000003 
🕒 Epoch 56/100 | Time: 126.05s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000003 
🕒 Epoch 57/100 | Time: 125.92s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000004 
🕒 Epoch 58/100 | Time: 125.14s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000006 
🕒 Epoch 59/100 | Time: 125.36s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000007 
🕒 Epoch 60/100 | Time: 125.77s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000009 
🕒 Epoch 61/100 | Time: 125.88s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000010 
🕒 Epoch 62/100 | Time: 125.74s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000012 
⏹️ Early stopping triggered.
✅ Training complete in 7807.72 seconds. Best model loaded.
📁 Model saved to ./output/models/ConvNeXt+dataset3+dataset3.pth
📂 Training metrics plot saved to: output/test/ConvNeXt+dataset3/training metric.png
Evaluate model:ConvNeXt+dataset3

🔥 Test Accuracy: 100.00%

📌 Classification Report:
                 precision    recall  f1-score   support

Bacterialblight     1.0000    1.0000    1.0000       160
          Blast     1.0000    1.0000    1.0000       145
      Brownspot     1.0000    1.0000    1.0000       160
         Tungro     1.0000    1.0000    1.0000       132

       accuracy                         1.0000       597
      macro avg     1.0000    1.0000    1.0000       597
   weighted avg     1.0000    1.0000    1.0000       597

📂 Confusion matrix saved to: output/test/ConvNeXt+dataset3/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+dataset3/grad_cam folder!

✅ Saved fold class distribution plot to: output/fold_class_distribution.png

📂 Fold 1/5
🕒 Epoch 1/100 | Train Loss: 1.2069 | Val Loss: 1.1140 | Val Acc: 0.8916
💾 Best model updated (val acc: 0.8916)
🕒 Epoch 2/100 | Train Loss: 0.8396 | Val Loss: 1.0134 | Val Acc: 0.9252
💾 Best model updated (val acc: 0.9252)
🕒 Epoch 3/100 | Train Loss: 0.7962 | Val Loss: 0.9582 | Val Acc: 0.9383
💾 Best model updated (val acc: 0.9383)
🕒 Epoch 4/100 | Train Loss: 0.7594 | Val Loss: 0.9416 | Val Acc: 0.9551
💾 Best model updated (val acc: 0.9551)
🕒 Epoch 5/100 | Train Loss: 0.7830 | Val Loss: 0.9632 | Val Acc: 0.9458
🕒 Epoch 6/100 | Train Loss: 0.7332 | Val Loss: 0.9165 | Val Acc: 0.9589
💾 Best model updated (val acc: 0.9589)
🕒 Epoch 7/100 | Train Loss: 0.7187 | Val Loss: 0.9283 | Val Acc: 0.9607
🕒 Epoch 8/100 | Train Loss: 0.7170 | Val Loss: 0.9419 | Val Acc: 0.9439
🕒 Epoch 9/100 | Train Loss: 0.7171 | Val Loss: 0.9613 | Val Acc: 0.9402
🕒 Epoch 10/100 | Train Loss: 0.7268 | Val Loss: 0.9462 | Val Acc: 0.9533
🕒 Epoch 11/100 | Train Loss: 0.7139 | Val Loss: 0.9225 | Val Acc: 0.9551
🕒 Epoch 12/100 | Train Loss: 0.7012 | Val Loss: 0.8980 | Val Acc: 0.9664
💾 Best model updated (val acc: 0.9664)
🕒 Epoch 13/100 | Train Loss: 0.7021 | Val Loss: 0.8947 | Val Acc: 0.9701
💾 Best model updated (val acc: 0.9701)
🕒 Epoch 14/100 | Train Loss: 0.6959 | Val Loss: 0.9148 | Val Acc: 0.9533
🕒 Epoch 15/100 | Train Loss: 0.6982 | Val Loss: 0.8987 | Val Acc: 0.9682
🕒 Epoch 16/100 | Train Loss: 0.6960 | Val Loss: 0.8805 | Val Acc: 0.9738
💾 Best model updated (val acc: 0.9738)
🕒 Epoch 17/100 | Train Loss: 0.6949 | Val Loss: 0.8908 | Val Acc: 0.9682
🕒 Epoch 18/100 | Train Loss: 0.6886 | Val Loss: 0.8833 | Val Acc: 0.9757
🕒 Epoch 19/100 | Train Loss: 0.7030 | Val Loss: 0.8831 | Val Acc: 0.9701
🕒 Epoch 20/100 | Train Loss: 0.6938 | Val Loss: 0.8914 | Val Acc: 0.9701
🕒 Epoch 21/100 | Train Loss: 0.6963 | Val Loss: 0.9033 | Val Acc: 0.9626
🕒 Epoch 22/100 | Train Loss: 0.6963 | Val Loss: 0.9048 | Val Acc: 0.9607
🕒 Epoch 23/100 | Train Loss: 0.6873 | Val Loss: 0.8810 | Val Acc: 0.9720
🕒 Epoch 24/100 | Train Loss: 0.6755 | Val Loss: 0.8903 | Val Acc: 0.9682
🕒 Epoch 25/100 | Train Loss: 0.6757 | Val Loss: 0.8682 | Val Acc: 0.9813
💾 Best model updated (val acc: 0.9813)
🕒 Epoch 26/100 | Train Loss: 0.6820 | Val Loss: 0.8806 | Val Acc: 0.9720
🕒 Epoch 27/100 | Train Loss: 0.6777 | Val Loss: 0.8741 | Val Acc: 0.9776
🕒 Epoch 28/100 | Train Loss: 0.6721 | Val Loss: 0.8787 | Val Acc: 0.9757
🕒 Epoch 29/100 | Train Loss: 0.6757 | Val Loss: 0.9036 | Val Acc: 0.9701
🕒 Epoch 30/100 | Train Loss: 0.6798 | Val Loss: 0.8900 | Val Acc: 0.9664
🕒 Epoch 31/100 | Train Loss: 0.6775 | Val Loss: 0.8717 | Val Acc: 0.9813
🕒 Epoch 32/100 | Train Loss: 0.6758 | Val Loss: 0.8774 | Val Acc: 0.9757
🕒 Epoch 33/100 | Train Loss: 0.6744 | Val Loss: 0.8989 | Val Acc: 0.9664
🕒 Epoch 34/100 | Train Loss: 0.6776 | Val Loss: 0.8744 | Val Acc: 0.9757
🕒 Epoch 35/100 | Train Loss: 0.6770 | Val Loss: 0.8694 | Val Acc: 0.9832
⏹️ Early stopping.
✅ Fold 1 complete. Saved: ./output/models/ConvNeXt+cbam+batchnorm+dataset2+dataset2_fold1.pth

📂 Fold 2/5
🕒 Epoch 1/100 | Train Loss: 1.2037 | Val Loss: 1.0359 | Val Acc: 0.9028
💾 Best model updated (val acc: 0.9028)
🕒 Epoch 2/100 | Train Loss: 0.8561 | Val Loss: 0.9793 | Val Acc: 0.9439
💾 Best model updated (val acc: 0.9439)
🕒 Epoch 3/100 | Train Loss: 0.7746 | Val Loss: 1.0095 | Val Acc: 0.9271
🕒 Epoch 4/100 | Train Loss: 0.7611 | Val Loss: 0.9488 | Val Acc: 0.9570
💾 Best model updated (val acc: 0.9570)
🕒 Epoch 5/100 | Train Loss: 0.7550 | Val Loss: 0.9640 | Val Acc: 0.9477
🕒 Epoch 6/100 | Train Loss: 0.7261 | Val Loss: 0.9407 | Val Acc: 0.9533
💾 Best model updated (val acc: 0.9533)
🕒 Epoch 7/100 | Train Loss: 0.7274 | Val Loss: 0.9540 | Val Acc: 0.9458
🕒 Epoch 8/100 | Train Loss: 0.7234 | Val Loss: 0.9330 | Val Acc: 0.9514
💾 Best model updated (val acc: 0.9514)
🕒 Epoch 9/100 | Train Loss: 0.7221 | Val Loss: 0.9016 | Val Acc: 0.9626
💾 Best model updated (val acc: 0.9626)
🕒 Epoch 10/100 | Train Loss: 0.7232 | Val Loss: 0.9040 | Val Acc: 0.9701
🕒 Epoch 11/100 | Train Loss: 0.7064 | Val Loss: 0.9002 | Val Acc: 0.9720
💾 Best model updated (val acc: 0.9720)
🕒 Epoch 12/100 | Train Loss: 0.7013 | Val Loss: 0.9046 | Val Acc: 0.9720
🕒 Epoch 13/100 | Train Loss: 0.7036 | Val Loss: 0.9047 | Val Acc: 0.9701
🕒 Epoch 14/100 | Train Loss: 0.6991 | Val Loss: 0.8965 | Val Acc: 0.9738
💾 Best model updated (val acc: 0.9738)
🕒 Epoch 15/100 | Train Loss: 0.6993 | Val Loss: 0.8901 | Val Acc: 0.9701
💾 Best model updated (val acc: 0.9701)
🕒 Epoch 16/100 | Train Loss: 0.6915 | Val Loss: 0.8590 | Val Acc: 0.9757
💾 Best model updated (val acc: 0.9757)
🕒 Epoch 17/100 | Train Loss: 0.6854 | Val Loss: 0.8623 | Val Acc: 0.9757
🕒 Epoch 18/100 | Train Loss: 0.6913 | Val Loss: 0.9080 | Val Acc: 0.9626
🕒 Epoch 19/100 | Train Loss: 0.6854 | Val Loss: 0.9095 | Val Acc: 0.9514
🕒 Epoch 20/100 | Train Loss: 0.6922 | Val Loss: 0.9004 | Val Acc: 0.9589
🕒 Epoch 21/100 | Train Loss: 0.6791 | Val Loss: 0.8953 | Val Acc: 0.9607
🕒 Epoch 22/100 | Train Loss: 0.7046 | Val Loss: 0.9252 | Val Acc: 0.9495
🕒 Epoch 23/100 | Train Loss: 0.7232 | Val Loss: 0.9277 | Val Acc: 0.9514
🕒 Epoch 24/100 | Train Loss: 0.6787 | Val Loss: 0.8773 | Val Acc: 0.9776
🕒 Epoch 25/100 | Train Loss: 0.6799 | Val Loss: 0.8868 | Val Acc: 0.9738
🕒 Epoch 26/100 | Train Loss: 0.6780 | Val Loss: 0.8946 | Val Acc: 0.9720
⏹️ Early stopping.
✅ Fold 2 complete. Saved: ./output/models/ConvNeXt+cbam+batchnorm+dataset2+dataset2_fold2.pth

📂 Fold 3/5
🕒 Epoch 1/100 | Train Loss: 1.1765 | Val Loss: 1.0835 | Val Acc: 0.8897
💾 Best model updated (val acc: 0.8897)
🕒 Epoch 2/100 | Train Loss: 0.8545 | Val Loss: 0.9716 | Val Acc: 0.9402
💾 Best model updated (val acc: 0.9402)
🕒 Epoch 3/100 | Train Loss: 0.8157 | Val Loss: 0.9429 | Val Acc: 0.9533
💾 Best model updated (val acc: 0.9533)
🕒 Epoch 4/100 | Train Loss: 0.7780 | Val Loss: 0.9378 | Val Acc: 0.9607
💾 Best model updated (val acc: 0.9607)
🕒 Epoch 5/100 | Train Loss: 0.7536 | Val Loss: 0.8979 | Val Acc: 0.9720
💾 Best model updated (val acc: 0.9720)
🕒 Epoch 6/100 | Train Loss: 0.7235 | Val Loss: 0.9248 | Val Acc: 0.9589
🕒 Epoch 7/100 | Train Loss: 0.7258 | Val Loss: 0.9133 | Val Acc: 0.9682
🕒 Epoch 8/100 | Train Loss: 0.7257 | Val Loss: 0.9117 | Val Acc: 0.9701
🕒 Epoch 9/100 | Train Loss: 0.7425 | Val Loss: 0.9198 | Val Acc: 0.9682
🕒 Epoch 10/100 | Train Loss: 0.7153 | Val Loss: 0.8881 | Val Acc: 0.9776
💾 Best model updated (val acc: 0.9776)
🕒 Epoch 11/100 | Train Loss: 0.7110 | Val Loss: 0.8908 | Val Acc: 0.9701
🕒 Epoch 12/100 | Train Loss: 0.6989 | Val Loss: 0.8905 | Val Acc: 0.9757
🕒 Epoch 13/100 | Train Loss: 0.7142 | Val Loss: 0.8737 | Val Acc: 0.9794
💾 Best model updated (val acc: 0.9794)
🕒 Epoch 14/100 | Train Loss: 0.6888 | Val Loss: 0.9025 | Val Acc: 0.9551
🕒 Epoch 15/100 | Train Loss: 0.7048 | Val Loss: 0.9242 | Val Acc: 0.9589
🕒 Epoch 16/100 | Train Loss: 0.7084 | Val Loss: 0.8997 | Val Acc: 0.9720
🕒 Epoch 17/100 | Train Loss: 0.7046 | Val Loss: 0.8705 | Val Acc: 0.9776
💾 Best model updated (val acc: 0.9776)
🕒 Epoch 18/100 | Train Loss: 0.6865 | Val Loss: 0.8563 | Val Acc: 0.9888
💾 Best model updated (val acc: 0.9888)
🕒 Epoch 19/100 | Train Loss: 0.6747 | Val Loss: 0.8624 | Val Acc: 0.9832
🕒 Epoch 20/100 | Train Loss: 0.6809 | Val Loss: 0.8615 | Val Acc: 0.9813
🕒 Epoch 21/100 | Train Loss: 0.6886 | Val Loss: 0.8829 | Val Acc: 0.9720
🕒 Epoch 22/100 | Train Loss: 0.6857 | Val Loss: 0.8788 | Val Acc: 0.9794
🕒 Epoch 23/100 | Train Loss: 0.6751 | Val Loss: 0.8701 | Val Acc: 0.9757
🕒 Epoch 24/100 | Train Loss: 0.6830 | Val Loss: 0.8781 | Val Acc: 0.9757
🕒 Epoch 25/100 | Train Loss: 0.6752 | Val Loss: 0.8820 | Val Acc: 0.9757
🕒 Epoch 26/100 | Train Loss: 0.6834 | Val Loss: 0.8872 | Val Acc: 0.9720
🕒 Epoch 27/100 | Train Loss: 0.6804 | Val Loss: 0.8738 | Val Acc: 0.9776
🕒 Epoch 28/100 | Train Loss: 0.6749 | Val Loss: 0.8586 | Val Acc: 0.9813
⏹️ Early stopping.
✅ Fold 3 complete. Saved: ./output/models/ConvNeXt+cbam+batchnorm+dataset2+dataset2_fold3.pth

📂 Fold 4/5
🕒 Epoch 1/100 | Train Loss: 1.2042 | Val Loss: 1.0871 | Val Acc: 0.9028
💾 Best model updated (val acc: 0.9028)
🕒 Epoch 2/100 | Train Loss: 0.8454 | Val Loss: 0.9749 | Val Acc: 0.9477
💾 Best model updated (val acc: 0.9477)
🕒 Epoch 3/100 | Train Loss: 0.8001 | Val Loss: 0.9370 | Val Acc: 0.9570
💾 Best model updated (val acc: 0.9570)
🕒 Epoch 4/100 | Train Loss: 0.7651 | Val Loss: 0.9277 | Val Acc: 0.9645
💾 Best model updated (val acc: 0.9645)
🕒 Epoch 5/100 | Train Loss: 0.7492 | Val Loss: 0.9213 | Val Acc: 0.9645
💾 Best model updated (val acc: 0.9645)
🕒 Epoch 6/100 | Train Loss: 0.7480 | Val Loss: 0.9545 | Val Acc: 0.9551
🕒 Epoch 7/100 | Train Loss: 0.7437 | Val Loss: 0.9215 | Val Acc: 0.9645
🕒 Epoch 8/100 | Train Loss: 0.7158 | Val Loss: 0.9187 | Val Acc: 0.9626
💾 Best model updated (val acc: 0.9626)
🕒 Epoch 9/100 | Train Loss: 0.7102 | Val Loss: 0.8999 | Val Acc: 0.9664
💾 Best model updated (val acc: 0.9664)
🕒 Epoch 10/100 | Train Loss: 0.7247 | Val Loss: 0.8938 | Val Acc: 0.9682
💾 Best model updated (val acc: 0.9682)
🕒 Epoch 11/100 | Train Loss: 0.7052 | Val Loss: 0.8835 | Val Acc: 0.9738
💾 Best model updated (val acc: 0.9738)
🕒 Epoch 12/100 | Train Loss: 0.7094 | Val Loss: 0.9031 | Val Acc: 0.9720
🕒 Epoch 13/100 | Train Loss: 0.6951 | Val Loss: 0.8709 | Val Acc: 0.9813
💾 Best model updated (val acc: 0.9813)
🕒 Epoch 14/100 | Train Loss: 0.7096 | Val Loss: 0.8930 | Val Acc: 0.9682
🕒 Epoch 15/100 | Train Loss: 0.7066 | Val Loss: 0.8710 | Val Acc: 0.9776
🕒 Epoch 16/100 | Train Loss: 0.7062 | Val Loss: 0.9323 | Val Acc: 0.9533
🕒 Epoch 17/100 | Train Loss: 0.7136 | Val Loss: 0.8810 | Val Acc: 0.9664
🕒 Epoch 18/100 | Train Loss: 0.6898 | Val Loss: 0.8799 | Val Acc: 0.9776
🕒 Epoch 19/100 | Train Loss: 0.6799 | Val Loss: 0.8800 | Val Acc: 0.9757
🕒 Epoch 20/100 | Train Loss: 0.6962 | Val Loss: 0.8663 | Val Acc: 0.9776
💾 Best model updated (val acc: 0.9776)
🕒 Epoch 21/100 | Train Loss: 0.6831 | Val Loss: 0.8734 | Val Acc: 0.9738
🕒 Epoch 22/100 | Train Loss: 0.6862 | Val Loss: 0.8809 | Val Acc: 0.9757
🕒 Epoch 23/100 | Train Loss: 0.6782 | Val Loss: 0.8651 | Val Acc: 0.9813
💾 Best model updated (val acc: 0.9813)
🕒 Epoch 24/100 | Train Loss: 0.6889 | Val Loss: 0.8609 | Val Acc: 0.9738
💾 Best model updated (val acc: 0.9738)
🕒 Epoch 25/100 | Train Loss: 0.6772 | Val Loss: 0.8882 | Val Acc: 0.9701
🕒 Epoch 26/100 | Train Loss: 0.6867 | Val Loss: 0.8709 | Val Acc: 0.9738
🕒 Epoch 27/100 | Train Loss: 0.6812 | Val Loss: 0.8587 | Val Acc: 0.9850
💾 Best model updated (val acc: 0.9850)
🕒 Epoch 28/100 | Train Loss: 0.6769 | Val Loss: 0.8585 | Val Acc: 0.9794
💾 Best model updated (val acc: 0.9794)
🕒 Epoch 29/100 | Train Loss: 0.6773 | Val Loss: 0.8501 | Val Acc: 0.9907
💾 Best model updated (val acc: 0.9907)
🕒 Epoch 30/100 | Train Loss: 0.6765 | Val Loss: 0.8601 | Val Acc: 0.9832
🕒 Epoch 31/100 | Train Loss: 0.6810 | Val Loss: 0.8544 | Val Acc: 0.9832
🕒 Epoch 32/100 | Train Loss: 0.6756 | Val Loss: 0.8542 | Val Acc: 0.9850
🕒 Epoch 33/100 | Train Loss: 0.6718 | Val Loss: 0.8534 | Val Acc: 0.9869
🕒 Epoch 34/100 | Train Loss: 0.6710 | Val Loss: 0.8652 | Val Acc: 0.9813
🕒 Epoch 35/100 | Train Loss: 0.6809 | Val Loss: 0.8512 | Val Acc: 0.9869
🕒 Epoch 36/100 | Train Loss: 0.6763 | Val Loss: 0.8515 | Val Acc: 0.9888
🕒 Epoch 37/100 | Train Loss: 0.6727 | Val Loss: 0.8528 | Val Acc: 0.9888
🕒 Epoch 38/100 | Train Loss: 0.6742 | Val Loss: 0.8554 | Val Acc: 0.9869
🕒 Epoch 39/100 | Train Loss: 0.6706 | Val Loss: 0.8545 | Val Acc: 0.9869
⏹️ Early stopping.
✅ Fold 4 complete. Saved: ./output/models/ConvNeXt+cbam+batchnorm+dataset2+dataset2_fold4.pth

📂 Fold 5/5
🕒 Epoch 1/100 | Train Loss: 1.1370 | Val Loss: 1.1130 | Val Acc: 0.8822
💾 Best model updated (val acc: 0.8822)
🕒 Epoch 2/100 | Train Loss: 0.8594 | Val Loss: 1.0119 | Val Acc: 0.9178
💾 Best model updated (val acc: 0.9178)
🕒 Epoch 3/100 | Train Loss: 0.7888 | Val Loss: 0.9540 | Val Acc: 0.9458
💾 Best model updated (val acc: 0.9458)
🕒 Epoch 4/100 | Train Loss: 0.7625 | Val Loss: 1.0231 | Val Acc: 0.9234
🕒 Epoch 5/100 | Train Loss: 0.7722 | Val Loss: 1.0126 | Val Acc: 0.9159
🕒 Epoch 6/100 | Train Loss: 0.7354 | Val Loss: 0.9564 | Val Acc: 0.9421
🕒 Epoch 7/100 | Train Loss: 0.7272 | Val Loss: 0.9238 | Val Acc: 0.9551
💾 Best model updated (val acc: 0.9551)
🕒 Epoch 8/100 | Train Loss: 0.7235 | Val Loss: 0.9014 | Val Acc: 0.9682
💾 Best model updated (val acc: 0.9682)
🕒 Epoch 9/100 | Train Loss: 0.7160 | Val Loss: 0.9045 | Val Acc: 0.9682
🕒 Epoch 10/100 | Train Loss: 0.7043 | Val Loss: 0.9192 | Val Acc: 0.9645
🕒 Epoch 11/100 | Train Loss: 0.7107 | Val Loss: 0.9052 | Val Acc: 0.9701
🕒 Epoch 12/100 | Train Loss: 0.6985 | Val Loss: 0.9568 | Val Acc: 0.9402
🕒 Epoch 13/100 | Train Loss: 0.7099 | Val Loss: 0.9120 | Val Acc: 0.9645
🕒 Epoch 14/100 | Train Loss: 0.7139 | Val Loss: 0.9846 | Val Acc: 0.9308
🕒 Epoch 15/100 | Train Loss: 0.7426 | Val Loss: 0.8961 | Val Acc: 0.9664
💾 Best model updated (val acc: 0.9664)
🕒 Epoch 16/100 | Train Loss: 0.6895 | Val Loss: 0.8966 | Val Acc: 0.9645
🕒 Epoch 17/100 | Train Loss: 0.6825 | Val Loss: 0.8850 | Val Acc: 0.9701
💾 Best model updated (val acc: 0.9701)
🕒 Epoch 18/100 | Train Loss: 0.6899 | Val Loss: 0.9017 | Val Acc: 0.9682
🕒 Epoch 19/100 | Train Loss: 0.6888 | Val Loss: 0.9157 | Val Acc: 0.9551
🕒 Epoch 20/100 | Train Loss: 0.7037 | Val Loss: 0.8983 | Val Acc: 0.9626
🕒 Epoch 21/100 | Train Loss: 0.6852 | Val Loss: 0.8962 | Val Acc: 0.9738
🕒 Epoch 22/100 | Train Loss: 0.6724 | Val Loss: 0.8940 | Val Acc: 0.9701
🕒 Epoch 23/100 | Train Loss: 0.6894 | Val Loss: 0.9057 | Val Acc: 0.9607
🕒 Epoch 24/100 | Train Loss: 0.6729 | Val Loss: 0.8831 | Val Acc: 0.9701
💾 Best model updated (val acc: 0.9701)
🕒 Epoch 25/100 | Train Loss: 0.6847 | Val Loss: 0.9042 | Val Acc: 0.9645
🕒 Epoch 26/100 | Train Loss: 0.6846 | Val Loss: 0.8747 | Val Acc: 0.9794
💾 Best model updated (val acc: 0.9794)
🕒 Epoch 27/100 | Train Loss: 0.6828 | Val Loss: 0.9019 | Val Acc: 0.9664
🕒 Epoch 28/100 | Train Loss: 0.6857 | Val Loss: 0.8747 | Val Acc: 0.9776
🕒 Epoch 29/100 | Train Loss: 0.6729 | Val Loss: 0.8816 | Val Acc: 0.9738
🕒 Epoch 30/100 | Train Loss: 0.6771 | Val Loss: 0.8848 | Val Acc: 0.9738
🕒 Epoch 31/100 | Train Loss: 0.6793 | Val Loss: 0.8914 | Val Acc: 0.9813
🕒 Epoch 32/100 | Train Loss: 0.6718 | Val Loss: 0.8781 | Val Acc: 0.9720
🕒 Epoch 33/100 | Train Loss: 0.6715 | Val Loss: 0.9055 | Val Acc: 0.9607
🕒 Epoch 34/100 | Train Loss: 0.6736 | Val Loss: 0.8765 | Val Acc: 0.9832
🕒 Epoch 35/100 | Train Loss: 0.6761 | Val Loss: 0.8832 | Val Acc: 0.9757
🕒 Epoch 36/100 | Train Loss: 0.6757 | Val Loss: 0.8782 | Val Acc: 0.9757
⏹️ Early stopping.
✅ Fold 5 complete. Saved: ./output/models/ConvNeXt+cbam+batchnorm+dataset2+dataset2_fold5.pth
📂 Training metrics plot saved for Fold 1: output/test/fold_1/training_metrics.png
📂 Training metrics plot saved for Fold 2: output/test/fold_2/training_metrics.png
📂 Training metrics plot saved for Fold 3: output/test/fold_3/training_metrics.png
📂 Training metrics plot saved for Fold 4: output/test/fold_4/training_metrics.png
📂 Training metrics plot saved for Fold 5: output/test/fold_5/training_metrics.png
🎉 All folds completed.
🚀 Evaluating 5 fold models on test set

📂 Evaluating Fold 1
📊 Fold 1 Metrics:
   - Accuracy: 0.9735
   - Precision: 0.9645
   - Recall: 0.9675
   - F1 Score: 0.9647

📂 Evaluating Fold 2
📊 Fold 2 Metrics:
   - Accuracy: 0.9735
   - Precision: 0.9666
   - Recall: 0.9674
   - F1 Score: 0.9656

📂 Evaluating Fold 3
📊 Fold 3 Metrics:
   - Accuracy: 0.9749
   - Precision: 0.9674
   - Recall: 0.9684
   - F1 Score: 0.9665

📂 Evaluating Fold 4
📊 Fold 4 Metrics:
   - Accuracy: 0.9735
   - Precision: 0.9693
   - Recall: 0.9692
   - F1 Score: 0.9681

📂 Evaluating Fold 5
📊 Fold 5 Metrics:
   - Accuracy: 0.9735
   - Precision: 0.9666
   - Recall: 0.9660
   - F1 Score: 0.9647

🧾 Classification Report for ConvNeXt+cbam+batchnorm+dataset2 (Majority Vote from 5 folds):

                       precision    recall  f1-score   support

     Bacterial Blight     1.0000    0.8980    0.9462        49
Bacterial Leaf Streak     0.8462    1.0000    0.9167        33
           Brown Spot     0.9742    0.9934    0.9837       152
              Healthy     0.9811    0.9873    0.9842       158
                Hispa     0.9924    0.9850    0.9887       133
           Leaf Blast     1.0000    0.9766    0.9881       128
        Sheath Blight     1.0000    0.9600    0.9796        25

             accuracy                         0.9794       678
            macro avg     0.9706    0.9715    0.9696       678
         weighted avg     0.9808    0.9794    0.9795       678

🔢 Confusion Matrix:
 [[ 44   5   0   0   0   0   0]
 [  0  33   0   0   0   0   0]
 [  0   0 151   1   0   0   0]
 [  0   0   2 156   0   0   0]
 [  0   0   0   2 131   0   0]
 [  0   0   2   0   1 125   0]
 [  0   1   0   0   0   0  24]]

📊 Average Metrics Across All Folds:
   - Accuracy: 0.9737
   - Precision: 0.9669
   - Recall: 0.9677
   - F1 Score: 0.9659
🚀 Starting training with 5-Fold Cross-Validation for model: ConvNeXt+cbam+batchnorm+dataset3_kfold
/media/data3/users/datlht/Rice_leaf_disease_detection/load_data.py:81: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/media/data3/users/datlht/Rice_leaf_disease_detection/load_data.py:84: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from font(s) DejaVu Sans.
  plt.savefig(plot_path)
✅ Saved fold class distribution plot to: output/fold_class_distribution.png

📂 Fold 1/5
🕒 Epoch 1/50 | Train Loss: 0.4287 | Val Loss: 0.3589 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 2/50 | Train Loss: 0.3687 | Val Loss: 0.3580 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 3/50 | Train Loss: 0.3671 | Val Loss: 0.3627 | Val Acc: 1.0000
🕒 Epoch 4/50 | Train Loss: 0.3631 | Val Loss: 0.3554 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 5/50 | Train Loss: 0.3627 | Val Loss: 0.3544 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 6/50 | Train Loss: 0.3623 | Val Loss: 0.3537 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 7/50 | Train Loss: 0.3635 | Val Loss: 0.3553 | Val Acc: 1.0000
🕒 Epoch 8/50 | Train Loss: 0.3621 | Val Loss: 0.3537 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 9/50 | Train Loss: 0.3628 | Val Loss: 0.3540 | Val Acc: 1.0000
🕒 Epoch 10/50 | Train Loss: 0.3622 | Val Loss: 0.3548 | Val Acc: 1.0000
🕒 Epoch 11/50 | Train Loss: 0.3622 | Val Loss: 0.3544 | Val Acc: 1.0000
🕒 Epoch 12/50 | Train Loss: 0.3725 | Val Loss: 0.4841 | Val Acc: 0.9353
🕒 Epoch 13/50 | Train Loss: 0.3903 | Val Loss: 0.3558 | Val Acc: 0.9991
🕒 Epoch 14/50 | Train Loss: 0.3621 | Val Loss: 0.3545 | Val Acc: 1.0000
🕒 Epoch 15/50 | Train Loss: 0.3618 | Val Loss: 0.3546 | Val Acc: 1.0000
🕒 Epoch 16/50 | Train Loss: 0.3617 | Val Loss: 0.3540 | Val Acc: 1.0000
🕒 Epoch 17/50 | Train Loss: 0.3613 | Val Loss: 0.3539 | Val Acc: 1.0000
🕒 Epoch 18/50 | Train Loss: 0.3616 | Val Loss: 0.3547 | Val Acc: 1.0000
⏹️ Early stopping.
✅ Fold 1 complete. Saved: ./output/models/ConvNeXt+cbam+batchnorm+dataset3_kfold+dataset3_kfold_fold1.pth

📂 Fold 2/5
🕒 Epoch 1/50 | Train Loss: 0.4261 | Val Loss: 0.3718 | Val Acc: 0.9972
💾 Best model updated (val acc: 0.9972)
🕒 Epoch 2/50 | Train Loss: 0.3746 | Val Loss: 0.3579 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 3/50 | Train Loss: 0.3634 | Val Loss: 0.3582 | Val Acc: 1.0000
🕒 Epoch 4/50 | Train Loss: 0.3632 | Val Loss: 0.3570 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 5/50 | Train Loss: 0.3626 | Val Loss: 0.3559 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 6/50 | Train Loss: 0.3629 | Val Loss: 0.3563 | Val Acc: 1.0000
🕒 Epoch 7/50 | Train Loss: 0.3623 | Val Loss: 0.3547 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 8/50 | Train Loss: 0.3616 | Val Loss: 0.3554 | Val Acc: 1.0000
🕒 Epoch 9/50 | Train Loss: 0.3624 | Val Loss: 0.3547 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 10/50 | Train Loss: 0.3619 | Val Loss: 0.3554 | Val Acc: 1.0000
🕒 Epoch 11/50 | Train Loss: 0.3618 | Val Loss: 0.3538 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 12/50 | Train Loss: 0.3624 | Val Loss: 0.3539 | Val Acc: 1.0000
🕒 Epoch 13/50 | Train Loss: 0.3618 | Val Loss: 0.3540 | Val Acc: 1.0000
🕒 Epoch 14/50 | Train Loss: 0.3621 | Val Loss: 0.3559 | Val Acc: 1.0000
🕒 Epoch 15/50 | Train Loss: 0.3611 | Val Loss: 0.3538 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 16/50 | Train Loss: 0.3620 | Val Loss: 0.3558 | Val Acc: 1.0000
🕒 Epoch 17/50 | Train Loss: 0.3626 | Val Loss: 0.3538 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 18/50 | Train Loss: 0.3619 | Val Loss: 0.3539 | Val Acc: 1.0000
🕒 Epoch 19/50 | Train Loss: 0.3604 | Val Loss: 0.3534 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 20/50 | Train Loss: 0.3611 | Val Loss: 0.3535 | Val Acc: 1.0000
🕒 Epoch 21/50 | Train Loss: 0.3612 | Val Loss: 0.3541 | Val Acc: 1.0000
🕒 Epoch 22/50 | Train Loss: 0.3618 | Val Loss: 0.3553 | Val Acc: 1.0000
🕒 Epoch 23/50 | Train Loss: 0.3620 | Val Loss: 0.3545 | Val Acc: 1.0000
🕒 Epoch 24/50 | Train Loss: 0.3626 | Val Loss: 0.3536 | Val Acc: 1.0000
🕒 Epoch 25/50 | Train Loss: 0.3608 | Val Loss: 0.3542 | Val Acc: 1.0000
🕒 Epoch 26/50 | Train Loss: 0.3608 | Val Loss: 0.3531 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 27/50 | Train Loss: 0.3606 | Val Loss: 0.3537 | Val Acc: 1.0000
🕒 Epoch 28/50 | Train Loss: 0.3703 | Val Loss: 0.3622 | Val Acc: 0.9972
🕒 Epoch 29/50 | Train Loss: 0.3632 | Val Loss: 0.3538 | Val Acc: 1.0000
🕒 Epoch 30/50 | Train Loss: 0.3622 | Val Loss: 0.3541 | Val Acc: 1.0000
🕒 Epoch 31/50 | Train Loss: 0.3609 | Val Loss: 0.3540 | Val Acc: 1.0000
🕒 Epoch 32/50 | Train Loss: 0.3604 | Val Loss: 0.3536 | Val Acc: 1.0000
🕒 Epoch 33/50 | Train Loss: 0.3611 | Val Loss: 0.3539 | Val Acc: 1.0000
🕒 Epoch 34/50 | Train Loss: 0.3616 | Val Loss: 0.3537 | Val Acc: 1.0000
🕒 Epoch 35/50 | Train Loss: 0.3619 | Val Loss: 0.3532 | Val Acc: 1.0000
🕒 Epoch 36/50 | Train Loss: 0.3607 | Val Loss: 0.3533 | Val Acc: 1.0000
⏹️ Early stopping.
✅ Fold 2 complete. Saved: ./output/models/ConvNeXt+cbam+batchnorm+dataset3_kfold+dataset3_kfold_fold2.pth

📂 Fold 3/5
🕒 Epoch 1/50 | Train Loss: 0.4291 | Val Loss: 0.3615 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 2/50 | Train Loss: 0.3706 | Val Loss: 0.3571 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 3/50 | Train Loss: 0.3677 | Val Loss: 0.3560 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 4/50 | Train Loss: 0.3644 | Val Loss: 0.3538 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 5/50 | Train Loss: 0.3647 | Val Loss: 0.4392 | Val Acc: 0.9569
🕒 Epoch 6/50 | Train Loss: 0.3827 | Val Loss: 0.3575 | Val Acc: 1.0000
🕒 Epoch 7/50 | Train Loss: 0.3641 | Val Loss: 0.3550 | Val Acc: 1.0000
🕒 Epoch 8/50 | Train Loss: 0.3621 | Val Loss: 0.3556 | Val Acc: 1.0000
🕒 Epoch 9/50 | Train Loss: 0.3618 | Val Loss: 0.3552 | Val Acc: 1.0000
🕒 Epoch 10/50 | Train Loss: 0.3635 | Val Loss: 0.3551 | Val Acc: 1.0000
🕒 Epoch 11/50 | Train Loss: 0.3619 | Val Loss: 0.3547 | Val Acc: 1.0000
🕒 Epoch 12/50 | Train Loss: 0.3618 | Val Loss: 0.3534 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 13/50 | Train Loss: 0.3621 | Val Loss: 0.3547 | Val Acc: 1.0000
🕒 Epoch 14/50 | Train Loss: 0.3628 | Val Loss: 0.3538 | Val Acc: 1.0000
🕒 Epoch 15/50 | Train Loss: 0.3625 | Val Loss: 0.3537 | Val Acc: 1.0000
🕒 Epoch 16/50 | Train Loss: 0.3616 | Val Loss: 0.3533 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 17/50 | Train Loss: 0.3619 | Val Loss: 0.3537 | Val Acc: 1.0000
🕒 Epoch 18/50 | Train Loss: 0.3618 | Val Loss: 0.3541 | Val Acc: 1.0000
🕒 Epoch 19/50 | Train Loss: 0.3616 | Val Loss: 0.3536 | Val Acc: 1.0000
🕒 Epoch 20/50 | Train Loss: 0.3614 | Val Loss: 0.3532 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 21/50 | Train Loss: 0.3620 | Val Loss: 0.3536 | Val Acc: 1.0000
🕒 Epoch 22/50 | Train Loss: 0.3615 | Val Loss: 0.3535 | Val Acc: 1.0000
🕒 Epoch 23/50 | Train Loss: 0.3605 | Val Loss: 0.3544 | Val Acc: 1.0000
🕒 Epoch 24/50 | Train Loss: 0.3691 | Val Loss: 0.3631 | Val Acc: 0.9981
🕒 Epoch 25/50 | Train Loss: 0.3617 | Val Loss: 0.3540 | Val Acc: 1.0000
🕒 Epoch 26/50 | Train Loss: 0.3627 | Val Loss: 0.3535 | Val Acc: 1.0000
🕒 Epoch 27/50 | Train Loss: 0.3614 | Val Loss: 0.3546 | Val Acc: 1.0000
🕒 Epoch 28/50 | Train Loss: 0.3606 | Val Loss: 0.3532 | Val Acc: 1.0000
🕒 Epoch 29/50 | Train Loss: 0.3610 | Val Loss: 0.3540 | Val Acc: 1.0000
🕒 Epoch 30/50 | Train Loss: 0.3609 | Val Loss: 0.3542 | Val Acc: 1.0000
⏹️ Early stopping.
✅ Fold 3 complete. Saved: ./output/models/ConvNeXt+cbam+batchnorm+dataset3_kfold+dataset3_kfold_fold3.pth

📂 Fold 4/5
🕒 Epoch 1/50 | Train Loss: 0.4181 | Val Loss: 0.3572 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 2/50 | Train Loss: 0.3691 | Val Loss: 0.3568 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 3/50 | Train Loss: 0.3654 | Val Loss: 0.3563 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 4/50 | Train Loss: 0.3638 | Val Loss: 0.3550 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 5/50 | Train Loss: 0.3632 | Val Loss: 0.3554 | Val Acc: 1.0000
🕒 Epoch 6/50 | Train Loss: 0.3627 | Val Loss: 0.3539 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 7/50 | Train Loss: 0.3617 | Val Loss: 0.3561 | Val Acc: 1.0000
🕒 Epoch 8/50 | Train Loss: 0.3617 | Val Loss: 0.3561 | Val Acc: 1.0000
🕒 Epoch 9/50 | Train Loss: 0.3754 | Val Loss: 0.4373 | Val Acc: 0.9634
🕒 Epoch 10/50 | Train Loss: 0.3827 | Val Loss: 0.3544 | Val Acc: 1.0000
🕒 Epoch 11/50 | Train Loss: 0.3636 | Val Loss: 0.3553 | Val Acc: 1.0000
🕒 Epoch 12/50 | Train Loss: 0.3629 | Val Loss: 0.3537 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 13/50 | Train Loss: 0.3631 | Val Loss: 0.3546 | Val Acc: 1.0000
🕒 Epoch 14/50 | Train Loss: 0.3620 | Val Loss: 0.3544 | Val Acc: 1.0000
🕒 Epoch 15/50 | Train Loss: 0.3620 | Val Loss: 0.3533 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 16/50 | Train Loss: 0.3634 | Val Loss: 0.3551 | Val Acc: 1.0000
🕒 Epoch 17/50 | Train Loss: 0.3618 | Val Loss: 0.3541 | Val Acc: 1.0000
🕒 Epoch 18/50 | Train Loss: 0.3620 | Val Loss: 0.3532 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 19/50 | Train Loss: 0.3624 | Val Loss: 0.3562 | Val Acc: 1.0000
🕒 Epoch 20/50 | Train Loss: 0.3626 | Val Loss: 0.3574 | Val Acc: 1.0000
🕒 Epoch 21/50 | Train Loss: 0.3620 | Val Loss: 0.3542 | Val Acc: 1.0000
🕒 Epoch 22/50 | Train Loss: 0.3643 | Val Loss: 0.3813 | Val Acc: 0.9897
🕒 Epoch 23/50 | Train Loss: 0.3662 | Val Loss: 0.3559 | Val Acc: 1.0000
🕒 Epoch 24/50 | Train Loss: 0.3615 | Val Loss: 0.3533 | Val Acc: 1.0000
🕒 Epoch 25/50 | Train Loss: 0.3617 | Val Loss: 0.3534 | Val Acc: 1.0000
🕒 Epoch 26/50 | Train Loss: 0.3613 | Val Loss: 0.3534 | Val Acc: 1.0000
🕒 Epoch 27/50 | Train Loss: 0.3624 | Val Loss: 0.3538 | Val Acc: 1.0000
🕒 Epoch 28/50 | Train Loss: 0.3618 | Val Loss: 0.3532 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 29/50 | Train Loss: 0.3619 | Val Loss: 0.3535 | Val Acc: 1.0000
🕒 Epoch 30/50 | Train Loss: 0.3612 | Val Loss: 0.3535 | Val Acc: 1.0000
🕒 Epoch 31/50 | Train Loss: 0.3606 | Val Loss: 0.3540 | Val Acc: 1.0000
🕒 Epoch 32/50 | Train Loss: 0.3615 | Val Loss: 0.3538 | Val Acc: 1.0000
🕒 Epoch 33/50 | Train Loss: 0.3620 | Val Loss: 0.3539 | Val Acc: 1.0000
🕒 Epoch 34/50 | Train Loss: 0.3612 | Val Loss: 0.3543 | Val Acc: 1.0000
🕒 Epoch 35/50 | Train Loss: 0.3614 | Val Loss: 0.3533 | Val Acc: 1.0000
🕒 Epoch 36/50 | Train Loss: 0.3618 | Val Loss: 0.3538 | Val Acc: 1.0000
🕒 Epoch 37/50 | Train Loss: 0.3605 | Val Loss: 0.3536 | Val Acc: 1.0000
🕒 Epoch 38/50 | Train Loss: 0.3598 | Val Loss: 0.3552 | Val Acc: 1.0000
⏹️ Early stopping.
✅ Fold 4 complete. Saved: ./output/models/ConvNeXt+cbam+batchnorm+dataset3_kfold+dataset3_kfold_fold4.pth

📂 Fold 5/5
🕒 Epoch 1/50 | Train Loss: 0.4232 | Val Loss: 0.3592 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 2/50 | Train Loss: 0.3709 | Val Loss: 0.3587 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 3/50 | Train Loss: 0.3671 | Val Loss: 0.3544 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 4/50 | Train Loss: 0.3649 | Val Loss: 0.3544 | Val Acc: 1.0000
🕒 Epoch 5/50 | Train Loss: 0.3631 | Val Loss: 0.3562 | Val Acc: 1.0000
🕒 Epoch 6/50 | Train Loss: 0.3629 | Val Loss: 0.3536 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 7/50 | Train Loss: 0.3626 | Val Loss: 0.3548 | Val Acc: 1.0000
🕒 Epoch 8/50 | Train Loss: 0.3614 | Val Loss: 0.3545 | Val Acc: 1.0000
🕒 Epoch 9/50 | Train Loss: 0.3627 | Val Loss: 0.3536 | Val Acc: 1.0000
💾 Best model updated (val acc: 1.0000)
🕒 Epoch 10/50 | Train Loss: 0.3623 | Val Loss: 0.3536 | Val Acc: 1.0000
🕒 Epoch 11/50 | Train Loss: 0.3625 | Val Loss: 0.3548 | Val Acc: 1.0000
🕒 Epoch 12/50 | Train Loss: 0.3949 | Val Loss: 0.3568 | Val Acc: 0.9991
🕒 Epoch 13/50 | Train Loss: 0.3633 | Val Loss: 0.3547 | Val Acc: 1.0000
🕒 Epoch 14/50 | Train Loss: 0.3622 | Val Loss: 0.3549 | Val Acc: 1.0000
🕒 Epoch 15/50 | Train Loss: 0.3609 | Val Loss: 0.3556 | Val Acc: 1.0000
🕒 Epoch 16/50 | Train Loss: 0.3623 | Val Loss: 0.3550 | Val Acc: 1.0000
🕒 Epoch 17/50 | Train Loss: 0.3612 | Val Loss: 0.3542 | Val Acc: 1.0000
🕒 Epoch 18/50 | Train Loss: 0.3620 | Val Loss: 0.3551 | Val Acc: 1.0000
🕒 Epoch 19/50 | Train Loss: 0.3615 | Val Loss: 0.3567 | Val Acc: 1.0000
⏹️ Early stopping.
✅ Fold 5 complete. Saved: ./output/models/ConvNeXt+cbam+batchnorm+dataset3_kfold+dataset3_kfold_fold5.pth
📂 Training metrics plot saved for Fold 1: output/test/fold_1/training_metrics.png
📂 Training metrics plot saved for Fold 2: output/test/fold_2/training_metrics.png
📂 Training metrics plot saved for Fold 3: output/test/fold_3/training_metrics.png
📂 Training metrics plot saved for Fold 4: output/test/fold_4/training_metrics.png
📂 Training metrics plot saved for Fold 5: output/test/fold_5/training_metrics.png
🎉 All folds completed.
🚀 Evaluating 5 fold models on test set

📂 Evaluating Fold 1
📊 Fold 1 Metrics:
   - Accuracy: 1.0000
   - Precision: 1.0000
   - Recall: 1.0000
   - F1 Score: 1.0000

📂 Evaluating Fold 2
📊 Fold 2 Metrics:
   - Accuracy: 1.0000
   - Precision: 1.0000
   - Recall: 1.0000
   - F1 Score: 1.0000

📂 Evaluating Fold 3
📊 Fold 3 Metrics:
   - Accuracy: 1.0000
   - Precision: 1.0000
   - Recall: 1.0000
   - F1 Score: 1.0000

📂 Evaluating Fold 4
📊 Fold 4 Metrics:
   - Accuracy: 1.0000
   - Precision: 1.0000
   - Recall: 1.0000
   - F1 Score: 1.0000

📂 Evaluating Fold 5
📊 Fold 5 Metrics:
   - Accuracy: 1.0000
   - Precision: 1.0000
   - Recall: 1.0000
   - F1 Score: 1.0000

🧾 Classification Report for ConvNeXt+cbam+batchnorm+dataset3_kfold (Majority Vote from 5 folds):

                 precision    recall  f1-score   support

Bacterialblight     1.0000    1.0000    1.0000       160
          Blast     1.0000    1.0000    1.0000       145
      Brownspot     1.0000    1.0000    1.0000       160
         Tungro     1.0000    1.0000    1.0000       132

       accuracy                         1.0000       597
      macro avg     1.0000    1.0000    1.0000       597
   weighted avg     1.0000    1.0000    1.0000       597

🔢 Confusion Matrix:
 [[160   0   0   0]
 [  0 145   0   0]
 [  0   0 160   0]
 [  0   0   0 132]]

📊 Average Metrics Across All Folds:
   - Accuracy: 1.0000
   - Precision: 1.0000
   - Recall: 1.0000
   - F1 Score: 1.0000
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: set_name_for_the_model_here+PlantVillageSplited]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
Epoch 1/50 | Time: 1136.87s | Train Loss: 0.8067 | Val Loss: 0.7181 | Val Acc: 0.9881 | LR: 0.000100 
Saving best val acc: 0.9881
Epoch 2/50 | Time: 1042.17s | Train Loss: 0.7137 | Val Loss: 0.6990 | Val Acc: 0.9944 | LR: 0.000100 
Saving best val acc: 0.9944
Epoch 3/50 | Time: 1042.30s | Train Loss: 0.7013 | Val Loss: 0.6935 | Val Acc: 0.9946 | LR: 0.000100 
Saving best val acc: 0.9946
Epoch 4/50 | Time: 1043.00s | Train Loss: 0.6992 | Val Loss: 0.6913 | Val Acc: 0.9952 | LR: 0.000099 
Saving best val acc: 0.9952
Epoch 5/50 | Time: 1042.10s | Train Loss: 0.6925 | Val Loss: 0.6892 | Val Acc: 0.9950 | LR: 0.000098 
Saving best val acc: 0.9950
Epoch 6/50 | Time: 1042.29s | Train Loss: 0.6938 | Val Loss: 0.6884 | Val Acc: 0.9973 | LR: 0.000098 
Saving best val acc: 0.9973
Epoch 7/50 | Time: 1042.07s | Train Loss: 0.6918 | Val Loss: 0.6901 | Val Acc: 0.9949 | LR: 0.000097 
Epoch 8/50 | Time: 1042.21s | Train Loss: 0.6892 | Val Loss: 0.6893 | Val Acc: 0.9957 | LR: 0.000095 
Epoch 9/50 | Time: 1042.19s | Train Loss: 0.6883 | Val Loss: 0.6826 | Val Acc: 0.9974 | LR: 0.000094 
Saving best val acc: 0.9974
Epoch 10/50 | Time: 1042.19s | Train Loss: 0.6855 | Val Loss: 0.7135 | Val Acc: 0.9864 | LR: 0.000092 
Epoch 11/50 | Time: 1042.40s | Train Loss: 0.6854 | Val Loss: 0.6942 | Val Acc: 0.9948 | LR: 0.000091 
Epoch 12/50 | Time: 1042.20s | Train Loss: 0.6847 | Val Loss: 0.6800 | Val Acc: 0.9981 | LR: 0.000089 
Saving best val acc: 0.9981
Epoch 13/50 | Time: 1042.28s | Train Loss: 0.6862 | Val Loss: 0.6844 | Val Acc: 0.9966 | LR: 0.000087 
Epoch 14/50 | Time: 1042.21s | Train Loss: 0.6824 | Val Loss: 0.6975 | Val Acc: 0.9914 | LR: 0.000084 
Epoch 15/50 | Time: 1042.09s | Train Loss: 0.6811 | Val Loss: 0.7113 | Val Acc: 0.9893 | LR: 0.000082 
Epoch 16/50 | Time: 1042.20s | Train Loss: 0.6813 | Val Loss: 0.6804 | Val Acc: 0.9982 | LR: 0.000080 
Epoch 17/50 | Time: 1042.20s | Train Loss: 0.6835 | Val Loss: 0.6813 | Val Acc: 0.9974 | LR: 0.000077 
Epoch 18/50 | Time: 1041.89s | Train Loss: 0.6805 | Val Loss: 0.6803 | Val Acc: 0.9975 | LR: 0.000074 
Epoch 19/50 | Time: 1042.12s | Train Loss: 0.6780 | Val Loss: 0.6842 | Val Acc: 0.9969 | LR: 0.000072 
Epoch 20/50 | Time: 1042.18s | Train Loss: 0.6808 | Val Loss: 0.6827 | Val Acc: 0.9969 | LR: 0.000069 
Epoch 21/50 | Time: 1042.83s | Train Loss: 0.6783 | Val Loss: 0.6895 | Val Acc: 0.9950 | LR: 0.000066 
Epoch 22/50 | Time: 1043.33s | Train Loss: 0.6780 | Val Loss: 0.6791 | Val Acc: 0.9983 | LR: 0.000063 
Saving best val acc: 0.9983
Epoch 23/50 | Time: 1042.06s | Train Loss: 0.6768 | Val Loss: 0.6862 | Val Acc: 0.9957 | LR: 0.000060 
Epoch 24/50 | Time: 1042.67s | Train Loss: 0.6770 | Val Loss: 0.6807 | Val Acc: 0.9976 | LR: 0.000057 
Epoch 25/50 | Time: 1042.15s | Train Loss: 0.6763 | Val Loss: 0.6830 | Val Acc: 0.9969 | LR: 0.000054 
Epoch 26/50 | Time: 1042.30s | Train Loss: 0.6762 | Val Loss: 0.6817 | Val Acc: 0.9975 | LR: 0.000050 
Epoch 27/50 | Time: 1042.20s | Train Loss: 0.6763 | Val Loss: 0.6827 | Val Acc: 0.9971 | LR: 0.000047 
Epoch 28/50 | Time: 1042.20s | Train Loss: 0.6751 | Val Loss: 0.6798 | Val Acc: 0.9983 | LR: 0.000044 
Epoch 29/50 | Time: 1042.09s | Train Loss: 0.6763 | Val Loss: 0.6808 | Val Acc: 0.9977 | LR: 0.000041 
Epoch 30/50 | Time: 1042.50s | Train Loss: 0.6748 | Val Loss: 0.6811 | Val Acc: 0.9977 | LR: 0.000038 
Epoch 31/50 | Time: 1042.21s | Train Loss: 0.6751 | Val Loss: 0.6817 | Val Acc: 0.9977 | LR: 0.000035 
Epoch 32/50 | Time: 1042.20s | Train Loss: 0.6750 | Val Loss: 0.6815 | Val Acc: 0.9981 | LR: 0.000032 
Early stopping triggered.
Training complete in 33448.06 seconds. Best model loaded.
Model saved to ./output/models/set_name_for_the_model_here+PlantVillageSplited+PlantVillageSplited.pth
 Training metrics plot saved to: output/test/set_name_for_the_model_here+PlantVillageSplited/training metric.png
Evaluate model:set_name_for_the_model_here+PlantVillageSplited

 Test Accuracy: 99.72%

 Classification Report:
                                                    precision    recall  f1-score   support

                                Apple___Apple_scab     1.0000    1.0000    1.0000        63
                                 Apple___Black_rot     1.0000    1.0000    1.0000        62
                          Apple___Cedar_apple_rust     1.0000    1.0000    1.0000        28
                                   Apple___healthy     0.9940    1.0000    0.9970       165
                               Blueberry___healthy     1.0000    1.0000    1.0000       151
          Cherry_(including_sour)___Powdery_mildew     1.0000    1.0000    1.0000       106
                 Cherry_(including_sour)___healthy     1.0000    1.0000    1.0000        86
Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot     0.9444    0.9808    0.9623        52
                       Corn_(maize)___Common_rust_     1.0000    0.9917    0.9958       120
               Corn_(maize)___Northern_Leaf_Blight     0.9796    0.9697    0.9746        99
                            Corn_(maize)___healthy     1.0000    1.0000    1.0000       117
                                 Grape___Black_rot     1.0000    1.0000    1.0000       118
                      Grape___Esca_(Black_Measles)     1.0000    1.0000    1.0000       139
        Grape___Leaf_blight_(Isariopsis_Leaf_Spot)     1.0000    1.0000    1.0000       108
                                   Grape___healthy     1.0000    1.0000    1.0000        43
          Orange___Haunglongbing_(Citrus_greening)     1.0000    1.0000    1.0000       551
                            Peach___Bacterial_spot     0.9957    1.0000    0.9978       230
                                   Peach___healthy     1.0000    0.9722    0.9859        36
                     Pepper,_bell___Bacterial_spot     0.9804    1.0000    0.9901       100
                            Pepper,_bell___healthy     1.0000    0.9797    0.9898       148
                             Potato___Early_blight     1.0000    1.0000    1.0000       100
                              Potato___Late_blight     1.0000    1.0000    1.0000       100
                                  Potato___healthy     1.0000    1.0000    1.0000        16
                               Raspberry___healthy     1.0000    1.0000    1.0000        38
                                 Soybean___healthy     1.0000    1.0000    1.0000       509
                           Squash___Powdery_mildew     1.0000    1.0000    1.0000       184
                          Strawberry___Leaf_scorch     1.0000    1.0000    1.0000       111
                              Strawberry___healthy     1.0000    1.0000    1.0000        46
                           Tomato___Bacterial_spot     0.9953    0.9953    0.9953       213
                             Tomato___Early_blight     0.9802    0.9900    0.9851       100
                              Tomato___Late_blight     1.0000    0.9895    0.9947       191
                                Tomato___Leaf_Mold     1.0000    1.0000    1.0000        96
                       Tomato___Septoria_leaf_spot     0.9888    0.9944    0.9916       178
     Tomato___Spider_mites_Two-spotted_spider_mite     1.0000    1.0000    1.0000       168
                              Tomato___Target_Spot     1.0000    0.9929    0.9964       141
            Tomato___Tomato_Yellow_Leaf_Curl_Virus     0.9981    1.0000    0.9991       536
                      Tomato___Tomato_mosaic_virus     1.0000    1.0000    1.0000        38
                                  Tomato___healthy     1.0000    1.0000    1.0000       160

                                          accuracy                         0.9972      5447
                                         macro avg     0.9962    0.9962    0.9962      5447
                                      weighted avg     0.9973    0.9972    0.9972      5447


✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: Convnext2+PlantDocSplited]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
Epoch 1/100 | Time: 202.60s | Train Loss: 1.7608 | Val Loss: 1.2701 | Val Acc: 0.7508 | LR: 0.000100 
Saving best val acc: 0.7508
Epoch 2/100 | Time: 158.95s | Train Loss: 1.1514 | Val Loss: 1.2034 | Val Acc: 0.7778 | LR: 0.000100 
Saving best val acc: 0.7778
Epoch 3/100 | Time: 158.21s | Train Loss: 1.0023 | Val Loss: 1.2673 | Val Acc: 0.7568 | LR: 0.000100 
Epoch 4/100 | Time: 158.05s | Train Loss: 0.8879 | Val Loss: 1.2340 | Val Acc: 0.7868 | LR: 0.000099 
Epoch 5/100 | Time: 157.98s | Train Loss: 0.8120 | Val Loss: 1.2172 | Val Acc: 0.8048 | LR: 0.000098 
Epoch 6/100 | Time: 157.34s | Train Loss: 0.7710 | Val Loss: 1.2373 | Val Acc: 0.7958 | LR: 0.000098 
Epoch 7/100 | Time: 158.19s | Train Loss: 0.7537 | Val Loss: 1.1785 | Val Acc: 0.8288 | LR: 0.000097 
Saving best val acc: 0.8288
Epoch 8/100 | Time: 158.32s | Train Loss: 0.7362 | Val Loss: 1.2897 | Val Acc: 0.7838 | LR: 0.000095 
Epoch 9/100 | Time: 159.69s | Train Loss: 0.7293 | Val Loss: 1.2240 | Val Acc: 0.8048 | LR: 0.000094 
Epoch 10/100 | Time: 158.14s | Train Loss: 0.7250 | Val Loss: 1.1956 | Val Acc: 0.8228 | LR: 0.000092 
Epoch 11/100 | Time: 158.30s | Train Loss: 0.7106 | Val Loss: 1.2112 | Val Acc: 0.8168 | LR: 0.000091 
Epoch 12/100 | Time: 153.40s | Train Loss: 0.7023 | Val Loss: 1.1697 | Val Acc: 0.8228 | LR: 0.000089 
Saving best val acc: 0.8228
Epoch 13/100 | Time: 158.59s | Train Loss: 0.6935 | Val Loss: 1.2092 | Val Acc: 0.8288 | LR: 0.000087 
Epoch 14/100 | Time: 158.07s | Train Loss: 0.6972 | Val Loss: 1.2332 | Val Acc: 0.8108 | LR: 0.000084 
Epoch 15/100 | Time: 158.24s | Train Loss: 0.6878 | Val Loss: 1.1707 | Val Acc: 0.8468 | LR: 0.000082 
Epoch 16/100 | Time: 158.75s | Train Loss: 0.6910 | Val Loss: 1.2134 | Val Acc: 0.8258 | LR: 0.000080 
Epoch 17/100 | Time: 157.92s | Train Loss: 0.6929 | Val Loss: 1.2081 | Val Acc: 0.7988 | LR: 0.000077 
Epoch 18/100 | Time: 157.32s | Train Loss: 0.6855 | Val Loss: 1.1677 | Val Acc: 0.8348 | LR: 0.000074 
Saving best val acc: 0.8348
Epoch 19/100 | Time: 157.68s | Train Loss: 0.6798 | Val Loss: 1.1577 | Val Acc: 0.8438 | LR: 0.000072 
Saving best val acc: 0.8438
Epoch 20/100 | Time: 157.19s | Train Loss: 0.6847 | Val Loss: 1.1344 | Val Acc: 0.8438 | LR: 0.000069 
Saving best val acc: 0.8438
Epoch 21/100 | Time: 158.12s | Train Loss: 0.6786 | Val Loss: 1.1734 | Val Acc: 0.8378 | LR: 0.000066 
Epoch 22/100 | Time: 157.88s | Train Loss: 0.6761 | Val Loss: 1.1845 | Val Acc: 0.8408 | LR: 0.000063 
Epoch 23/100 | Time: 157.60s | Train Loss: 0.6780 | Val Loss: 1.1868 | Val Acc: 0.8378 | LR: 0.000060 
Epoch 24/100 | Time: 157.98s | Train Loss: 0.6799 | Val Loss: 1.1807 | Val Acc: 0.8378 | LR: 0.000057 
Epoch 25/100 | Time: 157.86s | Train Loss: 0.6781 | Val Loss: 1.2083 | Val Acc: 0.8108 | LR: 0.000054 
Epoch 26/100 | Time: 158.79s | Train Loss: 0.6759 | Val Loss: 1.1763 | Val Acc: 0.8138 | LR: 0.000050 
Epoch 27/100 | Time: 159.18s | Train Loss: 0.6753 | Val Loss: 1.1900 | Val Acc: 0.8228 | LR: 0.000047 
Epoch 28/100 | Time: 158.28s | Train Loss: 0.6748 | Val Loss: 1.1762 | Val Acc: 0.8168 | LR: 0.000044 
Epoch 29/100 | Time: 158.43s | Train Loss: 0.6743 | Val Loss: 1.2026 | Val Acc: 0.8258 | LR: 0.000041 
Epoch 30/100 | Time: 158.87s | Train Loss: 0.6710 | Val Loss: 1.1887 | Val Acc: 0.8198 | LR: 0.000038 
Epoch 31/100 | Time: 157.96s | Train Loss: 0.6710 | Val Loss: 1.1894 | Val Acc: 0.8378 | LR: 0.000035 
Epoch 32/100 | Time: 158.09s | Train Loss: 0.6687 | Val Loss: 1.1833 | Val Acc: 0.8348 | LR: 0.000032 
Epoch 33/100 | Time: 158.07s | Train Loss: 0.6691 | Val Loss: 1.1964 | Val Acc: 0.8408 | LR: 0.000029 
Epoch 34/100 | Time: 155.93s | Train Loss: 0.6699 | Val Loss: 1.1525 | Val Acc: 0.8468 | LR: 0.000027 
Epoch 35/100 | Time: 159.11s | Train Loss: 0.6701 | Val Loss: 1.1695 | Val Acc: 0.8318 | LR: 0.000024 
Epoch 36/100 | Time: 157.89s | Train Loss: 0.6679 | Val Loss: 1.1836 | Val Acc: 0.8318 | LR: 0.000021 
Epoch 37/100 | Time: 158.67s | Train Loss: 0.6672 | Val Loss: 1.1803 | Val Acc: 0.8318 | LR: 0.000019 
Epoch 38/100 | Time: 159.11s | Train Loss: 0.6675 | Val Loss: 1.1706 | Val Acc: 0.8258 | LR: 0.000017 
Epoch 39/100 | Time: 158.47s | Train Loss: 0.6651 | Val Loss: 1.1861 | Val Acc: 0.8318 | LR: 0.000014 
Epoch 40/100 | Time: 157.79s | Train Loss: 0.6645 | Val Loss: 1.1767 | Val Acc: 0.8288 | LR: 0.000012 
Early stopping triggered.
Training complete in 6367.16 seconds. Best model loaded.
Model saved to ./output/models/Convnext2+PlantDocSplited+PlantDocSplited.pth
 Training metrics plot saved to: output/test/Convnext2+PlantDocSplited/training metric.png
Evaluate model:Convnext2+PlantDocSplited

 Test Accuracy: 68.25%

 Classification Report:
/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
                                      precision    recall  f1-score   support

                     Apple_Scab_Leaf     0.7273    0.8000    0.7619        10
                          Apple_leaf     0.7500    0.6667    0.7059         9
                     Apple_rust_leaf     0.9000    0.9000    0.9000        10
                    Bell_pepper_leaf     0.8750    0.8750    0.8750         8
               Bell_pepper_leaf_spot     0.8000    0.8889    0.8421         9
                      Blueberry_leaf     0.8333    0.9091    0.8696        11
                         Cherry_leaf     1.0000    0.8000    0.8889        10
                 Corn_Gray_leaf_spot     0.1111    0.2500    0.1538         4
                    Corn_leaf_blight     0.6250    0.4167    0.5000        12
                      Corn_rust_leaf     0.9000    0.9000    0.9000        10
                          Peach_leaf     1.0000    1.0000    1.0000         9
            Potato_leaf_early_blight     0.3333    0.2143    0.2609        14
             Potato_leaf_late_blight     0.2353    0.5000    0.3200         8
                      Raspberry_leaf     0.8750    1.0000    0.9333         7
                       Soyabean_leaf     0.7500    0.7500    0.7500         8
          Squash_Powdery_mildew_leaf     1.0000    1.0000    1.0000         6
                     Strawberry_leaf     1.0000    1.0000    1.0000         8
            Tomato_Early_blight_leaf     0.7000    0.7778    0.7368         9
           Tomato_Septoria_leaf_spot     0.8333    0.8333    0.8333        12
                         Tomato_leaf     1.0000    0.5000    0.6667         8
          Tomato_leaf_bacterial_spot     0.6250    0.5556    0.5882         9
             Tomato_leaf_late_blight     0.8750    0.7000    0.7778        10
            Tomato_leaf_mosaic_virus     0.8333    0.5000    0.6250        10
            Tomato_leaf_yellow_virus     0.8824    1.0000    0.9375        15
                    Tomato_mold_leaf     0.6250    0.8333    0.7143         6
Tomato_two_spotted_spider_mites_leaf     0.0000    0.0000    0.0000        12
                          grape_leaf     0.0000    0.0000    0.0000         8
                grape_leaf_black_rot     0.0000    0.0000    0.0000         0

                            accuracy                         0.6825       252
                           macro avg     0.6818    0.6632    0.6622       252
                        weighted avg     0.7103    0.6825    0.6865       252

 Confusion matrix saved to: output/test/Convnext2+PlantDocSplited/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/Convnext2+PlantDocSplited/grad_cam folder!
Traceback (most recent call last):
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/wrong_test.py", line 41, in <module>
    predicted_labels.append(class_names[preds[i].cpu().item()])
                            ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
IndexError: list index out of range
Evaluate model:Convnext2+PlantDocSplited

 Test Accuracy: 76.28%

 Classification Report:
                                      precision    recall  f1-score   support

                     Apple_Scab_Leaf     0.7273    0.8000    0.7619        10
                          Apple_leaf     0.7500    0.6667    0.7059         9
                     Apple_rust_leaf     0.9000    0.9000    0.9000        10
                    Bell_pepper_leaf     0.8750    0.8750    0.8750         8
               Bell_pepper_leaf_spot     0.8000    0.8889    0.8421         9
                      Blueberry_leaf     0.8333    0.9091    0.8696        11
                         Cherry_leaf     1.0000    0.8000    0.8889        10
                 Corn_Gray_leaf_spot     0.1111    0.2500    0.1538         4
                    Corn_leaf_blight     0.6250    0.4167    0.5000        12
                      Corn_rust_leaf     0.9000    0.9000    0.9000        10
                          Peach_leaf     1.0000    1.0000    1.0000         9
            Potato_leaf_early_blight     0.3333    0.2143    0.2609        14
             Potato_leaf_late_blight     0.2353    0.5000    0.3200         8
                      Raspberry_leaf     0.8750    1.0000    0.9333         7
                       Soyabean_leaf     0.7500    0.7500    0.7500         8
          Squash_Powdery_mildew_leaf     1.0000    1.0000    1.0000         6
                     Strawberry_leaf     1.0000    1.0000    1.0000         8
            Tomato_Early_blight_leaf     0.7000    0.7778    0.7368         9
           Tomato_Septoria_leaf_spot     0.8333    0.8333    0.8333        12
                         Tomato_leaf     1.0000    0.5000    0.6667         8
          Tomato_leaf_bacterial_spot     0.6250    0.5556    0.5882         9
             Tomato_leaf_late_blight     0.8750    0.7000    0.7778        10
            Tomato_leaf_mosaic_virus     0.8333    0.5000    0.6250        10
            Tomato_leaf_yellow_virus     0.8824    1.0000    0.9375        15
                    Tomato_mold_leaf     0.6250    0.8333    0.7143         6
Tomato_two_spotted_spider_mites_leaf     1.0000    1.0000    1.0000         1
                          grape_leaf     1.0000    1.0000    1.0000        12
                grape_leaf_black_rot     1.0000    1.0000    1.0000         8

                            accuracy                         0.7628       253
                           macro avg     0.7889    0.7704    0.7693       253
                        weighted avg     0.7905    0.7628    0.7668       253

 Confusion matrix saved to: output/test/Convnext2+PlantDocSplited/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/Convnext2+PlantDocSplited/grad_cam folder!
Saved misclassified images to output/test/Convnext2+PlantDocSplited/misclassified_images.png
Evaluate model:Convnext2+PlantDocSplited

 Test Accuracy: 77.20%

 Classification Report:
                                      precision    recall  f1-score   support

                     Apple_Scab_Leaf     0.7273    0.8000    0.7619        10
                          Apple_leaf     0.7500    0.6667    0.7059         9
                     Apple_rust_leaf     0.9000    0.9000    0.9000        10
                    Bell_pepper_leaf     0.8750    0.8750    0.8750         8
               Bell_pepper_leaf_spot     0.8000    0.8889    0.8421         9
                      Blueberry_leaf     0.9091    0.9091    0.9091        11
                         Cherry_leaf     1.0000    0.8000    0.8889        10
                 Corn_Gray_leaf_spot     0.1111    0.2500    0.1538         4
                    Corn_leaf_blight     0.6250    0.4167    0.5000        12
                      Corn_rust_leaf     0.9000    0.9000    0.9000        10
                          Peach_leaf     1.0000    1.0000    1.0000         9
            Potato_leaf_early_blight     0.3333    0.2143    0.2609        14
             Potato_leaf_late_blight     0.2353    0.5000    0.3200         8
                      Raspberry_leaf     0.8750    1.0000    0.9333         7
                       Soyabean_leaf     0.7500    0.8571    0.8000         7
          Squash_Powdery_mildew_leaf     1.0000    1.0000    1.0000         6
                     Strawberry_leaf     1.0000    1.0000    1.0000         8
            Tomato_Early_blight_leaf     0.7778    0.7778    0.7778         9
           Tomato_Septoria_leaf_spot     0.8333    0.8333    0.8333        12
                         Tomato_leaf     1.0000    0.5000    0.6667         8
          Tomato_leaf_bacterial_spot     0.7143    0.6250    0.6667         8
             Tomato_leaf_late_blight     0.8750    0.7000    0.7778        10
            Tomato_leaf_mosaic_virus     0.8333    0.5000    0.6250        10
            Tomato_leaf_yellow_virus     0.8824    1.0000    0.9375        15
                    Tomato_mold_leaf     0.6250    1.0000    0.7692         5
Tomato_two_spotted_spider_mites_leaf     1.0000    1.0000    1.0000         1
                          grape_leaf     1.0000    1.0000    1.0000        12
                grape_leaf_black_rot     1.0000    1.0000    1.0000         8

                            accuracy                         0.7720       250
                           macro avg     0.7976    0.7826    0.7787       250
                        weighted avg     0.8010    0.7720    0.7760       250

 Confusion matrix saved to: output/test/Convnext2+PlantDocSplited/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/Convnext2+PlantDocSplited/grad_cam folder!
Saved misclassified images to output/test/Convnext2+PlantDocSplited/misclassified_images.png
----------------------------------------DEPTH---------------------------
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: Convnext+depth+CBAM+dataset1]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Epoch 1/100 | Time: 213.10s | Train Loss: 1.0960 | Val Loss: 0.8843 | Val Acc: 0.7983 | LR: 0.000100 
Saving best val acc: 0.7983
Epoch 2/100 | Time: 179.90s | Train Loss: 0.6933 | Val Loss: 0.5607 | Val Acc: 0.9479 | LR: 0.000100 
Saving best val acc: 0.9479
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: Convnext+depth+CBAM+dataset1]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Epoch 1/100 | Time: 171.71s | Train Loss: 1.0551 | Val Loss: 0.8208 | Val Acc: 0.8373 | LR: 0.000100 
Saving best val acc: 0.8373
Epoch 2/100 | Time: 169.81s | Train Loss: 0.6604 | Val Loss: 0.5919 | Val Acc: 0.9306 | LR: 0.000100 
Saving best val acc: 0.9306
Epoch 3/100 | Time: 166.40s | Train Loss: 0.5838 | Val Loss: 0.5350 | Val Acc: 0.9436 | LR: 0.000100 
Saving best val acc: 0.9436
Epoch 4/100 | Time: 169.49s | Train Loss: 0.5431 | Val Loss: 0.5373 | Val Acc: 0.9610 | LR: 0.000099 
Epoch 5/100 | Time: 170.61s | Train Loss: 0.5102 | Val Loss: 0.5336 | Val Acc: 0.9544 | LR: 0.000098 
Saving best val acc: 0.9544
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: Convnext+depth+CBAM+dataset1]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Epoch 1/100 | Time: 175.94s | Train Loss: 0.9318 | Val Loss: 0.6438 | Val Acc: 0.9349 | LR: 0.000100 
Saving best val acc: 0.9349
Epoch 2/100 | Time: 172.18s | Train Loss: 0.6077 | Val Loss: 0.5926 | Val Acc: 0.9328 | LR: 0.000100 
Saving best val acc: 0.9328
Epoch 3/100 | Time: 171.23s | Train Loss: 0.5436 | Val Loss: 0.5472 | Val Acc: 0.9566 | LR: 0.000100 
Saving best val acc: 0.9566
Epoch 4/100 | Time: 174.08s | Train Loss: 0.5304 | Val Loss: 0.5403 | Val Acc: 0.9479 | LR: 0.000099 
Saving best val acc: 0.9479
Epoch 5/100 | Time: 174.00s | Train Loss: 0.5117 | Val Loss: 0.6408 | Val Acc: 0.9046 | LR: 0.000098 
Epoch 6/100 | Time: 174.54s | Train Loss: 0.5041 | Val Loss: 0.5192 | Val Acc: 0.9588 | LR: 0.000098 
Saving best val acc: 0.9588
Epoch 7/100 | Time: 174.74s | Train Loss: 0.5079 | Val Loss: 0.5286 | Val Acc: 0.9566 | LR: 0.000097 
Epoch 8/100 | Time: 175.84s | Train Loss: 0.4847 | Val Loss: 0.5099 | Val Acc: 0.9653 | LR: 0.000095 
Saving best val acc: 0.9653
Epoch 9/100 | Time: 173.56s | Train Loss: 0.4808 | Val Loss: 0.4955 | Val Acc: 0.9740 | LR: 0.000094 
Saving best val acc: 0.9740
Epoch 10/100 | Time: 168.37s | Train Loss: 0.4802 | Val Loss: 0.4881 | Val Acc: 0.9761 | LR: 0.000092 
Saving best val acc: 0.9761
Epoch 11/100 | Time: 173.73s | Train Loss: 0.4663 | Val Loss: 0.5110 | Val Acc: 0.9696 | LR: 0.000091 
Epoch 12/100 | Time: 180.50s | Train Loss: 0.4710 | Val Loss: 0.5994 | Val Acc: 0.9349 | LR: 0.000089 
Epoch 13/100 | Time: 176.61s | Train Loss: 0.4992 | Val Loss: 0.5497 | Val Acc: 0.9501 | LR: 0.000087 
Epoch 14/100 | Time: 179.80s | Train Loss: 0.4699 | Val Loss: 0.4886 | Val Acc: 0.9740 | LR: 0.000084 
Epoch 15/100 | Time: 177.04s | Train Loss: 0.4622 | Val Loss: 0.4952 | Val Acc: 0.9718 | LR: 0.000082 
Epoch 16/100 | Time: 171.40s | Train Loss: 0.4532 | Val Loss: 0.4945 | Val Acc: 0.9740 | LR: 0.000080 
Epoch 17/100 | Time: 171.49s | Train Loss: 0.4567 | Val Loss: 0.4774 | Val Acc: 0.9761 | LR: 0.000077 
Saving best val acc: 0.9761
Epoch 18/100 | Time: 173.53s | Train Loss: 0.4584 | Val Loss: 0.4863 | Val Acc: 0.9805 | LR: 0.000074 
Epoch 19/100 | Time: 174.44s | Train Loss: 0.4644 | Val Loss: 0.5116 | Val Acc: 0.9696 | LR: 0.000072 
Epoch 20/100 | Time: 172.69s | Train Loss: 0.4632 | Val Loss: 0.5082 | Val Acc: 0.9610 | LR: 0.000069 
Epoch 21/100 | Time: 173.63s | Train Loss: 0.4623 | Val Loss: 0.5018 | Val Acc: 0.9696 | LR: 0.000066 
Epoch 22/100 | Time: 178.46s | Train Loss: 0.4564 | Val Loss: 0.4940 | Val Acc: 0.9761 | LR: 0.000063 
Epoch 23/100 | Time: 182.06s | Train Loss: 0.4499 | Val Loss: 0.4949 | Val Acc: 0.9761 | LR: 0.000060 
Epoch 24/100 | Time: 187.25s | Train Loss: 0.4538 | Val Loss: 0.5123 | Val Acc: 0.9631 | LR: 0.000057 
Epoch 25/100 | Time: 201.12s | Train Loss: 0.4534 | Val Loss: 0.4997 | Val Acc: 0.9675 | LR: 0.000054 
Epoch 26/100 | Time: 191.66s | Train Loss: 0.4531 | Val Loss: 0.4817 | Val Acc: 0.9761 | LR: 0.000050 
Epoch 27/100 | Time: 187.24s | Train Loss: 0.4501 | Val Loss: 0.4953 | Val Acc: 0.9761 | LR: 0.000047 
Early stopping triggered.
Training complete in 4787.33 seconds. Best model loaded.
Model saved to ./output/models/Convnext+depth+CBAM+dataset1+dataset1.pth
 Training metrics plot saved to: output/test/Convnext+depth+CBAM+dataset1/training metric.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Evaluate model:Convnext+depth+CBAM+dataset1
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset

 Test Accuracy: 97.18%

 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     0.9048    1.0000    0.9500        19
           brown_spot     0.9176    0.9750    0.9455        80
              healthy     0.9688    1.0000    0.9841        93
           leaf_blast     0.9877    0.8791    0.9302        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9718       461
            macro avg     0.9631    0.9757    0.9683       461
         weighted avg     0.9730    0.9718    0.9715       461
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: Convnext+depth+dataset1]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Epoch 1/100 | Time: 158.63s | Train Loss: 0.7284 | Val Loss: 0.6033 | Val Acc: 0.9136 | LR: 0.000100 
Saving best val acc: 0.9136
Epoch 2/100 | Time: 154.38s | Train Loss: 0.5302 | Val Loss: 0.4975 | Val Acc: 0.9743 | LR: 0.000100 
Saving best val acc: 0.9743
Epoch 3/100 | Time: 153.99s | Train Loss: 0.4912 | Val Loss: 0.4699 | Val Acc: 0.9835 | LR: 0.000100 
Saving best val acc: 0.9835
Epoch 4/100 | Time: 155.09s | Train Loss: 0.4830 | Val Loss: 0.5198 | Val Acc: 0.9577 | LR: 0.000099 
Epoch 5/100 | Time: 155.14s | Train Loss: 0.4906 | Val Loss: 0.4816 | Val Acc: 0.9816 | LR: 0.000098 
Epoch 6/100 | Time: 155.26s | Train Loss: 0.4739 | Val Loss: 0.4833 | Val Acc: 0.9724 | LR: 0.000098 
Epoch 7/100 | Time: 155.08s | Train Loss: 0.4624 | Val Loss: 0.4677 | Val Acc: 0.9816 | LR: 0.000097 
Saving best val acc: 0.9816
Epoch 8/100 | Time: 155.57s | Train Loss: 0.4600 | Val Loss: 0.5025 | Val Acc: 0.9706 | LR: 0.000095 
Epoch 9/100 | Time: 155.56s | Train Loss: 0.4521 | Val Loss: 0.4905 | Val Acc: 0.9743 | LR: 0.000094 
Epoch 10/100 | Time: 155.98s | Train Loss: 0.4602 | Val Loss: 0.5062 | Val Acc: 0.9669 | LR: 0.000092 
Epoch 11/100 | Time: 155.70s | Train Loss: 0.4588 | Val Loss: 0.4726 | Val Acc: 0.9871 | LR: 0.000091 
Epoch 12/100 | Time: 156.36s | Train Loss: 0.4542 | Val Loss: 0.4768 | Val Acc: 0.9835 | LR: 0.000089 
Epoch 13/100 | Time: 157.41s | Train Loss: 0.4537 | Val Loss: 0.4840 | Val Acc: 0.9798 | LR: 0.000087 
Epoch 14/100 | Time: 156.23s | Train Loss: 0.4544 | Val Loss: 0.4802 | Val Acc: 0.9779 | LR: 0.000084 
Epoch 15/100 | Time: 156.47s | Train Loss: 0.4393 | Val Loss: 0.4545 | Val Acc: 0.9890 | LR: 0.000082 
Saving best val acc: 0.9890
Epoch 16/100 | Time: 156.01s | Train Loss: 0.4414 | Val Loss: 0.4683 | Val Acc: 0.9835 | LR: 0.000080 
Epoch 17/100 | Time: 156.77s | Train Loss: 0.4350 | Val Loss: 0.4621 | Val Acc: 0.9871 | LR: 0.000077 
Epoch 18/100 | Time: 155.51s | Train Loss: 0.4431 | Val Loss: 0.4634 | Val Acc: 0.9835 | LR: 0.000074 
Epoch 19/100 | Time: 155.32s | Train Loss: 0.4397 | Val Loss: 0.4697 | Val Acc: 0.9816 | LR: 0.000072 
Epoch 20/100 | Time: 155.52s | Train Loss: 0.4412 | Val Loss: 0.4773 | Val Acc: 0.9798 | LR: 0.000069 
Epoch 21/100 | Time: 171.64s | Train Loss: 0.4417 | Val Loss: 0.4569 | Val Acc: 0.9871 | LR: 0.000066 
Epoch 22/100 | Time: 155.78s | Train Loss: 0.4368 | Val Loss: 0.4658 | Val Acc: 0.9835 | LR: 0.000063 
Epoch 23/100 | Time: 155.51s | Train Loss: 0.4381 | Val Loss: 0.4580 | Val Acc: 0.9890 | LR: 0.000060 
Epoch 24/100 | Time: 155.40s | Train Loss: 0.4367 | Val Loss: 0.4641 | Val Acc: 0.9835 | LR: 0.000057 
Epoch 25/100 | Time: 155.50s | Train Loss: 0.4373 | Val Loss: 0.4678 | Val Acc: 0.9798 | LR: 0.000054 
Early stopping triggered.
Training complete in 3909.92 seconds. Best model loaded.
Model saved to ./output/models/Convnext+depth+dataset1+dataset1.pth
 Training metrics plot saved to: output/test/Convnext+depth+dataset1/training metric.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Evaluate model:Convnext+depth+dataset1
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset

 Test Accuracy: 98.90%

 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    0.9886    0.9943        88
           brown_spot     0.9783    0.9677    0.9730        93
              healthy     0.9789    1.0000    0.9894        93
           leaf_blast     0.9780    0.9780    0.9780        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9890       543
            macro avg     0.9892    0.9891    0.9891       543
         weighted avg     0.9890    0.9890    0.9889       543

 Saved misclassified images to output/test/Convnext+depth+dataset1/misclassified_images.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: Convnext+depth+PlantDocSplited]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Epoch 1/100 | Time: 218.24s | Train Loss: 1.8033 | Val Loss: 1.3808 | Val Acc: 0.7327 | LR: 0.000100 
Saving best val acc: 0.7327
Epoch 2/100 | Time: 214.66s | Train Loss: 1.1614 | Val Loss: 1.1612 | Val Acc: 0.8018 | LR: 0.000100 
Saving best val acc: 0.8018
Epoch 3/100 | Time: 180.64s | Train Loss: 0.9991 | Val Loss: 1.2304 | Val Acc: 0.7808 | LR: 0.000100 
Epoch 4/100 | Time: 179.85s | Train Loss: 0.8898 | Val Loss: 1.2229 | Val Acc: 0.7808 | LR: 0.000099 
Epoch 5/100 | Time: 179.65s | Train Loss: 0.8374 | Val Loss: 1.2389 | Val Acc: 0.8018 | LR: 0.000098 
Epoch 6/100 | Time: 179.27s | Train Loss: 0.7945 | Val Loss: 1.1467 | Val Acc: 0.8078 | LR: 0.000098 
Saving best val acc: 0.8078
Epoch 7/100 | Time: 180.57s | Train Loss: 0.7525 | Val Loss: 1.1681 | Val Acc: 0.8198 | LR: 0.000097 
Epoch 8/100 | Time: 184.85s | Train Loss: 0.7248 | Val Loss: 1.1781 | Val Acc: 0.8078 | LR: 0.000095 
Epoch 9/100 | Time: 182.47s | Train Loss: 0.7265 | Val Loss: 1.1821 | Val Acc: 0.8018 | LR: 0.000094 
Epoch 10/100 | Time: 180.71s | Train Loss: 0.7030 | Val Loss: 1.1818 | Val Acc: 0.8138 | LR: 0.000092 
Epoch 11/100 | Time: 180.02s | Train Loss: 0.7093 | Val Loss: 1.1726 | Val Acc: 0.8258 | LR: 0.000091 
Epoch 12/100 | Time: 179.44s | Train Loss: 0.7009 | Val Loss: 1.2777 | Val Acc: 0.7868 | LR: 0.000089 
Epoch 13/100 | Time: 179.99s | Train Loss: 0.7018 | Val Loss: 1.1660 | Val Acc: 0.8198 | LR: 0.000087 
Epoch 14/100 | Time: 181.04s | Train Loss: 0.7228 | Val Loss: 1.2137 | Val Acc: 0.7898 | LR: 0.000084 
Epoch 15/100 | Time: 179.72s | Train Loss: 0.6972 | Val Loss: 1.1877 | Val Acc: 0.8318 | LR: 0.000082 
Epoch 16/100 | Time: 180.97s | Train Loss: 0.6928 | Val Loss: 1.2986 | Val Acc: 0.7808 | LR: 0.000080 
Early stopping triggered.
Training complete in 2962.16 seconds. Best model loaded.
Model saved to ./output/models/Convnext+depth+PlantDocSplited+PlantDocSplited.pth
 Training metrics plot saved to: output/test/Convnext+depth+PlantDocSplited/training metric.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Evaluate model:Convnext+depth+PlantDocSplited
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset

 Test Accuracy: 75.20%

 Classification Report:
                                      precision    recall  f1-score   support

                     Apple_Scab_Leaf     0.8000    0.8000    0.8000        10
                          Apple_leaf     0.7778    0.7778    0.7778         9
                     Apple_rust_leaf     0.8889    0.8000    0.8421        10
                    Bell_pepper_leaf     0.7778    0.8750    0.8235         8
               Bell_pepper_leaf_spot     0.6667    0.8889    0.7619         9
                      Blueberry_leaf     1.0000    0.9091    0.9524        11
                         Cherry_leaf     0.9000    0.9000    0.9000        10
                 Corn_Gray_leaf_spot     0.0000    0.0000    0.0000         4
                    Corn_leaf_blight     0.6000    0.5000    0.5455        12
                      Corn_rust_leaf     1.0000    0.9000    0.9474        10
                          Peach_leaf     1.0000    0.8889    0.9412         9
            Potato_leaf_early_blight     0.4286    0.2143    0.2857        14
             Potato_leaf_late_blight     0.2353    0.5000    0.3200         8
                      Raspberry_leaf     0.8750    1.0000    0.9333         7
                       Soyabean_leaf     1.0000    0.7143    0.8333         7
          Squash_Powdery_mildew_leaf     1.0000    0.8333    0.9091         6
                     Strawberry_leaf     1.0000    1.0000    1.0000         8
            Tomato_Early_blight_leaf     0.7778    0.7778    0.7778         9
           Tomato_Septoria_leaf_spot     0.7059    1.0000    0.8276        12
                         Tomato_leaf     0.8333    0.6250    0.7143         8
          Tomato_leaf_bacterial_spot     0.7500    0.3750    0.5000         8
             Tomato_leaf_late_blight     0.7500    0.6000    0.6667        10
            Tomato_leaf_mosaic_virus     0.8000    0.4000    0.5333        10
            Tomato_leaf_yellow_virus     0.8750    0.9333    0.9032        15
                    Tomato_mold_leaf     0.3636    0.8000    0.5000         5
Tomato_two_spotted_spider_mites_leaf     1.0000    1.0000    1.0000         1
                          grape_leaf     1.0000    1.0000    1.0000        12
                grape_leaf_black_rot     1.0000    1.0000    1.0000         8

                            accuracy                         0.7520       250
                           macro avg     0.7788    0.7505    0.7499       250
                        weighted avg     0.7876    0.7520    0.7556       250

 Confusion matrix saved to: output/test/Convnext+depth+PlantDocSplited/confusion_matrix.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Device set to use cuda:0
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Saved 8 merged gradCAM images in the output/test/Convnext+depth+PlantDocSplited/grad_cam folder!
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Saved misclassified images to output/test/Convnext+depth+PlantDocSplited/misclassified_images.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Corn_Gray_leaf_spot
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Evaluate model:Convnext+depth+PlantDocSplited
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset

 Test Accuracy: 75.20%

 Classification Report:
                                      precision    recall  f1-score   support

                     Apple_Scab_Leaf     0.8000    0.8000    0.8000        10
                          Apple_leaf     0.7778    0.7778    0.7778         9
                     Apple_rust_leaf     0.8889    0.8000    0.8421        10
                    Bell_pepper_leaf     0.7778    0.8750    0.8235         8
               Bell_pepper_leaf_spot     0.6667    0.8889    0.7619         9
                      Blueberry_leaf     1.0000    0.9091    0.9524        11
                         Cherry_leaf     0.9000    0.9000    0.9000        10
                 Corn_Gray_leaf_spot     0.0000    0.0000    0.0000         4
                    Corn_leaf_blight     0.6000    0.5000    0.5455        12
                      Corn_rust_leaf     1.0000    0.9000    0.9474        10
                          Peach_leaf     1.0000    0.8889    0.9412         9
            Potato_leaf_early_blight     0.4286    0.2143    0.2857        14
             Potato_leaf_late_blight     0.2353    0.5000    0.3200         8
                      Raspberry_leaf     0.8750    1.0000    0.9333         7
                       Soyabean_leaf     1.0000    0.7143    0.8333         7
          Squash_Powdery_mildew_leaf     1.0000    0.8333    0.9091         6
                     Strawberry_leaf     1.0000    1.0000    1.0000         8
            Tomato_Early_blight_leaf     0.7778    0.7778    0.7778         9
           Tomato_Septoria_leaf_spot     0.7059    1.0000    0.8276        12
                         Tomato_leaf     0.8333    0.6250    0.7143         8
          Tomato_leaf_bacterial_spot     0.7500    0.3750    0.5000         8
             Tomato_leaf_late_blight     0.7500    0.6000    0.6667        10
            Tomato_leaf_mosaic_virus     0.8000    0.4000    0.5333        10
            Tomato_leaf_yellow_virus     0.8750    0.9333    0.9032        15
                    Tomato_mold_leaf     0.3636    0.8000    0.5000         5
Tomato_two_spotted_spider_mites_leaf     1.0000    1.0000    1.0000         1
                          grape_leaf     1.0000    1.0000    1.0000        12
                grape_leaf_black_rot     1.0000    1.0000    1.0000         8

                            accuracy                         0.7520       250
                           macro avg     0.7788    0.7505    0.7499       250
                        weighted avg     0.7876    0.7520    0.7556       250

 Confusion matrix saved to: output/test/Convnext+depth+PlantDocSplited/confusion_matrix.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Device set to use cuda:0
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Saved 8 merged gradCAM images in the output/test/Convnext+depth+PlantDocSplited/grad_cam folder!
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Saved misclassified images to output/test/Convnext+depth+PlantDocSplited/misclassified_images.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: Convnext+depth+PlantVillageSplited]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Epoch 1/100 | Time: 2827.63s | Train Loss: 0.8197 | Val Loss: 0.7349 | Val Acc: 0.9820 | LR: 0.000100 
Saving best val acc: 0.9820
Epoch 2/100 | Time: 2607.53s | Train Loss: 0.7180 | Val Loss: 0.7055 | Val Acc: 0.9923 | LR: 0.000100 
Saving best val acc: 0.9923
Epoch 3/100 | Time: 2471.16s | Train Loss: 0.7059 | Val Loss: 0.6963 | Val Acc: 0.9926 | LR: 0.000100 
Saving best val acc: 0.9926

Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: Convnext+depth+dataset1]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Epoch 1/100 | Time: 186.26s | Train Loss: 0.7406 | Val Loss: 0.5770 | Val Acc: 0.9485 | LR: 0.000100 
Saving best val acc: 0.9485
Epoch 2/100 | Time: 155.71s | Train Loss: 0.5349 | Val Loss: 0.5521 | Val Acc: 0.9393 | LR: 0.000100 
Saving best val acc: 0.9393
Epoch 3/100 | Time: 155.40s | Train Loss: 0.5071 | Val Loss: 0.5148 | Val Acc: 0.9724 | LR: 0.000100 
Saving best val acc: 0.9724
Epoch 4/100 | Time: 155.43s | Train Loss: 0.4875 | Val Loss: 0.5511 | Val Acc: 0.9522 | LR: 0.000099 
Epoch 5/100 | Time: 155.74s | Train Loss: 0.4740 | Val Loss: 0.4933 | Val Acc: 0.9669 | LR: 0.000098 
Saving best val acc: 0.9669
Epoch 6/100 | Time: 155.36s | Train Loss: 0.4701 | Val Loss: 0.5026 | Val Acc: 0.9669 | LR: 0.000098 
Epoch 7/100 | Time: 155.69s | Train Loss: 0.4694 | Val Loss: 0.5027 | Val Acc: 0.9540 | LR: 0.000097 
Epoch 8/100 | Time: 155.21s | Train Loss: 0.4583 | Val Loss: 0.4672 | Val Acc: 0.9779 | LR: 0.000095 
Saving best val acc: 0.9779
Epoch 9/100 | Time: 155.10s | Train Loss: 0.4498 | Val Loss: 0.4834 | Val Acc: 0.9779 | LR: 0.000094 
Epoch 10/100 | Time: 156.11s | Train Loss: 0.4605 | Val Loss: 0.4762 | Val Acc: 0.9761 | LR: 0.000092 
Epoch 11/100 | Time: 155.44s | Train Loss: 0.4517 | Val Loss: 0.4703 | Val Acc: 0.9853 | LR: 0.000091 
Epoch 12/100 | Time: 154.88s | Train Loss: 0.4591 | Val Loss: 0.4659 | Val Acc: 0.9835 | LR: 0.000089 
Saving best val acc: 0.9835
Epoch 13/100 | Time: 155.57s | Train Loss: 0.4457 | Val Loss: 0.4639 | Val Acc: 0.9853 | LR: 0.000087 
Saving best val acc: 0.9853
Epoch 14/100 | Time: 155.85s | Train Loss: 0.4400 | Val Loss: 0.4610 | Val Acc: 0.9835 | LR: 0.000084 
Saving best val acc: 0.9835
Epoch 15/100 | Time: 156.03s | Train Loss: 0.4399 | Val Loss: 0.4538 | Val Acc: 0.9871 | LR: 0.000082 
Saving best val acc: 0.9871
Epoch 16/100 | Time: 155.71s | Train Loss: 0.4369 | Val Loss: 0.4656 | Val Acc: 0.9835 | LR: 0.000080 
Epoch 17/100 | Time: 156.14s | Train Loss: 0.4422 | Val Loss: 0.4615 | Val Acc: 0.9835 | LR: 0.000077 
Epoch 18/100 | Time: 155.64s | Train Loss: 0.4445 | Val Loss: 0.4678 | Val Acc: 0.9816 | LR: 0.000074 
Epoch 19/100 | Time: 156.20s | Train Loss: 0.4418 | Val Loss: 0.4657 | Val Acc: 0.9871 | LR: 0.000072 
Epoch 20/100 | Time: 156.59s | Train Loss: 0.4340 | Val Loss: 0.4557 | Val Acc: 0.9835 | LR: 0.000069 
Epoch 21/100 | Time: 156.37s | Train Loss: 0.4344 | Val Loss: 0.4594 | Val Acc: 0.9816 | LR: 0.000066 
Epoch 22/100 | Time: 155.44s | Train Loss: 0.4338 | Val Loss: 0.4558 | Val Acc: 0.9890 | LR: 0.000063 
Epoch 23/100 | Time: 154.89s | Train Loss: 0.4367 | Val Loss: 0.4626 | Val Acc: 0.9853 | LR: 0.000060 
Epoch 24/100 | Time: 154.90s | Train Loss: 0.4418 | Val Loss: 0.4646 | Val Acc: 0.9816 | LR: 0.000057 
Epoch 25/100 | Time: 155.47s | Train Loss: 0.4350 | Val Loss: 0.4646 | Val Acc: 0.9853 | LR: 0.000054 
Early stopping triggered.
Training complete in 3921.31 seconds. Best model loaded.
Model saved to ./output/models/Convnext+depth+dataset1+dataset1.pth
 Training metrics plot saved to: output/test/Convnext+depth+dataset1/training metric.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Evaluate model:Convnext+depth+dataset1
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset

 Test Accuracy: 98.71%

 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    0.9886    0.9943        88
           brown_spot     0.9579    0.9785    0.9681        93
              healthy     0.9789    1.0000    0.9894        93
           leaf_blast     0.9886    0.9560    0.9721        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9871       543
            macro avg     0.9876    0.9872    0.9873       543
         weighted avg     0.9873    0.9871    0.9871       543

 Confusion matrix saved to: output/test/Convnext+depth+dataset1/confusion_matrix.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Device set to use cuda:0
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Saved 8 merged gradCAM images in the output/test/Convnext+depth+dataset1/grad_cam folder!
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Saved misclassified images to output/test/Convnext+depth+dataset1/misclassified_images.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: Convnext+depth+dataset3]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Epoch 1/100 | Time: 288.76s | Train Loss: 0.4345 | Val Loss: 0.3534 | Val Acc: 1.0000 | LR: 0.000100 
Saving best val acc: 1.0000
Epoch 2/100 | Time: 272.37s | Train Loss: 0.3674 | Val Loss: 0.3560 | Val Acc: 1.0000 | LR: 0.000100 
Epoch 3/100 | Time: 273.01s | Train Loss: 0.3638 | Val Loss: 0.3495 | Val Acc: 1.0000 | LR: 0.000100 
Saving best val acc: 1.0000
Epoch 4/100 | Time: 269.28s | Train Loss: 0.3609 | Val Loss: 0.3509 | Val Acc: 1.0000 | LR: 0.000099 
Epoch 5/100 | Time: 270.82s | Train Loss: 0.3615 | Val Loss: 0.3504 | Val Acc: 1.0000 | LR: 0.000098 
Epoch 6/100 | Time: 268.88s | Train Loss: 0.3617 | Val Loss: 0.3506 | Val Acc: 1.0000 | LR: 0.000098 
Epoch 7/100 | Time: 270.57s | Train Loss: 0.3602 | Val Loss: 0.3496 | Val Acc: 1.0000 | LR: 0.000097 
Epoch 8/100 | Time: 270.24s | Train Loss: 0.3619 | Val Loss: 0.3495 | Val Acc: 1.0000 | LR: 0.000095 
Epoch 9/100 | Time: 268.11s | Train Loss: 0.3608 | Val Loss: 0.3499 | Val Acc: 1.0000 | LR: 0.000094 
Epoch 10/100 | Time: 271.31s | Train Loss: 0.3606 | Val Loss: 0.3513 | Val Acc: 1.0000 | LR: 0.000092 
Epoch 11/100 | Time: 269.66s | Train Loss: 0.3599 | Val Loss: 0.3492 | Val Acc: 1.0000 | LR: 0.000091 
Saving best val acc: 1.0000
Epoch 12/100 | Time: 270.60s | Train Loss: 0.3943 | Val Loss: 0.4251 | Val Acc: 0.9629 | LR: 0.000089 
Epoch 13/100 | Time: 269.19s | Train Loss: 0.3761 | Val Loss: 0.3535 | Val Acc: 0.9992 | LR: 0.000087 
Epoch 14/100 | Time: 268.38s | Train Loss: 0.3617 | Val Loss: 0.3502 | Val Acc: 1.0000 | LR: 0.000084 
Epoch 15/100 | Time: 270.32s | Train Loss: 0.3605 | Val Loss: 0.3501 | Val Acc: 1.0000 | LR: 0.000082 
Epoch 16/100 | Time: 268.01s | Train Loss: 0.3605 | Val Loss: 0.3501 | Val Acc: 1.0000 | LR: 0.000080 
Epoch 17/100 | Time: 272.10s | Train Loss: 0.3607 | Val Loss: 0.3530 | Val Acc: 1.0000 | LR: 0.000077 
Epoch 18/100 | Time: 273.27s | Train Loss: 0.3603 | Val Loss: 0.3494 | Val Acc: 1.0000 | LR: 0.000074 
Epoch 19/100 | Time: 270.61s | Train Loss: 0.3592 | Val Loss: 0.3518 | Val Acc: 1.0000 | LR: 0.000072 
Epoch 20/100 | Time: 271.69s | Train Loss: 0.3594 | Val Loss: 0.3498 | Val Acc: 1.0000 | LR: 0.000069 
Epoch 21/100 | Time: 271.98s | Train Loss: 0.3587 | Val Loss: 0.3497 | Val Acc: 1.0000 | LR: 0.000066 
Early stopping triggered.
Training complete in 5699.22 seconds. Best model loaded.
Model saved to ./output/models/Convnext+depth+dataset3+dataset3.pth
 Training metrics plot saved to: output/test/Convnext+depth+dataset3/training metric.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Evaluate model:Convnext+depth+dataset3
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset

 Test Accuracy: 100.00%

 Classification Report:
                 precision    recall  f1-score   support

Bacterialblight     1.0000    1.0000    1.0000       160
          Blast     1.0000    1.0000    1.0000       145
      Brownspot     1.0000    1.0000    1.0000       160
         Tungro     1.0000    1.0000    1.0000       132

       accuracy                         1.0000       597
      macro avg     1.0000    1.0000    1.0000       597
   weighted avg     1.0000    1.0000    1.0000       597

=========================================================================================================


Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: Convnext+depth4channel+dataset1]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Epoch 1/100 | Time: 323.39s | Train Loss: 1.2867 | Val Loss: 2.3658 | Val Acc: 0.2500 | LR: 0.000100 
Saving best val acc: 0.2500
Epoch 2/100 | Time: 292.59s | Train Loss: 0.9587 | Val Loss: 1.1345 | Val Acc: 0.7096 | LR: 0.000100 
Saving best val acc: 0.7096
Epoch 3/100 | Time: 291.12s | Train Loss: 0.8225 | Val Loss: 1.6049 | Val Acc: 0.5165 | LR: 0.000100 
Epoch 4/100 | Time: 293.33s | Train Loss: 0.7669 | Val Loss: 0.7846 | Val Acc: 0.8456 | LR: 0.000099 
Saving best val acc: 0.8456
Epoch 5/100 | Time: 291.80s | Train Loss: 0.7098 | Val Loss: 0.8122 | Val Acc: 0.8456 | LR: 0.000098 
Epoch 6/100 | Time: 292.72s | Train Loss: 0.6711 | Val Loss: 0.7137 | Val Acc: 0.8952 | LR: 0.000098 
Saving best val acc: 0.8952
Epoch 7/100 | Time: 292.06s | Train Loss: 0.6112 | Val Loss: 0.6468 | Val Acc: 0.9099 | LR: 0.000097 
Saving best val acc: 0.9099
Epoch 8/100 | Time: 291.75s | Train Loss: 0.5746 | Val Loss: 0.7196 | Val Acc: 0.8915 | LR: 0.000095 
Epoch 9/100 | Time: 293.08s | Train Loss: 0.5685 | Val Loss: 0.8548 | Val Acc: 0.8438 | LR: 0.000094 
Epoch 10/100 | Time: 293.88s | Train Loss: 0.5470 | Val Loss: 0.7761 | Val Acc: 0.8768 | LR: 0.000092 
Epoch 11/100 | Time: 293.75s | Train Loss: 0.5348 | Val Loss: 0.5457 | Val Acc: 0.9430 | LR: 0.000091 
Saving best val acc: 0.9430
Epoch 12/100 | Time: 293.15s | Train Loss: 0.5261 | Val Loss: 0.5458 | Val Acc: 0.9485 | LR: 0.000089 
Epoch 13/100 | Time: 292.52s | Train Loss: 0.5079 | Val Loss: 0.5388 | Val Acc: 0.9632 | LR: 0.000087 
Saving best val acc: 0.9632
Epoch 14/100 | Time: 291.01s | Train Loss: 0.5037 | Val Loss: 0.5341 | Val Acc: 0.9596 | LR: 0.000084 
Saving best val acc: 0.9596
Epoch 15/100 | Time: 290.22s | Train Loss: 0.5041 | Val Loss: 0.5672 | Val Acc: 0.9375 | LR: 0.000082 
Epoch 16/100 | Time: 290.44s | Train Loss: 0.4864 | Val Loss: 0.5214 | Val Acc: 0.9614 | LR: 0.000080 
Saving best val acc: 0.9614
Epoch 17/100 | Time: 289.07s | Train Loss: 0.4820 | Val Loss: 0.4947 | Val Acc: 0.9651 | LR: 0.000077 
Saving best val acc: 0.9651
Epoch 18/100 | Time: 292.59s | Train Loss: 0.4698 | Val Loss: 0.5329 | Val Acc: 0.9540 | LR: 0.000074 
Epoch 19/100 | Time: 290.36s | Train Loss: 0.4712 | Val Loss: 0.5178 | Val Acc: 0.9596 | LR: 0.000072 
Epoch 20/100 | Time: 288.71s | Train Loss: 0.4656 | Val Loss: 0.5084 | Val Acc: 0.9706 | LR: 0.000069 
Epoch 21/100 | Time: 290.90s | Train Loss: 0.4646 | Val Loss: 0.4975 | Val Acc: 0.9743 | LR: 0.000066 
Epoch 22/100 | Time: 290.29s | Train Loss: 0.4617 | Val Loss: 0.5192 | Val Acc: 0.9596 | LR: 0.000063 
Epoch 23/100 | Time: 287.05s | Train Loss: 0.4622 | Val Loss: 0.5191 | Val Acc: 0.9688 | LR: 0.000060 
Epoch 24/100 | Time: 289.15s | Train Loss: 0.4454 | Val Loss: 0.4987 | Val Acc: 0.9669 | LR: 0.000057 
Epoch 25/100 | Time: 287.66s | Train Loss: 0.4420 | Val Loss: 0.4977 | Val Acc: 0.9706 | LR: 0.000054 
Epoch 26/100 | Time: 289.01s | Train Loss: 0.4614 | Val Loss: 0.5177 | Val Acc: 0.9632 | LR: 0.000050 
Epoch 27/100 | Time: 287.79s | Train Loss: 0.4564 | Val Loss: 0.5085 | Val Acc: 0.9669 | LR: 0.000047 
Early stopping triggered.
Training complete in 7889.58 seconds. Best model loaded.
Model saved to ./output/models/Convnext+depth4channel+dataset1+dataset1.pth
 Training metrics plot saved to: output/test/Convnext+depth4channel+dataset1/training metric.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Evaluate model:Convnext+depth4channel+dataset1
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset

 Test Accuracy: 96.87%

 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     0.9884    0.9659    0.9770        88
           brown_spot     0.9247    0.9247    0.9247        93
              healthy     0.9789    1.0000    0.9894        93
           leaf_blast     0.9231    0.9231    0.9231        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9687       543
            macro avg     0.9692    0.9690    0.9690       543
         weighted avg     0.9687    0.9687    0.9687       543

 Confusion matrix saved to: output/test/Convnext+depth4channel+dataset1/confusion_matrix.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Device set to use cuda:0
Traceback (most recent call last):
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/grad_cam.py", line 117, in <module>
    output = model(input_tensor)
             ^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/models/convnext_cbam.py", line 31, in forward
    x = self.model.stem(x)  # Initial Conv + LayerNorm
        ^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 554, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 549, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
RuntimeError: Given groups=1, weight of size [128, 4, 4, 4], expected input[1, 3, 224, 224] to have 4 channels, but got 3 channels instead
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Traceback (most recent call last):
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/wrong_test.py", line 32, in <module>
    outputs = model(images)
              ^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/models/convnext_cbam.py", line 31, in forward
    x = self.model.stem(x)  # Initial Conv + LayerNorm
        ^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 554, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 549, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
RuntimeError: Given groups=1, weight of size [128, 4, 4, 4], expected input[16, 3, 224, 224] to have 4 channels, but got 3 channels instead
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Evaluate model:Convnext+depth4channel+dataset1
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset

 Test Accuracy: 96.87%

 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     0.9884    0.9659    0.9770        88
           brown_spot     0.9247    0.9247    0.9247        93
              healthy     0.9789    1.0000    0.9894        93
           leaf_blast     0.9231    0.9231    0.9231        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9687       543
            macro avg     0.9692    0.9690    0.9690       543
         weighted avg     0.9687    0.9687    0.9687       543

 Confusion matrix saved to: output/test/Convnext+depth4channel+dataset1/confusion_matrix.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Device set to use cuda:0
Traceback (most recent call last):
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/grad_cam.py", line 117, in <module>
    output = model(input_tensor)
             ^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/models/convnext_cbam.py", line 101, in forward
    x = self.model.stem(x)  # First conv + norm
        ^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 554, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 549, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
RuntimeError: Given groups=1, weight of size [128, 4, 4, 4], expected input[1, 3, 224, 224] to have 4 channels, but got 3 channels instead
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Traceback (most recent call last):
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/wrong_test.py", line 32, in <module>
    outputs = model(images)
              ^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/models/convnext_cbam.py", line 101, in forward
    x = self.model.stem(x)  # First conv + norm
        ^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 554, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 549, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
RuntimeError: Given groups=1, weight of size [128, 4, 4, 4], expected input[16, 3, 224, 224] to have 4 channels, but got 3 channels instead
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: Convnext+depth4channel_v2+dataset1]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Epoch 1/100 | Time: 281.68s | Train Loss: 0.7531 | Val Loss: 0.5296 | Val Acc: 0.9614 | LR: 0.000100 
Saving best val acc: 0.9614
Epoch 2/100 | Time: 267.75s | Train Loss: 0.5266 | Val Loss: 0.4945 | Val Acc: 0.9724 | LR: 0.000100 
Saving best val acc: 0.9724
Epoch 3/100 | Time: 264.61s | Train Loss: 0.4998 | Val Loss: 0.4843 | Val Acc: 0.9779 | LR: 0.000100 
Saving best val acc: 0.9779
Epoch 4/100 | Time: 267.28s | Train Loss: 0.4831 | Val Loss: 0.4753 | Val Acc: 0.9761 | LR: 0.000099 
Saving best val acc: 0.9761
Epoch 5/100 | Time: 268.15s | Train Loss: 0.4671 | Val Loss: 0.4804 | Val Acc: 0.9761 | LR: 0.000098 
Epoch 6/100 | Time: 267.49s | Train Loss: 0.4546 | Val Loss: 0.4742 | Val Acc: 0.9835 | LR: 0.000098 
Saving best val acc: 0.9835
Epoch 7/100 | Time: 266.68s | Train Loss: 0.4525 | Val Loss: 0.4632 | Val Acc: 0.9798 | LR: 0.000097 
Saving best val acc: 0.9798
Epoch 8/100 | Time: 266.44s | Train Loss: 0.4583 | Val Loss: 0.4671 | Val Acc: 0.9835 | LR: 0.000095 
Epoch 9/100 | Time: 266.59s | Train Loss: 0.4482 | Val Loss: 0.4702 | Val Acc: 0.9853 | LR: 0.000094 
Epoch 10/100 | Time: 266.15s | Train Loss: 0.4410 | Val Loss: 0.4634 | Val Acc: 0.9890 | LR: 0.000092 
Epoch 11/100 | Time: 266.49s | Train Loss: 0.4578 | Val Loss: 0.5618 | Val Acc: 0.9375 | LR: 0.000091 
Epoch 12/100 | Time: 265.72s | Train Loss: 0.4602 | Val Loss: 0.5006 | Val Acc: 0.9724 | LR: 0.000089 
Epoch 13/100 | Time: 267.95s | Train Loss: 0.4464 | Val Loss: 0.4585 | Val Acc: 0.9835 | LR: 0.000087 
Saving best val acc: 0.9835
Epoch 14/100 | Time: 265.95s | Train Loss: 0.4391 | Val Loss: 0.4542 | Val Acc: 0.9871 | LR: 0.000084 
Saving best val acc: 0.9871
Epoch 15/100 | Time: 266.01s | Train Loss: 0.4404 | Val Loss: 0.4559 | Val Acc: 0.9835 | LR: 0.000082 
Epoch 16/100 | Time: 265.94s | Train Loss: 0.4436 | Val Loss: 0.5139 | Val Acc: 0.9688 | LR: 0.000080 
Epoch 17/100 | Time: 267.54s | Train Loss: 0.4408 | Val Loss: 0.4788 | Val Acc: 0.9761 | LR: 0.000077 
Epoch 18/100 | Time: 265.71s | Train Loss: 0.4424 | Val Loss: 0.4654 | Val Acc: 0.9835 | LR: 0.000074 
Epoch 19/100 | Time: 266.27s | Train Loss: 0.4420 | Val Loss: 0.5173 | Val Acc: 0.9632 | LR: 0.000072 
Epoch 20/100 | Time: 264.83s | Train Loss: 0.4435 | Val Loss: 0.4850 | Val Acc: 0.9688 | LR: 0.000069 
Epoch 21/100 | Time: 266.42s | Train Loss: 0.4320 | Val Loss: 0.4793 | Val Acc: 0.9798 | LR: 0.000066 
Epoch 22/100 | Time: 265.28s | Train Loss: 0.4343 | Val Loss: 0.4679 | Val Acc: 0.9835 | LR: 0.000063 
Epoch 23/100 | Time: 265.53s | Train Loss: 0.4326 | Val Loss: 0.4606 | Val Acc: 0.9835 | LR: 0.000060 
Epoch 24/100 | Time: 265.04s | Train Loss: 0.4381 | Val Loss: 0.5075 | Val Acc: 0.9706 | LR: 0.000057 
Early stopping triggered.
Training complete in 6407.64 seconds. Best model loaded.
Model saved to ./output/models/Convnext+depth4channel_v2+dataset1+dataset1.pth
 Training metrics plot saved to: output/test/Convnext+depth4channel_v2+dataset1/training metric.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Evaluate model:Convnext+depth4channel_v2+dataset1
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset

 Test Accuracy: 98.16%

 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     0.9886    0.9886    0.9886        88
           brown_spot     0.9474    0.9677    0.9574        93
              healthy     0.9789    1.0000    0.9894        93
           leaf_blast     0.9770    0.9341    0.9551        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9816       543
            macro avg     0.9820    0.9817    0.9818       543
         weighted avg     0.9817    0.9816    0.9815       543

 Confusion matrix saved to: output/test/Convnext+depth4channel_v2+dataset1/confusion_matrix.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Device set to use cuda:0
Traceback (most recent call last):
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/grad_cam.py", line 117, in <module>
    output = model(input_tensor)
             ^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/models/convnext_cbam.py", line 101, in forward
    x = self.model.stem(x)  # First conv + norm
        ^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 554, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 549, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
RuntimeError: Given groups=1, weight of size [128, 4, 4, 4], expected input[1, 3, 224, 224] to have 4 channels, but got 3 channels instead
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Traceback (most recent call last):
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/wrong_test.py", line 32, in <module>
    outputs = model(images)
              ^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/models/convnext_cbam.py", line 101, in forward
    x = self.model.stem(x)  # First conv + norm
        ^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 554, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 549, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
RuntimeError: Given groups=1, weight of size [128, 4, 4, 4], expected input[16, 3, 224, 224] to have 4 channels, but got 3 channels instead
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Evaluate model:Convnext+depth4channel_v2+dataset1
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset

 Test Accuracy: 98.16%

 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     0.9886    0.9886    0.9886        88
           brown_spot     0.9474    0.9677    0.9574        93
              healthy     0.9789    1.0000    0.9894        93
           leaf_blast     0.9770    0.9341    0.9551        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9816       543
            macro avg     0.9820    0.9817    0.9818       543
         weighted avg     0.9817    0.9816    0.9815       543

 Confusion matrix saved to: output/test/Convnext+depth4channel_v2+dataset1/confusion_matrix.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.

✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: Convnext+depth4channel+dataset2_splited]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: Convnext+depth4channel+dataset2_splited]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔

✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: Convnext+depth4channel+dataset2_splited]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Epoch 1/100 | Time: 487.65s | Train Loss: 0.9429 | Val Loss: 0.6933 | Val Acc: 0.9071 | LR: 0.000100 
Saving best val acc: 0.9071
Epoch 2/100 | Time: 473.89s | Train Loss: 0.6417 | Val Loss: 0.5984 | Val Acc: 0.9412 | LR: 0.000100 
Saving best val acc: 0.9412
Epoch 3/100 | Time: 470.32s | Train Loss: 0.5696 | Val Loss: 0.5621 | Val Acc: 0.9505 | LR: 0.000100 
Saving best val acc: 0.9505
Epoch 4/100 | Time: 645.40s | Train Loss: 0.5429 | Val Loss: 0.5919 | Val Acc: 0.9381 | LR: 0.000099 
Epoch 5/100 | Time: 627.21s | Train Loss: 0.5405 | Val Loss: 0.5619 | Val Acc: 0.9567 | LR: 0.000098 
Saving best val acc: 0.9567
Epoch 6/100 | Time: 634.55s | Train Loss: 0.5385 | Val Loss: 0.5993 | Val Acc: 0.9505 | LR: 0.000098 
Epoch 7/100 | Time: 628.48s | Train Loss: 0.5153 | Val Loss: 0.5756 | Val Acc: 0.9567 | LR: 0.000097 
Epoch 8/100 | Time: 618.07s | Train Loss: 0.4967 | Val Loss: 0.5388 | Val Acc: 0.9628 | LR: 0.000095 
Saving best val acc: 0.9628
Epoch 9/100 | Time: 626.62s | Train Loss: 0.4974 | Val Loss: 0.5485 | Val Acc: 0.9505 | LR: 0.000094 
Epoch 10/100 | Time: 622.57s | Train Loss: 0.4950 | Val Loss: 0.5554 | Val Acc: 0.9536 | LR: 0.000092 
Epoch 11/100 | Time: 623.11s | Train Loss: 0.4996 | Val Loss: 0.5396 | Val Acc: 0.9598 | LR: 0.000091 
Epoch 12/100 | Time: 558.40s | Train Loss: 0.4868 | Val Loss: 0.5507 | Val Acc: 0.9567 | LR: 0.000089 
Epoch 13/100 | Time: 452.26s | Train Loss: 0.4830 | Val Loss: 0.5418 | Val Acc: 0.9659 | LR: 0.000087 
Epoch 14/100 | Time: 479.66s | Train Loss: 0.4861 | Val Loss: 0.5798 | Val Acc: 0.9505 | LR: 0.000084 
Epoch 15/100 | Time: 460.29s | Train Loss: 0.4835 | Val Loss: 0.5453 | Val Acc: 0.9598 | LR: 0.000082 
Epoch 16/100 | Time: 895.98s | Train Loss: 0.4692 | Val Loss: 0.5266 | Val Acc: 0.9659 | LR: 0.000080 
Saving best val acc: 0.9659
Epoch 17/100 | Time: 1365.39s | Train Loss: 0.4754 | Val Loss: 0.5502 | Val Acc: 0.9598 | LR: 0.000077 
Epoch 18/100 | Time: 1360.35s | Train Loss: 0.4716 | Val Loss: 0.5173 | Val Acc: 0.9659 | LR: 0.000074 
Saving best val acc: 0.9659
Epoch 19/100 | Time: 1475.96s | Train Loss: 0.4691 | Val Loss: 0.5348 | Val Acc: 0.9628 | LR: 0.000072 
Epoch 20/100 | Time: 1325.68s | Train Loss: 0.4744 | Val Loss: 0.5264 | Val Acc: 0.9536 | LR: 0.000069 
Epoch 21/100 | Time: 602.10s | Train Loss: 0.4733 | Val Loss: 0.5353 | Val Acc: 0.9598 | LR: 0.000066 
Epoch 22/100 | Time: 1455.35s | Train Loss: 0.4628 | Val Loss: 0.5298 | Val Acc: 0.9598 | LR: 0.000063 
Epoch 23/100 | Time: 1402.63s | Train Loss: 0.4760 | Val Loss: 0.5306 | Val Acc: 0.9690 | LR: 0.000060 
Epoch 24/100 | Time: 1365.60s | Train Loss: 0.4628 | Val Loss: 0.5433 | Val Acc: 0.9598 | LR: 0.000057 
Epoch 25/100 | Time: 719.94s | Train Loss: 0.4633 | Val Loss: 0.5698 | Val Acc: 0.9505 | LR: 0.000054 
Epoch 26/100 | Time: 1193.59s | Train Loss: 0.4678 | Val Loss: 0.5322 | Val Acc: 0.9721 | LR: 0.000050 
Epoch 27/100 | Time: 1384.50s | Train Loss: 0.4637 | Val Loss: 0.5412 | Val Acc: 0.9659 | LR: 0.000047 
Epoch 28/100 | Time: 1420.73s | Train Loss: 0.4625 | Val Loss: 0.5303 | Val Acc: 0.9598 | LR: 0.000044 
Early stopping triggered.
Training complete in 24378.81 seconds. Best model loaded.
Model saved to ./output/models/Convnext+depth4channel+dataset2_splited+dataset2_splited.pth
 Training metrics plot saved to: output/test/Convnext+depth4channel+dataset2_splited/training metric.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Evaluate model:Convnext+depth4channel+dataset2_splited
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset

 Test Accuracy: 96.76%

 Classification Report:
                       precision    recall  f1-score   support

     Bacterial Blight     0.9783    0.9184    0.9474        49
Bacterial Leaf Streak     0.8684    1.0000    0.9296        33
           Brown Spot     0.9359    0.9605    0.9481       152
              Healthy     0.9872    0.9747    0.9809       158
                Hispa     0.9925    0.9925    0.9925       133
           Leaf Blast     0.9760    0.9531    0.9644       128
        Sheath Blight     1.0000    0.9600    0.9796        25

             accuracy                         0.9676       678
            macro avg     0.9626    0.9656    0.9632       678
         weighted avg     0.9687    0.9676    0.9677       678

 Confusion matrix saved to: output/test/Convnext+depth4channel+dataset2_splited/confusion_matrix.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Device set to use cuda:0
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Saved 8 merged gradCAM images in the output/test/Convnext+depth4channel+dataset2_splited/grad_cam folder!
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Evaluate model:Convnext+depth4channel+dataset2_splited
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset

 Test Accuracy: 96.76%

 Classification Report:
                       precision    recall  f1-score   support

     Bacterial Blight     0.9783    0.9184    0.9474        49
Bacterial Leaf Streak     0.8684    1.0000    0.9296        33
           Brown Spot     0.9359    0.9605    0.9481       152
              Healthy     0.9872    0.9747    0.9809       158
                Hispa     0.9925    0.9925    0.9925       133
           Leaf Blast     0.9760    0.9531    0.9644       128
        Sheath Blight     1.0000    0.9600    0.9796        25

             accuracy                         0.9676       678
            macro avg     0.9626    0.9656    0.9632       678
         weighted avg     0.9687    0.9676    0.9677       678


Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: ConvNext+depth4channel_v3+dataset1]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Epoch 1/100 | Time: 977.27s | Train Loss: 0.7750 | Val Loss: 0.5327 | Val Acc: 0.9485 | LR: 0.000100 
Saving best val acc: 0.9485
Epoch 2/100 | Time: 712.61s | Train Loss: 0.5234 | Val Loss: 0.5244 | Val Acc: 0.9522 | LR: 0.000100 
Saving best val acc: 0.9522
Epoch 3/100 | Time: 349.10s | Train Loss: 0.4820 | Val Loss: 0.4990 | Val Acc: 0.9706 | LR: 0.000100 
Saving best val acc: 0.9706
Epoch 4/100 | Time: 316.76s | Train Loss: 0.4989 | Val Loss: 0.4866 | Val Acc: 0.9798 | LR: 0.000099 
Saving best val acc: 0.9798
Epoch 5/100 | Time: 262.94s | Train Loss: 0.4830 | Val Loss: 0.4939 | Val Acc: 0.9761 | LR: 0.000098 
Epoch 6/100 | Time: 261.88s | Train Loss: 0.4637 | Val Loss: 0.4934 | Val Acc: 0.9798 | LR: 0.000098 
Epoch 7/100 | Time: 263.33s | Train Loss: 0.4751 | Val Loss: 0.4920 | Val Acc: 0.9688 | LR: 0.000097 
Epoch 8/100 | Time: 262.37s | Train Loss: 0.4658 | Val Loss: 0.5052 | Val Acc: 0.9596 | LR: 0.000095 
Epoch 9/100 | Time: 262.21s | Train Loss: 0.4665 | Val Loss: 0.4959 | Val Acc: 0.9688 | LR: 0.000094 
Epoch 10/100 | Time: 261.99s | Train Loss: 0.4492 | Val Loss: 0.4843 | Val Acc: 0.9743 | LR: 0.000092 
Saving best val acc: 0.9743
Epoch 11/100 | Time: 263.37s | Train Loss: 0.4511 | Val Loss: 0.4627 | Val Acc: 0.9853 | LR: 0.000091 
Saving best val acc: 0.9853
Epoch 12/100 | Time: 262.32s | Train Loss: 0.4562 | Val Loss: 0.4571 | Val Acc: 0.9853 | LR: 0.000089 
Saving best val acc: 0.9853
Epoch 13/100 | Time: 263.25s | Train Loss: 0.4478 | Val Loss: 0.4874 | Val Acc: 0.9816 | LR: 0.000087 
Epoch 14/100 | Time: 262.71s | Train Loss: 0.4452 | Val Loss: 0.4709 | Val Acc: 0.9853 | LR: 0.000084 
Epoch 15/100 | Time: 264.35s | Train Loss: 0.4367 | Val Loss: 0.4609 | Val Acc: 0.9890 | LR: 0.000082 
Epoch 16/100 | Time: 262.41s | Train Loss: 0.4387 | Val Loss: 0.4636 | Val Acc: 0.9890 | LR: 0.000080 
Epoch 17/100 | Time: 262.90s | Train Loss: 0.4440 | Val Loss: 0.4672 | Val Acc: 0.9835 | LR: 0.000077 
Epoch 18/100 | Time: 263.46s | Train Loss: 0.4420 | Val Loss: 0.4647 | Val Acc: 0.9853 | LR: 0.000074 
Epoch 19/100 | Time: 266.24s | Train Loss: 0.4400 | Val Loss: 0.4622 | Val Acc: 0.9871 | LR: 0.000072 
Epoch 20/100 | Time: 263.12s | Train Loss: 0.4411 | Val Loss: 0.4661 | Val Acc: 0.9816 | LR: 0.000069 
Epoch 21/100 | Time: 262.19s | Train Loss: 0.4460 | Val Loss: 0.4718 | Val Acc: 0.9816 | LR: 0.000066 
Epoch 22/100 | Time: 279.77s | Train Loss: 0.4385 | Val Loss: 0.4668 | Val Acc: 0.9853 | LR: 0.000063 
Early stopping triggered.
Training complete in 7106.78 seconds. Best model loaded.
Model saved to ./output/models/ConvNext+depth4channel_v3+dataset1+dataset1.pth
 Training metrics plot saved to: output/test/ConvNext+depth4channel_v3+dataset1/training metric.png
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: convnext+cbam+depth+precompute+dataset_2_depth_AUG]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
Epoch 1/50 | Time: 232.74s | Train Loss: 0.8145 | Val Loss: 0.6098 | Val Acc: 0.9319 | LR: 0.000100 
Saving best val acc: 0.9319
Epoch 2/50 | Time: 234.48s | Train Loss: 0.5851 | Val Loss: 0.6294 | Val Acc: 0.9350 | LR: 0.000100 
Epoch 3/50 | Time: 233.78s | Train Loss: 0.5484 | Val Loss: 0.5721 | Val Acc: 0.9536 | LR: 0.000100 
Saving best val acc: 0.9536
Epoch 4/50 | Time: 236.23s | Train Loss: 0.5256 | Val Loss: 0.6376 | Val Acc: 0.9164 | LR: 0.000099 
Epoch 5/50 | Time: 246.28s | Train Loss: 0.5181 | Val Loss: 0.5713 | Val Acc: 0.9412 | LR: 0.000098 
Saving best val acc: 0.9412
Epoch 6/50 | Time: 245.87s | Train Loss: 0.4994 | Val Loss: 0.5791 | Val Acc: 0.9536 | LR: 0.000098 
Epoch 7/50 | Time: 246.45s | Train Loss: 0.4891 | Val Loss: 0.5550 | Val Acc: 0.9567 | LR: 0.000097 
Saving best val acc: 0.9567
Epoch 8/50 | Time: 246.48s | Train Loss: 0.4997 | Val Loss: 0.5449 | Val Acc: 0.9659 | LR: 0.000095 
Saving best val acc: 0.9659
Epoch 9/50 | Time: 247.53s | Train Loss: 0.4777 | Val Loss: 0.5253 | Val Acc: 0.9690 | LR: 0.000094 
Saving best val acc: 0.9690
Epoch 10/50 | Time: 244.88s | Train Loss: 0.4928 | Val Loss: 0.5300 | Val Acc: 0.9628 | LR: 0.000092 
Epoch 11/50 | Time: 233.00s | Train Loss: 0.4752 | Val Loss: 0.5548 | Val Acc: 0.9567 | LR: 0.000091 
Epoch 12/50 | Time: 237.90s | Train Loss: 0.4826 | Val Loss: 0.6422 | Val Acc: 0.9257 | LR: 0.000089 
Epoch 13/50 | Time: 241.03s | Train Loss: 0.4805 | Val Loss: 0.5146 | Val Acc: 0.9721 | LR: 0.000087 
Saving best val acc: 0.9721
Epoch 14/50 | Time: 234.08s | Train Loss: 0.4785 | Val Loss: 0.5398 | Val Acc: 0.9598 | LR: 0.000084 
Epoch 15/50 | Time: 233.66s | Train Loss: 0.4760 | Val Loss: 0.5238 | Val Acc: 0.9598 | LR: 0.000082 
Epoch 16/50 | Time: 234.23s | Train Loss: 0.4767 | Val Loss: 0.5353 | Val Acc: 0.9659 | LR: 0.000080 
Epoch 17/50 | Time: 234.14s | Train Loss: 0.4679 | Val Loss: 0.5175 | Val Acc: 0.9721 | LR: 0.000077 
Epoch 18/50 | Time: 234.05s | Train Loss: 0.4620 | Val Loss: 0.5009 | Val Acc: 0.9814 | LR: 0.000074 
Saving best val acc: 0.9814
Epoch 19/50 | Time: 247.43s | Train Loss: 0.4723 | Val Loss: 0.5836 | Val Acc: 0.9598 | LR: 0.000072 
Epoch 20/50 | Time: 251.22s | Train Loss: 0.4755 | Val Loss: 0.5292 | Val Acc: 0.9690 | LR: 0.000069 
Epoch 21/50 | Time: 241.33s | Train Loss: 0.4700 | Val Loss: 0.5500 | Val Acc: 0.9598 | LR: 0.000066 
Epoch 22/50 | Time: 232.52s | Train Loss: 0.4621 | Val Loss: 0.5028 | Val Acc: 0.9752 | LR: 0.000063 
Epoch 23/50 | Time: 233.74s | Train Loss: 0.4604 | Val Loss: 0.5132 | Val Acc: 0.9690 | LR: 0.000060 
Epoch 24/50 | Time: 233.89s | Train Loss: 0.4631 | Val Loss: 0.5257 | Val Acc: 0.9721 | LR: 0.000057 
Epoch 25/50 | Time: 231.97s | Train Loss: 0.4646 | Val Loss: 0.4755 | Val Acc: 0.9876 | LR: 0.000054 
Saving best val acc: 0.9876
Epoch 26/50 | Time: 234.88s | Train Loss: 0.4586 | Val Loss: 0.5412 | Val Acc: 0.9567 | LR: 0.000050 
Epoch 27/50 | Time: 245.00s | Train Loss: 0.4598 | Val Loss: 0.5120 | Val Acc: 0.9721 | LR: 0.000047 
Epoch 28/50 | Time: 260.20s | Train Loss: 0.4603 | Val Loss: 0.5189 | Val Acc: 0.9690 | LR: 0.000044 
Epoch 29/50 | Time: 260.37s | Train Loss: 0.4595 | Val Loss: 0.4689 | Val Acc: 0.9907 | LR: 0.000041 
Saving best val acc: 0.9907
Epoch 30/50 | Time: 235.89s | Train Loss: 0.4606 | Val Loss: 0.5225 | Val Acc: 0.9752 | LR: 0.000038 
Epoch 31/50 | Time: 233.76s | Train Loss: 0.4638 | Val Loss: 0.5002 | Val Acc: 0.9783 | LR: 0.000035 
Epoch 32/50 | Time: 233.20s | Train Loss: 0.4571 | Val Loss: 0.5073 | Val Acc: 0.9721 | LR: 0.000032 
Epoch 33/50 | Time: 232.91s | Train Loss: 0.4575 | Val Loss: 0.4996 | Val Acc: 0.9783 | LR: 0.000029 
Epoch 34/50 | Time: 233.30s | Train Loss: 0.4577 | Val Loss: 0.4899 | Val Acc: 0.9814 | LR: 0.000027 
Epoch 35/50 | Time: 240.50s | Train Loss: 0.4563 | Val Loss: 0.4800 | Val Acc: 0.9814 | LR: 0.000024 
Epoch 36/50 | Time: 247.77s | Train Loss: 0.4555 | Val Loss: 0.4830 | Val Acc: 0.9907 | LR: 0.000021 
Epoch 37/50 | Time: 250.74s | Train Loss: 0.4561 | Val Loss: 0.4787 | Val Acc: 0.9876 | LR: 0.000019 
Epoch 38/50 | Time: 248.77s | Train Loss: 0.4555 | Val Loss: 0.5007 | Val Acc: 0.9783 | LR: 0.000017 
Epoch 39/50 | Time: 232.29s | Train Loss: 0.4544 | Val Loss: 0.4959 | Val Acc: 0.9783 | LR: 0.000014 
Early stopping triggered.
Training complete in 9358.68 seconds. Best model loaded.
Model saved to ./output/models/convnext+cbam+depth+precompute+dataset_2_depth_AUG+dataset_2_depth_AUG.pth
 Training metrics plot saved to: output/test/convnext+cbam+depth+precompute+dataset_2_depth_AUG/training metric.png
Evaluate model:convnext+cbam+depth+precompute+dataset_2_depth_AUG

 Test Accuracy: 97.49%

 Classification Report:
                       precision    recall  f1-score   support

     Bacterial Blight     0.9783    0.9184    0.9474        49
Bacterial Leaf Streak     0.9167    1.0000    0.9565        33
           Brown Spot     0.9737    0.9737    0.9737       152
              Healthy     0.9809    0.9747    0.9778       158
                Hispa     0.9706    0.9925    0.9814       133
           Leaf Blast     0.9843    0.9766    0.9804       128
        Sheath Blight     1.0000    0.9600    0.9796        25

             accuracy                         0.9749       678
            macro avg     0.9720    0.9708    0.9710       678
         weighted avg     0.9753    0.9749    0.9749       678

 Confusion matrix saved to: output/test/convnext+cbam+depth+precompute+dataset_2_depth_AUG/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/convnext+cbam+depth+precompute+dataset_2_depth_AUG/grad_cam folder!
Saved misclassified images to output/test/convnext+cbam+depth+precompute+dataset_2_depth_AUG/misclassified_images.png



✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: convnext+cbam+depth+precompute+dataset_1_depth_AUG]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
Epoch 1/50 | Time: 204.31s | Train Loss: 0.6640 | Val Loss: 0.5533 | Val Acc: 0.9375 | LR: 0.000100 
Saving best val acc: 0.9375
Epoch 2/50 | Time: 131.21s | Train Loss: 0.5032 | Val Loss: 0.6440 | Val Acc: 0.8989 | LR: 0.000100 
Epoch 3/50 | Time: 131.48s | Train Loss: 0.4759 | Val Loss: 0.4705 | Val Acc: 0.9798 | LR: 0.000100 
Saving best val acc: 0.9798
Epoch 4/50 | Time: 148.96s | Train Loss: 0.4606 | Val Loss: 0.5585 | Val Acc: 0.9577 | LR: 0.000099 
Epoch 5/50 | Time: 140.12s | Train Loss: 0.4600 | Val Loss: 0.4905 | Val Acc: 0.9761 | LR: 0.000098 
Epoch 6/50 | Time: 133.00s | Train Loss: 0.4585 | Val Loss: 0.5114 | Val Acc: 0.9688 | LR: 0.000098 
Epoch 7/50 | Time: 134.18s | Train Loss: 0.4581 | Val Loss: 0.4808 | Val Acc: 0.9761 | LR: 0.000097 
Epoch 8/50 | Time: 141.85s | Train Loss: 0.4520 | Val Loss: 0.4779 | Val Acc: 0.9761 | LR: 0.000095 
Epoch 9/50 | Time: 142.19s | Train Loss: 0.4565 | Val Loss: 0.4700 | Val Acc: 0.9816 | LR: 0.000094 
Saving best val acc: 0.9816
Epoch 10/50 | Time: 142.57s | Train Loss: 0.4491 | Val Loss: 0.4604 | Val Acc: 0.9835 | LR: 0.000092 
Saving best val acc: 0.9835
Epoch 11/50 | Time: 141.86s | Train Loss: 0.4456 | Val Loss: 0.4850 | Val Acc: 0.9724 | LR: 0.000091 
Epoch 12/50 | Time: 142.45s | Train Loss: 0.4481 | Val Loss: 0.4679 | Val Acc: 0.9835 | LR: 0.000089 
Epoch 13/50 | Time: 142.88s | Train Loss: 0.4363 | Val Loss: 0.4794 | Val Acc: 0.9798 | LR: 0.000087 
Epoch 14/50 | Time: 143.31s | Train Loss: 0.4434 | Val Loss: 0.4755 | Val Acc: 0.9798 | LR: 0.000084 
Epoch 15/50 | Time: 141.78s | Train Loss: 0.4413 | Val Loss: 0.4861 | Val Acc: 0.9724 | LR: 0.000082 
Epoch 16/50 | Time: 143.22s | Train Loss: 0.4359 | Val Loss: 0.4597 | Val Acc: 0.9890 | LR: 0.000080 
Saving best val acc: 0.9890
Epoch 17/50 | Time: 142.23s | Train Loss: 0.4359 | Val Loss: 0.4723 | Val Acc: 0.9798 | LR: 0.000077 
Epoch 18/50 | Time: 142.23s | Train Loss: 0.4371 | Val Loss: 0.4717 | Val Acc: 0.9816 | LR: 0.000074 
Epoch 19/50 | Time: 142.70s | Train Loss: 0.4431 | Val Loss: 0.4652 | Val Acc: 0.9853 | LR: 0.000072 
Epoch 20/50 | Time: 142.02s | Train Loss: 0.4389 | Val Loss: 0.4875 | Val Acc: 0.9743 | LR: 0.000069 
Epoch 21/50 | Time: 142.99s | Train Loss: 0.4492 | Val Loss: 0.5011 | Val Acc: 0.9614 | LR: 0.000066 
Epoch 22/50 | Time: 141.39s | Train Loss: 0.4403 | Val Loss: 0.4709 | Val Acc: 0.9835 | LR: 0.000063 
Epoch 23/50 | Time: 141.35s | Train Loss: 0.4384 | Val Loss: 0.4635 | Val Acc: 0.9853 | LR: 0.000060 
Epoch 24/50 | Time: 141.99s | Train Loss: 0.4348 | Val Loss: 0.4699 | Val Acc: 0.9835 | LR: 0.000057 
Epoch 25/50 | Time: 141.05s | Train Loss: 0.4326 | Val Loss: 0.4723 | Val Acc: 0.9835 | LR: 0.000054 
Epoch 26/50 | Time: 142.73s | Train Loss: 0.4316 | Val Loss: 0.4729 | Val Acc: 0.9816 | LR: 0.000050 
Early stopping triggered.
Training complete in 3726.18 seconds. Best model loaded.
Model saved to ./output/models/convnext+cbam+depth+precompute+dataset_1_depth_AUG+dataset_1_depth_AUG.pth
 Training metrics plot saved to: output/test/convnext+cbam+depth+precompute+dataset_1_depth_AUG/training metric.png
Evaluate model:convnext+cbam+depth+precompute+dataset_1_depth_AUG

 Test Accuracy: 98.53%

 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    0.9886    0.9943        88
           brown_spot     0.9778    0.9462    0.9617        93
              healthy     0.9688    1.0000    0.9841        93
           leaf_blast     0.9674    0.9780    0.9727        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9853       543
            macro avg     0.9857    0.9855    0.9855       543
         weighted avg     0.9854    0.9853    0.9852       543

 Confusion matrix saved to: output/test/convnext+cbam+depth+precompute+dataset_1_depth_AUG/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/convnext+cbam+depth+precompute+dataset_1_depth_AUG/grad_cam folder!


Evaluate model:convnext+cbam+depth+precompute+dataset_1_depth_AUG

 Test Accuracy: 98.53%

 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    0.9886    0.9943        88
           brown_spot     0.9778    0.9462    0.9617        93
              healthy     0.9688    1.0000    0.9841        93
           leaf_blast     0.9674    0.9780    0.9727        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9853       543
            macro avg     0.9857    0.9855    0.9855       543
         weighted avg     0.9854    0.9853    0.9852       543

 Confusion matrix saved to: output/test/convnext+cbam+depth+precompute+dataset_1_depth_AUG/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/convnext+cbam+depth+precompute+dataset_1_depth_AUG/grad_cam folder!
Saved misclassified images to output/test/convnext+cbam+depth+precompute+dataset_1_depth_AUG/misclassified_images.png
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: convnext_only+dataset2_splited]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
Epoch 1/50 | Time: 172.06s | Train Loss: 0.9638 | Val Loss: 0.6279 | Val Acc: 0.9257 | LR: 0.000100 
Saving best val acc: 0.9257
Epoch 2/50 | Time: 129.45s | Train Loss: 0.6259 | Val Loss: 0.5639 | Val Acc: 0.9536 | LR: 0.000100 
Saving best val acc: 0.9536
Epoch 3/50 | Time: 130.28s | Train Loss: 0.5569 | Val Loss: 0.5349 | Val Acc: 0.9659 | LR: 0.000100 
Saving best val acc: 0.9659
Epoch 4/50 | Time: 128.64s | Train Loss: 0.5240 | Val Loss: 0.5740 | Val Acc: 0.9536 | LR: 0.000099 
Epoch 5/50 | Time: 129.97s | Train Loss: 0.5284 | Val Loss: 0.5492 | Val Acc: 0.9690 | LR: 0.000098 
Epoch 6/50 | Time: 129.61s | Train Loss: 0.4973 | Val Loss: 0.5369 | Val Acc: 0.9598 | LR: 0.000098 
Epoch 7/50 | Time: 129.39s | Train Loss: 0.4876 | Val Loss: 0.5778 | Val Acc: 0.9443 | LR: 0.000097 
Epoch 8/50 | Time: 130.60s | Train Loss: 0.4855 | Val Loss: 0.5197 | Val Acc: 0.9659 | LR: 0.000095 
Saving best val acc: 0.9659
Epoch 9/50 | Time: 130.85s | Train Loss: 0.4804 | Val Loss: 0.5378 | Val Acc: 0.9690 | LR: 0.000094 
Epoch 10/50 | Time: 129.03s | Train Loss: 0.4812 | Val Loss: 0.5244 | Val Acc: 0.9721 | LR: 0.000092 
Epoch 11/50 | Time: 130.85s | Train Loss: 0.4802 | Val Loss: 0.5450 | Val Acc: 0.9598 | LR: 0.000091 
Epoch 12/50 | Time: 128.92s | Train Loss: 0.4756 | Val Loss: 0.5589 | Val Acc: 0.9628 | LR: 0.000089 
Epoch 13/50 | Time: 129.87s | Train Loss: 0.4849 | Val Loss: 0.5273 | Val Acc: 0.9752 | LR: 0.000087 
Epoch 14/50 | Time: 129.98s | Train Loss: 0.4669 | Val Loss: 0.5342 | Val Acc: 0.9567 | LR: 0.000084 
Epoch 15/50 | Time: 129.75s | Train Loss: 0.4604 | Val Loss: 0.5357 | Val Acc: 0.9598 | LR: 0.000082 
Epoch 16/50 | Time: 128.79s | Train Loss: 0.4719 | Val Loss: 0.5491 | Val Acc: 0.9598 | LR: 0.000080 
Epoch 17/50 | Time: 128.80s | Train Loss: 0.4691 | Val Loss: 0.5559 | Val Acc: 0.9505 | LR: 0.000077 
Epoch 18/50 | Time: 128.83s | Train Loss: 0.4654 | Val Loss: 0.5238 | Val Acc: 0.9628 | LR: 0.000074 
Early stopping triggered.
Training complete in 2375.76 seconds. Best model loaded.
Model saved to ./output/models/convnext_only+dataset2_splited+dataset2_splited.pth
 Training metrics plot saved to: output/test/convnext_only+dataset2_splited/training metric.png
Evaluate model:convnext_only+dataset2_splited

 Test Accuracy: 96.31%

 Classification Report:
                       precision    recall  f1-score   support

     Bacterial Blight     0.9565    0.8980    0.9263        49
Bacterial Leaf Streak     0.8378    0.9394    0.8857        33
           Brown Spot     0.9545    0.9671    0.9608       152
              Healthy     0.9742    0.9557    0.9649       158
                Hispa     0.9706    0.9925    0.9814       133
           Leaf Blast     0.9841    0.9688    0.9764       128
        Sheath Blight     1.0000    0.9600    0.9796        25

             accuracy                         0.9631       678
            macro avg     0.9540    0.9545    0.9536       678
         weighted avg     0.9640    0.9631    0.9633       678

 Confusion matrix saved to: output/test/convnext_only+dataset2_splited/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/convnext_only+dataset2_splited/grad_cam folder!
Saved misclassified images to output/test/convnext_only+dataset2_splited/misclassified_images.png
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: convnext_only+dataset2_splited]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: convnext+CBAM+dataset2_splited]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
Epoch 1/50 | Time: 157.63s | Train Loss: 0.9238 | Val Loss: 0.6559 | Val Acc: 0.9102 | LR: 0.000100 
Saving best val acc: 0.9102
Epoch 2/50 | Time: 128.87s | Train Loss: 0.6725 | Val Loss: 0.6111 | Val Acc: 0.9319 | LR: 0.000100 
Saving best val acc: 0.9319
Epoch 3/50 | Time: 128.21s | Train Loss: 0.5949 | Val Loss: 0.5760 | Val Acc: 0.9381 | LR: 0.000100 
Saving best val acc: 0.9381
Epoch 4/50 | Time: 131.92s | Train Loss: 0.5641 | Val Loss: 0.5566 | Val Acc: 0.9567 | LR: 0.000099 
Saving best val acc: 0.9567
Epoch 5/50 | Time: 130.37s | Train Loss: 0.5448 | Val Loss: 0.5562 | Val Acc: 0.9567 | LR: 0.000098 
Saving best val acc: 0.9567
Epoch 6/50 | Time: 131.07s | Train Loss: 0.5193 | Val Loss: 0.5327 | Val Acc: 0.9628 | LR: 0.000098 
Saving best val acc: 0.9628
Epoch 7/50 | Time: 131.60s | Train Loss: 0.5229 | Val Loss: 0.5669 | Val Acc: 0.9567 | LR: 0.000097 
Epoch 8/50 | Time: 131.55s | Train Loss: 0.5066 | Val Loss: 0.5479 | Val Acc: 0.9721 | LR: 0.000095 
Epoch 9/50 | Time: 131.84s | Train Loss: 0.4955 | Val Loss: 0.5215 | Val Acc: 0.9783 | LR: 0.000094 
Saving best val acc: 0.9783
Epoch 10/50 | Time: 130.93s | Train Loss: 0.4937 | Val Loss: 0.5304 | Val Acc: 0.9752 | LR: 0.000092 
Epoch 11/50 | Time: 131.12s | Train Loss: 0.4816 | Val Loss: 0.5577 | Val Acc: 0.9598 | LR: 0.000091 
Epoch 12/50 | Time: 130.69s | Train Loss: 0.5016 | Val Loss: 0.5509 | Val Acc: 0.9659 | LR: 0.000089 
Epoch 13/50 | Time: 131.06s | Train Loss: 0.4839 | Val Loss: 0.5572 | Val Acc: 0.9690 | LR: 0.000087 
Epoch 14/50 | Time: 128.51s | Train Loss: 0.4901 | Val Loss: 0.5502 | Val Acc: 0.9598 | LR: 0.000084 
Epoch 15/50 | Time: 131.06s | Train Loss: 0.4835 | Val Loss: 0.5482 | Val Acc: 0.9598 | LR: 0.000082 
Epoch 16/50 | Time: 131.36s | Train Loss: 0.4833 | Val Loss: 0.5669 | Val Acc: 0.9505 | LR: 0.000080 
Epoch 17/50 | Time: 131.76s | Train Loss: 0.4860 | Val Loss: 0.5574 | Val Acc: 0.9628 | LR: 0.000077 
Epoch 18/50 | Time: 129.43s | Train Loss: 0.4676 | Val Loss: 0.5318 | Val Acc: 0.9690 | LR: 0.000074 
Epoch 19/50 | Time: 129.27s | Train Loss: 0.4703 | Val Loss: 0.5476 | Val Acc: 0.9628 | LR: 0.000072 
Early stopping triggered.
Training complete in 2508.37 seconds. Best model loaded.
Model saved to ./output/models/convnext+CBAM+dataset2_splited+dataset2_splited.pth
 Training metrics plot saved to: output/test/convnext+CBAM+dataset2_splited/training metric.png
Evaluate model:convnext+CBAM+dataset2_splited

 Test Accuracy: 97.35%

 Classification Report:
                       precision    recall  f1-score   support

     Bacterial Blight     1.0000    0.8571    0.9231        49
Bacterial Leaf Streak     0.8684    1.0000    0.9296        33
           Brown Spot     0.9737    0.9737    0.9737       152
              Healthy     0.9693    1.0000    0.9844       158
                Hispa     1.0000    0.9850    0.9924       133
           Leaf Blast     0.9841    0.9688    0.9764       128
        Sheath Blight     0.9231    0.9600    0.9412        25

             accuracy                         0.9735       678
            macro avg     0.9598    0.9635    0.9601       678
         weighted avg     0.9747    0.9735    0.9734       678

 Confusion matrix saved to: output/test/convnext+CBAM+dataset2_splited/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/convnext+CBAM+dataset2_splited/grad_cam folder!
Saved misclassified images to output/test/convnext+CBAM+dataset2_splited/misclassified_images.png

✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: convnext+CBAM+PlantVillageSplited_depth_AUG]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
Epoch 1/50 | Time: 2636.27s | Train Loss: 0.7706 | Val Loss: 0.7008 | Val Acc: 0.9931 | LR: 0.000100 
Saving best val acc: 0.9931
Epoch 2/50 | Time: 2105.60s | Train Loss: 0.7050 | Val Loss: 0.7091 | Val Acc: 0.9889 | LR: 0.000100 
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: convnext+CBAM+PlantDocSplited_depth_AUG]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
Epoch 1/50 | Time: 159.67s | Train Loss: 1.4471 | Val Loss: 1.1405 | Val Acc: 0.8048 | LR: 0.000100 
Saving best val acc: 0.8048
Epoch 2/50 | Time: 160.03s | Train Loss: 0.9513 | Val Loss: 1.1624 | Val Acc: 0.8018 | LR: 0.000100 
Epoch 3/50 | Time: 160.37s | Train Loss: 0.8123 | Val Loss: 1.2513 | Val Acc: 0.7868 | LR: 0.000100 
Epoch 4/50 | Time: 161.41s | Train Loss: 0.7619 | Val Loss: 1.1818 | Val Acc: 0.8168 | LR: 0.000099 
Epoch 5/50 | Time: 161.92s | Train Loss: 0.7155 | Val Loss: 1.2052 | Val Acc: 0.8048 | LR: 0.000098 
Epoch 6/50 | Time: 161.51s | Train Loss: 0.7053 | Val Loss: 1.1428 | Val Acc: 0.8468 | LR: 0.000098 
Epoch 7/50 | Time: 162.12s | Train Loss: 0.6833 | Val Loss: 1.1575 | Val Acc: 0.8198 | LR: 0.000097 
Epoch 8/50 | Time: 161.74s | Train Loss: 0.6817 | Val Loss: 1.1172 | Val Acc: 0.8288 | LR: 0.000095 
Saving best val acc: 0.8288
Epoch 9/50 | Time: 161.11s | Train Loss: 0.6825 | Val Loss: 1.1577 | Val Acc: 0.8198 | LR: 0.000094 
Epoch 10/50 | Time: 161.62s | Train Loss: 0.6976 | Val Loss: 1.1588 | Val Acc: 0.8108 | LR: 0.000092 
Epoch 11/50 | Time: 161.82s | Train Loss: 0.6905 | Val Loss: 1.2292 | Val Acc: 0.8048 | LR: 0.000091 
Epoch 12/50 | Time: 160.85s | Train Loss: 0.6914 | Val Loss: 1.2299 | Val Acc: 0.8078 | LR: 0.000089 
Epoch 13/50 | Time: 162.32s | Train Loss: 0.6761 | Val Loss: 1.1723 | Val Acc: 0.8198 | LR: 0.000087 
Epoch 14/50 | Time: 161.79s | Train Loss: 0.6652 | Val Loss: 1.1648 | Val Acc: 0.8408 | LR: 0.000084 
Epoch 15/50 | Time: 162.22s | Train Loss: 0.6686 | Val Loss: 1.3086 | Val Acc: 0.7808 | LR: 0.000082 
Epoch 16/50 | Time: 161.93s | Train Loss: 0.6690 | Val Loss: 1.1664 | Val Acc: 0.8318 | LR: 0.000080 
Epoch 17/50 | Time: 161.55s | Train Loss: 0.6616 | Val Loss: 1.1864 | Val Acc: 0.8318 | LR: 0.000077 
Epoch 18/50 | Time: 162.46s | Train Loss: 0.6603 | Val Loss: 1.2098 | Val Acc: 0.8198 | LR: 0.000074 
Early stopping triggered.
Training complete in 2906.48 seconds. Best model loaded.
Model saved to ./output/models/convnext+CBAM+PlantDocSplited_depth_AUG+PlantDocSplited_depth_AUG.pth
 Training metrics plot saved to: output/test/convnext+CBAM+PlantDocSplited_depth_AUG/training metric.png
Evaluate model:convnext+CBAM+PlantDocSplited_depth_AUG

 Test Accuracy: 77.20%

 Classification Report:
                                      precision    recall  f1-score   support

                     Apple_Scab_Leaf     0.8889    0.8000    0.8421        10
                          Apple_leaf     0.7778    0.7778    0.7778         9
                     Apple_rust_leaf     0.9000    0.9000    0.9000        10
                    Bell_pepper_leaf     0.7778    0.8750    0.8235         8
               Bell_pepper_leaf_spot     0.5833    0.7778    0.6667         9
                      Blueberry_leaf     0.9000    0.8182    0.8571        11
                         Cherry_leaf     0.8889    0.8000    0.8421        10
                 Corn_Gray_leaf_spot     0.1667    0.2500    0.2000         4
                    Corn_leaf_blight     0.7000    0.5833    0.6364        12
                      Corn_rust_leaf     1.0000    1.0000    1.0000        10
                          Peach_leaf     0.8750    0.7778    0.8235         9
            Potato_leaf_early_blight     0.3333    0.1429    0.2000        14
             Potato_leaf_late_blight     0.2500    0.5000    0.3333         8
                      Raspberry_leaf     0.8750    1.0000    0.9333         7
                       Soyabean_leaf     1.0000    0.7143    0.8333         7
          Squash_Powdery_mildew_leaf     1.0000    1.0000    1.0000         6
                     Strawberry_leaf     1.0000    1.0000    1.0000         8
            Tomato_Early_blight_leaf     0.7273    0.8889    0.8000         9
           Tomato_Septoria_leaf_spot     0.7857    0.9167    0.8462        12
                         Tomato_leaf     0.7500    0.3750    0.5000         8
          Tomato_leaf_bacterial_spot     0.5714    0.5000    0.5333         8
             Tomato_leaf_late_blight     0.8889    0.8000    0.8421        10
            Tomato_leaf_mosaic_virus     0.6667    0.8000    0.7273        10
            Tomato_leaf_yellow_virus     0.9333    0.9333    0.9333        15
                    Tomato_mold_leaf     0.6667    0.8000    0.7273         5
Tomato_two_spotted_spider_mites_leaf     1.0000    1.0000    1.0000         1
                          grape_leaf     1.0000    1.0000    1.0000        12
                grape_leaf_black_rot     1.0000    1.0000    1.0000         8

                            accuracy                         0.7720       250
                           macro avg     0.7824    0.7761    0.7707       250
                        weighted avg     0.7853    0.7720    0.7700       250

 Confusion matrix saved to: output/test/convnext+CBAM+PlantDocSplited_depth_AUG/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/convnext+CBAM+PlantDocSplited_depth_AUG/grad_cam folder!
Saved misclassified images to output/test/convnext+CBAM+PlantDocSplited_depth_AUG/misclassified_images.png
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: ConvNeXt+CBAM_Potato_splited_depth_AUG]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
Epoch 1/50 | Time: 174.06s | Train Loss: 0.8846 | Val Loss: 0.7589 | Val Acc: 0.8480 | LR: 0.000100 
Saving best val acc: 0.8480
Epoch 2/50 | Time: 162.82s | Train Loss: 0.6136 | Val Loss: 0.7119 | Val Acc: 0.8856 | LR: 0.000100 
Saving best val acc: 0.8856
Epoch 3/50 | Time: 155.26s | Train Loss: 0.5435 | Val Loss: 0.7106 | Val Acc: 0.8856 | LR: 0.000100 
Saving best val acc: 0.8856
Epoch 4/50 | Time: 148.72s | Train Loss: 0.5210 | Val Loss: 0.7521 | Val Acc: 0.8824 | LR: 0.000099 
Epoch 5/50 | Time: 148.79s | Train Loss: 0.4981 | Val Loss: 0.7209 | Val Acc: 0.8922 | LR: 0.000098 
Epoch 6/50 | Time: 149.16s | Train Loss: 0.4862 | Val Loss: 0.6761 | Val Acc: 0.9118 | LR: 0.000098 
Saving best val acc: 0.9118
Epoch 7/50 | Time: 151.18s | Train Loss: 0.4972 | Val Loss: 0.6967 | Val Acc: 0.8987 | LR: 0.000097 
Epoch 8/50 | Time: 150.22s | Train Loss: 0.4967 | Val Loss: 0.7620 | Val Acc: 0.8709 | LR: 0.000095 
Epoch 9/50 | Time: 150.82s | Train Loss: 0.5006 | Val Loss: 0.7086 | Val Acc: 0.9020 | LR: 0.000094 
Epoch 10/50 | Time: 149.98s | Train Loss: 0.4717 | Val Loss: 0.7727 | Val Acc: 0.8807 | LR: 0.000092 
Epoch 11/50 | Time: 151.33s | Train Loss: 0.4727 | Val Loss: 0.7805 | Val Acc: 0.8775 | LR: 0.000091 
Epoch 12/50 | Time: 150.50s | Train Loss: 0.4759 | Val Loss: 0.6771 | Val Acc: 0.9118 | LR: 0.000089 
Epoch 13/50 | Time: 150.41s | Train Loss: 0.4710 | Val Loss: 0.6954 | Val Acc: 0.9036 | LR: 0.000087 
Epoch 14/50 | Time: 149.97s | Train Loss: 0.4650 | Val Loss: 0.6892 | Val Acc: 0.9101 | LR: 0.000084 
Epoch 15/50 | Time: 147.30s | Train Loss: 0.4686 | Val Loss: 0.7670 | Val Acc: 0.8758 | LR: 0.000082 
Epoch 16/50 | Time: 150.35s | Train Loss: 0.4711 | Val Loss: 0.7465 | Val Acc: 0.8938 | LR: 0.000080 
Early stopping triggered.
Training complete in 2440.95 seconds. Best model loaded.
Model saved to ./output/models/ConvNeXt+CBAM_Potato_splited_depth_AUG.pth
 Training metrics plot saved to: output/test/ConvNeXt+CBAM_Potato_splited_depth_AUG/training metric.png
Evaluate model:ConvNeXt+CBAM_Potato_splited_depth_AUG

 Test Accuracy: 88.75%

 Classification Report:
              precision    recall  f1-score   support

    Bacteria     0.9741    0.9826    0.9784       115
       Fungi     0.8741    0.8278    0.8503       151
     Healthy     0.7917    0.9268    0.8539        41
    Nematode     0.8824    1.0000    0.9375        15
        Pest     0.8387    0.8455    0.8421       123
 Phytopthora     0.9077    0.8429    0.8741        70
       Virus     0.8991    0.9159    0.9074       107

    accuracy                         0.8875       622
   macro avg     0.8811    0.9059    0.8920       622
weighted avg     0.8884    0.8875    0.8872       622

 Confusion matrix saved to: output/test/ConvNeXt+CBAM_Potato_splited_depth_AUG/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+CBAM_Potato_splited_depth_AUG/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+CBAM_Potato_splited_depth_AUG/misclassified_images.png
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: ConvNeXt+CBAM_Potato_splited_depth_AUG+v2]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
Epoch 1/50 | Time: 167.38s | Train Loss: 0.8577 | Val Loss: 0.8265 | Val Acc: 0.8562 | LR: 0.000100 
Saving best val acc: 0.8562
Epoch 2/50 | Time: 168.84s | Train Loss: 0.6096 | Val Loss: 0.8174 | Val Acc: 0.8333 | LR: 0.000100 
Saving best val acc: 0.8333
Epoch 3/50 | Time: 170.32s | Train Loss: 0.5500 | Val Loss: 0.7067 | Val Acc: 0.9069 | LR: 0.000100 
Saving best val acc: 0.9069
Epoch 4/50 | Time: 170.32s | Train Loss: 0.5160 | Val Loss: 0.7766 | Val Acc: 0.8758 | LR: 0.000099 
Epoch 5/50 | Time: 172.06s | Train Loss: 0.5045 | Val Loss: 0.7002 | Val Acc: 0.8987 | LR: 0.000098 
Saving best val acc: 0.8987
Epoch 6/50 | Time: 172.15s | Train Loss: 0.4889 | Val Loss: 0.8079 | Val Acc: 0.8611 | LR: 0.000098 
Epoch 7/50 | Time: 171.42s | Train Loss: 0.4907 | Val Loss: 0.7147 | Val Acc: 0.8840 | LR: 0.000097 
Epoch 8/50 | Time: 172.23s | Train Loss: 0.4742 | Val Loss: 0.7531 | Val Acc: 0.8856 | LR: 0.000095 
Epoch 9/50 | Time: 172.91s | Train Loss: 0.4750 | Val Loss: 0.8666 | Val Acc: 0.8562 | LR: 0.000094 
Epoch 10/50 | Time: 169.11s | Train Loss: 0.4832 | Val Loss: 0.8338 | Val Acc: 0.8464 | LR: 0.000092 
Epoch 11/50 | Time: 172.47s | Train Loss: 0.4886 | Val Loss: 0.7185 | Val Acc: 0.8938 | LR: 0.000091 
Epoch 12/50 | Time: 172.73s | Train Loss: 0.4705 | Val Loss: 0.7797 | Val Acc: 0.8775 | LR: 0.000089 
Epoch 13/50 | Time: 171.77s | Train Loss: 0.4699 | Val Loss: 0.7717 | Val Acc: 0.8742 | LR: 0.000087 
Epoch 14/50 | Time: 172.87s | Train Loss: 0.4770 | Val Loss: 0.7424 | Val Acc: 0.8873 | LR: 0.000084 
Epoch 15/50 | Time: 171.39s | Train Loss: 0.4717 | Val Loss: 0.7897 | Val Acc: 0.8725 | LR: 0.000082 
Early stopping triggered.
Training complete in 2568.04 seconds. Best model loaded.
Model saved to ./output/models/ConvNeXt+CBAM_Potato_splited_depth_AUG+v2.pth
 Training metrics plot saved to: output/test/ConvNeXt+CBAM_Potato_splited_depth_AUG+v2/training metric.png
Evaluate model:ConvNeXt+CBAM_Potato_splited_depth_AUG+v2

 Test Accuracy: 90.48%

 Classification Report:
              precision    recall  f1-score   support

    Bacteria     0.9355    1.0000    0.9667        58
       Fungi     0.8889    0.8421    0.8649        76
     Healthy     1.0000    0.9048    0.9500        21
    Nematode     0.8750    0.8750    0.8750         8
        Pest     0.8438    0.8710    0.8571        62
 Phytopthora     0.8889    0.8889    0.8889        36
       Virus     0.9444    0.9444    0.9444        54

    accuracy                         0.9048       315
   macro avg     0.9109    0.9037    0.9067       315
weighted avg     0.9052    0.9048    0.9044       315

 Confusion matrix saved to: output/test/ConvNeXt+CBAM_Potato_splited_depth_AUG+v2/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+CBAM_Potato_splited_depth_AUG+v2/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+CBAM_Potato_splited_depth_AUG+v2/misclassified_images.png
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: ConvNeXt+CBAM_PlantVillageSplited_depth_AUG]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
Epoch 1/50 | Time: 4514.90s | Train Loss: 0.7695 | Val Loss: 0.7345 | Val Acc: 0.9828 | LR: 0.000100 
Saving best val acc: 0.9828
Epoch 2/50 | Time: 2199.09s | Train Loss: 0.7054 | Val Loss: 0.7234 | Val Acc: 0.9840 | LR: 0.000100 
Saving best val acc: 0.9840
Epoch 3/50 | Time: 2015.85s | Train Loss: 0.6969 | Val Loss: 0.6956 | Val Acc: 0.9925 | LR: 0.000100 
Saving best val acc: 0.9925
Epoch 4/50 | Time: 2015.27s | Train Loss: 0.6920 | Val Loss: 0.6851 | Val Acc: 0.9969 | LR: 0.000099 
Saving best val acc: 0.9969
Epoch 5/50 | Time: 2015.16s | Train Loss: 0.6877 | Val Loss: 0.6891 | Val Acc: 0.9954 | LR: 0.000098 
Epoch 6/50 | Time: 2017.75s | Train Loss: 0.6893 | Val Loss: 0.6838 | Val Acc: 0.9968 | LR: 0.000098 
Saving best val acc: 0.9968
Epoch 7/50 | Time: 2015.78s | Train Loss: 0.6848 | Val Loss: 0.6863 | Val Acc: 0.9954 | LR: 0.000097 
Epoch 8/50 | Time: 2089.54s | Train Loss: 0.6854 | Val Loss: 0.7014 | Val Acc: 0.9909 | LR: 0.000095 
Epoch 9/50 | Time: 3351.00s | Train Loss: 0.6836 | Val Loss: 0.6830 | Val Acc: 0.9970 | LR: 0.000094 
Saving best val acc: 0.9970
Epoch 10/50 | Time: 2925.68s | Train Loss: 0.6840 | Val Loss: 0.6859 | Val Acc: 0.9963 | LR: 0.000092 
Epoch 11/50 | Time: 2432.79s | Train Loss: 0.6819 | Val Loss: 0.6825 | Val Acc: 0.9975 | LR: 0.000091 
Saving best val acc: 0.9975
Epoch 12/50 | Time: 2281.63s | Train Loss: 0.6816 | Val Loss: 0.6925 | Val Acc: 0.9940 | LR: 0.000089 
Epoch 13/50 | Time: 2015.58s | Train Loss: 0.6811 | Val Loss: 0.6880 | Val Acc: 0.9961 | LR: 0.000087 
Epoch 14/50 | Time: 2015.01s | Train Loss: 0.6802 | Val Loss: 0.6834 | Val Acc: 0.9970 | LR: 0.000084 
Epoch 15/50 | Time: 2014.85s | Train Loss: 0.6789 | Val Loss: 0.6838 | Val Acc: 0.9970 | LR: 0.000082 
Epoch 16/50 | Time: 2015.08s | Train Loss: 0.6790 | Val Loss: 0.6917 | Val Acc: 0.9955 | LR: 0.000080 
Epoch 17/50 | Time: 2015.08s | Train Loss: 0.6785 | Val Loss: 0.6850 | Val Acc: 0.9962 | LR: 0.000077 
Epoch 18/50 | Time: 2015.10s | Train Loss: 0.6771 | Val Loss: 0.6885 | Val Acc: 0.9958 | LR: 0.000074 
Epoch 19/50 | Time: 2014.84s | Train Loss: 0.6779 | Val Loss: 0.6839 | Val Acc: 0.9972 | LR: 0.000072 
Epoch 20/50 | Time: 2015.09s | Train Loss: 0.6776 | Val Loss: 0.6865 | Val Acc: 0.9971 | LR: 0.000069 
Epoch 21/50 | Time: 2015.08s | Train Loss: 0.6763 | Val Loss: 0.6983 | Val Acc: 0.9929 | LR: 0.000066 
Early stopping triggered.
Training complete in 48010.48 seconds. Best model loaded.
Model saved to ./output/models/ConvNeXt+CBAM_PlantVillageSplited_depth_AUG.pth
 Training metrics plot saved to: output/test/ConvNeXt+CBAM_PlantVillageSplited_depth_AUG/training metric.png
Evaluate model:ConvNeXt+CBAM_PlantVillageSplited_depth_AUG

 Test Accuracy: 99.69%

 Classification Report:
                                                    precision    recall  f1-score   support

                                Apple___Apple_scab     1.0000    1.0000    1.0000        63
                                 Apple___Black_rot     1.0000    1.0000    1.0000        62
                          Apple___Cedar_apple_rust     1.0000    1.0000    1.0000        28
                                   Apple___healthy     1.0000    1.0000    1.0000       165
                               Blueberry___healthy     1.0000    1.0000    1.0000       151
          Cherry_(including_sour)___Powdery_mildew     1.0000    1.0000    1.0000       106
                 Cherry_(including_sour)___healthy     1.0000    1.0000    1.0000        86
Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot     0.9600    0.9231    0.9412        52
                       Corn_(maize)___Common_rust_     0.9756    1.0000    0.9877       120
               Corn_(maize)___Northern_Leaf_Blight     0.9796    0.9697    0.9746        99
                            Corn_(maize)___healthy     1.0000    1.0000    1.0000       117
                                 Grape___Black_rot     1.0000    1.0000    1.0000       118
                      Grape___Esca_(Black_Measles)     1.0000    1.0000    1.0000       139
        Grape___Leaf_blight_(Isariopsis_Leaf_Spot)     1.0000    1.0000    1.0000       108
                                   Grape___healthy     1.0000    1.0000    1.0000        43
          Orange___Haunglongbing_(Citrus_greening)     1.0000    1.0000    1.0000       551
                            Peach___Bacterial_spot     0.9957    1.0000    0.9978       230
                                   Peach___healthy     1.0000    0.9722    0.9859        36
                     Pepper,_bell___Bacterial_spot     1.0000    1.0000    1.0000       100
                            Pepper,_bell___healthy     1.0000    1.0000    1.0000       148
                             Potato___Early_blight     1.0000    0.9900    0.9950       100
                              Potato___Late_blight     1.0000    1.0000    1.0000       100
                                  Potato___healthy     1.0000    1.0000    1.0000        16
                               Raspberry___healthy     1.0000    1.0000    1.0000        38
                                 Soybean___healthy     1.0000    1.0000    1.0000       509
                           Squash___Powdery_mildew     1.0000    1.0000    1.0000       184
                          Strawberry___Leaf_scorch     1.0000    1.0000    1.0000       111
                              Strawberry___healthy     1.0000    1.0000    1.0000        46
                           Tomato___Bacterial_spot     0.9816    1.0000    0.9907       213
                             Tomato___Early_blight     1.0000    0.9900    0.9950       100
                              Tomato___Late_blight     1.0000    0.9895    0.9947       191
                                Tomato___Leaf_Mold     1.0000    1.0000    1.0000        96
                       Tomato___Septoria_leaf_spot     0.9780    1.0000    0.9889       178
     Tomato___Spider_mites_Two-spotted_spider_mite     0.9941    1.0000    0.9970       168
                              Tomato___Target_Spot     1.0000    0.9858    0.9929       141
            Tomato___Tomato_Yellow_Leaf_Curl_Virus     1.0000    0.9944    0.9972       536
                      Tomato___Tomato_mosaic_virus     1.0000    1.0000    1.0000        38
                                  Tomato___healthy     1.0000    1.0000    1.0000       160

                                          accuracy                         0.9969      5447
                                         macro avg     0.9964    0.9951    0.9958      5447
                                      weighted avg     0.9969    0.9969    0.9969      5447

 Confusion matrix saved to: output/test/ConvNeXt+CBAM_PlantVillageSplited_depth_AUG/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+CBAM_PlantVillageSplited_depth_AUG/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+CBAM_PlantVillageSplited_depth_AUG/misclassified_images.png

✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: ConvNeXt+CBAM_Citrus_splited_depth_AUG]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
Epoch 1/50 | Time: 21.50s | Train Loss: 0.7235 | Val Loss: 0.5767 | Val Acc: 0.9060 | LR: 0.000100 
Saving best val acc: 0.9060
Epoch 2/50 | Time: 22.26s | Train Loss: 0.5019 | Val Loss: 0.7220 | Val Acc: 0.8462 | LR: 0.000100 
Epoch 3/50 | Time: 22.44s | Train Loss: 0.4563 | Val Loss: 0.5740 | Val Acc: 0.9231 | LR: 0.000100 
Saving best val acc: 0.9231
Epoch 4/50 | Time: 22.66s | Train Loss: 0.4250 | Val Loss: 0.5388 | Val Acc: 0.9060 | LR: 0.000099 
Saving best val acc: 0.9060
Epoch 5/50 | Time: 22.83s | Train Loss: 0.4062 | Val Loss: 0.5955 | Val Acc: 0.9060 | LR: 0.000098 
Epoch 6/50 | Time: 22.96s | Train Loss: 0.4095 | Val Loss: 0.5340 | Val Acc: 0.9316 | LR: 0.000098 
Saving best val acc: 0.9316
Epoch 7/50 | Time: 23.14s | Train Loss: 0.4014 | Val Loss: 0.5685 | Val Acc: 0.9145 | LR: 0.000097 
Epoch 8/50 | Time: 23.28s | Train Loss: 0.4017 | Val Loss: 0.5901 | Val Acc: 0.9145 | LR: 0.000095 
Epoch 9/50 | Time: 23.36s | Train Loss: 0.3877 | Val Loss: 0.5528 | Val Acc: 0.9060 | LR: 0.000094 
Epoch 10/50 | Time: 23.37s | Train Loss: 0.3943 | Val Loss: 0.5428 | Val Acc: 0.9316 | LR: 0.000092 
Epoch 11/50 | Time: 23.18s | Train Loss: 0.3944 | Val Loss: 0.5915 | Val Acc: 0.9060 | LR: 0.000091 
Epoch 12/50 | Time: 22.73s | Train Loss: 0.3949 | Val Loss: 0.5758 | Val Acc: 0.9145 | LR: 0.000089 
Epoch 13/50 | Time: 22.50s | Train Loss: 0.3838 | Val Loss: 0.5640 | Val Acc: 0.9145 | LR: 0.000087 
Epoch 14/50 | Time: 22.35s | Train Loss: 0.3913 | Val Loss: 0.5743 | Val Acc: 0.9145 | LR: 0.000084 
Epoch 15/50 | Time: 22.34s | Train Loss: 0.3739 | Val Loss: 0.5710 | Val Acc: 0.9145 | LR: 0.000082 
Epoch 16/50 | Time: 22.53s | Train Loss: 0.3907 | Val Loss: 0.6162 | Val Acc: 0.9145 | LR: 0.000080 
Early stopping triggered.
Training complete in 363.50 seconds. Best model loaded.
Model saved to ./output/models/ConvNeXt+CBAM_Citrus_splited_depth_AUG.pth
 Training metrics plot saved to: output/test/ConvNeXt+CBAM_Citrus_splited_depth_AUG/training metric.png
Evaluate model:ConvNeXt+CBAM_Citrus_splited_depth_AUG

 Test Accuracy: 98.44%

 Classification Report:
              precision    recall  f1-score   support

  Black spot     0.9474    1.0000    0.9730        18
      canker     1.0000    1.0000    1.0000        17
    greening     1.0000    0.9545    0.9767        22
     healthy     1.0000    1.0000    1.0000         7

    accuracy                         0.9844        64
   macro avg     0.9868    0.9886    0.9874        64
weighted avg     0.9852    0.9844    0.9844        64

 Confusion matrix saved to: output/test/ConvNeXt+CBAM_Citrus_splited_depth_AUG/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+CBAM_Citrus_splited_depth_AUG/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+CBAM_Citrus_splited_depth_AUG/misclassified_images.png
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: ConvNeXt+Potato_splited]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
Epoch 1/50 | Time: 154.32s | Train Loss: 1.1286 | Val Loss: 0.9526 | Val Acc: 0.7892 | LR: 0.000100 
Saving best val acc: 0.7892
Epoch 2/50 | Time: 93.29s | Train Loss: 0.7054 | Val Loss: 0.7752 | Val Acc: 0.8562 | LR: 0.000100 
Saving best val acc: 0.8562
Epoch 3/50 | Time: 92.91s | Train Loss: 0.5897 | Val Loss: 0.7659 | Val Acc: 0.8644 | LR: 0.000100 
Saving best val acc: 0.8644
Epoch 4/50 | Time: 94.57s | Train Loss: 0.5383 | Val Loss: 0.6954 | Val Acc: 0.8856 | LR: 0.000099 
Saving best val acc: 0.8856
Epoch 5/50 | Time: 92.32s | Train Loss: 0.5120 | Val Loss: 0.6998 | Val Acc: 0.8824 | LR: 0.000098 
Epoch 6/50 | Time: 92.54s | Train Loss: 0.4869 | Val Loss: 0.6786 | Val Acc: 0.8971 | LR: 0.000098 
Saving best val acc: 0.8971
Epoch 7/50 | Time: 94.08s | Train Loss: 0.4722 | Val Loss: 0.7286 | Val Acc: 0.8807 | LR: 0.000097 
Epoch 8/50 | Time: 93.21s | Train Loss: 0.4781 | Val Loss: 0.7263 | Val Acc: 0.8856 | LR: 0.000095 
Epoch 9/50 | Time: 93.76s | Train Loss: 0.4799 | Val Loss: 0.7564 | Val Acc: 0.8725 | LR: 0.000094 
Epoch 10/50 | Time: 93.62s | Train Loss: 0.4651 | Val Loss: 0.7239 | Val Acc: 0.8987 | LR: 0.000092 
Epoch 11/50 | Time: 93.60s | Train Loss: 0.4666 | Val Loss: 0.7188 | Val Acc: 0.8873 | LR: 0.000091 
Epoch 12/50 | Time: 93.80s | Train Loss: 0.4702 | Val Loss: 0.7946 | Val Acc: 0.8513 | LR: 0.000089 
Epoch 13/50 | Time: 94.35s | Train Loss: 0.4847 | Val Loss: 0.7300 | Val Acc: 0.8938 | LR: 0.000087 
Epoch 14/50 | Time: 94.19s | Train Loss: 0.4726 | Val Loss: 0.7528 | Val Acc: 0.8775 | LR: 0.000084 
Epoch 15/50 | Time: 94.08s | Train Loss: 0.4856 | Val Loss: 0.7486 | Val Acc: 0.8758 | LR: 0.000082 
Epoch 16/50 | Time: 94.42s | Train Loss: 0.4605 | Val Loss: 0.7412 | Val Acc: 0.8824 | LR: 0.000080 
Early stopping triggered.
Training complete in 1559.15 seconds. Best model loaded.
Model saved to ./output/models/ConvNeXt+Potato_splited.pth
 Training metrics plot saved to: output/test/ConvNeXt+Potato_splited/training metric.png
Evaluate model:ConvNeXt+Potato_splited

 Test Accuracy: 88.57%

 Classification Report:
              precision    recall  f1-score   support

    Bacteria     0.9500    0.9828    0.9661        58
       Fungi     0.9143    0.8421    0.8767        76
     Healthy     0.9500    0.9048    0.9268        21
    Nematode     0.8000    1.0000    0.8889         8
        Pest     0.7971    0.8871    0.8397        62
 Phytopthora     0.8710    0.7500    0.8060        36
       Virus     0.8909    0.9074    0.8991        54

    accuracy                         0.8857       315
   macro avg     0.8819    0.8963    0.8862       315
weighted avg     0.8883    0.8857    0.8853       315

 Confusion matrix saved to: output/test/ConvNeXt+Potato_splited/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+Potato_splited/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+Potato_splited/misclassified_images.png
✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔[NEW LOG: ConvNeXt+CBAM+Potato_splited]✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔✔
Epoch 1/50 | Time: 141.29s | Train Loss: 0.9998 | Val Loss: 0.9248 | Val Acc: 0.8007 | LR: 0.000100 
Saving best model: 0.8007
Epoch 2/50 | Time: 102.85s | Train Loss: 0.6977 | Val Loss: 0.8287 | Val Acc: 0.8333 | LR: 0.000100 
Saving best model: 0.8333
Epoch 3/50 | Time: 102.70s | Train Loss: 0.6137 | Val Loss: 0.7582 | Val Acc: 0.8676 | LR: 0.000100 
Saving best model: 0.8676
Epoch 4/50 | Time: 103.28s | Train Loss: 0.5628 | Val Loss: 0.7409 | Val Acc: 0.8709 | LR: 0.000099 
Saving best model: 0.8709
Epoch 5/50 | Time: 103.72s | Train Loss: 0.5329 | Val Loss: 0.7150 | Val Acc: 0.8905 | LR: 0.000098 
Saving best model: 0.8905
Epoch 6/50 | Time: 103.64s | Train Loss: 0.5311 | Val Loss: 0.6873 | Val Acc: 0.8938 | LR: 0.000098 
Saving best model: 0.8938
Epoch 7/50 | Time: 103.42s | Train Loss: 0.5075 | Val Loss: 0.8023 | Val Acc: 0.8725 | LR: 0.000097 
Epoch 8/50 | Time: 103.21s | Train Loss: 0.5086 | Val Loss: 0.7226 | Val Acc: 0.8840 | LR: 0.000095 
Epoch 9/50 | Time: 103.14s | Train Loss: 0.4907 | Val Loss: 0.7537 | Val Acc: 0.8709 | LR: 0.000094 
Epoch 10/50 | Time: 103.94s | Train Loss: 0.4963 | Val Loss: 0.7451 | Val Acc: 0.8824 | LR: 0.000092 
Epoch 11/50 | Time: 103.25s | Train Loss: 0.4935 | Val Loss: 0.7687 | Val Acc: 0.8775 | LR: 0.000091 
Epoch 12/50 | Time: 103.43s | Train Loss: 0.4889 | Val Loss: 0.8965 | Val Acc: 0.8235 | LR: 0.000089 
Epoch 13/50 | Time: 104.21s | Train Loss: 0.4817 | Val Loss: 0.7754 | Val Acc: 0.8627 | LR: 0.000087 
Epoch 14/50 | Time: 103.41s | Train Loss: 0.4768 | Val Loss: 0.7417 | Val Acc: 0.8791 | LR: 0.000084 
Epoch 15/50 | Time: 104.08s | Train Loss: 0.4804 | Val Loss: 0.8960 | Val Acc: 0.8448 | LR: 0.000082 
Epoch 16/50 | Time: 102.94s | Train Loss: 0.4907 | Val Loss: 0.7850 | Val Acc: 0.8693 | LR: 0.000080 
Early stopping triggered.
Training complete in 1692.63 seconds.
Model saved

Evaluate model:ConvNeXt+CBAM+Potato_splited

 Test Accuracy: 88.89%

 Classification Report:
              precision    recall  f1-score   support

    Bacteria     0.9333    0.9655    0.9492        58
       Fungi     0.8293    0.8947    0.8608        76
     Healthy     1.0000    0.7619    0.8649        21
    Nematode     0.8000    1.0000    0.8889         8
        Pest     0.8462    0.8871    0.8661        62
 Phytopthora     0.9643    0.7500    0.8438        36
       Virus     0.9259    0.9259    0.9259        54

    accuracy                         0.8889       315
   macro avg     0.8999    0.8836    0.8856       315
weighted avg     0.8944    0.8889    0.8883       315

 Confusion matrix saved
Saved gradCAM images
Saved misclassified images
