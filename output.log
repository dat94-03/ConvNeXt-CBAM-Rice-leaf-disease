âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: ConvNeXt+3cbam+norm+dataset1]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
ğŸ•’ Epoch 1/100 | Time: 74.19s | Train Loss: 0.8288 | Val Loss: 0.5507 | Val Acc: 0.9629 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9629
ğŸ•’ Epoch 2/100 | Time: 74.05s | Train Loss: 0.5193 | Val Loss: 0.4932 | Val Acc: 0.9759 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9759
ğŸ•’ Epoch 3/100 | Time: 74.20s | Train Loss: 0.4722 | Val Loss: 0.4772 | Val Acc: 0.9796 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9796
ğŸ•’ Epoch 4/100 | Time: 73.70s | Train Loss: 0.4599 | Val Loss: 0.5030 | Val Acc: 0.9703 | LR: 0.000099 
ğŸ•’ Epoch 5/100 | Time: 74.19s | Train Loss: 0.4609 | Val Loss: 0.4696 | Val Acc: 0.9796 | LR: 0.000098 
ğŸ’¾ Saving best val acc: 0.9796
ğŸ•’ Epoch 6/100 | Time: 74.44s | Train Loss: 0.4482 | Val Loss: 0.4770 | Val Acc: 0.9777 | LR: 0.000098 
ğŸ•’ Epoch 7/100 | Time: 74.30s | Train Loss: 0.4415 | Val Loss: 0.4564 | Val Acc: 0.9833 | LR: 0.000097 
ğŸ’¾ Saving best val acc: 0.9833
ğŸ•’ Epoch 8/100 | Time: 74.44s | Train Loss: 0.4328 | Val Loss: 0.4801 | Val Acc: 0.9740 | LR: 0.000095 
ğŸ•’ Epoch 9/100 | Time: 74.47s | Train Loss: 0.4721 | Val Loss: 0.4795 | Val Acc: 0.9777 | LR: 0.000094 
ğŸ•’ Epoch 10/100 | Time: 74.02s | Train Loss: 0.4377 | Val Loss: 0.4789 | Val Acc: 0.9833 | LR: 0.000092 
ğŸ•’ Epoch 11/100 | Time: 74.68s | Train Loss: 0.4317 | Val Loss: 0.4711 | Val Acc: 0.9833 | LR: 0.000091 
ğŸ•’ Epoch 12/100 | Time: 74.76s | Train Loss: 0.4328 | Val Loss: 0.4643 | Val Acc: 0.9814 | LR: 0.000089 
ğŸ•’ Epoch 13/100 | Time: 74.62s | Train Loss: 0.4315 | Val Loss: 0.4634 | Val Acc: 0.9852 | LR: 0.000087 
ğŸ•’ Epoch 14/100 | Time: 74.77s | Train Loss: 0.4355 | Val Loss: 0.4788 | Val Acc: 0.9814 | LR: 0.000084 
ğŸ•’ Epoch 15/100 | Time: 75.28s | Train Loss: 0.4357 | Val Loss: 0.4824 | Val Acc: 0.9814 | LR: 0.000082 
ğŸ•’ Epoch 16/100 | Time: 74.63s | Train Loss: 0.4335 | Val Loss: 0.4985 | Val Acc: 0.9722 | LR: 0.000080 
ğŸ•’ Epoch 17/100 | Time: 74.88s | Train Loss: 0.4305 | Val Loss: 0.4638 | Val Acc: 0.9833 | LR: 0.000077 
â¹ï¸ Early stopping triggered.
âœ… Training complete in 1265.72 seconds. Best model loaded.
ğŸ“ Model saved to ./output/models/ConvNeXt+3cbam+norm+dataset1+dataset1.pth
ğŸ“‚ Training metrics plot saved to: output/test/ConvNeXt+3cbam+norm+dataset1/training metric.png

Evaluate model:ConvNeXt+3cbam+norm+dataset1

ğŸ”¥ Test Accuracy: 97.99%

ğŸ“Œ Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    0.9775    0.9886        89
           brown_spot     0.9775    0.9255    0.9508        94
              healthy     0.9792    1.0000    0.9895        94
           leaf_blast     0.9278    0.9783    0.9524        92
           leaf_scald     1.0000    1.0000    1.0000        91
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9799       548
            macro avg     0.9808    0.9802    0.9802       548
         weighted avg     0.9805    0.9799    0.9799       548

ğŸ“‚ Confusion matrix saved to: output/test/ConvNeXt+3cbam+norm+dataset1/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+3cbam+norm+dataset1/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+3cbam+norm+dataset1/misclassified_images.png
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: ConvNeXt+dataset1]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
ğŸ•’ Epoch 1/100 | Time: 73.84s | Train Loss: 0.7870 | Val Loss: 0.5196 | Val Acc: 0.9666 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9666
ğŸ•’ Epoch 2/100 | Time: 74.33s | Train Loss: 0.5057 | Val Loss: 0.5590 | Val Acc: 0.9703 | LR: 0.000100 
ğŸ•’ Epoch 3/100 | Time: 74.16s | Train Loss: 0.4852 | Val Loss: 0.4982 | Val Acc: 0.9722 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9722
ğŸ•’ Epoch 4/100 | Time: 74.25s | Train Loss: 0.4643 | Val Loss: 0.4728 | Val Acc: 0.9814 | LR: 0.000099 
ğŸ’¾ Saving best val acc: 0.9814
ğŸ•’ Epoch 5/100 | Time: 74.46s | Train Loss: 0.4486 | Val Loss: 0.4796 | Val Acc: 0.9759 | LR: 0.000098 
ğŸ•’ Epoch 6/100 | Time: 73.96s | Train Loss: 0.4468 | Val Loss: 0.4765 | Val Acc: 0.9777 | LR: 0.000098 
ğŸ•’ Epoch 7/100 | Time: 75.54s | Train Loss: 0.4447 | Val Loss: 0.4871 | Val Acc: 0.9759 | LR: 0.000097 
ğŸ•’ Epoch 8/100 | Time: 74.62s | Train Loss: 0.4480 | Val Loss: 0.4914 | Val Acc: 0.9722 | LR: 0.000095 
ğŸ•’ Epoch 9/100 | Time: 75.40s | Train Loss: 0.4426 | Val Loss: 0.4652 | Val Acc: 0.9852 | LR: 0.000094 
ğŸ’¾ Saving best val acc: 0.9852
ğŸ•’ Epoch 10/100 | Time: 75.88s | Train Loss: 0.4340 | Val Loss: 0.4625 | Val Acc: 0.9833 | LR: 0.000092 
ğŸ’¾ Saving best val acc: 0.9833
ğŸ•’ Epoch 11/100 | Time: 74.76s | Train Loss: 0.4340 | Val Loss: 0.4649 | Val Acc: 0.9870 | LR: 0.000091 
ğŸ•’ Epoch 12/100 | Time: 74.81s | Train Loss: 0.4303 | Val Loss: 0.4562 | Val Acc: 0.9870 | LR: 0.000089 
ğŸ’¾ Saving best val acc: 0.9870
ğŸ•’ Epoch 13/100 | Time: 74.29s | Train Loss: 0.4275 | Val Loss: 0.4609 | Val Acc: 0.9889 | LR: 0.000087 
ğŸ•’ Epoch 14/100 | Time: 74.81s | Train Loss: 0.4251 | Val Loss: 0.4421 | Val Acc: 0.9926 | LR: 0.000084 
ğŸ’¾ Saving best val acc: 0.9926
ğŸ•’ Epoch 15/100 | Time: 74.63s | Train Loss: 0.4276 | Val Loss: 0.4647 | Val Acc: 0.9852 | LR: 0.000082 
ğŸ•’ Epoch 16/100 | Time: 74.27s | Train Loss: 0.4268 | Val Loss: 0.4508 | Val Acc: 0.9907 | LR: 0.000080 
ğŸ•’ Epoch 17/100 | Time: 73.58s | Train Loss: 0.4253 | Val Loss: 0.4701 | Val Acc: 0.9814 | LR: 0.000077 
ğŸ•’ Epoch 18/100 | Time: 73.78s | Train Loss: 0.4276 | Val Loss: 0.4542 | Val Acc: 0.9870 | LR: 0.000074 
ğŸ•’ Epoch 19/100 | Time: 74.25s | Train Loss: 0.4257 | Val Loss: 0.4605 | Val Acc: 0.9889 | LR: 0.000072 
ğŸ•’ Epoch 20/100 | Time: 74.33s | Train Loss: 0.4263 | Val Loss: 0.4458 | Val Acc: 0.9889 | LR: 0.000069 
ğŸ•’ Epoch 21/100 | Time: 74.65s | Train Loss: 0.4307 | Val Loss: 0.4590 | Val Acc: 0.9889 | LR: 0.000066 
ğŸ•’ Epoch 22/100 | Time: 73.70s | Train Loss: 0.4283 | Val Loss: 0.4547 | Val Acc: 0.9889 | LR: 0.000063 
ğŸ•’ Epoch 23/100 | Time: 74.05s | Train Loss: 0.4367 | Val Loss: 0.4554 | Val Acc: 0.9870 | LR: 0.000060 
ğŸ•’ Epoch 24/100 | Time: 74.80s | Train Loss: 0.4323 | Val Loss: 0.4545 | Val Acc: 0.9889 | LR: 0.000057 
â¹ï¸ Early stopping triggered.
âœ… Training complete in 1787.29 seconds. Best model loaded.
ğŸ“ Model saved to ./output/models/ConvNeXt+dataset1+dataset1.pth
ğŸ“‚ Training metrics plot saved to: output/test/ConvNeXt+dataset1/training metric.png
Evaluate model:ConvNeXt+dataset1

ğŸ”¥ Test Accuracy: 98.36%

ğŸ“Œ Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    1.0000    1.0000        89
           brown_spot     0.9474    0.9574    0.9524        94
              healthy     1.0000    1.0000    1.0000        94
           leaf_blast     0.9560    0.9457    0.9508        92
           leaf_scald     1.0000    1.0000    1.0000        91
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9836       548
            macro avg     0.9839    0.9838    0.9839       548
         weighted avg     0.9836    0.9836    0.9836       548

ğŸ“‚ Confusion matrix saved to: output/test/ConvNeXt+dataset1/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+dataset1/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+dataset1/misclassified_images.png

âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: ConvNeXt+3cbam+norn+dataset21]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
ğŸ•’ Epoch 1/100 | Time: 70.12s | Train Loss: 0.7757 | Val Loss: 0.5315 | Val Acc: 0.9540 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9540
ğŸ•’ Epoch 2/100 | Time: 70.85s | Train Loss: 0.5146 | Val Loss: 0.5034 | Val Acc: 0.9761 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9761
ğŸ•’ Epoch 3/100 | Time: 70.38s | Train Loss: 0.4625 | Val Loss: 0.4770 | Val Acc: 0.9761 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9761
ğŸ•’ Epoch 4/100 | Time: 70.65s | Train Loss: 0.4528 | Val Loss: 0.4786 | Val Acc: 0.9798 | LR: 0.000099 
ğŸ•’ Epoch 5/100 | Time: 69.93s | Train Loss: 0.4649 | Val Loss: 0.4843 | Val Acc: 0.9761 | LR: 0.000098 
ğŸ•’ Epoch 6/100 | Time: 70.88s | Train Loss: 0.4613 | Val Loss: 0.4827 | Val Acc: 0.9779 | LR: 0.000098 
ğŸ•’ Epoch 7/100 | Time: 70.00s | Train Loss: 0.4640 | Val Loss: 0.5023 | Val Acc: 0.9596 | LR: 0.000097 
ğŸ•’ Epoch 8/100 | Time: 71.23s | Train Loss: 0.4462 | Val Loss: 0.4746 | Val Acc: 0.9798 | LR: 0.000095 
ğŸ’¾ Saving best val acc: 0.9798
ğŸ•’ Epoch 9/100 | Time: 70.39s | Train Loss: 0.4391 | Val Loss: 0.4815 | Val Acc: 0.9761 | LR: 0.000094 
ğŸ•’ Epoch 10/100 | Time: 70.96s | Train Loss: 0.4336 | Val Loss: 0.4793 | Val Acc: 0.9798 | LR: 0.000092 
ğŸ•’ Epoch 11/100 | Time: 70.38s | Train Loss: 0.4289 | Val Loss: 0.4661 | Val Acc: 0.9816 | LR: 0.000091 
ğŸ’¾ Saving best val acc: 0.9816
ğŸ•’ Epoch 12/100 | Time: 97.33s | Train Loss: 0.4269 | Val Loss: 0.4729 | Val Acc: 0.9835 | LR: 0.000089 
ğŸ•’ Epoch 13/100 | Time: 88.32s | Train Loss: 0.4306 | Val Loss: 0.4780 | Val Acc: 0.9798 | LR: 0.000087 
ğŸ•’ Epoch 14/100 | Time: 71.94s | Train Loss: 0.4280 | Val Loss: 0.4692 | Val Acc: 0.9835 | LR: 0.000084 
ğŸ•’ Epoch 15/100 | Time: 71.08s | Train Loss: 0.4256 | Val Loss: 0.4732 | Val Acc: 0.9816 | LR: 0.000082 
ğŸ•’ Epoch 16/100 | Time: 71.11s | Train Loss: 0.4269 | Val Loss: 0.4802 | Val Acc: 0.9798 | LR: 0.000080 
ğŸ•’ Epoch 17/100 | Time: 71.08s | Train Loss: 0.4349 | Val Loss: 0.4859 | Val Acc: 0.9761 | LR: 0.000077 
ğŸ•’ Epoch 18/100 | Time: 71.80s | Train Loss: 0.4447 | Val Loss: 0.5840 | Val Acc: 0.9467 | LR: 0.000074 
ğŸ•’ Epoch 19/100 | Time: 71.03s | Train Loss: 0.4704 | Val Loss: 0.4755 | Val Acc: 0.9798 | LR: 0.000072 
ğŸ•’ Epoch 20/100 | Time: 71.01s | Train Loss: 0.4338 | Val Loss: 0.4752 | Val Acc: 0.9798 | LR: 0.000069 
ğŸ•’ Epoch 21/100 | Time: 71.59s | Train Loss: 0.4291 | Val Loss: 0.4615 | Val Acc: 0.9853 | LR: 0.000066 
ğŸ’¾ Saving best val acc: 0.9853
ğŸ•’ Epoch 22/100 | Time: 71.42s | Train Loss: 0.4290 | Val Loss: 0.4604 | Val Acc: 0.9890 | LR: 0.000063 
ğŸ’¾ Saving best val acc: 0.9890
ğŸ•’ Epoch 23/100 | Time: 71.13s | Train Loss: 0.4269 | Val Loss: 0.4594 | Val Acc: 0.9871 | LR: 0.000060 
ğŸ’¾ Saving best val acc: 0.9871
ğŸ•’ Epoch 24/100 | Time: 70.17s | Train Loss: 0.4262 | Val Loss: 0.4880 | Val Acc: 0.9798 | LR: 0.000057 
ğŸ•’ Epoch 25/100 | Time: 71.17s | Train Loss: 0.4231 | Val Loss: 0.4806 | Val Acc: 0.9816 | LR: 0.000054 
ğŸ•’ Epoch 26/100 | Time: 70.73s | Train Loss: 0.4236 | Val Loss: 0.4792 | Val Acc: 0.9816 | LR: 0.000050 
ğŸ•’ Epoch 27/100 | Time: 71.48s | Train Loss: 0.4232 | Val Loss: 0.4720 | Val Acc: 0.9779 | LR: 0.000047 
ğŸ•’ Epoch 28/100 | Time: 70.82s | Train Loss: 0.4258 | Val Loss: 0.4595 | Val Acc: 0.9871 | LR: 0.000044 
ğŸ•’ Epoch 29/100 | Time: 71.72s | Train Loss: 0.4226 | Val Loss: 0.4609 | Val Acc: 0.9871 | LR: 0.000041 
ğŸ•’ Epoch 30/100 | Time: 72.55s | Train Loss: 0.4228 | Val Loss: 0.4609 | Val Acc: 0.9871 | LR: 0.000038 
ğŸ•’ Epoch 31/100 | Time: 70.84s | Train Loss: 0.4225 | Val Loss: 0.4655 | Val Acc: 0.9871 | LR: 0.000035 
ğŸ•’ Epoch 32/100 | Time: 70.95s | Train Loss: 0.4220 | Val Loss: 0.4638 | Val Acc: 0.9871 | LR: 0.000032 
ğŸ•’ Epoch 33/100 | Time: 70.75s | Train Loss: 0.4217 | Val Loss: 0.4641 | Val Acc: 0.9853 | LR: 0.000029 
â¹ï¸ Early stopping triggered.
âœ… Training complete in 2385.95 seconds. Best model loaded.
ğŸ“ Model saved to ./output/models/ConvNeXt+3cbam+norn+dataset21+dataset21.pth
ğŸ“‚ Training metrics plot saved to: output/test/ConvNeXt+3cbam+norn+dataset21/training metric.png
Evaluate model:ConvNeXt+3cbam+norn+dataset21

ğŸ”¥ Test Accuracy: 98.53%

ğŸ“Œ Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    1.0000    1.0000        88
           brown_spot     0.9474    0.9677    0.9574        93
              healthy     0.9894    1.0000    0.9947        93
           leaf_blast     0.9773    0.9451    0.9609        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9853       543
            macro avg     0.9857    0.9855    0.9855       543
         weighted avg     0.9854    0.9853    0.9852       543

ğŸ“‚ Confusion matrix saved to: output/test/ConvNeXt+3cbam+norn+dataset21/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+3cbam+norn+dataset21/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+3cbam+norn+dataset21/misclassified_images.png
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: ConvNeXt+dataset21]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
ğŸ•’ Epoch 1/100 | Time: 79.92s | Train Loss: 0.7694 | Val Loss: 0.5436 | Val Acc: 0.9596 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9596
ğŸ•’ Epoch 2/100 | Time: 69.36s | Train Loss: 0.4981 | Val Loss: 0.5127 | Val Acc: 0.9724 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9724
ğŸ•’ Epoch 3/100 | Time: 69.61s | Train Loss: 0.4783 | Val Loss: 0.4962 | Val Acc: 0.9706 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9706
ğŸ•’ Epoch 4/100 | Time: 69.99s | Train Loss: 0.4643 | Val Loss: 0.4940 | Val Acc: 0.9706 | LR: 0.000099 
ğŸ’¾ Saving best val acc: 0.9706
ğŸ•’ Epoch 5/100 | Time: 69.81s | Train Loss: 0.4489 | Val Loss: 0.4843 | Val Acc: 0.9798 | LR: 0.000098 
ğŸ’¾ Saving best val acc: 0.9798
ğŸ•’ Epoch 6/100 | Time: 70.70s | Train Loss: 0.4463 | Val Loss: 0.4610 | Val Acc: 0.9871 | LR: 0.000098 
ğŸ’¾ Saving best val acc: 0.9871
ğŸ•’ Epoch 7/100 | Time: 70.98s | Train Loss: 0.4421 | Val Loss: 0.4706 | Val Acc: 0.9779 | LR: 0.000097 
ğŸ•’ Epoch 8/100 | Time: 70.11s | Train Loss: 0.4311 | Val Loss: 0.4648 | Val Acc: 0.9871 | LR: 0.000095 
ğŸ•’ Epoch 9/100 | Time: 69.94s | Train Loss: 0.4333 | Val Loss: 0.4582 | Val Acc: 0.9890 | LR: 0.000094 
ğŸ’¾ Saving best val acc: 0.9890
ğŸ•’ Epoch 10/100 | Time: 70.45s | Train Loss: 0.4300 | Val Loss: 0.4680 | Val Acc: 0.9835 | LR: 0.000092 
ğŸ•’ Epoch 11/100 | Time: 69.07s | Train Loss: 0.4299 | Val Loss: 0.4756 | Val Acc: 0.9761 | LR: 0.000091 
ğŸ•’ Epoch 12/100 | Time: 70.38s | Train Loss: 0.4412 | Val Loss: 0.4787 | Val Acc: 0.9743 | LR: 0.000089 
ğŸ•’ Epoch 13/100 | Time: 69.82s | Train Loss: 0.4485 | Val Loss: 0.4665 | Val Acc: 0.9871 | LR: 0.000087 
ğŸ•’ Epoch 14/100 | Time: 70.11s | Train Loss: 0.4280 | Val Loss: 0.4611 | Val Acc: 0.9871 | LR: 0.000084 
ğŸ•’ Epoch 15/100 | Time: 69.68s | Train Loss: 0.4322 | Val Loss: 0.5030 | Val Acc: 0.9669 | LR: 0.000082 
ğŸ•’ Epoch 16/100 | Time: 70.87s | Train Loss: 0.4439 | Val Loss: 0.5460 | Val Acc: 0.9577 | LR: 0.000080 
ğŸ•’ Epoch 17/100 | Time: 69.83s | Train Loss: 0.4581 | Val Loss: 0.4589 | Val Acc: 0.9816 | LR: 0.000077 
ğŸ•’ Epoch 18/100 | Time: 70.68s | Train Loss: 0.4315 | Val Loss: 0.4705 | Val Acc: 0.9816 | LR: 0.000074 
ğŸ•’ Epoch 19/100 | Time: 69.90s | Train Loss: 0.4233 | Val Loss: 0.4515 | Val Acc: 0.9853 | LR: 0.000072 
ğŸ’¾ Saving best val acc: 0.9853
ğŸ•’ Epoch 20/100 | Time: 70.68s | Train Loss: 0.4309 | Val Loss: 0.4887 | Val Acc: 0.9779 | LR: 0.000069 
ğŸ•’ Epoch 21/100 | Time: 70.12s | Train Loss: 0.4573 | Val Loss: 0.4671 | Val Acc: 0.9871 | LR: 0.000066 
ğŸ•’ Epoch 22/100 | Time: 70.14s | Train Loss: 0.4263 | Val Loss: 0.4556 | Val Acc: 0.9853 | LR: 0.000063 
ğŸ•’ Epoch 23/100 | Time: 69.61s | Train Loss: 0.4242 | Val Loss: 0.4538 | Val Acc: 0.9871 | LR: 0.000060 
ğŸ•’ Epoch 24/100 | Time: 70.83s | Train Loss: 0.4248 | Val Loss: 0.4562 | Val Acc: 0.9853 | LR: 0.000057 
ğŸ•’ Epoch 25/100 | Time: 69.98s | Train Loss: 0.4228 | Val Loss: 0.4586 | Val Acc: 0.9816 | LR: 0.000054 
ğŸ•’ Epoch 26/100 | Time: 70.64s | Train Loss: 0.4237 | Val Loss: 0.4528 | Val Acc: 0.9835 | LR: 0.000050 
ğŸ•’ Epoch 27/100 | Time: 70.08s | Train Loss: 0.4220 | Val Loss: 0.4504 | Val Acc: 0.9871 | LR: 0.000047 
ğŸ’¾ Saving best val acc: 0.9871
ğŸ•’ Epoch 28/100 | Time: 70.56s | Train Loss: 0.4227 | Val Loss: 0.4825 | Val Acc: 0.9706 | LR: 0.000044 
ğŸ•’ Epoch 29/100 | Time: 69.64s | Train Loss: 0.4258 | Val Loss: 0.4492 | Val Acc: 0.9871 | LR: 0.000041 
ğŸ’¾ Saving best val acc: 0.9871
ğŸ•’ Epoch 30/100 | Time: 70.41s | Train Loss: 0.4221 | Val Loss: 0.4514 | Val Acc: 0.9871 | LR: 0.000038 
ğŸ•’ Epoch 31/100 | Time: 69.54s | Train Loss: 0.4216 | Val Loss: 0.4524 | Val Acc: 0.9871 | LR: 0.000035 
ğŸ•’ Epoch 32/100 | Time: 69.11s | Train Loss: 0.4255 | Val Loss: 0.4622 | Val Acc: 0.9798 | LR: 0.000032 
ğŸ•’ Epoch 33/100 | Time: 70.07s | Train Loss: 0.4221 | Val Loss: 0.4498 | Val Acc: 0.9871 | LR: 0.000029 
ğŸ•’ Epoch 34/100 | Time: 69.92s | Train Loss: 0.4219 | Val Loss: 0.4546 | Val Acc: 0.9853 | LR: 0.000027 
ğŸ•’ Epoch 35/100 | Time: 69.83s | Train Loss: 0.4215 | Val Loss: 0.4556 | Val Acc: 0.9853 | LR: 0.000024 
ğŸ•’ Epoch 36/100 | Time: 69.27s | Train Loss: 0.4222 | Val Loss: 0.4482 | Val Acc: 0.9871 | LR: 0.000021 
ğŸ’¾ Saving best val acc: 0.9871
ğŸ•’ Epoch 37/100 | Time: 70.97s | Train Loss: 0.4214 | Val Loss: 0.4479 | Val Acc: 0.9890 | LR: 0.000019 
ğŸ’¾ Saving best val acc: 0.9890
ğŸ•’ Epoch 38/100 | Time: 70.77s | Train Loss: 0.4229 | Val Loss: 0.4562 | Val Acc: 0.9871 | LR: 0.000017 
ğŸ•’ Epoch 39/100 | Time: 70.89s | Train Loss: 0.4218 | Val Loss: 0.4558 | Val Acc: 0.9871 | LR: 0.000014 
ğŸ•’ Epoch 40/100 | Time: 70.32s | Train Loss: 0.4214 | Val Loss: 0.4555 | Val Acc: 0.9871 | LR: 0.000012 
ğŸ•’ Epoch 41/100 | Time: 71.13s | Train Loss: 0.4213 | Val Loss: 0.4553 | Val Acc: 0.9871 | LR: 0.000010 
ğŸ•’ Epoch 42/100 | Time: 71.45s | Train Loss: 0.4213 | Val Loss: 0.4548 | Val Acc: 0.9871 | LR: 0.000009 
ğŸ•’ Epoch 43/100 | Time: 70.45s | Train Loss: 0.4213 | Val Loss: 0.4546 | Val Acc: 0.9871 | LR: 0.000007 
ğŸ•’ Epoch 44/100 | Time: 71.29s | Train Loss: 0.4216 | Val Loss: 0.4548 | Val Acc: 0.9871 | LR: 0.000006 
ğŸ•’ Epoch 45/100 | Time: 70.07s | Train Loss: 0.4213 | Val Loss: 0.4545 | Val Acc: 0.9871 | LR: 0.000004 
ğŸ•’ Epoch 46/100 | Time: 71.20s | Train Loss: 0.4213 | Val Loss: 0.4546 | Val Acc: 0.9871 | LR: 0.000003 
ğŸ•’ Epoch 47/100 | Time: 70.86s | Train Loss: 0.4226 | Val Loss: 0.4547 | Val Acc: 0.9871 | LR: 0.000003 
â¹ï¸ Early stopping triggered.
âœ… Training complete in 3311.26 seconds. Best model loaded.
ğŸ“ Model saved to ./output/models/ConvNeXt+dataset21+dataset21.pth
ğŸ“‚ Training metrics plot saved to: output/test/ConvNeXt+dataset21/training metric.png
Evaluate model:ConvNeXt+dataset21

ğŸ”¥ Test Accuracy: 98.53%

ğŸ“Œ Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    0.9886    0.9943        88
           brown_spot     0.9677    0.9677    0.9677        93
              healthy     0.9787    0.9892    0.9840        93
           leaf_blast     0.9670    0.9670    0.9670        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9853       543
            macro avg     0.9856    0.9854    0.9855       543
         weighted avg     0.9853    0.9853    0.9853       543

ğŸ“‚ Confusion matrix saved to: output/test/ConvNeXt+dataset21/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+dataset21/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+dataset21/misclassified_images.png

âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: ConvNeXt+dataset21]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
ğŸ•’ Epoch 1/100 | Time: 150.91s | Train Loss: 0.7430 | Val Loss: 0.5240 | Val Acc: 0.9577 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9577
ğŸ•’ Epoch 2/100 | Time: 108.86s | Train Loss: 0.5114 | Val Loss: 0.5314 | Val Acc: 0.9430 | LR: 0.000100 
ğŸ•’ Epoch 3/100 | Time: 112.93s | Train Loss: 0.4781 | Val Loss: 0.4912 | Val Acc: 0.9743 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9743
ğŸ•’ Epoch 4/100 | Time: 109.01s | Train Loss: 0.4844 | Val Loss: 0.5197 | Val Acc: 0.9706 | LR: 0.000099 
ğŸ•’ Epoch 5/100 | Time: 108.21s | Train Loss: 0.4582 | Val Loss: 0.5042 | Val Acc: 0.9614 | LR: 0.000098 
ğŸ•’ Epoch 6/100 | Time: 108.60s | Train Loss: 0.4533 | Val Loss: 0.4682 | Val Acc: 0.9816 | LR: 0.000098 
ğŸ’¾ Saving best val acc: 0.9816
ğŸ•’ Epoch 7/100 | Time: 108.67s | Train Loss: 0.4454 | Val Loss: 0.4903 | Val Acc: 0.9651 | LR: 0.000097 
ğŸ•’ Epoch 8/100 | Time: 109.50s | Train Loss: 0.4409 | Val Loss: 0.4841 | Val Acc: 0.9724 | LR: 0.000095 
ğŸ•’ Epoch 9/100 | Time: 107.47s | Train Loss: 0.4481 | Val Loss: 0.4693 | Val Acc: 0.9816 | LR: 0.000094 
ğŸ•’ Epoch 10/100 | Time: 109.57s | Train Loss: 0.4440 | Val Loss: 0.4927 | Val Acc: 0.9743 | LR: 0.000092 
ğŸ•’ Epoch 11/100 | Time: 111.26s | Train Loss: 0.4335 | Val Loss: 0.4928 | Val Acc: 0.9706 | LR: 0.000091 
ğŸ•’ Epoch 12/100 | Time: 108.98s | Train Loss: 0.4383 | Val Loss: 0.4778 | Val Acc: 0.9798 | LR: 0.000089 
ğŸ•’ Epoch 13/100 | Time: 109.50s | Train Loss: 0.4313 | Val Loss: 0.4959 | Val Acc: 0.9724 | LR: 0.000087 
ğŸ•’ Epoch 14/100 | Time: 108.74s | Train Loss: 0.4310 | Val Loss: 0.4733 | Val Acc: 0.9816 | LR: 0.000084 
ğŸ•’ Epoch 15/100 | Time: 110.42s | Train Loss: 0.4285 | Val Loss: 0.4657 | Val Acc: 0.9853 | LR: 0.000082 
ğŸ’¾ Saving best val acc: 0.9853
ğŸ•’ Epoch 16/100 | Time: 110.32s | Train Loss: 0.4247 | Val Loss: 0.5092 | Val Acc: 0.9688 | LR: 0.000080 
ğŸ•’ Epoch 17/100 | Time: 109.55s | Train Loss: 0.4338 | Val Loss: 0.4740 | Val Acc: 0.9798 | LR: 0.000077 
ğŸ•’ Epoch 18/100 | Time: 109.42s | Train Loss: 0.4311 | Val Loss: 0.5308 | Val Acc: 0.9632 | LR: 0.000074 
ğŸ•’ Epoch 19/100 | Time: 108.74s | Train Loss: 0.4442 | Val Loss: 0.4714 | Val Acc: 0.9835 | LR: 0.000072 
ğŸ•’ Epoch 20/100 | Time: 107.72s | Train Loss: 0.4274 | Val Loss: 0.4583 | Val Acc: 0.9890 | LR: 0.000069 
ğŸ’¾ Saving best val acc: 0.9890
ğŸ•’ Epoch 21/100 | Time: 108.19s | Train Loss: 0.4342 | Val Loss: 0.4682 | Val Acc: 0.9835 | LR: 0.000066 
ğŸ•’ Epoch 22/100 | Time: 98.69s | Train Loss: 0.4305 | Val Loss: 0.4723 | Val Acc: 0.9835 | LR: 0.000063 
ğŸ•’ Epoch 23/100 | Time: 71.80s | Train Loss: 0.4350 | Val Loss: 0.4649 | Val Acc: 0.9798 | LR: 0.000060 
ğŸ•’ Epoch 24/100 | Time: 72.65s | Train Loss: 0.4223 | Val Loss: 0.4605 | Val Acc: 0.9835 | LR: 0.000057 
ğŸ•’ Epoch 25/100 | Time: 72.34s | Train Loss: 0.4222 | Val Loss: 0.4638 | Val Acc: 0.9816 | LR: 0.000054 
ğŸ•’ Epoch 26/100 | Time: 70.86s | Train Loss: 0.4226 | Val Loss: 0.4631 | Val Acc: 0.9853 | LR: 0.000050 
ğŸ•’ Epoch 27/100 | Time: 71.02s | Train Loss: 0.4224 | Val Loss: 0.4617 | Val Acc: 0.9853 | LR: 0.000047 
ğŸ•’ Epoch 28/100 | Time: 70.66s | Train Loss: 0.4230 | Val Loss: 0.4526 | Val Acc: 0.9908 | LR: 0.000044 
ğŸ’¾ Saving best val acc: 0.9908
ğŸ•’ Epoch 29/100 | Time: 71.86s | Train Loss: 0.4243 | Val Loss: 0.4593 | Val Acc: 0.9890 | LR: 0.000041 
ğŸ•’ Epoch 30/100 | Time: 71.36s | Train Loss: 0.4225 | Val Loss: 0.4845 | Val Acc: 0.9798 | LR: 0.000038 
ğŸ•’ Epoch 31/100 | Time: 71.45s | Train Loss: 0.4281 | Val Loss: 0.4570 | Val Acc: 0.9890 | LR: 0.000035 
ğŸ•’ Epoch 32/100 | Time: 71.89s | Train Loss: 0.4223 | Val Loss: 0.4614 | Val Acc: 0.9890 | LR: 0.000032 
ğŸ•’ Epoch 33/100 | Time: 71.88s | Train Loss: 0.4255 | Val Loss: 0.4615 | Val Acc: 0.9871 | LR: 0.000029 
ğŸ•’ Epoch 34/100 | Time: 71.55s | Train Loss: 0.4224 | Val Loss: 0.4649 | Val Acc: 0.9835 | LR: 0.000027 
ğŸ•’ Epoch 35/100 | Time: 71.57s | Train Loss: 0.4217 | Val Loss: 0.4647 | Val Acc: 0.9835 | LR: 0.000024 
ğŸ•’ Epoch 36/100 | Time: 71.17s | Train Loss: 0.4215 | Val Loss: 0.4636 | Val Acc: 0.9853 | LR: 0.000021 
ğŸ•’ Epoch 37/100 | Time: 71.33s | Train Loss: 0.4213 | Val Loss: 0.4632 | Val Acc: 0.9853 | LR: 0.000019 
ğŸ•’ Epoch 38/100 | Time: 71.90s | Train Loss: 0.4222 | Val Loss: 0.4601 | Val Acc: 0.9853 | LR: 0.000017 
â¹ï¸ Early stopping triggered.
âœ… Training complete in 3580.80 seconds. Best model loaded.
ğŸ“ Model saved to ./output/models/ConvNeXt+dataset21+dataset21.pth
ğŸ“‚ Training metrics plot saved to: output/test/ConvNeXt+dataset21/training metric.png
Evaluate model:ConvNeXt+dataset21

ğŸ”¥ Test Accuracy: 99.26%

ğŸ“Œ Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     0.9888    1.0000    0.9944        88
           brown_spot     0.9787    0.9892    0.9840        93
              healthy     1.0000    1.0000    1.0000        93
           leaf_blast     0.9888    0.9670    0.9778        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9926       543
            macro avg     0.9927    0.9927    0.9927       543
         weighted avg     0.9927    0.9926    0.9926       543

ğŸ“‚ Confusion matrix saved to: output/test/ConvNeXt+dataset21/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+dataset21/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+dataset21/misclassified_images.png
âœ… Saved fold class distribution plot to: output/fold_class_distribution.png

ğŸ“‚ Fold 1/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.6968 | Val Loss: 0.5083 | Val Acc: 0.9631
ğŸ’¾ Best model updated (val acc: 0.9631)
ğŸ•’ Epoch 2/100 | Train Loss: 0.4836 | Val Loss: 0.4973 | Val Acc: 0.9631
ğŸ’¾ Best model updated (val acc: 0.9631)
ğŸ•’ Epoch 3/100 | Train Loss: 0.4608 | Val Loss: 0.4766 | Val Acc: 0.9700
ğŸ’¾ Best model updated (val acc: 0.9700)
ğŸ•’ Epoch 4/100 | Train Loss: 0.4311 | Val Loss: 0.4515 | Val Acc: 0.9885
ğŸ’¾ Best model updated (val acc: 0.9885)
ğŸ•’ Epoch 5/100 | Train Loss: 0.4286 | Val Loss: 0.4443 | Val Acc: 0.9862
ğŸ’¾ Best model updated (val acc: 0.9862)
ğŸ•’ Epoch 6/100 | Train Loss: 0.4233 | Val Loss: 0.4485 | Val Acc: 0.9839
ğŸ•’ Epoch 7/100 | Train Loss: 0.4220 | Val Loss: 0.4420 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 8/100 | Train Loss: 0.4216 | Val Loss: 0.4426 | Val Acc: 0.9931
ğŸ•’ Epoch 9/100 | Train Loss: 0.4214 | Val Loss: 0.4429 | Val Acc: 0.9839
ğŸ•’ Epoch 10/100 | Train Loss: 0.4214 | Val Loss: 0.4431 | Val Acc: 0.9839
ğŸ•’ Epoch 11/100 | Train Loss: 0.4214 | Val Loss: 0.4431 | Val Acc: 0.9839
ğŸ•’ Epoch 12/100 | Train Loss: 0.4213 | Val Loss: 0.4433 | Val Acc: 0.9862
ğŸ•’ Epoch 13/100 | Train Loss: 0.4213 | Val Loss: 0.4433 | Val Acc: 0.9839
ğŸ•’ Epoch 14/100 | Train Loss: 0.4213 | Val Loss: 0.4433 | Val Acc: 0.9839
ğŸ•’ Epoch 15/100 | Train Loss: 0.4213 | Val Loss: 0.4433 | Val Acc: 0.9885
ğŸ•’ Epoch 16/100 | Train Loss: 0.4212 | Val Loss: 0.4434 | Val Acc: 0.9839
ğŸ•’ Epoch 17/100 | Train Loss: 0.4212 | Val Loss: 0.4434 | Val Acc: 0.9839
â¹ï¸ Early stopping.
âœ… Fold 1 complete. Saved: ./output/models/kfold/ConvNeXt+4cbam+kfold+dataset22+dataset22_fold1.pth

ğŸ“‚ Fold 2/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7119 | Val Loss: 0.5069 | Val Acc: 0.9631
ğŸ’¾ Best model updated (val acc: 0.9631)
ğŸ•’ Epoch 2/100 | Train Loss: 0.4677 | Val Loss: 0.5047 | Val Acc: 0.9654
ğŸ’¾ Best model updated (val acc: 0.9654)
ğŸ•’ Epoch 3/100 | Train Loss: 0.4604 | Val Loss: 0.4640 | Val Acc: 0.9862
ğŸ’¾ Best model updated (val acc: 0.9862)
ğŸ•’ Epoch 4/100 | Train Loss: 0.4389 | Val Loss: 0.4681 | Val Acc: 0.9816
ğŸ•’ Epoch 5/100 | Train Loss: 0.4296 | Val Loss: 0.4658 | Val Acc: 0.9793
ğŸ•’ Epoch 6/100 | Train Loss: 0.4223 | Val Loss: 0.4592 | Val Acc: 0.9816
ğŸ’¾ Best model updated (val acc: 0.9816)
ğŸ•’ Epoch 7/100 | Train Loss: 0.4217 | Val Loss: 0.4584 | Val Acc: 0.9816
ğŸ’¾ Best model updated (val acc: 0.9816)
ğŸ•’ Epoch 8/100 | Train Loss: 0.4216 | Val Loss: 0.4581 | Val Acc: 0.9816
ğŸ’¾ Best model updated (val acc: 0.9816)
ğŸ•’ Epoch 9/100 | Train Loss: 0.4214 | Val Loss: 0.4577 | Val Acc: 0.9816
ğŸ’¾ Best model updated (val acc: 0.9816)
ğŸ•’ Epoch 10/100 | Train Loss: 0.4214 | Val Loss: 0.4578 | Val Acc: 0.9816
ğŸ•’ Epoch 11/100 | Train Loss: 0.4213 | Val Loss: 0.4579 | Val Acc: 0.9816
ğŸ•’ Epoch 12/100 | Train Loss: 0.4213 | Val Loss: 0.4578 | Val Acc: 0.9816
ğŸ•’ Epoch 13/100 | Train Loss: 0.4213 | Val Loss: 0.4577 | Val Acc: 0.9839
ğŸ’¾ Best model updated (val acc: 0.9839)
ğŸ•’ Epoch 14/100 | Train Loss: 0.4213 | Val Loss: 0.4577 | Val Acc: 0.9839
ğŸ’¾ Best model updated (val acc: 0.9839)
ğŸ•’ Epoch 15/100 | Train Loss: 0.4213 | Val Loss: 0.4577 | Val Acc: 0.9839
ğŸ•’ Epoch 16/100 | Train Loss: 0.4213 | Val Loss: 0.4578 | Val Acc: 0.9839
ğŸ•’ Epoch 17/100 | Train Loss: 0.4213 | Val Loss: 0.4578 | Val Acc: 0.9839
ğŸ•’ Epoch 18/100 | Train Loss: 0.4212 | Val Loss: 0.4578 | Val Acc: 0.9839
ğŸ•’ Epoch 19/100 | Train Loss: 0.4212 | Val Loss: 0.4577 | Val Acc: 0.9839
ğŸ•’ Epoch 20/100 | Train Loss: 0.4212 | Val Loss: 0.4579 | Val Acc: 0.9839
ğŸ•’ Epoch 21/100 | Train Loss: 0.4212 | Val Loss: 0.4578 | Val Acc: 0.9839
ğŸ•’ Epoch 22/100 | Train Loss: 0.4212 | Val Loss: 0.4578 | Val Acc: 0.9839
ğŸ•’ Epoch 23/100 | Train Loss: 0.4212 | Val Loss: 0.4579 | Val Acc: 0.9839
ğŸ•’ Epoch 24/100 | Train Loss: 0.4212 | Val Loss: 0.4579 | Val Acc: 0.9839
â¹ï¸ Early stopping.
âœ… Fold 2 complete. Saved: ./output/models/kfold/ConvNeXt+4cbam+kfold+dataset22+dataset22_fold2.pth

ğŸ“‚ Fold 3/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.6849 | Val Loss: 0.4943 | Val Acc: 0.9654
ğŸ’¾ Best model updated (val acc: 0.9654)
ğŸ•’ Epoch 2/100 | Train Loss: 0.4761 | Val Loss: 0.5573 | Val Acc: 0.9330
ğŸ•’ Epoch 3/100 | Train Loss: 0.4496 | Val Loss: 0.4641 | Val Acc: 0.9746
ğŸ’¾ Best model updated (val acc: 0.9746)
ğŸ•’ Epoch 4/100 | Train Loss: 0.4372 | Val Loss: 0.4510 | Val Acc: 0.9838
ğŸ’¾ Best model updated (val acc: 0.9838)
ğŸ•’ Epoch 5/100 | Train Loss: 0.4340 | Val Loss: 0.4581 | Val Acc: 0.9861
ğŸ•’ Epoch 6/100 | Train Loss: 0.4398 | Val Loss: 0.5184 | Val Acc: 0.9584
ğŸ•’ Epoch 7/100 | Train Loss: 0.4305 | Val Loss: 0.4476 | Val Acc: 0.9838
ğŸ’¾ Best model updated (val acc: 0.9838)
ğŸ•’ Epoch 8/100 | Train Loss: 0.4222 | Val Loss: 0.4442 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 9/100 | Train Loss: 0.4216 | Val Loss: 0.4407 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 10/100 | Train Loss: 0.4215 | Val Loss: 0.4396 | Val Acc: 0.9931
ğŸ’¾ Best model updated (val acc: 0.9931)
ğŸ•’ Epoch 11/100 | Train Loss: 0.4214 | Val Loss: 0.4393 | Val Acc: 0.9931
ğŸ’¾ Best model updated (val acc: 0.9931)
ğŸ•’ Epoch 12/100 | Train Loss: 0.4214 | Val Loss: 0.4391 | Val Acc: 0.9931
ğŸ’¾ Best model updated (val acc: 0.9931)
ğŸ•’ Epoch 13/100 | Train Loss: 0.4213 | Val Loss: 0.4388 | Val Acc: 0.9931
ğŸ’¾ Best model updated (val acc: 0.9931)
ğŸ•’ Epoch 14/100 | Train Loss: 0.4213 | Val Loss: 0.4387 | Val Acc: 0.9931
ğŸ’¾ Best model updated (val acc: 0.9931)
ğŸ•’ Epoch 15/100 | Train Loss: 0.4213 | Val Loss: 0.4387 | Val Acc: 0.9931
ğŸ’¾ Best model updated (val acc: 0.9931)
ğŸ•’ Epoch 16/100 | Train Loss: 0.4213 | Val Loss: 0.4387 | Val Acc: 0.9931
ğŸ’¾ Best model updated (val acc: 0.9931)
ğŸ•’ Epoch 17/100 | Train Loss: 0.4213 | Val Loss: 0.4385 | Val Acc: 0.9931
ğŸ’¾ Best model updated (val acc: 0.9931)
ğŸ•’ Epoch 18/100 | Train Loss: 0.4212 | Val Loss: 0.4386 | Val Acc: 0.9931
ğŸ•’ Epoch 19/100 | Train Loss: 0.4212 | Val Loss: 0.4385 | Val Acc: 0.9931
ğŸ’¾ Best model updated (val acc: 0.9931)
ğŸ•’ Epoch 20/100 | Train Loss: 0.4212 | Val Loss: 0.4384 | Val Acc: 0.9931
ğŸ’¾ Best model updated (val acc: 0.9931)
ğŸ•’ Epoch 21/100 | Train Loss: 0.4212 | Val Loss: 0.4384 | Val Acc: 0.9931
ğŸ•’ Epoch 22/100 | Train Loss: 0.4212 | Val Loss: 0.4384 | Val Acc: 0.9908
ğŸ•’ Epoch 23/100 | Train Loss: 0.4212 | Val Loss: 0.4384 | Val Acc: 0.9908
ğŸ•’ Epoch 24/100 | Train Loss: 0.4212 | Val Loss: 0.4384 | Val Acc: 0.9908
ğŸ•’ Epoch 25/100 | Train Loss: 0.4212 | Val Loss: 0.4384 | Val Acc: 0.9908
ğŸ•’ Epoch 26/100 | Train Loss: 0.4212 | Val Loss: 0.4384 | Val Acc: 0.9908
ğŸ•’ Epoch 27/100 | Train Loss: 0.4212 | Val Loss: 0.4385 | Val Acc: 0.9908
ğŸ•’ Epoch 28/100 | Train Loss: 0.4212 | Val Loss: 0.4384 | Val Acc: 0.9908
ğŸ•’ Epoch 29/100 | Train Loss: 0.4212 | Val Loss: 0.4385 | Val Acc: 0.9908
ğŸ•’ Epoch 30/100 | Train Loss: 0.4212 | Val Loss: 0.4385 | Val Acc: 0.9908
â¹ï¸ Early stopping.
âœ… Fold 3 complete. Saved: ./output/models/kfold/ConvNeXt+4cbam+kfold+dataset22+dataset22_fold3.pth

ğŸ“‚ Fold 4/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.6810 | Val Loss: 0.5507 | Val Acc: 0.9376
ğŸ’¾ Best model updated (val acc: 0.9376)
ğŸ•’ Epoch 2/100 | Train Loss: 0.4843 | Val Loss: 0.5742 | Val Acc: 0.9446
ğŸ•’ Epoch 3/100 | Train Loss: 0.4484 | Val Loss: 0.4592 | Val Acc: 0.9838
ğŸ’¾ Best model updated (val acc: 0.9838)
ğŸ•’ Epoch 4/100 | Train Loss: 0.4282 | Val Loss: 0.4635 | Val Acc: 0.9815
ğŸ•’ Epoch 5/100 | Train Loss: 0.4251 | Val Loss: 0.4568 | Val Acc: 0.9861
ğŸ’¾ Best model updated (val acc: 0.9861)
ğŸ•’ Epoch 6/100 | Train Loss: 0.4218 | Val Loss: 0.4571 | Val Acc: 0.9861
ğŸ•’ Epoch 7/100 | Train Loss: 0.4215 | Val Loss: 0.4572 | Val Acc: 0.9861
ğŸ•’ Epoch 8/100 | Train Loss: 0.4214 | Val Loss: 0.4575 | Val Acc: 0.9861
ğŸ•’ Epoch 9/100 | Train Loss: 0.4214 | Val Loss: 0.4582 | Val Acc: 0.9861
ğŸ•’ Epoch 10/100 | Train Loss: 0.4213 | Val Loss: 0.4582 | Val Acc: 0.9861
ğŸ•’ Epoch 11/100 | Train Loss: 0.4213 | Val Loss: 0.4584 | Val Acc: 0.9861
ğŸ•’ Epoch 12/100 | Train Loss: 0.4212 | Val Loss: 0.4587 | Val Acc: 0.9861
ğŸ•’ Epoch 13/100 | Train Loss: 0.4213 | Val Loss: 0.4589 | Val Acc: 0.9861
ğŸ•’ Epoch 14/100 | Train Loss: 0.4213 | Val Loss: 0.4591 | Val Acc: 0.9861
ğŸ•’ Epoch 15/100 | Train Loss: 0.4213 | Val Loss: 0.4593 | Val Acc: 0.9861
â¹ï¸ Early stopping.
âœ… Fold 4 complete. Saved: ./output/models/kfold/ConvNeXt+4cbam+kfold+dataset22+dataset22_fold4.pth

ğŸ“‚ Fold 5/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7047 | Val Loss: 0.5009 | Val Acc: 0.9654
ğŸ’¾ Best model updated (val acc: 0.9654)
ğŸ•’ Epoch 2/100 | Train Loss: 0.4821 | Val Loss: 0.5170 | Val Acc: 0.9584
ğŸ•’ Epoch 3/100 | Train Loss: 0.4368 | Val Loss: 0.4567 | Val Acc: 0.9815
ğŸ’¾ Best model updated (val acc: 0.9815)
ğŸ•’ Epoch 4/100 | Train Loss: 0.4245 | Val Loss: 0.4529 | Val Acc: 0.9861
ğŸ’¾ Best model updated (val acc: 0.9861)
ğŸ•’ Epoch 5/100 | Train Loss: 0.4226 | Val Loss: 0.4552 | Val Acc: 0.9838
ğŸ•’ Epoch 6/100 | Train Loss: 0.4218 | Val Loss: 0.4544 | Val Acc: 0.9861
ğŸ•’ Epoch 7/100 | Train Loss: 0.4216 | Val Loss: 0.4550 | Val Acc: 0.9838
ğŸ•’ Epoch 8/100 | Train Loss: 0.4215 | Val Loss: 0.4554 | Val Acc: 0.9838
ğŸ•’ Epoch 9/100 | Train Loss: 0.4214 | Val Loss: 0.4557 | Val Acc: 0.9838
ğŸ•’ Epoch 10/100 | Train Loss: 0.4213 | Val Loss: 0.4560 | Val Acc: 0.9838
ğŸ•’ Epoch 11/100 | Train Loss: 0.4214 | Val Loss: 0.4563 | Val Acc: 0.9838
ğŸ•’ Epoch 12/100 | Train Loss: 0.4213 | Val Loss: 0.4565 | Val Acc: 0.9838
ğŸ•’ Epoch 13/100 | Train Loss: 0.4213 | Val Loss: 0.4567 | Val Acc: 0.9838
ğŸ•’ Epoch 14/100 | Train Loss: 0.4213 | Val Loss: 0.4569 | Val Acc: 0.9838
â¹ï¸ Early stopping.
âœ… Fold 5 complete. Saved: ./output/models/kfold/ConvNeXt+4cbam+kfold+dataset22+dataset22_fold5.pth

ğŸš€ Evaluating 5 fold models on test set

ğŸ“‚ Evaluating Fold 1
ğŸ“Š Fold 1 Metrics:
   - Accuracy: 0.9853
   - Precision: 0.9854
   - Recall: 0.9855
   - F1 Score: 0.9854

ğŸ“‚ Evaluating Fold 2
ğŸ“Š Fold 2 Metrics:
   - Accuracy: 0.9834
   - Precision: 0.9838
   - Recall: 0.9837
   - F1 Score: 0.9837

ğŸ“‚ Evaluating Fold 3
ğŸ“Š Fold 3 Metrics:
   - Accuracy: 0.9890
   - Precision: 0.9891
   - Recall: 0.9892
   - F1 Score: 0.9891

ğŸ“‚ Evaluating Fold 4
ğŸ“Š Fold 4 Metrics:
   - Accuracy: 0.9816
   - Precision: 0.9819
   - Recall: 0.9819
   - F1 Score: 0.9818

ğŸ“‚ Evaluating Fold 5
ğŸ“Š Fold 5 Metrics:
   - Accuracy: 0.9871
   - Precision: 0.9873
   - Recall: 0.9873
   - F1 Score: 0.9873

ğŸ§¾ Classification Report for ConvNeXt+4cbam+kfold+dataset22 (Majority Vote from 5 folds):

                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    1.0000    1.0000        88
           brown_spot     0.9674    0.9570    0.9622        93
              healthy     0.9894    1.0000    0.9947        93
           leaf_blast     0.9670    0.9670    0.9670        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9871       543
            macro avg     0.9873    0.9873    0.9873       543
         weighted avg     0.9871    0.9871    0.9871       543

ğŸ”¢ Confusion Matrix:
 [[88  0  0  0  0  0]
 [ 0 89  1  3  0  0]
 [ 0  0 93  0  0  0]
 [ 0  3  0 88  0  0]
 [ 0  0  0  0 90  0]
 [ 0  0  0  0  0 88]]

ğŸ“Š Average Metrics Across All Folds:
   - Accuracy: 0.9853
   - Precision: 0.9855
   - Recall: 0.9855
   - F1 Score: 0.9855
-----------------------------------------------------------------------------------------------------------------------Traceback (most recent call last):

âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: ConvNeXt+4cbam+dataset1]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
ğŸ•’ Epoch 1/100 | Time: 99.94s | Train Loss: 0.7424 | Val Loss: 0.5265 | Val Acc: 0.9577 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9577
ğŸ•’ Epoch 2/100 | Time: 70.56s | Train Loss: 0.5106 | Val Loss: 0.5265 | Val Acc: 0.9540 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9540
ğŸ•’ Epoch 3/100 | Time: 71.17s | Train Loss: 0.4799 | Val Loss: 0.4995 | Val Acc: 0.9669 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9669
ğŸ•’ Epoch 4/100 | Time: 71.09s | Train Loss: 0.4699 | Val Loss: 0.5269 | Val Acc: 0.9485 | LR: 0.000099 
ğŸ•’ Epoch 5/100 | Time: 71.09s | Train Loss: 0.4763 | Val Loss: 0.5152 | Val Acc: 0.9632 | LR: 0.000098 
ğŸ•’ Epoch 6/100 | Time: 71.88s | Train Loss: 0.4603 | Val Loss: 0.4885 | Val Acc: 0.9706 | LR: 0.000098 
ğŸ’¾ Saving best val acc: 0.9706
ğŸ•’ Epoch 7/100 | Time: 71.30s | Train Loss: 0.4375 | Val Loss: 0.5256 | Val Acc: 0.9522 | LR: 0.000097 
ğŸ•’ Epoch 8/100 | Time: 71.06s | Train Loss: 0.4481 | Val Loss: 0.4602 | Val Acc: 0.9798 | LR: 0.000095 
ğŸ’¾ Saving best val acc: 0.9798
ğŸ•’ Epoch 9/100 | Time: 70.90s | Train Loss: 0.4370 | Val Loss: 0.4767 | Val Acc: 0.9743 | LR: 0.000094 
ğŸ•’ Epoch 10/100 | Time: 71.40s | Train Loss: 0.4549 | Val Loss: 0.4915 | Val Acc: 0.9743 | LR: 0.000092 
ğŸ•’ Epoch 11/100 | Time: 71.46s | Train Loss: 0.4309 | Val Loss: 0.4754 | Val Acc: 0.9798 | LR: 0.000091 
ğŸ•’ Epoch 12/100 | Time: 71.13s | Train Loss: 0.4412 | Val Loss: 0.4532 | Val Acc: 0.9890 | LR: 0.000089 
ğŸ’¾ Saving best val acc: 0.9890
ğŸ•’ Epoch 13/100 | Time: 71.58s | Train Loss: 0.4354 | Val Loss: 0.4502 | Val Acc: 0.9853 | LR: 0.000087 
ğŸ’¾ Saving best val acc: 0.9853
ğŸ•’ Epoch 14/100 | Time: 71.31s | Train Loss: 0.4295 | Val Loss: 0.4583 | Val Acc: 0.9871 | LR: 0.000084 
ğŸ•’ Epoch 15/100 | Time: 70.55s | Train Loss: 0.4300 | Val Loss: 0.4587 | Val Acc: 0.9871 | LR: 0.000082 
ğŸ•’ Epoch 16/100 | Time: 71.36s | Train Loss: 0.4231 | Val Loss: 0.4577 | Val Acc: 0.9853 | LR: 0.000080 
ğŸ•’ Epoch 17/100 | Time: 70.71s | Train Loss: 0.4260 | Val Loss: 0.4843 | Val Acc: 0.9779 | LR: 0.000077 
ğŸ•’ Epoch 18/100 | Time: 71.12s | Train Loss: 0.4417 | Val Loss: 0.4864 | Val Acc: 0.9761 | LR: 0.000074 
ğŸ•’ Epoch 19/100 | Time: 71.89s | Train Loss: 0.4296 | Val Loss: 0.4698 | Val Acc: 0.9816 | LR: 0.000072 
ğŸ•’ Epoch 20/100 | Time: 71.76s | Train Loss: 0.4248 | Val Loss: 0.4731 | Val Acc: 0.9816 | LR: 0.000069 
ğŸ•’ Epoch 21/100 | Time: 71.49s | Train Loss: 0.4273 | Val Loss: 0.4759 | Val Acc: 0.9798 | LR: 0.000066 
ğŸ•’ Epoch 22/100 | Time: 71.64s | Train Loss: 0.4339 | Val Loss: 0.4837 | Val Acc: 0.9743 | LR: 0.000063 
ğŸ•’ Epoch 23/100 | Time: 71.51s | Train Loss: 0.4260 | Val Loss: 0.4543 | Val Acc: 0.9871 | LR: 0.000060 
â¹ï¸ Early stopping triggered.
âœ… Training complete in 1668.05 seconds. Best model loaded.
ğŸ“ Model saved to ./output/models/ConvNeXt+4cbam+dataset1+dataset1.pth
ğŸ“‚ Training metrics plot saved to: output/test/ConvNeXt+4cbam+dataset1/training metric.png

Evaluate model:ConvNeXt+4cbam+dataset1

ğŸ”¥ Test Accuracy: 99.08%

ğŸ“Œ Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    1.0000    1.0000        88
           brown_spot     0.9783    0.9677    0.9730        93
              healthy     1.0000    1.0000    1.0000        93
           leaf_blast     0.9677    0.9890    0.9783        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    0.9886    0.9943        88

             accuracy                         0.9908       543
            macro avg     0.9910    0.9909    0.9909       543
         weighted avg     0.9909    0.9908    0.9908       543

ğŸ“‚ Confusion matrix saved to: output/test/ConvNeXt+4cbam+dataset1/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+4cbam+dataset1/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+4cbam+dataset1/misclassified_images.png
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: ConvNeXt+dataset1]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
ğŸ•’ Epoch 1/100 | Time: 68.84s | Train Loss: 0.7694 | Val Loss: 0.5436 | Val Acc: 0.9596 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9596
ğŸ•’ Epoch 2/100 | Time: 68.55s | Train Loss: 0.4981 | Val Loss: 0.5127 | Val Acc: 0.9724 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9724
ğŸ•’ Epoch 3/100 | Time: 69.02s | Train Loss: 0.4783 | Val Loss: 0.4962 | Val Acc: 0.9706 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9706
ğŸ•’ Epoch 4/100 | Time: 68.78s | Train Loss: 0.4644 | Val Loss: 0.4942 | Val Acc: 0.9706 | LR: 0.000099 
ğŸ’¾ Saving best val acc: 0.9706
ğŸ•’ Epoch 5/100 | Time: 68.91s | Train Loss: 0.4490 | Val Loss: 0.4853 | Val Acc: 0.9779 | LR: 0.000098 
ğŸ’¾ Saving best val acc: 0.9779
ğŸ•’ Epoch 6/100 | Time: 69.52s | Train Loss: 0.4476 | Val Loss: 0.4618 | Val Acc: 0.9853 | LR: 0.000098 
ğŸ’¾ Saving best val acc: 0.9853
ğŸ•’ Epoch 7/100 | Time: 70.39s | Train Loss: 0.4423 | Val Loss: 0.4734 | Val Acc: 0.9816 | LR: 0.000097 
ğŸ•’ Epoch 8/100 | Time: 70.70s | Train Loss: 0.4345 | Val Loss: 0.4557 | Val Acc: 0.9890 | LR: 0.000095 
ğŸ’¾ Saving best val acc: 0.9890
ğŸ•’ Epoch 9/100 | Time: 70.62s | Train Loss: 0.4310 | Val Loss: 0.4621 | Val Acc: 0.9871 | LR: 0.000094 
ğŸ•’ Epoch 10/100 | Time: 70.74s | Train Loss: 0.4311 | Val Loss: 0.4737 | Val Acc: 0.9798 | LR: 0.000092 
ğŸ•’ Epoch 11/100 | Time: 70.27s | Train Loss: 0.4442 | Val Loss: 0.5675 | Val Acc: 0.9577 | LR: 0.000091 
ğŸ•’ Epoch 12/100 | Time: 71.04s | Train Loss: 0.4685 | Val Loss: 0.5239 | Val Acc: 0.9596 | LR: 0.000089 
ğŸ•’ Epoch 13/100 | Time: 71.08s | Train Loss: 0.4651 | Val Loss: 0.4721 | Val Acc: 0.9798 | LR: 0.000087 
ğŸ•’ Epoch 14/100 | Time: 70.15s | Train Loss: 0.4395 | Val Loss: 0.4712 | Val Acc: 0.9835 | LR: 0.000084 
ğŸ•’ Epoch 15/100 | Time: 70.50s | Train Loss: 0.4387 | Val Loss: 0.4701 | Val Acc: 0.9779 | LR: 0.000082 
ğŸ•’ Epoch 16/100 | Time: 70.78s | Train Loss: 0.4371 | Val Loss: 0.4825 | Val Acc: 0.9743 | LR: 0.000080 
ğŸ•’ Epoch 17/100 | Time: 70.31s | Train Loss: 0.4304 | Val Loss: 0.4705 | Val Acc: 0.9835 | LR: 0.000077 
ğŸ•’ Epoch 18/100 | Time: 69.96s | Train Loss: 0.4301 | Val Loss: 0.4649 | Val Acc: 0.9871 | LR: 0.000074 
â¹ï¸ Early stopping triggered.
âœ… Training complete in 1260.25 seconds. Best model loaded.
ğŸ“ Model saved to ./output/models/ConvNeXt+dataset1+dataset1.pth
ğŸ“‚ Training metrics plot saved to: output/test/ConvNeXt+dataset1/training metric.png
Evaluate model:ConvNeXt+dataset1

ğŸ”¥ Test Accuracy: 98.34%

ğŸ“Œ Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    1.0000    1.0000        88
           brown_spot     0.9474    0.9677    0.9574        93
              healthy     0.9688    1.0000    0.9841        93
           leaf_blast     0.9884    0.9341    0.9605        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9834       543
            macro avg     0.9841    0.9836    0.9837       543
         weighted avg     0.9837    0.9834    0.9834       543

ğŸ“‚ Confusion matrix saved to: output/test/ConvNeXt+dataset1/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+dataset1/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+dataset1/misclassified_images.png
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: ConvNeXt+1cbam_last+dataset1]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
ğŸ•’ Epoch 1/100 | Time: 69.14s | Train Loss: 0.7864 | Val Loss: 0.5911 | Val Acc: 0.9357 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9357
ğŸ•’ Epoch 2/100 | Time: 69.85s | Train Loss: 0.4980 | Val Loss: 0.5033 | Val Acc: 0.9743 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9743
ğŸ•’ Epoch 3/100 | Time: 69.78s | Train Loss: 0.4666 | Val Loss: 0.4981 | Val Acc: 0.9761 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9761
ğŸ•’ Epoch 4/100 | Time: 70.01s | Train Loss: 0.4593 | Val Loss: 0.4716 | Val Acc: 0.9798 | LR: 0.000099 
ğŸ’¾ Saving best val acc: 0.9798
ğŸ•’ Epoch 5/100 | Time: 69.21s | Train Loss: 0.4428 | Val Loss: 0.4882 | Val Acc: 0.9688 | LR: 0.000098 
ğŸ•’ Epoch 6/100 | Time: 69.43s | Train Loss: 0.4555 | Val Loss: 0.4771 | Val Acc: 0.9798 | LR: 0.000098 
ğŸ•’ Epoch 7/100 | Time: 70.13s | Train Loss: 0.4430 | Val Loss: 0.4748 | Val Acc: 0.9835 | LR: 0.000097 
ğŸ•’ Epoch 8/100 | Time: 71.08s | Train Loss: 0.4397 | Val Loss: 0.5016 | Val Acc: 0.9706 | LR: 0.000095 
ğŸ•’ Epoch 9/100 | Time: 71.35s | Train Loss: 0.4411 | Val Loss: 0.5249 | Val Acc: 0.9651 | LR: 0.000094 
ğŸ•’ Epoch 10/100 | Time: 70.68s | Train Loss: 0.4581 | Val Loss: 0.4803 | Val Acc: 0.9779 | LR: 0.000092 
ğŸ•’ Epoch 11/100 | Time: 70.85s | Train Loss: 0.4370 | Val Loss: 0.4726 | Val Acc: 0.9853 | LR: 0.000091 
ğŸ•’ Epoch 12/100 | Time: 70.61s | Train Loss: 0.4305 | Val Loss: 0.5043 | Val Acc: 0.9688 | LR: 0.000089 
ğŸ•’ Epoch 13/100 | Time: 70.73s | Train Loss: 0.4301 | Val Loss: 0.4945 | Val Acc: 0.9724 | LR: 0.000087 
ğŸ•’ Epoch 14/100 | Time: 71.44s | Train Loss: 0.4319 | Val Loss: 0.4663 | Val Acc: 0.9871 | LR: 0.000084 
ğŸ’¾ Saving best val acc: 0.9871
ğŸ•’ Epoch 15/100 | Time: 70.99s | Train Loss: 0.4251 | Val Loss: 0.4670 | Val Acc: 0.9853 | LR: 0.000082 
ğŸ•’ Epoch 16/100 | Time: 70.80s | Train Loss: 0.4305 | Val Loss: 0.4661 | Val Acc: 0.9853 | LR: 0.000080 
ğŸ’¾ Saving best val acc: 0.9853
ğŸ•’ Epoch 17/100 | Time: 71.03s | Train Loss: 0.4246 | Val Loss: 0.4665 | Val Acc: 0.9853 | LR: 0.000077 
ğŸ•’ Epoch 18/100 | Time: 71.21s | Train Loss: 0.4231 | Val Loss: 0.4683 | Val Acc: 0.9853 | LR: 0.000074 
ğŸ•’ Epoch 19/100 | Time: 71.24s | Train Loss: 0.4230 | Val Loss: 0.4660 | Val Acc: 0.9871 | LR: 0.000072 
ğŸ’¾ Saving best val acc: 0.9871
ğŸ•’ Epoch 20/100 | Time: 71.19s | Train Loss: 0.4222 | Val Loss: 0.4652 | Val Acc: 0.9871 | LR: 0.000069 
ğŸ’¾ Saving best val acc: 0.9871
ğŸ•’ Epoch 21/100 | Time: 70.34s | Train Loss: 0.4248 | Val Loss: 0.4724 | Val Acc: 0.9871 | LR: 0.000066 
ğŸ•’ Epoch 22/100 | Time: 71.34s | Train Loss: 0.4277 | Val Loss: 0.4725 | Val Acc: 0.9816 | LR: 0.000063 
ğŸ•’ Epoch 23/100 | Time: 70.77s | Train Loss: 0.4258 | Val Loss: 0.4651 | Val Acc: 0.9835 | LR: 0.000060 
ğŸ’¾ Saving best val acc: 0.9835
ğŸ•’ Epoch 24/100 | Time: 70.69s | Train Loss: 0.4229 | Val Loss: 0.4631 | Val Acc: 0.9853 | LR: 0.000057 
ğŸ’¾ Saving best val acc: 0.9853
ğŸ•’ Epoch 25/100 | Time: 70.80s | Train Loss: 0.4222 | Val Loss: 0.4696 | Val Acc: 0.9798 | LR: 0.000054 
ğŸ•’ Epoch 26/100 | Time: 70.56s | Train Loss: 0.4229 | Val Loss: 0.4627 | Val Acc: 0.9871 | LR: 0.000050 
ğŸ’¾ Saving best val acc: 0.9871
ğŸ•’ Epoch 27/100 | Time: 70.76s | Train Loss: 0.4236 | Val Loss: 0.4664 | Val Acc: 0.9798 | LR: 0.000047 
ğŸ•’ Epoch 28/100 | Time: 70.04s | Train Loss: 0.4221 | Val Loss: 0.4611 | Val Acc: 0.9816 | LR: 0.000044 
ğŸ’¾ Saving best val acc: 0.9816
ğŸ•’ Epoch 29/100 | Time: 69.26s | Train Loss: 0.4221 | Val Loss: 0.4607 | Val Acc: 0.9890 | LR: 0.000041 
ğŸ’¾ Saving best val acc: 0.9890
ğŸ•’ Epoch 30/100 | Time: 70.07s | Train Loss: 0.4251 | Val Loss: 0.4581 | Val Acc: 0.9890 | LR: 0.000038 
ğŸ’¾ Saving best val acc: 0.9890
ğŸ•’ Epoch 31/100 | Time: 69.98s | Train Loss: 0.4221 | Val Loss: 0.4563 | Val Acc: 0.9890 | LR: 0.000035 
ğŸ’¾ Saving best val acc: 0.9890
ğŸ•’ Epoch 32/100 | Time: 69.72s | Train Loss: 0.4223 | Val Loss: 0.4570 | Val Acc: 0.9871 | LR: 0.000032 
ğŸ•’ Epoch 33/100 | Time: 69.14s | Train Loss: 0.4222 | Val Loss: 0.4559 | Val Acc: 0.9890 | LR: 0.000029 
ğŸ’¾ Saving best val acc: 0.9890
ğŸ•’ Epoch 34/100 | Time: 71.05s | Train Loss: 0.4216 | Val Loss: 0.4547 | Val Acc: 0.9890 | LR: 0.000027 
ğŸ’¾ Saving best val acc: 0.9890
ğŸ•’ Epoch 35/100 | Time: 69.66s | Train Loss: 0.4214 | Val Loss: 0.4546 | Val Acc: 0.9890 | LR: 0.000024 
ğŸ’¾ Saving best val acc: 0.9890
ğŸ•’ Epoch 36/100 | Time: 70.54s | Train Loss: 0.4213 | Val Loss: 0.4545 | Val Acc: 0.9890 | LR: 0.000021 
ğŸ’¾ Saving best val acc: 0.9890
ğŸ•’ Epoch 37/100 | Time: 69.69s | Train Loss: 0.4212 | Val Loss: 0.4548 | Val Acc: 0.9890 | LR: 0.000019 
ğŸ•’ Epoch 38/100 | Time: 70.14s | Train Loss: 0.4213 | Val Loss: 0.4548 | Val Acc: 0.9853 | LR: 0.000017 
ğŸ•’ Epoch 39/100 | Time: 69.57s | Train Loss: 0.4212 | Val Loss: 0.4578 | Val Acc: 0.9871 | LR: 0.000014 
ğŸ•’ Epoch 40/100 | Time: 69.39s | Train Loss: 0.4213 | Val Loss: 0.4562 | Val Acc: 0.9871 | LR: 0.000012 
ğŸ•’ Epoch 41/100 | Time: 70.00s | Train Loss: 0.4224 | Val Loss: 0.4571 | Val Acc: 0.9890 | LR: 0.000010 
ğŸ•’ Epoch 42/100 | Time: 69.82s | Train Loss: 0.4212 | Val Loss: 0.4562 | Val Acc: 0.9890 | LR: 0.000009 
ğŸ•’ Epoch 43/100 | Time: 69.46s | Train Loss: 0.4212 | Val Loss: 0.4560 | Val Acc: 0.9890 | LR: 0.000007 
ğŸ•’ Epoch 44/100 | Time: 69.42s | Train Loss: 0.4212 | Val Loss: 0.4557 | Val Acc: 0.9890 | LR: 0.000006 
ğŸ•’ Epoch 45/100 | Time: 69.84s | Train Loss: 0.4213 | Val Loss: 0.4567 | Val Acc: 0.9890 | LR: 0.000004 
ğŸ•’ Epoch 46/100 | Time: 70.53s | Train Loss: 0.4212 | Val Loss: 0.4567 | Val Acc: 0.9890 | LR: 0.000003 
â¹ï¸ Early stopping triggered.
âœ… Training complete in 3233.68 seconds. Best model loaded.
ğŸ“ Model saved to ./output/models/ConvNeXt+1cbam_last+dataset1+dataset1.pth
ğŸ“‚ Training metrics plot saved to: output/test/ConvNeXt+1cbam_last+dataset1/training metric.png
Evaluate model:ConvNeXt+1cbam_last+dataset1

ğŸ”¥ Test Accuracy: 98.90%

ğŸ“Œ Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    1.0000    1.0000        88
           brown_spot     0.9677    0.9677    0.9677        93
              healthy     0.9789    1.0000    0.9894        93
           leaf_blast     0.9888    0.9670    0.9778        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9890       543
            macro avg     0.9892    0.9891    0.9891       543
         weighted avg     0.9890    0.9890    0.9889       543

ğŸ“‚ Confusion matrix saved to: output/test/ConvNeXt+1cbam_last+dataset1/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+1cbam_last+dataset1/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+1cbam_last+dataset1/misclassified_images.png
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: ConvNeXt+3cbam+no-res+no-norm+dataset1]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
ğŸ•’ Epoch 1/100 | Time: 69.77s | Train Loss: 0.9778 | Val Loss: 0.6641 | Val Acc: 0.9099 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9099
ğŸ•’ Epoch 2/100 | Time: 69.45s | Train Loss: 0.5950 | Val Loss: 0.6455 | Val Acc: 0.9154 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9154
ğŸ•’ Epoch 3/100 | Time: 68.92s | Train Loss: 0.5300 | Val Loss: 0.5217 | Val Acc: 0.9669 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9669
ğŸ•’ Epoch 4/100 | Time: 69.72s | Train Loss: 0.5006 | Val Loss: 0.5034 | Val Acc: 0.9688 | LR: 0.000099 
ğŸ’¾ Saving best val acc: 0.9688
ğŸ•’ Epoch 5/100 | Time: 69.92s | Train Loss: 0.4673 | Val Loss: 0.5094 | Val Acc: 0.9596 | LR: 0.000098 
ğŸ•’ Epoch 6/100 | Time: 69.75s | Train Loss: 0.4743 | Val Loss: 0.5074 | Val Acc: 0.9706 | LR: 0.000098 
ğŸ•’ Epoch 7/100 | Time: 69.85s | Train Loss: 0.4660 | Val Loss: 0.4781 | Val Acc: 0.9779 | LR: 0.000097 
ğŸ’¾ Saving best val acc: 0.9779
ğŸ•’ Epoch 8/100 | Time: 69.21s | Train Loss: 0.4376 | Val Loss: 0.4729 | Val Acc: 0.9835 | LR: 0.000095 
ğŸ’¾ Saving best val acc: 0.9835
ğŸ•’ Epoch 9/100 | Time: 69.14s | Train Loss: 0.4392 | Val Loss: 0.4853 | Val Acc: 0.9798 | LR: 0.000094 
ğŸ•’ Epoch 10/100 | Time: 69.14s | Train Loss: 0.4809 | Val Loss: 0.4970 | Val Acc: 0.9669 | LR: 0.000092 
ğŸ•’ Epoch 11/100 | Time: 70.24s | Train Loss: 0.4694 | Val Loss: 0.5442 | Val Acc: 0.9504 | LR: 0.000091 
ğŸ•’ Epoch 12/100 | Time: 70.30s | Train Loss: 0.4629 | Val Loss: 0.4654 | Val Acc: 0.9871 | LR: 0.000089 
ğŸ’¾ Saving best val acc: 0.9871
ğŸ•’ Epoch 13/100 | Time: 70.58s | Train Loss: 0.4492 | Val Loss: 0.4950 | Val Acc: 0.9706 | LR: 0.000087 
ğŸ•’ Epoch 14/100 | Time: 70.66s | Train Loss: 0.4390 | Val Loss: 0.4744 | Val Acc: 0.9835 | LR: 0.000084 
ğŸ•’ Epoch 15/100 | Time: 70.69s | Train Loss: 0.4521 | Val Loss: 0.5079 | Val Acc: 0.9614 | LR: 0.000082 
ğŸ•’ Epoch 16/100 | Time: 70.25s | Train Loss: 0.4380 | Val Loss: 0.4888 | Val Acc: 0.9743 | LR: 0.000080 
ğŸ•’ Epoch 17/100 | Time: 70.99s | Train Loss: 0.4408 | Val Loss: 0.4897 | Val Acc: 0.9724 | LR: 0.000077 
ğŸ•’ Epoch 18/100 | Time: 70.09s | Train Loss: 0.4362 | Val Loss: 0.4833 | Val Acc: 0.9816 | LR: 0.000074 
ğŸ•’ Epoch 19/100 | Time: 74.07s | Train Loss: 0.4447 | Val Loss: 0.5115 | Val Acc: 0.9669 | LR: 0.000072 
ğŸ•’ Epoch 20/100 | Time: 94.35s | Train Loss: 0.4336 | Val Loss: 0.4584 | Val Acc: 0.9853 | LR: 0.000069 
ğŸ’¾ Saving best val acc: 0.9853
ğŸ•’ Epoch 21/100 | Time: 94.08s | Train Loss: 0.4327 | Val Loss: 0.4539 | Val Acc: 0.9890 | LR: 0.000066 
ğŸ’¾ Saving best val acc: 0.9890
ğŸ•’ Epoch 22/100 | Time: 95.07s | Train Loss: 0.4253 | Val Loss: 0.4594 | Val Acc: 0.9871 | LR: 0.000063 
ğŸ•’ Epoch 23/100 | Time: 88.86s | Train Loss: 0.4291 | Val Loss: 0.4582 | Val Acc: 0.9871 | LR: 0.000060 
ğŸ•’ Epoch 24/100 | Time: 71.38s | Train Loss: 0.4244 | Val Loss: 0.4574 | Val Acc: 0.9871 | LR: 0.000057 
ğŸ•’ Epoch 25/100 | Time: 70.54s | Train Loss: 0.4263 | Val Loss: 0.4572 | Val Acc: 0.9871 | LR: 0.000054 
ğŸ•’ Epoch 26/100 | Time: 70.69s | Train Loss: 0.4243 | Val Loss: 0.4552 | Val Acc: 0.9890 | LR: 0.000050 
ğŸ•’ Epoch 27/100 | Time: 70.68s | Train Loss: 0.4227 | Val Loss: 0.4534 | Val Acc: 0.9890 | LR: 0.000047 
ğŸ’¾ Saving best val acc: 0.9890
ğŸ•’ Epoch 28/100 | Time: 71.23s | Train Loss: 0.4223 | Val Loss: 0.4519 | Val Acc: 0.9890 | LR: 0.000044 
ğŸ’¾ Saving best val acc: 0.9890
ğŸ•’ Epoch 29/100 | Time: 70.90s | Train Loss: 0.4242 | Val Loss: 0.4565 | Val Acc: 0.9890 | LR: 0.000041 
ğŸ•’ Epoch 30/100 | Time: 70.11s | Train Loss: 0.4250 | Val Loss: 0.4531 | Val Acc: 0.9871 | LR: 0.000038 
ğŸ•’ Epoch 31/100 | Time: 70.64s | Train Loss: 0.4227 | Val Loss: 0.4542 | Val Acc: 0.9871 | LR: 0.000035 
ğŸ•’ Epoch 32/100 | Time: 71.22s | Train Loss: 0.4225 | Val Loss: 0.4520 | Val Acc: 0.9908 | LR: 0.000032 
ğŸ•’ Epoch 33/100 | Time: 71.46s | Train Loss: 0.4227 | Val Loss: 0.4720 | Val Acc: 0.9835 | LR: 0.000029 
ğŸ•’ Epoch 34/100 | Time: 70.11s | Train Loss: 0.4225 | Val Loss: 0.4608 | Val Acc: 0.9871 | LR: 0.000027 
ğŸ•’ Epoch 35/100 | Time: 71.17s | Train Loss: 0.4220 | Val Loss: 0.4618 | Val Acc: 0.9853 | LR: 0.000024 
ğŸ•’ Epoch 36/100 | Time: 71.21s | Train Loss: 0.4219 | Val Loss: 0.4593 | Val Acc: 0.9871 | LR: 0.000021 
ğŸ•’ Epoch 37/100 | Time: 71.31s | Train Loss: 0.4219 | Val Loss: 0.4643 | Val Acc: 0.9835 | LR: 0.000019 
ğŸ•’ Epoch 38/100 | Time: 71.17s | Train Loss: 0.4215 | Val Loss: 0.4629 | Val Acc: 0.9835 | LR: 0.000017 
â¹ï¸ Early stopping triggered.
âœ… Training complete in 2769.07 seconds. Best model loaded.
ğŸ“ Model saved to ./output/models/ConvNeXt+3cbam+no-res+no-norm+dataset1+dataset1.pth
ğŸ“‚ Training metrics plot saved to: output/test/ConvNeXt+3cbam+no-res+no-norm+dataset1/training metric.png
Evaluate model:ConvNeXt+3cbam+no-res+no-norm+dataset1

ğŸ”¥ Test Accuracy: 98.90%

ğŸ“Œ Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    0.9886    0.9943        88
           brown_spot     0.9889    0.9570    0.9727        93
              healthy     0.9789    1.0000    0.9894        93
           leaf_blast     0.9677    0.9890    0.9783        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9890       543
            macro avg     0.9893    0.9891    0.9891       543
         weighted avg     0.9891    0.9890    0.9889       543

ğŸ“‚ Confusion matrix saved to: output/test/ConvNeXt+3cbam+no-res+no-norm+dataset1/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+3cbam+no-res+no-norm+dataset1/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+3cbam+no-res+no-norm+dataset1/misclassified_images.png
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: ConvNeXt+last_cbam+res+norm+dataset1]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
ğŸ•’ Epoch 1/100 | Time: 68.85s | Train Loss: 0.8027 | Val Loss: 0.5549 | Val Acc: 0.9449 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9449
ğŸ•’ Epoch 2/100 | Time: 69.52s | Train Loss: 0.5002 | Val Loss: 0.4923 | Val Acc: 0.9724 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9724
ğŸ•’ Epoch 3/100 | Time: 69.50s | Train Loss: 0.4830 | Val Loss: 0.4783 | Val Acc: 0.9779 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9779
ğŸ•’ Epoch 4/100 | Time: 69.27s | Train Loss: 0.4561 | Val Loss: 0.4715 | Val Acc: 0.9835 | LR: 0.000099 
ğŸ’¾ Saving best val acc: 0.9835
ğŸ•’ Epoch 5/100 | Time: 69.04s | Train Loss: 0.4585 | Val Loss: 0.4793 | Val Acc: 0.9816 | LR: 0.000098 
ğŸ•’ Epoch 6/100 | Time: 68.72s | Train Loss: 0.4462 | Val Loss: 0.5216 | Val Acc: 0.9577 | LR: 0.000098 
ğŸ•’ Epoch 7/100 | Time: 68.90s | Train Loss: 0.4461 | Val Loss: 0.4710 | Val Acc: 0.9853 | LR: 0.000097 
ğŸ’¾ Saving best val acc: 0.9853
ğŸ•’ Epoch 8/100 | Time: 70.37s | Train Loss: 0.4456 | Val Loss: 0.4711 | Val Acc: 0.9798 | LR: 0.000095 
ğŸ•’ Epoch 9/100 | Time: 69.07s | Train Loss: 0.4453 | Val Loss: 0.4646 | Val Acc: 0.9798 | LR: 0.000094 
ğŸ’¾ Saving best val acc: 0.9798
ğŸ•’ Epoch 10/100 | Time: 70.86s | Train Loss: 0.4333 | Val Loss: 0.4669 | Val Acc: 0.9816 | LR: 0.000092 
ğŸ•’ Epoch 11/100 | Time: 70.20s | Train Loss: 0.4345 | Val Loss: 0.4671 | Val Acc: 0.9853 | LR: 0.000091 
ğŸ•’ Epoch 12/100 | Time: 70.31s | Train Loss: 0.4563 | Val Loss: 0.5003 | Val Acc: 0.9743 | LR: 0.000089 
ğŸ•’ Epoch 13/100 | Time: 69.52s | Train Loss: 0.4481 | Val Loss: 0.4767 | Val Acc: 0.9743 | LR: 0.000087 
ğŸ•’ Epoch 14/100 | Time: 69.38s | Train Loss: 0.4390 | Val Loss: 0.4720 | Val Acc: 0.9779 | LR: 0.000084 
ğŸ•’ Epoch 15/100 | Time: 70.20s | Train Loss: 0.4329 | Val Loss: 0.4742 | Val Acc: 0.9798 | LR: 0.000082 
ğŸ•’ Epoch 16/100 | Time: 69.90s | Train Loss: 0.4315 | Val Loss: 0.4651 | Val Acc: 0.9853 | LR: 0.000080 
ğŸ•’ Epoch 17/100 | Time: 69.98s | Train Loss: 0.4281 | Val Loss: 0.4526 | Val Acc: 0.9871 | LR: 0.000077 
ğŸ’¾ Saving best val acc: 0.9871
ğŸ•’ Epoch 18/100 | Time: 69.58s | Train Loss: 0.4229 | Val Loss: 0.4512 | Val Acc: 0.9871 | LR: 0.000074 
ğŸ’¾ Saving best val acc: 0.9871
ğŸ•’ Epoch 19/100 | Time: 70.57s | Train Loss: 0.4228 | Val Loss: 0.4516 | Val Acc: 0.9890 | LR: 0.000072 
ğŸ•’ Epoch 20/100 | Time: 69.81s | Train Loss: 0.4255 | Val Loss: 0.4858 | Val Acc: 0.9743 | LR: 0.000069 
ğŸ•’ Epoch 21/100 | Time: 69.69s | Train Loss: 0.4290 | Val Loss: 0.4601 | Val Acc: 0.9835 | LR: 0.000066 
ğŸ•’ Epoch 22/100 | Time: 70.55s | Train Loss: 0.4390 | Val Loss: 0.4812 | Val Acc: 0.9724 | LR: 0.000063 
ğŸ•’ Epoch 23/100 | Time: 69.54s | Train Loss: 0.4262 | Val Loss: 0.4537 | Val Acc: 0.9853 | LR: 0.000060 
ğŸ•’ Epoch 24/100 | Time: 70.43s | Train Loss: 0.4224 | Val Loss: 0.4619 | Val Acc: 0.9835 | LR: 0.000057 
ğŸ•’ Epoch 25/100 | Time: 69.08s | Train Loss: 0.4229 | Val Loss: 0.4573 | Val Acc: 0.9835 | LR: 0.000054 
ğŸ•’ Epoch 26/100 | Time: 68.82s | Train Loss: 0.4225 | Val Loss: 0.4528 | Val Acc: 0.9890 | LR: 0.000050 
ğŸ•’ Epoch 27/100 | Time: 70.01s | Train Loss: 0.4242 | Val Loss: 0.4716 | Val Acc: 0.9761 | LR: 0.000047 
ğŸ•’ Epoch 28/100 | Time: 70.46s | Train Loss: 0.4222 | Val Loss: 0.4668 | Val Acc: 0.9798 | LR: 0.000044 
â¹ï¸ Early stopping triggered.
âœ… Training complete in 1952.29 seconds. Best model loaded.
ğŸ“ Model saved to ./output/models/ConvNeXt+last_cbam+res+norm+dataset1+dataset1.pth
ğŸ“‚ Training metrics plot saved to: output/test/ConvNeXt+last_cbam+res+norm+dataset1/training metric.png
Evaluate model:ConvNeXt+last_cbam+res+norm+dataset1

ğŸ”¥ Test Accuracy: 98.71%

ğŸ“Œ Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    1.0000    1.0000        88
           brown_spot     0.9674    0.9570    0.9622        93
              healthy     0.9789    1.0000    0.9894        93
           leaf_blast     0.9778    0.9670    0.9724        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9871       543
            macro avg     0.9874    0.9873    0.9873       543
         weighted avg     0.9871    0.9871    0.9871       543

ğŸ“‚ Confusion matrix saved to: output/test/ConvNeXt+last_cbam+res+norm+dataset1/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+last_cbam+res+norm+dataset1/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+last_cbam+res+norm+dataset1/misclassified_images.png
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: ConvNeXt+4cbam+res+dataset1]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
ğŸ•’ Epoch 1/100 | Time: 70.64s | Train Loss: 0.7993 | Val Loss: 0.5322 | Val Acc: 0.9540 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9540
ğŸ•’ Epoch 2/100 | Time: 70.17s | Train Loss: 0.5219 | Val Loss: 0.5522 | Val Acc: 0.9540 | LR: 0.000100 
ğŸ•’ Epoch 3/100 | Time: 69.48s | Train Loss: 0.4736 | Val Loss: 0.4975 | Val Acc: 0.9779 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9779
ğŸ•’ Epoch 4/100 | Time: 71.01s | Train Loss: 0.4651 | Val Loss: 0.4802 | Val Acc: 0.9743 | LR: 0.000099 
ğŸ’¾ Saving best val acc: 0.9743
ğŸ•’ Epoch 5/100 | Time: 70.41s | Train Loss: 0.4462 | Val Loss: 0.4748 | Val Acc: 0.9798 | LR: 0.000098 
ğŸ’¾ Saving best val acc: 0.9798
ğŸ•’ Epoch 6/100 | Time: 71.28s | Train Loss: 0.4521 | Val Loss: 0.4738 | Val Acc: 0.9853 | LR: 0.000098 
ğŸ’¾ Saving best val acc: 0.9853
ğŸ•’ Epoch 7/100 | Time: 70.88s | Train Loss: 0.4392 | Val Loss: 0.4733 | Val Acc: 0.9798 | LR: 0.000097 
ğŸ’¾ Saving best val acc: 0.9798
ğŸ•’ Epoch 8/100 | Time: 70.58s | Train Loss: 0.4345 | Val Loss: 0.4765 | Val Acc: 0.9798 | LR: 0.000095 
ğŸ•’ Epoch 9/100 | Time: 71.34s | Train Loss: 0.4493 | Val Loss: 0.4913 | Val Acc: 0.9706 | LR: 0.000094 
ğŸ•’ Epoch 10/100 | Time: 70.09s | Train Loss: 0.4661 | Val Loss: 0.5047 | Val Acc: 0.9669 | LR: 0.000092 
ğŸ•’ Epoch 11/100 | Time: 70.89s | Train Loss: 0.4629 | Val Loss: 0.4681 | Val Acc: 0.9871 | LR: 0.000091 
ğŸ’¾ Saving best val acc: 0.9871
ğŸ•’ Epoch 12/100 | Time: 71.60s | Train Loss: 0.4532 | Val Loss: 0.4811 | Val Acc: 0.9835 | LR: 0.000089 
ğŸ•’ Epoch 13/100 | Time: 70.68s | Train Loss: 0.4383 | Val Loss: 0.4817 | Val Acc: 0.9724 | LR: 0.000087 
ğŸ•’ Epoch 14/100 | Time: 70.79s | Train Loss: 0.4318 | Val Loss: 0.4590 | Val Acc: 0.9871 | LR: 0.000084 
ğŸ’¾ Saving best val acc: 0.9871
ğŸ•’ Epoch 15/100 | Time: 70.95s | Train Loss: 0.4334 | Val Loss: 0.4769 | Val Acc: 0.9779 | LR: 0.000082 
ğŸ•’ Epoch 16/100 | Time: 70.43s | Train Loss: 0.4267 | Val Loss: 0.4693 | Val Acc: 0.9816 | LR: 0.000080 
ğŸ•’ Epoch 17/100 | Time: 70.79s | Train Loss: 0.4299 | Val Loss: 0.4860 | Val Acc: 0.9761 | LR: 0.000077 
ğŸ•’ Epoch 18/100 | Time: 70.94s | Train Loss: 0.4260 | Val Loss: 0.4670 | Val Acc: 0.9835 | LR: 0.000074 
ğŸ•’ Epoch 19/100 | Time: 70.38s | Train Loss: 0.4378 | Val Loss: 0.5161 | Val Acc: 0.9651 | LR: 0.000072 
ğŸ•’ Epoch 20/100 | Time: 70.79s | Train Loss: 0.4300 | Val Loss: 0.4686 | Val Acc: 0.9853 | LR: 0.000069 
ğŸ•’ Epoch 21/100 | Time: 70.84s | Train Loss: 0.4262 | Val Loss: 0.4624 | Val Acc: 0.9853 | LR: 0.000066 
ğŸ•’ Epoch 22/100 | Time: 71.19s | Train Loss: 0.4321 | Val Loss: 0.4641 | Val Acc: 0.9835 | LR: 0.000063 
ğŸ•’ Epoch 23/100 | Time: 71.87s | Train Loss: 0.4260 | Val Loss: 0.4600 | Val Acc: 0.9853 | LR: 0.000060 
ğŸ•’ Epoch 24/100 | Time: 71.13s | Train Loss: 0.4225 | Val Loss: 0.4604 | Val Acc: 0.9853 | LR: 0.000057 
â¹ï¸ Early stopping triggered.
âœ… Training complete in 1699.28 seconds. Best model loaded.
ğŸ“ Model saved to ./output/models/ConvNeXt+4cbam+res+dataset1+dataset1.pth
ğŸ“‚ Training metrics plot saved to: output/test/ConvNeXt+4cbam+res+dataset1/training metric.png
Evaluate model:ConvNeXt+4cbam+res+dataset1

ğŸ”¥ Test Accuracy: 98.16%

ğŸ“Œ Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    0.9886    0.9943        88
           brown_spot     0.9884    0.9140    0.9497        93
              healthy     0.9688    1.0000    0.9841        93
           leaf_blast     0.9375    0.9890    0.9626        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9816       543
            macro avg     0.9824    0.9819    0.9818       543
         weighted avg     0.9822    0.9816    0.9815       543

ğŸ“‚ Confusion matrix saved to: output/test/ConvNeXt+4cbam+res+dataset1/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+4cbam+res+dataset1/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+4cbam+res+dataset1/misclassified_images.png
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: ConvNeXt+4cbam+res+last-norm+dataset1]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
ğŸ•’ Epoch 1/100 | Time: 69.38s | Train Loss: 0.7487 | Val Loss: 0.5258 | Val Acc: 0.9632 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9632
ğŸ•’ Epoch 2/100 | Time: 69.63s | Train Loss: 0.5181 | Val Loss: 0.5511 | Val Acc: 0.9449 | LR: 0.000100 
ğŸ•’ Epoch 3/100 | Time: 71.42s | Train Loss: 0.4903 | Val Loss: 0.4744 | Val Acc: 0.9779 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9779
ğŸ•’ Epoch 4/100 | Time: 71.28s | Train Loss: 0.4713 | Val Loss: 0.4723 | Val Acc: 0.9816 | LR: 0.000099 
ğŸ’¾ Saving best val acc: 0.9816
ğŸ•’ Epoch 5/100 | Time: 71.17s | Train Loss: 0.4456 | Val Loss: 0.5064 | Val Acc: 0.9614 | LR: 0.000098 
ğŸ•’ Epoch 6/100 | Time: 69.91s | Train Loss: 0.4448 | Val Loss: 0.4747 | Val Acc: 0.9798 | LR: 0.000098 
ğŸ•’ Epoch 7/100 | Time: 70.75s | Train Loss: 0.4405 | Val Loss: 0.4663 | Val Acc: 0.9835 | LR: 0.000097 
ğŸ’¾ Saving best val acc: 0.9835
ğŸ•’ Epoch 8/100 | Time: 70.51s | Train Loss: 0.4304 | Val Loss: 0.4604 | Val Acc: 0.9835 | LR: 0.000095 
ğŸ’¾ Saving best val acc: 0.9835
ğŸ•’ Epoch 9/100 | Time: 70.62s | Train Loss: 0.4509 | Val Loss: 0.4752 | Val Acc: 0.9724 | LR: 0.000094 
ğŸ•’ Epoch 10/100 | Time: 70.84s | Train Loss: 0.4344 | Val Loss: 0.4769 | Val Acc: 0.9798 | LR: 0.000092 
ğŸ•’ Epoch 11/100 | Time: 70.50s | Train Loss: 0.4380 | Val Loss: 0.4845 | Val Acc: 0.9779 | LR: 0.000091 
ğŸ•’ Epoch 12/100 | Time: 71.65s | Train Loss: 0.4379 | Val Loss: 0.4747 | Val Acc: 0.9798 | LR: 0.000089 
ğŸ•’ Epoch 13/100 | Time: 72.11s | Train Loss: 0.4417 | Val Loss: 0.4884 | Val Acc: 0.9706 | LR: 0.000087 
ğŸ•’ Epoch 14/100 | Time: 70.31s | Train Loss: 0.4592 | Val Loss: 0.5189 | Val Acc: 0.9596 | LR: 0.000084 
ğŸ•’ Epoch 15/100 | Time: 71.55s | Train Loss: 0.4409 | Val Loss: 0.4650 | Val Acc: 0.9816 | LR: 0.000082 
ğŸ•’ Epoch 16/100 | Time: 71.81s | Train Loss: 0.4348 | Val Loss: 0.4628 | Val Acc: 0.9853 | LR: 0.000080 
ğŸ•’ Epoch 17/100 | Time: 70.94s | Train Loss: 0.4255 | Val Loss: 0.4614 | Val Acc: 0.9853 | LR: 0.000077 
ğŸ•’ Epoch 18/100 | Time: 70.80s | Train Loss: 0.4236 | Val Loss: 0.4571 | Val Acc: 0.9853 | LR: 0.000074 
ğŸ’¾ Saving best val acc: 0.9853
ğŸ•’ Epoch 19/100 | Time: 71.73s | Train Loss: 0.4273 | Val Loss: 0.4661 | Val Acc: 0.9835 | LR: 0.000072 
ğŸ•’ Epoch 20/100 | Time: 70.92s | Train Loss: 0.4223 | Val Loss: 0.4652 | Val Acc: 0.9835 | LR: 0.000069 
ğŸ•’ Epoch 21/100 | Time: 70.97s | Train Loss: 0.4233 | Val Loss: 0.4636 | Val Acc: 0.9835 | LR: 0.000066 
ğŸ•’ Epoch 22/100 | Time: 70.20s | Train Loss: 0.4237 | Val Loss: 0.4583 | Val Acc: 0.9853 | LR: 0.000063 
ğŸ•’ Epoch 23/100 | Time: 69.32s | Train Loss: 0.4314 | Val Loss: 0.4663 | Val Acc: 0.9816 | LR: 0.000060 
ğŸ•’ Epoch 24/100 | Time: 70.44s | Train Loss: 0.4254 | Val Loss: 0.4630 | Val Acc: 0.9871 | LR: 0.000057 
ğŸ•’ Epoch 25/100 | Time: 70.24s | Train Loss: 0.4252 | Val Loss: 0.4563 | Val Acc: 0.9890 | LR: 0.000054 
ğŸ’¾ Saving best val acc: 0.9890
ğŸ•’ Epoch 26/100 | Time: 71.01s | Train Loss: 0.4247 | Val Loss: 0.4603 | Val Acc: 0.9871 | LR: 0.000050 
ğŸ•’ Epoch 27/100 | Time: 70.17s | Train Loss: 0.4225 | Val Loss: 0.4636 | Val Acc: 0.9871 | LR: 0.000047 
ğŸ•’ Epoch 28/100 | Time: 71.20s | Train Loss: 0.4313 | Val Loss: 0.4736 | Val Acc: 0.9835 | LR: 0.000044 
ğŸ•’ Epoch 29/100 | Time: 70.87s | Train Loss: 0.4236 | Val Loss: 0.4618 | Val Acc: 0.9871 | LR: 0.000041 
ğŸ•’ Epoch 30/100 | Time: 71.32s | Train Loss: 0.4220 | Val Loss: 0.4573 | Val Acc: 0.9871 | LR: 0.000038 
ğŸ•’ Epoch 31/100 | Time: 71.69s | Train Loss: 0.4214 | Val Loss: 0.4558 | Val Acc: 0.9890 | LR: 0.000035 
ğŸ’¾ Saving best val acc: 0.9890
ğŸ•’ Epoch 32/100 | Time: 71.17s | Train Loss: 0.4231 | Val Loss: 0.4562 | Val Acc: 0.9890 | LR: 0.000032 
ğŸ•’ Epoch 33/100 | Time: 70.95s | Train Loss: 0.4225 | Val Loss: 0.4607 | Val Acc: 0.9853 | LR: 0.000029 
ğŸ•’ Epoch 34/100 | Time: 71.21s | Train Loss: 0.4308 | Val Loss: 0.4631 | Val Acc: 0.9798 | LR: 0.000027 
ğŸ•’ Epoch 35/100 | Time: 71.10s | Train Loss: 0.4234 | Val Loss: 0.4634 | Val Acc: 0.9816 | LR: 0.000024 
ğŸ•’ Epoch 36/100 | Time: 71.00s | Train Loss: 0.4233 | Val Loss: 0.4565 | Val Acc: 0.9853 | LR: 0.000021 
ğŸ•’ Epoch 37/100 | Time: 70.92s | Train Loss: 0.4231 | Val Loss: 0.4564 | Val Acc: 0.9890 | LR: 0.000019 
ğŸ•’ Epoch 38/100 | Time: 70.87s | Train Loss: 0.4233 | Val Loss: 0.4648 | Val Acc: 0.9835 | LR: 0.000017 
ğŸ•’ Epoch 39/100 | Time: 71.32s | Train Loss: 0.4216 | Val Loss: 0.4607 | Val Acc: 0.9871 | LR: 0.000014 
ğŸ•’ Epoch 40/100 | Time: 70.10s | Train Loss: 0.4220 | Val Loss: 0.4584 | Val Acc: 0.9835 | LR: 0.000012 
ğŸ•’ Epoch 41/100 | Time: 70.47s | Train Loss: 0.4219 | Val Loss: 0.4685 | Val Acc: 0.9798 | LR: 0.000010 
â¹ï¸ Early stopping triggered.
âœ… Training complete in 2904.49 seconds. Best model loaded.
ğŸ“ Model saved to ./output/models/ConvNeXt+4cbam+res+last-norm+dataset1+dataset1.pth
ğŸ“‚ Training metrics plot saved to: output/test/ConvNeXt+4cbam+res+last-norm+dataset1/training metric.png
Evaluate model:ConvNeXt+4cbam+res+last-norm+dataset1

ğŸ”¥ Test Accuracy: 98.53%

ğŸ“Œ Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    0.9886    0.9943        88
           brown_spot     0.9674    0.9570    0.9622        93
              healthy     0.9688    1.0000    0.9841        93
           leaf_blast     0.9778    0.9670    0.9724        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9853       543
            macro avg     0.9857    0.9854    0.9855       543
         weighted avg     0.9853    0.9853    0.9852       543

ğŸ“‚ Confusion matrix saved to: output/test/ConvNeXt+4cbam+res+last-norm+dataset1/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+4cbam+res+last-norm+dataset1/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+4cbam+res+last-norm+dataset1/misclassified_images.png


Traceback (most recent call last):
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/train.py", line 11, in <module>
    from load_data import get_kfold_loaders, num_classes  # âœ… using new loader function
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ImportError: cannot import name 'get_kfold_loaders' from 'load_data' (/media/data3/users/datlht/Rice_leaf_disease_detection/load_data.py)
ğŸš€ Starting training with 5-Fold Cross-Validation for model: ConvNeXt+4cbam+dataset1
/media/data3/users/datlht/Rice_leaf_disease_detection/load_data.py:78: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/media/data3/users/datlht/Rice_leaf_disease_detection/load_data.py:81: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from font(s) DejaVu Sans.
  plt.savefig(plot_path)
âœ… Saved fold class distribution plot to: output/fold_class_distribution.png

ğŸ“‚ Fold 1/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7662 | Val Loss: 0.5814 | Val Acc: 0.9385
ğŸ’¾ Best model updated (val acc: 0.9385)
ğŸ•’ Epoch 2/100 | Train Loss: 0.4880 | Val Loss: 0.5168 | Val Acc: 0.9446
ğŸ’¾ Best model updated (val acc: 0.9446)
ğŸ•’ Epoch 3/100 | Train Loss: 0.4353 | Val Loss: 0.4679 | Val Acc: 0.9815
ğŸ’¾ Best model updated (val acc: 0.9815)
ğŸ•’ Epoch 4/100 | Train Loss: 0.4326 | Val Loss: 0.4380 | Val Acc: 0.9969
ğŸ’¾ Best model updated (val acc: 0.9969)
ğŸ•’ Epoch 5/100 | Train Loss: 0.4230 | Val Loss: 0.4484 | Val Acc: 0.9846
ğŸ•’ Epoch 6/100 | Train Loss: 0.4219 | Val Loss: 0.4477 | Val Acc: 0.9877
ğŸ•’ Epoch 7/100 | Train Loss: 0.4217 | Val Loss: 0.4481 | Val Acc: 0.9877
ğŸ•’ Epoch 8/100 | Train Loss: 0.4217 | Val Loss: 0.4491 | Val Acc: 0.9877
ğŸ•’ Epoch 9/100 | Train Loss: 0.4214 | Val Loss: 0.4492 | Val Acc: 0.9846
ğŸ•’ Epoch 10/100 | Train Loss: 0.4214 | Val Loss: 0.4499 | Val Acc: 0.9846
ğŸ•’ Epoch 11/100 | Train Loss: 0.4215 | Val Loss: 0.4509 | Val Acc: 0.9846
ğŸ•’ Epoch 12/100 | Train Loss: 0.4213 | Val Loss: 0.4519 | Val Acc: 0.9846
ğŸ•’ Epoch 13/100 | Train Loss: 0.4214 | Val Loss: 0.4522 | Val Acc: 0.9846
ğŸ•’ Epoch 14/100 | Train Loss: 0.4212 | Val Loss: 0.4527 | Val Acc: 0.9846
â¹ï¸ Early stopping.
âœ… Fold 1 complete. Saved: ./output/models/ConvNeXt+4cbam+dataset1+dataset1_fold1.pth

ğŸ“‚ Fold 2/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7506 | Val Loss: 0.5050 | Val Acc: 0.9723
ğŸ’¾ Best model updated (val acc: 0.9723)
ğŸ•’ Epoch 2/100 | Train Loss: 0.4821 | Val Loss: 0.5232 | Val Acc: 0.9538
ğŸ•’ Epoch 3/100 | Train Loss: 0.4651 | Val Loss: 0.5118 | Val Acc: 0.9569
ğŸ•’ Epoch 4/100 | Train Loss: 0.4371 | Val Loss: 0.4761 | Val Acc: 0.9815
ğŸ’¾ Best model updated (val acc: 0.9815)
ğŸ•’ Epoch 5/100 | Train Loss: 0.4326 | Val Loss: 0.4543 | Val Acc: 0.9877
ğŸ’¾ Best model updated (val acc: 0.9877)
ğŸ•’ Epoch 6/100 | Train Loss: 0.4265 | Val Loss: 0.5085 | Val Acc: 0.9631
ğŸ•’ Epoch 7/100 | Train Loss: 0.4390 | Val Loss: 0.4640 | Val Acc: 0.9815
ğŸ•’ Epoch 8/100 | Train Loss: 0.4342 | Val Loss: 0.5517 | Val Acc: 0.9415
ğŸ•’ Epoch 9/100 | Train Loss: 0.4534 | Val Loss: 0.4557 | Val Acc: 0.9815
ğŸ•’ Epoch 10/100 | Train Loss: 0.4250 | Val Loss: 0.4488 | Val Acc: 0.9846
ğŸ’¾ Best model updated (val acc: 0.9846)
ğŸ•’ Epoch 11/100 | Train Loss: 0.4229 | Val Loss: 0.4569 | Val Acc: 0.9846
ğŸ•’ Epoch 12/100 | Train Loss: 0.4218 | Val Loss: 0.4563 | Val Acc: 0.9846
ğŸ•’ Epoch 13/100 | Train Loss: 0.4215 | Val Loss: 0.4558 | Val Acc: 0.9846
ğŸ•’ Epoch 14/100 | Train Loss: 0.4216 | Val Loss: 0.4557 | Val Acc: 0.9846
ğŸ•’ Epoch 15/100 | Train Loss: 0.4213 | Val Loss: 0.4555 | Val Acc: 0.9846
ğŸ•’ Epoch 16/100 | Train Loss: 0.4214 | Val Loss: 0.4554 | Val Acc: 0.9846
ğŸ•’ Epoch 17/100 | Train Loss: 0.4214 | Val Loss: 0.4555 | Val Acc: 0.9846
ğŸ•’ Epoch 18/100 | Train Loss: 0.4213 | Val Loss: 0.4556 | Val Acc: 0.9846
ğŸ•’ Epoch 19/100 | Train Loss: 0.4214 | Val Loss: 0.4556 | Val Acc: 0.9846
ğŸ•’ Epoch 20/100 | Train Loss: 0.4213 | Val Loss: 0.4555 | Val Acc: 0.9846
â¹ï¸ Early stopping.
âœ… Fold 2 complete. Saved: ./output/models/ConvNeXt+4cbam+dataset1+dataset1_fold2.pth

ğŸ“‚ Fold 3/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7834 | Val Loss: 0.6012 | Val Acc: 0.9385
ğŸ’¾ Best model updated (val acc: 0.9385)
ğŸ•’ Epoch 2/100 | Train Loss: 0.4840 | Val Loss: 0.4720 | Val Acc: 0.9723
ğŸ’¾ Best model updated (val acc: 0.9723)
ğŸ•’ Epoch 3/100 | Train Loss: 0.4476 | Val Loss: 0.5106 | Val Acc: 0.9569
ğŸ•’ Epoch 4/100 | Train Loss: 0.4361 | Val Loss: 0.4861 | Val Acc: 0.9754
ğŸ•’ Epoch 5/100 | Train Loss: 0.4349 | Val Loss: 0.4705 | Val Acc: 0.9846
ğŸ’¾ Best model updated (val acc: 0.9846)
ğŸ•’ Epoch 6/100 | Train Loss: 0.4270 | Val Loss: 0.4880 | Val Acc: 0.9754
ğŸ•’ Epoch 7/100 | Train Loss: 0.4231 | Val Loss: 0.4485 | Val Acc: 0.9846
ğŸ’¾ Best model updated (val acc: 0.9846)
ğŸ•’ Epoch 8/100 | Train Loss: 0.4219 | Val Loss: 0.4472 | Val Acc: 0.9877
ğŸ’¾ Best model updated (val acc: 0.9877)
ğŸ•’ Epoch 9/100 | Train Loss: 0.4214 | Val Loss: 0.4468 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 10/100 | Train Loss: 0.4214 | Val Loss: 0.4467 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 11/100 | Train Loss: 0.4214 | Val Loss: 0.4466 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 12/100 | Train Loss: 0.4214 | Val Loss: 0.4465 | Val Acc: 0.9877
ğŸ’¾ Best model updated (val acc: 0.9877)
ğŸ•’ Epoch 13/100 | Train Loss: 0.4212 | Val Loss: 0.4467 | Val Acc: 0.9877
ğŸ•’ Epoch 14/100 | Train Loss: 0.4213 | Val Loss: 0.4468 | Val Acc: 0.9877
ğŸ•’ Epoch 15/100 | Train Loss: 0.4212 | Val Loss: 0.4468 | Val Acc: 0.9877
ğŸ•’ Epoch 16/100 | Train Loss: 0.4214 | Val Loss: 0.4466 | Val Acc: 0.9877
ğŸ•’ Epoch 17/100 | Train Loss: 0.4213 | Val Loss: 0.4468 | Val Acc: 0.9877
ğŸ•’ Epoch 18/100 | Train Loss: 0.4212 | Val Loss: 0.4467 | Val Acc: 0.9877
ğŸ•’ Epoch 19/100 | Train Loss: 0.4212 | Val Loss: 0.4468 | Val Acc: 0.9877
ğŸ•’ Epoch 20/100 | Train Loss: 0.4212 | Val Loss: 0.4468 | Val Acc: 0.9877
ğŸ•’ Epoch 21/100 | Train Loss: 0.4213 | Val Loss: 0.4467 | Val Acc: 0.9877
ğŸ•’ Epoch 22/100 | Train Loss: 0.4213 | Val Loss: 0.4469 | Val Acc: 0.9877
â¹ï¸ Early stopping.
âœ… Fold 3 complete. Saved: ./output/models/ConvNeXt+4cbam+dataset1+dataset1_fold3.pth

ğŸ“‚ Fold 4/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7433 | Val Loss: 0.5066 | Val Acc: 0.9660
ğŸ’¾ Best model updated (val acc: 0.9660)
ğŸ•’ Epoch 2/100 | Train Loss: 0.5082 | Val Loss: 0.4852 | Val Acc: 0.9691
ğŸ’¾ Best model updated (val acc: 0.9691)
ğŸ•’ Epoch 3/100 | Train Loss: 0.4329 | Val Loss: 0.4686 | Val Acc: 0.9784
ğŸ’¾ Best model updated (val acc: 0.9784)
ğŸ•’ Epoch 4/100 | Train Loss: 0.4234 | Val Loss: 0.4604 | Val Acc: 0.9815
ğŸ’¾ Best model updated (val acc: 0.9815)
ğŸ•’ Epoch 5/100 | Train Loss: 0.4223 | Val Loss: 0.4621 | Val Acc: 0.9815
ğŸ•’ Epoch 6/100 | Train Loss: 0.4218 | Val Loss: 0.4619 | Val Acc: 0.9815
ğŸ•’ Epoch 7/100 | Train Loss: 0.4216 | Val Loss: 0.4617 | Val Acc: 0.9815
ğŸ•’ Epoch 8/100 | Train Loss: 0.4215 | Val Loss: 0.4621 | Val Acc: 0.9815
ğŸ•’ Epoch 9/100 | Train Loss: 0.4214 | Val Loss: 0.4618 | Val Acc: 0.9815
ğŸ•’ Epoch 10/100 | Train Loss: 0.4213 | Val Loss: 0.4618 | Val Acc: 0.9815
ğŸ•’ Epoch 11/100 | Train Loss: 0.4213 | Val Loss: 0.4619 | Val Acc: 0.9815
ğŸ•’ Epoch 12/100 | Train Loss: 0.4213 | Val Loss: 0.4621 | Val Acc: 0.9815
ğŸ•’ Epoch 13/100 | Train Loss: 0.4213 | Val Loss: 0.4622 | Val Acc: 0.9815
ğŸ•’ Epoch 14/100 | Train Loss: 0.4214 | Val Loss: 0.4619 | Val Acc: 0.9815
â¹ï¸ Early stopping.
âœ… Fold 4 complete. Saved: ./output/models/ConvNeXt+4cbam+dataset1+dataset1_fold4.pth

ğŸ“‚ Fold 5/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7716 | Val Loss: 0.5519 | Val Acc: 0.9414
ğŸ’¾ Best model updated (val acc: 0.9414)
ğŸ•’ Epoch 2/100 | Train Loss: 0.4771 | Val Loss: 0.4836 | Val Acc: 0.9660
ğŸ’¾ Best model updated (val acc: 0.9660)
ğŸ•’ Epoch 3/100 | Train Loss: 0.4357 | Val Loss: 0.5182 | Val Acc: 0.9537
ğŸ•’ Epoch 4/100 | Train Loss: 0.4290 | Val Loss: 0.4799 | Val Acc: 0.9784
ğŸ’¾ Best model updated (val acc: 0.9784)
ğŸ•’ Epoch 5/100 | Train Loss: 0.4236 | Val Loss: 0.4763 | Val Acc: 0.9815
ğŸ’¾ Best model updated (val acc: 0.9815)
ğŸ•’ Epoch 6/100 | Train Loss: 0.4243 | Val Loss: 0.5285 | Val Acc: 0.9568
ğŸ•’ Epoch 7/100 | Train Loss: 0.4457 | Val Loss: 0.5004 | Val Acc: 0.9691
ğŸ•’ Epoch 8/100 | Train Loss: 0.4911 | Val Loss: 0.7285 | Val Acc: 0.8673
ğŸ•’ Epoch 9/100 | Train Loss: 0.4637 | Val Loss: 0.5166 | Val Acc: 0.9537
ğŸ•’ Epoch 10/100 | Train Loss: 0.4375 | Val Loss: 0.4784 | Val Acc: 0.9784
ğŸ•’ Epoch 11/100 | Train Loss: 0.4245 | Val Loss: 0.4935 | Val Acc: 0.9722
ğŸ•’ Epoch 12/100 | Train Loss: 0.4221 | Val Loss: 0.4789 | Val Acc: 0.9784
ğŸ•’ Epoch 13/100 | Train Loss: 0.4216 | Val Loss: 0.4784 | Val Acc: 0.9784
ğŸ•’ Epoch 14/100 | Train Loss: 0.4215 | Val Loss: 0.4780 | Val Acc: 0.9784
ğŸ•’ Epoch 15/100 | Train Loss: 0.4215 | Val Loss: 0.4779 | Val Acc: 0.9784
â¹ï¸ Early stopping.
âœ… Fold 5 complete. Saved: ./output/models/ConvNeXt+4cbam+dataset1+dataset1_fold5.pth
Traceback (most recent call last):
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/train.py", line 114, in <module>
    plot_training_metrics(all_fold_train_losses, all_fold_val_losses, all_fold_train_accs, all_fold_val_accs, kfold=KFOLD_SPLITS)
TypeError: plot_training_metrics() got an unexpected keyword argument 'kfold'
ğŸš€ Evaluating 5 fold models on test set

ğŸ“‚ Evaluating Fold 1
ğŸ“Š Fold 1 Metrics:
   - Accuracy: 0.9797
   - Precision: 0.9799
   - Recall: 0.9801
   - F1 Score: 0.9799

ğŸ“‚ Evaluating Fold 2
ğŸ“Š Fold 2 Metrics:
   - Accuracy: 0.9705
   - Precision: 0.9709
   - Recall: 0.9710
   - F1 Score: 0.9708

ğŸ“‚ Evaluating Fold 3
ğŸ“Š Fold 3 Metrics:
   - Accuracy: 0.9816
   - Precision: 0.9821
   - Recall: 0.9818
   - F1 Score: 0.9818

ğŸ“‚ Evaluating Fold 4
ğŸ“Š Fold 4 Metrics:
   - Accuracy: 0.9761
   - Precision: 0.9765
   - Recall: 0.9764
   - F1 Score: 0.9764

ğŸ“‚ Evaluating Fold 5
ğŸ“Š Fold 5 Metrics:
   - Accuracy: 0.9816
   - Precision: 0.9821
   - Recall: 0.9818
   - F1 Score: 0.9818

ğŸ§¾ Classification Report for ConvNeXt+4cbam+dataset1 (Majority Vote from 5 folds):

                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    1.0000    1.0000        88
           brown_spot     0.9778    0.9462    0.9617        93
              healthy     0.9688    1.0000    0.9841        93
           leaf_blast     0.9778    0.9670    0.9724        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     0.9888    1.0000    0.9944        88

             accuracy                         0.9853       543
            macro avg     0.9855    0.9855    0.9854       543
         weighted avg     0.9853    0.9853    0.9852       543

ğŸ”¢ Confusion Matrix:
 [[88  0  0  0  0  0]
 [ 0 88  2  2  0  1]
 [ 0  0 93  0  0  0]
 [ 0  2  1 88  0  0]
 [ 0  0  0  0 90  0]
 [ 0  0  0  0  0 88]]

ğŸ“Š Average Metrics Across All Folds:
   - Accuracy: 0.9779
   - Precision: 0.9783
   - Recall: 0.9782
   - F1 Score: 0.9781
ğŸš€ Starting training with 5-Fold Cross-Validation for model: ConvNeXt+4cbam+dataset1_kfold
/media/data3/users/datlht/Rice_leaf_disease_detection/load_data.py:78: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/media/data3/users/datlht/Rice_leaf_disease_detection/load_data.py:81: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from font(s) DejaVu Sans.
  plt.savefig(plot_path)
âœ… Saved fold class distribution plot to: output/fold_class_distribution.png

ğŸ“‚ Fold 1/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.6968 | Val Loss: 0.5085 | Val Acc: 0.9631
ğŸ’¾ Best model updated (val acc: 0.9631)
ğŸ•’ Epoch 2/100 | Train Loss: 0.4840 | Val Loss: 0.4917 | Val Acc: 0.9677
ğŸ’¾ Best model updated (val acc: 0.9677)
ğŸ•’ Epoch 3/100 | Train Loss: 0.4389 | Val Loss: 0.4561 | Val Acc: 0.9862
ğŸ’¾ Best model updated (val acc: 0.9862)
ğŸ•’ Epoch 4/100 | Train Loss: 0.4562 | Val Loss: 0.5424 | Val Acc: 0.9493
ğŸ•’ Epoch 5/100 | Train Loss: 0.4374 | Val Loss: 0.4908 | Val Acc: 0.9770
ğŸ•’ Epoch 6/100 | Train Loss: 0.4323 | Val Loss: 0.4460 | Val Acc: 0.9839
ğŸ’¾ Best model updated (val acc: 0.9839)
ğŸ•’ Epoch 7/100 | Train Loss: 0.4228 | Val Loss: 0.4454 | Val Acc: 0.9839
ğŸ’¾ Best model updated (val acc: 0.9839)
ğŸ•’ Epoch 8/100 | Train Loss: 0.4217 | Val Loss: 0.4471 | Val Acc: 0.9839
ğŸ•’ Epoch 9/100 | Train Loss: 0.4215 | Val Loss: 0.4481 | Val Acc: 0.9862
ğŸ•’ Epoch 10/100 | Train Loss: 0.4214 | Val Loss: 0.4479 | Val Acc: 0.9862
ğŸ•’ Epoch 11/100 | Train Loss: 0.4214 | Val Loss: 0.4484 | Val Acc: 0.9862
ğŸ•’ Epoch 12/100 | Train Loss: 0.4213 | Val Loss: 0.4487 | Val Acc: 0.9862
ğŸ•’ Epoch 13/100 | Train Loss: 0.4213 | Val Loss: 0.4492 | Val Acc: 0.9862
ğŸ•’ Epoch 14/100 | Train Loss: 0.4213 | Val Loss: 0.4493 | Val Acc: 0.9862
ğŸ•’ Epoch 15/100 | Train Loss: 0.4213 | Val Loss: 0.4494 | Val Acc: 0.9862
ğŸ•’ Epoch 16/100 | Train Loss: 0.4212 | Val Loss: 0.4500 | Val Acc: 0.9862
ğŸ•’ Epoch 17/100 | Train Loss: 0.4212 | Val Loss: 0.4504 | Val Acc: 0.9862
â¹ï¸ Early stopping.
âœ… Fold 1 complete. Saved: ./output/models/ConvNeXt+4cbam+dataset1_kfold+dataset1_kfold_fold1.pth

ğŸ“‚ Fold 2/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7128 | Val Loss: 0.5068 | Val Acc: 0.9654
ğŸ’¾ Best model updated (val acc: 0.9654)
ğŸ•’ Epoch 2/100 | Train Loss: 0.4719 | Val Loss: 0.4915 | Val Acc: 0.9724
ğŸ’¾ Best model updated (val acc: 0.9724)
ğŸ•’ Epoch 3/100 | Train Loss: 0.4407 | Val Loss: 0.4982 | Val Acc: 0.9677
ğŸ•’ Epoch 4/100 | Train Loss: 0.4387 | Val Loss: 0.4729 | Val Acc: 0.9770
ğŸ’¾ Best model updated (val acc: 0.9770)
ğŸ•’ Epoch 5/100 | Train Loss: 0.4226 | Val Loss: 0.4627 | Val Acc: 0.9793
ğŸ’¾ Best model updated (val acc: 0.9793)
ğŸ•’ Epoch 6/100 | Train Loss: 0.4218 | Val Loss: 0.4635 | Val Acc: 0.9793
ğŸ•’ Epoch 7/100 | Train Loss: 0.4216 | Val Loss: 0.4643 | Val Acc: 0.9793
ğŸ•’ Epoch 8/100 | Train Loss: 0.4215 | Val Loss: 0.4646 | Val Acc: 0.9793
ğŸ•’ Epoch 9/100 | Train Loss: 0.4214 | Val Loss: 0.4646 | Val Acc: 0.9793
ğŸ•’ Epoch 10/100 | Train Loss: 0.4214 | Val Loss: 0.4652 | Val Acc: 0.9793
ğŸ•’ Epoch 11/100 | Train Loss: 0.4213 | Val Loss: 0.4653 | Val Acc: 0.9793
ğŸ•’ Epoch 12/100 | Train Loss: 0.4213 | Val Loss: 0.4657 | Val Acc: 0.9793
ğŸ•’ Epoch 13/100 | Train Loss: 0.4213 | Val Loss: 0.4658 | Val Acc: 0.9793
ğŸ•’ Epoch 14/100 | Train Loss: 0.4213 | Val Loss: 0.4659 | Val Acc: 0.9793
ğŸ•’ Epoch 15/100 | Train Loss: 0.4213 | Val Loss: 0.4661 | Val Acc: 0.9793
â¹ï¸ Early stopping.
âœ… Fold 2 complete. Saved: ./output/models/ConvNeXt+4cbam+dataset1_kfold+dataset1_kfold_fold2.pth

ğŸ“‚ Fold 3/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7021 | Val Loss: 0.5188 | Val Acc: 0.9515
ğŸ’¾ Best model updated (val acc: 0.9515)
ğŸ•’ Epoch 2/100 | Train Loss: 0.4756 | Val Loss: 0.4716 | Val Acc: 0.9815
ğŸ’¾ Best model updated (val acc: 0.9815)
ğŸ•’ Epoch 3/100 | Train Loss: 0.4516 | Val Loss: 0.4630 | Val Acc: 0.9838
ğŸ’¾ Best model updated (val acc: 0.9838)
ğŸ•’ Epoch 4/100 | Train Loss: 0.4322 | Val Loss: 0.4698 | Val Acc: 0.9792
ğŸ•’ Epoch 5/100 | Train Loss: 0.4277 | Val Loss: 0.4461 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 6/100 | Train Loss: 0.4276 | Val Loss: 0.4614 | Val Acc: 0.9861
ğŸ•’ Epoch 7/100 | Train Loss: 0.4234 | Val Loss: 0.4581 | Val Acc: 0.9838
ğŸ•’ Epoch 8/100 | Train Loss: 0.4452 | Val Loss: 0.4974 | Val Acc: 0.9746
ğŸ•’ Epoch 9/100 | Train Loss: 0.4636 | Val Loss: 0.5135 | Val Acc: 0.9607
ğŸ•’ Epoch 10/100 | Train Loss: 0.4599 | Val Loss: 0.4481 | Val Acc: 0.9908
ğŸ•’ Epoch 11/100 | Train Loss: 0.4227 | Val Loss: 0.4452 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 12/100 | Train Loss: 0.4217 | Val Loss: 0.4422 | Val Acc: 0.9931
ğŸ’¾ Best model updated (val acc: 0.9931)
ğŸ•’ Epoch 13/100 | Train Loss: 0.4215 | Val Loss: 0.4424 | Val Acc: 0.9931
ğŸ•’ Epoch 14/100 | Train Loss: 0.4215 | Val Loss: 0.4424 | Val Acc: 0.9931
ğŸ•’ Epoch 15/100 | Train Loss: 0.4214 | Val Loss: 0.4424 | Val Acc: 0.9931
ğŸ•’ Epoch 16/100 | Train Loss: 0.4214 | Val Loss: 0.4425 | Val Acc: 0.9931
ğŸ•’ Epoch 17/100 | Train Loss: 0.4213 | Val Loss: 0.4423 | Val Acc: 0.9931
ğŸ•’ Epoch 18/100 | Train Loss: 0.4213 | Val Loss: 0.4424 | Val Acc: 0.9931
ğŸ•’ Epoch 19/100 | Train Loss: 0.4213 | Val Loss: 0.4424 | Val Acc: 0.9931
ğŸ•’ Epoch 20/100 | Train Loss: 0.4212 | Val Loss: 0.4424 | Val Acc: 0.9931
ğŸ•’ Epoch 21/100 | Train Loss: 0.4213 | Val Loss: 0.4424 | Val Acc: 0.9931
ğŸ•’ Epoch 22/100 | Train Loss: 0.4213 | Val Loss: 0.4425 | Val Acc: 0.9931
â¹ï¸ Early stopping.
âœ… Fold 3 complete. Saved: ./output/models/ConvNeXt+4cbam+dataset1_kfold+dataset1_kfold_fold3.pth

ğŸ“‚ Fold 4/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7113 | Val Loss: 0.5148 | Val Acc: 0.9538
ğŸ’¾ Best model updated (val acc: 0.9538)
ğŸ•’ Epoch 2/100 | Train Loss: 0.4632 | Val Loss: 0.4810 | Val Acc: 0.9746
ğŸ’¾ Best model updated (val acc: 0.9746)
ğŸ•’ Epoch 3/100 | Train Loss: 0.4344 | Val Loss: 0.5072 | Val Acc: 0.9607
ğŸ•’ Epoch 4/100 | Train Loss: 0.4503 | Val Loss: 0.5079 | Val Acc: 0.9630
ğŸ•’ Epoch 5/100 | Train Loss: 0.4398 | Val Loss: 0.4835 | Val Acc: 0.9723
ğŸ•’ Epoch 6/100 | Train Loss: 0.4368 | Val Loss: 0.4918 | Val Acc: 0.9746
ğŸ•’ Epoch 7/100 | Train Loss: 0.4307 | Val Loss: 0.4587 | Val Acc: 0.9769
ğŸ’¾ Best model updated (val acc: 0.9769)
ğŸ•’ Epoch 8/100 | Train Loss: 0.4228 | Val Loss: 0.4600 | Val Acc: 0.9815
ğŸ•’ Epoch 9/100 | Train Loss: 0.4287 | Val Loss: 0.4733 | Val Acc: 0.9769
ğŸ•’ Epoch 10/100 | Train Loss: 0.4282 | Val Loss: 0.4611 | Val Acc: 0.9861
ğŸ•’ Epoch 11/100 | Train Loss: 0.4541 | Val Loss: 0.4762 | Val Acc: 0.9769
ğŸ•’ Epoch 12/100 | Train Loss: 0.4250 | Val Loss: 0.6612 | Val Acc: 0.9122
ğŸ•’ Epoch 13/100 | Train Loss: 0.4585 | Val Loss: 0.4750 | Val Acc: 0.9815
ğŸ•’ Epoch 14/100 | Train Loss: 0.4240 | Val Loss: 0.4678 | Val Acc: 0.9792
ğŸ•’ Epoch 15/100 | Train Loss: 0.4217 | Val Loss: 0.4663 | Val Acc: 0.9792
ğŸ•’ Epoch 16/100 | Train Loss: 0.4214 | Val Loss: 0.4667 | Val Acc: 0.9792
ğŸ•’ Epoch 17/100 | Train Loss: 0.4214 | Val Loss: 0.4676 | Val Acc: 0.9792
â¹ï¸ Early stopping.
âœ… Fold 4 complete. Saved: ./output/models/ConvNeXt+4cbam+dataset1_kfold+dataset1_kfold_fold4.pth

ğŸ“‚ Fold 5/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7164 | Val Loss: 0.5222 | Val Acc: 0.9584
ğŸ’¾ Best model updated (val acc: 0.9584)
ğŸ•’ Epoch 2/100 | Train Loss: 0.4828 | Val Loss: 0.4694 | Val Acc: 0.9792
ğŸ’¾ Best model updated (val acc: 0.9792)
ğŸ•’ Epoch 3/100 | Train Loss: 0.4440 | Val Loss: 0.4601 | Val Acc: 0.9838
ğŸ’¾ Best model updated (val acc: 0.9838)
ğŸ•’ Epoch 4/100 | Train Loss: 0.4293 | Val Loss: 0.4543 | Val Acc: 0.9838
ğŸ’¾ Best model updated (val acc: 0.9838)
ğŸ•’ Epoch 5/100 | Train Loss: 0.4322 | Val Loss: 0.4599 | Val Acc: 0.9792
ğŸ•’ Epoch 6/100 | Train Loss: 0.4259 | Val Loss: 0.4541 | Val Acc: 0.9861
ğŸ’¾ Best model updated (val acc: 0.9861)
ğŸ•’ Epoch 7/100 | Train Loss: 0.4219 | Val Loss: 0.4496 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 8/100 | Train Loss: 0.4215 | Val Loss: 0.4497 | Val Acc: 0.9908
ğŸ•’ Epoch 9/100 | Train Loss: 0.4214 | Val Loss: 0.4500 | Val Acc: 0.9908
ğŸ•’ Epoch 10/100 | Train Loss: 0.4214 | Val Loss: 0.4503 | Val Acc: 0.9908
ğŸ•’ Epoch 11/100 | Train Loss: 0.4213 | Val Loss: 0.4503 | Val Acc: 0.9908
ğŸ•’ Epoch 12/100 | Train Loss: 0.4213 | Val Loss: 0.4505 | Val Acc: 0.9885
ğŸ•’ Epoch 13/100 | Train Loss: 0.4213 | Val Loss: 0.4506 | Val Acc: 0.9885
ğŸ•’ Epoch 14/100 | Train Loss: 0.4212 | Val Loss: 0.4508 | Val Acc: 0.9885
ğŸ•’ Epoch 15/100 | Train Loss: 0.4212 | Val Loss: 0.4508 | Val Acc: 0.9885
ğŸ•’ Epoch 16/100 | Train Loss: 0.4213 | Val Loss: 0.4507 | Val Acc: 0.9908
ğŸ•’ Epoch 17/100 | Train Loss: 0.4212 | Val Loss: 0.4509 | Val Acc: 0.9885
â¹ï¸ Early stopping.
âœ… Fold 5 complete. Saved: ./output/models/ConvNeXt+4cbam+dataset1_kfold+dataset1_kfold_fold5.pth
ğŸ“‚ Training metrics plot saved for Fold 1: output/test/fold_1/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 2: output/test/fold_2/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 3: output/test/fold_3/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 4: output/test/fold_4/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 5: output/test/fold_5/training_metrics.png
ğŸ‰ All folds completed.
ğŸš€ Evaluating 5 fold models on test set

ğŸ“‚ Evaluating Fold 1
ğŸ“Š Fold 1 Metrics:
   - Accuracy: 0.9834
   - Precision: 0.9837
   - Recall: 0.9837
   - F1 Score: 0.9837

ğŸ“‚ Evaluating Fold 2
ğŸ“Š Fold 2 Metrics:
   - Accuracy: 0.9853
   - Precision: 0.9856
   - Recall: 0.9855
   - F1 Score: 0.9855

ğŸ“‚ Evaluating Fold 3
ğŸ“Š Fold 3 Metrics:
   - Accuracy: 0.9871
   - Precision: 0.9873
   - Recall: 0.9873
   - F1 Score: 0.9873

ğŸ“‚ Evaluating Fold 4
ğŸ“Š Fold 4 Metrics:
   - Accuracy: 0.9797
   - Precision: 0.9805
   - Recall: 0.9800
   - F1 Score: 0.9799

ğŸ“‚ Evaluating Fold 5
ğŸ“Š Fold 5 Metrics:
   - Accuracy: 0.9853
   - Precision: 0.9856
   - Recall: 0.9855
   - F1 Score: 0.9855

ğŸ§¾ Classification Report for ConvNeXt+4cbam+dataset1_kfold (Majority Vote from 5 folds):

                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    1.0000    1.0000        88
           brown_spot     0.9783    0.9677    0.9730        93
              healthy     0.9789    1.0000    0.9894        93
           leaf_blast     0.9778    0.9670    0.9724        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9890       543
            macro avg     0.9892    0.9891    0.9891       543
         weighted avg     0.9889    0.9890    0.9889       543

ğŸ”¢ Confusion Matrix:
 [[88  0  0  0  0  0]
 [ 0 90  1  2  0  0]
 [ 0  0 93  0  0  0]
 [ 0  2  1 88  0  0]
 [ 0  0  0  0 90  0]
 [ 0  0  0  0  0 88]]

ğŸ“Š Average Metrics Across All Folds:
   - Accuracy: 0.9842
   - Precision: 0.9845
   - Recall: 0.9844
   - F1 Score: 0.9844
ğŸš€ Starting training with 5-Fold Cross-Validation for model: ConvNeXt+4cbam+v2+dataset1_kfold
/media/data3/users/datlht/Rice_leaf_disease_detection/load_data.py:81: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/media/data3/users/datlht/Rice_leaf_disease_detection/load_data.py:84: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from font(s) DejaVu Sans.
  plt.savefig(plot_path)
âœ… Saved fold class distribution plot to: output/fold_class_distribution.png

ğŸ“‚ Fold 1/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7753 | Val Loss: 0.5237 | Val Acc: 0.9700
ğŸ’¾ Best model updated (val acc: 0.9700)
ğŸ•’ Epoch 2/100 | Train Loss: 0.5046 | Val Loss: 0.4690 | Val Acc: 0.9862
ğŸ’¾ Best model updated (val acc: 0.9862)
ğŸ•’ Epoch 3/100 | Train Loss: 0.4951 | Val Loss: 0.4747 | Val Acc: 0.9816
ğŸ•’ Epoch 4/100 | Train Loss: 0.4643 | Val Loss: 0.4901 | Val Acc: 0.9654
ğŸ•’ Epoch 5/100 | Train Loss: 0.4503 | Val Loss: 0.4591 | Val Acc: 0.9862
ğŸ’¾ Best model updated (val acc: 0.9862)
ğŸ•’ Epoch 6/100 | Train Loss: 0.4702 | Val Loss: 0.4678 | Val Acc: 0.9816
ğŸ•’ Epoch 7/100 | Train Loss: 0.4431 | Val Loss: 0.4761 | Val Acc: 0.9747
ğŸ•’ Epoch 8/100 | Train Loss: 0.4458 | Val Loss: 0.4500 | Val Acc: 0.9816
ğŸ’¾ Best model updated (val acc: 0.9816)
ğŸ•’ Epoch 9/100 | Train Loss: 0.4411 | Val Loss: 0.4404 | Val Acc: 0.9954
ğŸ’¾ Best model updated (val acc: 0.9954)
ğŸ•’ Epoch 10/100 | Train Loss: 0.4400 | Val Loss: 0.4553 | Val Acc: 0.9908
ğŸ•’ Epoch 11/100 | Train Loss: 0.4392 | Val Loss: 0.4441 | Val Acc: 0.9885
ğŸ•’ Epoch 12/100 | Train Loss: 0.4277 | Val Loss: 0.4443 | Val Acc: 0.9885
ğŸ•’ Epoch 13/100 | Train Loss: 0.4281 | Val Loss: 0.4492 | Val Acc: 0.9862
ğŸ•’ Epoch 14/100 | Train Loss: 0.4298 | Val Loss: 0.4420 | Val Acc: 0.9885
ğŸ•’ Epoch 15/100 | Train Loss: 0.4706 | Val Loss: 0.4863 | Val Acc: 0.9724
ğŸ•’ Epoch 16/100 | Train Loss: 0.4540 | Val Loss: 0.4460 | Val Acc: 0.9908
ğŸ•’ Epoch 17/100 | Train Loss: 0.4319 | Val Loss: 0.4628 | Val Acc: 0.9816
ğŸ•’ Epoch 18/100 | Train Loss: 0.4306 | Val Loss: 0.4529 | Val Acc: 0.9839
ğŸ•’ Epoch 19/100 | Train Loss: 0.4319 | Val Loss: 0.4491 | Val Acc: 0.9839
â¹ï¸ Early stopping.
âœ… Fold 1 complete. Saved: ./output/models/ConvNeXt+4cbam+v2+dataset1_kfold+dataset1_kfold_fold1.pth

ğŸ“‚ Fold 2/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7279 | Val Loss: 0.5524 | Val Acc: 0.9401
ğŸ’¾ Best model updated (val acc: 0.9401)
ğŸ•’ Epoch 2/100 | Train Loss: 0.5063 | Val Loss: 0.4851 | Val Acc: 0.9700
ğŸ’¾ Best model updated (val acc: 0.9700)
ğŸ•’ Epoch 3/100 | Train Loss: 0.4946 | Val Loss: 0.5126 | Val Acc: 0.9631
ğŸ•’ Epoch 4/100 | Train Loss: 0.4840 | Val Loss: 0.4732 | Val Acc: 0.9816
ğŸ’¾ Best model updated (val acc: 0.9816)
ğŸ•’ Epoch 5/100 | Train Loss: 0.4662 | Val Loss: 0.4565 | Val Acc: 0.9816
ğŸ’¾ Best model updated (val acc: 0.9816)
ğŸ•’ Epoch 6/100 | Train Loss: 0.4442 | Val Loss: 0.4665 | Val Acc: 0.9747
ğŸ•’ Epoch 7/100 | Train Loss: 0.4450 | Val Loss: 0.4512 | Val Acc: 0.9885
ğŸ’¾ Best model updated (val acc: 0.9885)
ğŸ•’ Epoch 8/100 | Train Loss: 0.4498 | Val Loss: 0.4546 | Val Acc: 0.9885
ğŸ•’ Epoch 9/100 | Train Loss: 0.4380 | Val Loss: 0.5055 | Val Acc: 0.9700
ğŸ•’ Epoch 10/100 | Train Loss: 0.4633 | Val Loss: 0.4692 | Val Acc: 0.9793
ğŸ•’ Epoch 11/100 | Train Loss: 0.4356 | Val Loss: 0.4469 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 12/100 | Train Loss: 0.4346 | Val Loss: 0.4527 | Val Acc: 0.9885
ğŸ•’ Epoch 13/100 | Train Loss: 0.4403 | Val Loss: 0.4703 | Val Acc: 0.9816
ğŸ•’ Epoch 14/100 | Train Loss: 0.4361 | Val Loss: 0.4442 | Val Acc: 0.9885
ğŸ’¾ Best model updated (val acc: 0.9885)
ğŸ•’ Epoch 15/100 | Train Loss: 0.4271 | Val Loss: 0.4485 | Val Acc: 0.9839
ğŸ•’ Epoch 16/100 | Train Loss: 0.4353 | Val Loss: 0.4504 | Val Acc: 0.9885
ğŸ•’ Epoch 17/100 | Train Loss: 0.4274 | Val Loss: 0.4408 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 18/100 | Train Loss: 0.4284 | Val Loss: 0.4581 | Val Acc: 0.9862
ğŸ•’ Epoch 19/100 | Train Loss: 0.4280 | Val Loss: 0.4606 | Val Acc: 0.9816
ğŸ•’ Epoch 20/100 | Train Loss: 0.4258 | Val Loss: 0.4497 | Val Acc: 0.9862
ğŸ•’ Epoch 21/100 | Train Loss: 0.4274 | Val Loss: 0.4425 | Val Acc: 0.9931
ğŸ•’ Epoch 22/100 | Train Loss: 0.4332 | Val Loss: 0.4571 | Val Acc: 0.9862
ğŸ•’ Epoch 23/100 | Train Loss: 0.4293 | Val Loss: 0.4561 | Val Acc: 0.9839
ğŸ•’ Epoch 24/100 | Train Loss: 0.4285 | Val Loss: 0.4555 | Val Acc: 0.9885
ğŸ•’ Epoch 25/100 | Train Loss: 0.4246 | Val Loss: 0.4455 | Val Acc: 0.9885
ğŸ•’ Epoch 26/100 | Train Loss: 0.4236 | Val Loss: 0.4446 | Val Acc: 0.9885
ğŸ•’ Epoch 27/100 | Train Loss: 0.4228 | Val Loss: 0.4451 | Val Acc: 0.9908
â¹ï¸ Early stopping.
âœ… Fold 2 complete. Saved: ./output/models/ConvNeXt+4cbam+v2+dataset1_kfold+dataset1_kfold_fold2.pth

ğŸ“‚ Fold 3/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7776 | Val Loss: 0.5093 | Val Acc: 0.9654
ğŸ’¾ Best model updated (val acc: 0.9654)
ğŸ•’ Epoch 2/100 | Train Loss: 0.5205 | Val Loss: 0.4892 | Val Acc: 0.9630
ğŸ’¾ Best model updated (val acc: 0.9630)
ğŸ•’ Epoch 3/100 | Train Loss: 0.4816 | Val Loss: 0.4818 | Val Acc: 0.9746
ğŸ’¾ Best model updated (val acc: 0.9746)
ğŸ•’ Epoch 4/100 | Train Loss: 0.4526 | Val Loss: 0.4541 | Val Acc: 0.9861
ğŸ’¾ Best model updated (val acc: 0.9861)
ğŸ•’ Epoch 5/100 | Train Loss: 0.4659 | Val Loss: 0.4508 | Val Acc: 0.9885
ğŸ’¾ Best model updated (val acc: 0.9885)
ğŸ•’ Epoch 6/100 | Train Loss: 0.4448 | Val Loss: 0.4529 | Val Acc: 0.9815
ğŸ•’ Epoch 7/100 | Train Loss: 0.4592 | Val Loss: 0.4664 | Val Acc: 0.9792
ğŸ•’ Epoch 8/100 | Train Loss: 0.4635 | Val Loss: 0.4573 | Val Acc: 0.9885
ğŸ•’ Epoch 9/100 | Train Loss: 0.4478 | Val Loss: 0.4694 | Val Acc: 0.9815
ğŸ•’ Epoch 10/100 | Train Loss: 0.4463 | Val Loss: 0.4561 | Val Acc: 0.9861
ğŸ•’ Epoch 11/100 | Train Loss: 0.4357 | Val Loss: 0.4653 | Val Acc: 0.9792
ğŸ•’ Epoch 12/100 | Train Loss: 0.4325 | Val Loss: 0.4579 | Val Acc: 0.9861
ğŸ•’ Epoch 13/100 | Train Loss: 0.4288 | Val Loss: 0.4613 | Val Acc: 0.9792
ğŸ•’ Epoch 14/100 | Train Loss: 0.4362 | Val Loss: 0.4454 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 15/100 | Train Loss: 0.4370 | Val Loss: 0.4557 | Val Acc: 0.9885
ğŸ•’ Epoch 16/100 | Train Loss: 0.4303 | Val Loss: 0.4549 | Val Acc: 0.9861
ğŸ•’ Epoch 17/100 | Train Loss: 0.4277 | Val Loss: 0.4452 | Val Acc: 0.9861
ğŸ’¾ Best model updated (val acc: 0.9861)
ğŸ•’ Epoch 18/100 | Train Loss: 0.4328 | Val Loss: 0.4362 | Val Acc: 0.9954
ğŸ’¾ Best model updated (val acc: 0.9954)
ğŸ•’ Epoch 19/100 | Train Loss: 0.4251 | Val Loss: 0.4439 | Val Acc: 0.9908
ğŸ•’ Epoch 20/100 | Train Loss: 0.4346 | Val Loss: 0.4464 | Val Acc: 0.9908
ğŸ•’ Epoch 21/100 | Train Loss: 0.4261 | Val Loss: 0.4604 | Val Acc: 0.9885
ğŸ•’ Epoch 22/100 | Train Loss: 0.4339 | Val Loss: 0.4412 | Val Acc: 0.9885
ğŸ•’ Epoch 23/100 | Train Loss: 0.4228 | Val Loss: 0.4433 | Val Acc: 0.9931
ğŸ•’ Epoch 24/100 | Train Loss: 0.4256 | Val Loss: 0.4407 | Val Acc: 0.9885
ğŸ•’ Epoch 25/100 | Train Loss: 0.4244 | Val Loss: 0.4517 | Val Acc: 0.9885
ğŸ•’ Epoch 26/100 | Train Loss: 0.4226 | Val Loss: 0.4475 | Val Acc: 0.9908
ğŸ•’ Epoch 27/100 | Train Loss: 0.4231 | Val Loss: 0.4478 | Val Acc: 0.9885
ğŸ•’ Epoch 28/100 | Train Loss: 0.4344 | Val Loss: 0.4446 | Val Acc: 0.9885
â¹ï¸ Early stopping.
âœ… Fold 3 complete. Saved: ./output/models/ConvNeXt+4cbam+v2+dataset1_kfold+dataset1_kfold_fold3.pth

ğŸ“‚ Fold 4/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7668 | Val Loss: 0.5465 | Val Acc: 0.9515
ğŸ’¾ Best model updated (val acc: 0.9515)
ğŸ•’ Epoch 2/100 | Train Loss: 0.5095 | Val Loss: 0.4986 | Val Acc: 0.9746
ğŸ’¾ Best model updated (val acc: 0.9746)
ğŸ•’ Epoch 3/100 | Train Loss: 0.4829 | Val Loss: 0.4968 | Val Acc: 0.9654
ğŸ’¾ Best model updated (val acc: 0.9654)
ğŸ•’ Epoch 4/100 | Train Loss: 0.4699 | Val Loss: 0.4782 | Val Acc: 0.9769
ğŸ’¾ Best model updated (val acc: 0.9769)
ğŸ•’ Epoch 5/100 | Train Loss: 0.4673 | Val Loss: 0.5663 | Val Acc: 0.9215
ğŸ•’ Epoch 6/100 | Train Loss: 0.4695 | Val Loss: 0.5366 | Val Acc: 0.9469
ğŸ•’ Epoch 7/100 | Train Loss: 0.4545 | Val Loss: 0.4983 | Val Acc: 0.9607
ğŸ•’ Epoch 8/100 | Train Loss: 0.4396 | Val Loss: 0.4704 | Val Acc: 0.9815
ğŸ’¾ Best model updated (val acc: 0.9815)
ğŸ•’ Epoch 9/100 | Train Loss: 0.4381 | Val Loss: 0.4799 | Val Acc: 0.9746
ğŸ•’ Epoch 10/100 | Train Loss: 0.4551 | Val Loss: 0.4667 | Val Acc: 0.9861
ğŸ’¾ Best model updated (val acc: 0.9861)
ğŸ•’ Epoch 11/100 | Train Loss: 0.4493 | Val Loss: 0.4794 | Val Acc: 0.9746
ğŸ•’ Epoch 12/100 | Train Loss: 0.4302 | Val Loss: 0.4580 | Val Acc: 0.9838
ğŸ’¾ Best model updated (val acc: 0.9838)
ğŸ•’ Epoch 13/100 | Train Loss: 0.4283 | Val Loss: 0.4687 | Val Acc: 0.9838
ğŸ•’ Epoch 14/100 | Train Loss: 0.4339 | Val Loss: 0.4625 | Val Acc: 0.9815
ğŸ•’ Epoch 15/100 | Train Loss: 0.4234 | Val Loss: 0.4501 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 16/100 | Train Loss: 0.4311 | Val Loss: 0.4460 | Val Acc: 0.9931
ğŸ’¾ Best model updated (val acc: 0.9931)
ğŸ•’ Epoch 17/100 | Train Loss: 0.4259 | Val Loss: 0.4508 | Val Acc: 0.9908
ğŸ•’ Epoch 18/100 | Train Loss: 0.4243 | Val Loss: 0.4520 | Val Acc: 0.9885
ğŸ•’ Epoch 19/100 | Train Loss: 0.4233 | Val Loss: 0.4527 | Val Acc: 0.9908
ğŸ•’ Epoch 20/100 | Train Loss: 0.4326 | Val Loss: 0.4817 | Val Acc: 0.9746
ğŸ•’ Epoch 21/100 | Train Loss: 0.4299 | Val Loss: 0.4484 | Val Acc: 0.9885
ğŸ•’ Epoch 22/100 | Train Loss: 0.4240 | Val Loss: 0.4606 | Val Acc: 0.9815
ğŸ•’ Epoch 23/100 | Train Loss: 0.4238 | Val Loss: 0.4493 | Val Acc: 0.9861
ğŸ•’ Epoch 24/100 | Train Loss: 0.4333 | Val Loss: 0.4506 | Val Acc: 0.9908
ğŸ•’ Epoch 25/100 | Train Loss: 0.4287 | Val Loss: 0.4520 | Val Acc: 0.9861
ğŸ•’ Epoch 26/100 | Train Loss: 0.4231 | Val Loss: 0.4680 | Val Acc: 0.9815
â¹ï¸ Early stopping.
âœ… Fold 4 complete. Saved: ./output/models/ConvNeXt+4cbam+v2+dataset1_kfold+dataset1_kfold_fold4.pth

ğŸ“‚ Fold 5/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7677 | Val Loss: 0.5462 | Val Acc: 0.9307
ğŸ’¾ Best model updated (val acc: 0.9307)
ğŸ•’ Epoch 2/100 | Train Loss: 0.5110 | Val Loss: 0.5266 | Val Acc: 0.9515
ğŸ’¾ Best model updated (val acc: 0.9515)
ğŸ•’ Epoch 3/100 | Train Loss: 0.4791 | Val Loss: 0.4649 | Val Acc: 0.9838
ğŸ’¾ Best model updated (val acc: 0.9838)
ğŸ•’ Epoch 4/100 | Train Loss: 0.4811 | Val Loss: 0.4690 | Val Acc: 0.9792
ğŸ•’ Epoch 5/100 | Train Loss: 0.4525 | Val Loss: 0.4635 | Val Acc: 0.9792
ğŸ’¾ Best model updated (val acc: 0.9792)
ğŸ•’ Epoch 6/100 | Train Loss: 0.4395 | Val Loss: 0.4728 | Val Acc: 0.9769
ğŸ•’ Epoch 7/100 | Train Loss: 0.4417 | Val Loss: 0.4709 | Val Acc: 0.9769
ğŸ•’ Epoch 8/100 | Train Loss: 0.4598 | Val Loss: 0.4930 | Val Acc: 0.9723
ğŸ•’ Epoch 9/100 | Train Loss: 0.4501 | Val Loss: 0.4921 | Val Acc: 0.9746
ğŸ•’ Epoch 10/100 | Train Loss: 0.4577 | Val Loss: 0.4574 | Val Acc: 0.9838
ğŸ’¾ Best model updated (val acc: 0.9838)
ğŸ•’ Epoch 11/100 | Train Loss: 0.4333 | Val Loss: 0.4633 | Val Acc: 0.9838
ğŸ•’ Epoch 12/100 | Train Loss: 0.4299 | Val Loss: 0.4573 | Val Acc: 0.9861
ğŸ’¾ Best model updated (val acc: 0.9861)
ğŸ•’ Epoch 13/100 | Train Loss: 0.4254 | Val Loss: 0.4613 | Val Acc: 0.9861
ğŸ•’ Epoch 14/100 | Train Loss: 0.4272 | Val Loss: 0.4500 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 15/100 | Train Loss: 0.4233 | Val Loss: 0.4568 | Val Acc: 0.9861
ğŸ•’ Epoch 16/100 | Train Loss: 0.4247 | Val Loss: 0.4524 | Val Acc: 0.9885
ğŸ•’ Epoch 17/100 | Train Loss: 0.4606 | Val Loss: 0.4560 | Val Acc: 0.9885
ğŸ•’ Epoch 18/100 | Train Loss: 0.4322 | Val Loss: 0.4514 | Val Acc: 0.9885
ğŸ•’ Epoch 19/100 | Train Loss: 0.4445 | Val Loss: 0.4667 | Val Acc: 0.9792
ğŸ•’ Epoch 20/100 | Train Loss: 0.4373 | Val Loss: 0.4666 | Val Acc: 0.9815
ğŸ•’ Epoch 21/100 | Train Loss: 0.4263 | Val Loss: 0.4540 | Val Acc: 0.9838
ğŸ•’ Epoch 22/100 | Train Loss: 0.4299 | Val Loss: 0.4539 | Val Acc: 0.9861
ğŸ•’ Epoch 23/100 | Train Loss: 0.4236 | Val Loss: 0.4542 | Val Acc: 0.9861
ğŸ•’ Epoch 24/100 | Train Loss: 0.4232 | Val Loss: 0.4681 | Val Acc: 0.9746
â¹ï¸ Early stopping.
âœ… Fold 5 complete. Saved: ./output/models/ConvNeXt+4cbam+v2+dataset1_kfold+dataset1_kfold_fold5.pth
ğŸ“‚ Training metrics plot saved for Fold 1: output/test/fold_1/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 2: output/test/fold_2/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 3: output/test/fold_3/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 4: output/test/fold_4/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 5: output/test/fold_5/training_metrics.png
ğŸ‰ All folds completed.
ğŸš€ Evaluating 5 fold models on test set

ğŸ“‚ Evaluating Fold 1
ğŸ“Š Fold 1 Metrics:
   - Accuracy: 0.9853
   - Precision: 0.9859
   - Recall: 0.9856
   - F1 Score: 0.9856

ğŸ“‚ Evaluating Fold 2
ğŸ“Š Fold 2 Metrics:
   - Accuracy: 0.9834
   - Precision: 0.9838
   - Recall: 0.9835
   - F1 Score: 0.9834

ğŸ“‚ Evaluating Fold 3
ğŸ“Š Fold 3 Metrics:
   - Accuracy: 0.9908
   - Precision: 0.9912
   - Recall: 0.9909
   - F1 Score: 0.9910

ğŸ“‚ Evaluating Fold 4
ğŸ“Š Fold 4 Metrics:
   - Accuracy: 0.9834
   - Precision: 0.9836
   - Recall: 0.9838
   - F1 Score: 0.9836

ğŸ“‚ Evaluating Fold 5
ğŸ“Š Fold 5 Metrics:
   - Accuracy: 0.9890
   - Precision: 0.9895
   - Recall: 0.9891
   - F1 Score: 0.9891

ğŸ§¾ Classification Report for ConvNeXt+4cbam+v2+dataset1_kfold (Majority Vote from 5 folds):

                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    1.0000    1.0000        88
           brown_spot     0.9681    0.9785    0.9733        93
              healthy     0.9894    1.0000    0.9947        93
           leaf_blast     0.9888    0.9670    0.9778        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9908       543
            macro avg     0.9910    0.9909    0.9909       543
         weighted avg     0.9908    0.9908    0.9908       543

ğŸ”¢ Confusion Matrix:
 [[88  0  0  0  0  0]
 [ 0 91  1  1  0  0]
 [ 0  0 93  0  0  0]
 [ 0  3  0 88  0  0]
 [ 0  0  0  0 90  0]
 [ 0  0  0  0  0 88]]

ğŸ“Š Average Metrics Across All Folds:
   - Accuracy: 0.9864
   - Precision: 0.9868
   - Recall: 0.9866
   - F1 Score: 0.9865
ğŸš€ Starting training with 5-Fold Cross-Validation for model: ConvNeXt+4cbam+res+no-norm+dataset1_kfold
/media/data3/users/datlht/Rice_leaf_disease_detection/load_data.py:81: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/media/data3/users/datlht/Rice_leaf_disease_detection/load_data.py:84: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from font(s) DejaVu Sans.
  plt.savefig(plot_path)
âœ… Saved fold class distribution plot to: output/fold_class_distribution.png

ğŸ“‚ Fold 1/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7593 | Val Loss: 0.5166 | Val Acc: 0.9654
ğŸ’¾ Best model updated (val acc: 0.9654)
ğŸ•’ Epoch 2/100 | Train Loss: 0.5157 | Val Loss: 0.4883 | Val Acc: 0.9793
ğŸ’¾ Best model updated (val acc: 0.9793)
ğŸ•’ Epoch 3/100 | Train Loss: 0.4755 | Val Loss: 0.4691 | Val Acc: 0.9816
ğŸ’¾ Best model updated (val acc: 0.9816)
ğŸ•’ Epoch 4/100 | Train Loss: 0.4662 | Val Loss: 0.4894 | Val Acc: 0.9700
ğŸ•’ Epoch 5/100 | Train Loss: 0.4653 | Val Loss: 0.4539 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 6/100 | Train Loss: 0.4509 | Val Loss: 0.4696 | Val Acc: 0.9839
ğŸ•’ Epoch 7/100 | Train Loss: 0.4491 | Val Loss: 0.4694 | Val Acc: 0.9862
ğŸ•’ Epoch 8/100 | Train Loss: 0.4409 | Val Loss: 0.4428 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 9/100 | Train Loss: 0.4416 | Val Loss: 0.4651 | Val Acc: 0.9839
ğŸ•’ Epoch 10/100 | Train Loss: 0.4394 | Val Loss: 0.4767 | Val Acc: 0.9839
ğŸ•’ Epoch 11/100 | Train Loss: 0.4371 | Val Loss: 0.4436 | Val Acc: 0.9931
ğŸ•’ Epoch 12/100 | Train Loss: 0.4324 | Val Loss: 0.4459 | Val Acc: 0.9908
ğŸ•’ Epoch 13/100 | Train Loss: 0.4617 | Val Loss: 0.4547 | Val Acc: 0.9908
ğŸ•’ Epoch 14/100 | Train Loss: 0.4370 | Val Loss: 0.4468 | Val Acc: 0.9908
ğŸ•’ Epoch 15/100 | Train Loss: 0.4407 | Val Loss: 0.4587 | Val Acc: 0.9839
ğŸ•’ Epoch 16/100 | Train Loss: 0.4494 | Val Loss: 0.4749 | Val Acc: 0.9770
ğŸ•’ Epoch 17/100 | Train Loss: 0.4394 | Val Loss: 0.4404 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 18/100 | Train Loss: 0.4247 | Val Loss: 0.4328 | Val Acc: 0.9977
ğŸ’¾ Best model updated (val acc: 0.9977)
ğŸ•’ Epoch 19/100 | Train Loss: 0.4319 | Val Loss: 0.4413 | Val Acc: 0.9908
ğŸ•’ Epoch 20/100 | Train Loss: 0.4249 | Val Loss: 0.4522 | Val Acc: 0.9816
ğŸ•’ Epoch 21/100 | Train Loss: 0.4259 | Val Loss: 0.4396 | Val Acc: 0.9931
ğŸ•’ Epoch 22/100 | Train Loss: 0.4230 | Val Loss: 0.4435 | Val Acc: 0.9908
ğŸ•’ Epoch 23/100 | Train Loss: 0.4265 | Val Loss: 0.4356 | Val Acc: 0.9977
ğŸ•’ Epoch 24/100 | Train Loss: 0.4269 | Val Loss: 0.4831 | Val Acc: 0.9747
ğŸ•’ Epoch 25/100 | Train Loss: 0.4384 | Val Loss: 0.4631 | Val Acc: 0.9770
ğŸ•’ Epoch 26/100 | Train Loss: 0.4284 | Val Loss: 0.4486 | Val Acc: 0.9839
ğŸ•’ Epoch 27/100 | Train Loss: 0.4262 | Val Loss: 0.4534 | Val Acc: 0.9862
ğŸ•’ Epoch 28/100 | Train Loss: 0.4256 | Val Loss: 0.4391 | Val Acc: 0.9931
â¹ï¸ Early stopping.
âœ… Fold 1 complete. Saved: ./output/models/ConvNeXt+4cbam+res+no-norm+dataset1_kfold+dataset1_kfold_fold1.pth

ğŸ“‚ Fold 2/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7719 | Val Loss: 0.5120 | Val Acc: 0.9724
ğŸ’¾ Best model updated (val acc: 0.9724)
ğŸ•’ Epoch 2/100 | Train Loss: 0.5006 | Val Loss: 0.4978 | Val Acc: 0.9793
ğŸ’¾ Best model updated (val acc: 0.9793)
ğŸ•’ Epoch 3/100 | Train Loss: 0.4782 | Val Loss: 0.4702 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 4/100 | Train Loss: 0.4677 | Val Loss: 0.4591 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 5/100 | Train Loss: 0.4572 | Val Loss: 0.4669 | Val Acc: 0.9908
ğŸ•’ Epoch 6/100 | Train Loss: 0.4420 | Val Loss: 0.5034 | Val Acc: 0.9608
ğŸ•’ Epoch 7/100 | Train Loss: 0.4636 | Val Loss: 0.4633 | Val Acc: 0.9885
ğŸ•’ Epoch 8/100 | Train Loss: 0.4426 | Val Loss: 0.4452 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 9/100 | Train Loss: 0.4516 | Val Loss: 0.4460 | Val Acc: 0.9931
ğŸ•’ Epoch 10/100 | Train Loss: 0.4301 | Val Loss: 0.4487 | Val Acc: 0.9862
ğŸ•’ Epoch 11/100 | Train Loss: 0.4336 | Val Loss: 0.4961 | Val Acc: 0.9747
ğŸ•’ Epoch 12/100 | Train Loss: 0.4418 | Val Loss: 0.4539 | Val Acc: 0.9885
ğŸ•’ Epoch 13/100 | Train Loss: 0.4422 | Val Loss: 0.4670 | Val Acc: 0.9885
ğŸ•’ Epoch 14/100 | Train Loss: 0.4501 | Val Loss: 0.4484 | Val Acc: 0.9908
ğŸ•’ Epoch 15/100 | Train Loss: 0.4354 | Val Loss: 0.4682 | Val Acc: 0.9770
ğŸ•’ Epoch 16/100 | Train Loss: 0.4510 | Val Loss: 0.4726 | Val Acc: 0.9839
ğŸ•’ Epoch 17/100 | Train Loss: 0.4494 | Val Loss: 0.4639 | Val Acc: 0.9862
ğŸ•’ Epoch 18/100 | Train Loss: 0.4369 | Val Loss: 0.4487 | Val Acc: 0.9862
â¹ï¸ Early stopping.
âœ… Fold 2 complete. Saved: ./output/models/ConvNeXt+4cbam+res+no-norm+dataset1_kfold+dataset1_kfold_fold2.pth

ğŸ“‚ Fold 3/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7679 | Val Loss: 0.5199 | Val Acc: 0.9700
ğŸ’¾ Best model updated (val acc: 0.9700)
ğŸ•’ Epoch 2/100 | Train Loss: 0.5156 | Val Loss: 0.4833 | Val Acc: 0.9746
ğŸ’¾ Best model updated (val acc: 0.9746)
ğŸ•’ Epoch 3/100 | Train Loss: 0.4881 | Val Loss: 0.4802 | Val Acc: 0.9792
ğŸ’¾ Best model updated (val acc: 0.9792)
ğŸ•’ Epoch 4/100 | Train Loss: 0.4535 | Val Loss: 0.4927 | Val Acc: 0.9677
ğŸ•’ Epoch 5/100 | Train Loss: 0.4682 | Val Loss: 0.4666 | Val Acc: 0.9746
ğŸ’¾ Best model updated (val acc: 0.9746)
ğŸ•’ Epoch 6/100 | Train Loss: 0.4439 | Val Loss: 0.4553 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 7/100 | Train Loss: 0.4658 | Val Loss: 0.4752 | Val Acc: 0.9792
ğŸ•’ Epoch 8/100 | Train Loss: 0.4608 | Val Loss: 0.4979 | Val Acc: 0.9723
ğŸ•’ Epoch 9/100 | Train Loss: 0.4681 | Val Loss: 0.4786 | Val Acc: 0.9861
ğŸ•’ Epoch 10/100 | Train Loss: 0.4454 | Val Loss: 0.4527 | Val Acc: 0.9861
ğŸ’¾ Best model updated (val acc: 0.9861)
ğŸ•’ Epoch 11/100 | Train Loss: 0.4293 | Val Loss: 0.4485 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 12/100 | Train Loss: 0.4334 | Val Loss: 0.4546 | Val Acc: 0.9885
ğŸ•’ Epoch 13/100 | Train Loss: 0.4285 | Val Loss: 0.4518 | Val Acc: 0.9861
ğŸ•’ Epoch 14/100 | Train Loss: 0.4375 | Val Loss: 0.4462 | Val Acc: 0.9885
ğŸ’¾ Best model updated (val acc: 0.9885)
ğŸ•’ Epoch 15/100 | Train Loss: 0.4349 | Val Loss: 0.4717 | Val Acc: 0.9815
ğŸ•’ Epoch 16/100 | Train Loss: 0.4427 | Val Loss: 0.4744 | Val Acc: 0.9769
ğŸ•’ Epoch 17/100 | Train Loss: 0.4295 | Val Loss: 0.4510 | Val Acc: 0.9861
ğŸ•’ Epoch 18/100 | Train Loss: 0.4291 | Val Loss: 0.4495 | Val Acc: 0.9838
ğŸ•’ Epoch 19/100 | Train Loss: 0.4301 | Val Loss: 0.4493 | Val Acc: 0.9931
ğŸ•’ Epoch 20/100 | Train Loss: 0.4303 | Val Loss: 0.4365 | Val Acc: 0.9931
ğŸ’¾ Best model updated (val acc: 0.9931)
ğŸ•’ Epoch 21/100 | Train Loss: 0.4258 | Val Loss: 0.4549 | Val Acc: 0.9861
ğŸ•’ Epoch 22/100 | Train Loss: 0.4305 | Val Loss: 0.4525 | Val Acc: 0.9885
ğŸ•’ Epoch 23/100 | Train Loss: 0.4236 | Val Loss: 0.4503 | Val Acc: 0.9908
ğŸ•’ Epoch 24/100 | Train Loss: 0.4234 | Val Loss: 0.4666 | Val Acc: 0.9861
ğŸ•’ Epoch 25/100 | Train Loss: 0.4247 | Val Loss: 0.4372 | Val Acc: 0.9931
ğŸ•’ Epoch 26/100 | Train Loss: 0.4225 | Val Loss: 0.4406 | Val Acc: 0.9931
ğŸ•’ Epoch 27/100 | Train Loss: 0.4265 | Val Loss: 0.4700 | Val Acc: 0.9838
ğŸ•’ Epoch 28/100 | Train Loss: 0.4296 | Val Loss: 0.4558 | Val Acc: 0.9838
ğŸ•’ Epoch 29/100 | Train Loss: 0.4241 | Val Loss: 0.4441 | Val Acc: 0.9908
ğŸ•’ Epoch 30/100 | Train Loss: 0.4221 | Val Loss: 0.4488 | Val Acc: 0.9885
â¹ï¸ Early stopping.
âœ… Fold 3 complete. Saved: ./output/models/ConvNeXt+4cbam+res+no-norm+dataset1_kfold+dataset1_kfold_fold3.pth

ğŸ“‚ Fold 4/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7772 | Val Loss: 0.7260 | Val Acc: 0.8637
ğŸ’¾ Best model updated (val acc: 0.8637)
ğŸ•’ Epoch 2/100 | Train Loss: 0.5118 | Val Loss: 0.5177 | Val Acc: 0.9538
ğŸ’¾ Best model updated (val acc: 0.9538)
ğŸ•’ Epoch 3/100 | Train Loss: 0.4697 | Val Loss: 0.5274 | Val Acc: 0.9515
ğŸ•’ Epoch 4/100 | Train Loss: 0.4587 | Val Loss: 0.4706 | Val Acc: 0.9815
ğŸ’¾ Best model updated (val acc: 0.9815)
ğŸ•’ Epoch 5/100 | Train Loss: 0.4619 | Val Loss: 0.4857 | Val Acc: 0.9815
ğŸ•’ Epoch 6/100 | Train Loss: 0.4491 | Val Loss: 0.4688 | Val Acc: 0.9861
ğŸ’¾ Best model updated (val acc: 0.9861)
ğŸ•’ Epoch 7/100 | Train Loss: 0.4360 | Val Loss: 0.4469 | Val Acc: 0.9954
ğŸ’¾ Best model updated (val acc: 0.9954)
ğŸ•’ Epoch 8/100 | Train Loss: 0.4368 | Val Loss: 0.4835 | Val Acc: 0.9838
ğŸ•’ Epoch 9/100 | Train Loss: 0.4380 | Val Loss: 0.4463 | Val Acc: 0.9954
ğŸ’¾ Best model updated (val acc: 0.9954)
ğŸ•’ Epoch 10/100 | Train Loss: 0.4317 | Val Loss: 0.4644 | Val Acc: 0.9908
ğŸ•’ Epoch 11/100 | Train Loss: 0.4419 | Val Loss: 0.4788 | Val Acc: 0.9792
ğŸ•’ Epoch 12/100 | Train Loss: 0.4519 | Val Loss: 0.4853 | Val Acc: 0.9815
ğŸ•’ Epoch 13/100 | Train Loss: 0.4422 | Val Loss: 0.4644 | Val Acc: 0.9838
ğŸ•’ Epoch 14/100 | Train Loss: 0.4396 | Val Loss: 0.4511 | Val Acc: 0.9908
ğŸ•’ Epoch 15/100 | Train Loss: 0.4324 | Val Loss: 0.4575 | Val Acc: 0.9861
ğŸ•’ Epoch 16/100 | Train Loss: 0.4325 | Val Loss: 0.4560 | Val Acc: 0.9861
ğŸ•’ Epoch 17/100 | Train Loss: 0.4277 | Val Loss: 0.4583 | Val Acc: 0.9861
ğŸ•’ Epoch 18/100 | Train Loss: 0.4344 | Val Loss: 0.4750 | Val Acc: 0.9769
ğŸ•’ Epoch 19/100 | Train Loss: 0.4237 | Val Loss: 0.4485 | Val Acc: 0.9885
â¹ï¸ Early stopping.
âœ… Fold 4 complete. Saved: ./output/models/ConvNeXt+4cbam+res+no-norm+dataset1_kfold+dataset1_kfold_fold4.pth

ğŸ“‚ Fold 5/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7275 | Val Loss: 0.5698 | Val Acc: 0.9515
ğŸ’¾ Best model updated (val acc: 0.9515)
ğŸ•’ Epoch 2/100 | Train Loss: 0.4982 | Val Loss: 0.5975 | Val Acc: 0.9330
ğŸ•’ Epoch 3/100 | Train Loss: 0.4908 | Val Loss: 0.5165 | Val Acc: 0.9584
ğŸ’¾ Best model updated (val acc: 0.9584)
ğŸ•’ Epoch 4/100 | Train Loss: 0.4623 | Val Loss: 0.4800 | Val Acc: 0.9769
ğŸ’¾ Best model updated (val acc: 0.9769)
ğŸ•’ Epoch 5/100 | Train Loss: 0.4440 | Val Loss: 0.4612 | Val Acc: 0.9861
ğŸ’¾ Best model updated (val acc: 0.9861)
ğŸ•’ Epoch 6/100 | Train Loss: 0.4452 | Val Loss: 0.4850 | Val Acc: 0.9723
ğŸ•’ Epoch 7/100 | Train Loss: 0.4665 | Val Loss: 0.4707 | Val Acc: 0.9792
ğŸ•’ Epoch 8/100 | Train Loss: 0.4497 | Val Loss: 0.5129 | Val Acc: 0.9607
ğŸ•’ Epoch 9/100 | Train Loss: 0.4392 | Val Loss: 0.4584 | Val Acc: 0.9861
ğŸ’¾ Best model updated (val acc: 0.9861)
ğŸ•’ Epoch 10/100 | Train Loss: 0.4293 | Val Loss: 0.4538 | Val Acc: 0.9838
ğŸ’¾ Best model updated (val acc: 0.9838)
ğŸ•’ Epoch 11/100 | Train Loss: 0.4528 | Val Loss: 0.4598 | Val Acc: 0.9908
ğŸ•’ Epoch 12/100 | Train Loss: 0.4572 | Val Loss: 0.5046 | Val Acc: 0.9654
ğŸ•’ Epoch 13/100 | Train Loss: 0.4616 | Val Loss: 0.4754 | Val Acc: 0.9792
ğŸ•’ Epoch 14/100 | Train Loss: 0.4443 | Val Loss: 0.4654 | Val Acc: 0.9815
ğŸ•’ Epoch 15/100 | Train Loss: 0.4318 | Val Loss: 0.4581 | Val Acc: 0.9815
ğŸ•’ Epoch 16/100 | Train Loss: 0.4283 | Val Loss: 0.4587 | Val Acc: 0.9815
ğŸ•’ Epoch 17/100 | Train Loss: 0.4263 | Val Loss: 0.4594 | Val Acc: 0.9861
ğŸ•’ Epoch 18/100 | Train Loss: 0.4284 | Val Loss: 0.4600 | Val Acc: 0.9838
ğŸ•’ Epoch 19/100 | Train Loss: 0.4296 | Val Loss: 0.4574 | Val Acc: 0.9838
ğŸ•’ Epoch 20/100 | Train Loss: 0.4259 | Val Loss: 0.4602 | Val Acc: 0.9815
â¹ï¸ Early stopping.
âœ… Fold 5 complete. Saved: ./output/models/ConvNeXt+4cbam+res+no-norm+dataset1_kfold+dataset1_kfold_fold5.pth
ğŸ“‚ Training metrics plot saved for Fold 1: output/test/fold_1/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 2: output/test/fold_2/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 3: output/test/fold_3/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 4: output/test/fold_4/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 5: output/test/fold_5/training_metrics.png
ğŸ‰ All folds completed.
ğŸš€ Evaluating 5 fold models on test set

ğŸ“‚ Evaluating Fold 1
ğŸ“Š Fold 1 Metrics:
   - Accuracy: 0.9871
   - Precision: 0.9873
   - Recall: 0.9873
   - F1 Score: 0.9873

ğŸ“‚ Evaluating Fold 2
ğŸ“Š Fold 2 Metrics:
   - Accuracy: 0.9742
   - Precision: 0.9751
   - Recall: 0.9747
   - F1 Score: 0.9745

ğŸ“‚ Evaluating Fold 3
ğŸ“Š Fold 3 Metrics:
   - Accuracy: 0.9890
   - Precision: 0.9892
   - Recall: 0.9891
   - F1 Score: 0.9891

ğŸ“‚ Evaluating Fold 4
ğŸ“Š Fold 4 Metrics:
   - Accuracy: 0.9871
   - Precision: 0.9875
   - Recall: 0.9873
   - F1 Score: 0.9873

ğŸ“‚ Evaluating Fold 5
ğŸ“Š Fold 5 Metrics:
   - Accuracy: 0.9779
   - Precision: 0.9785
   - Recall: 0.9784
   - F1 Score: 0.9782

ğŸ§¾ Classification Report for ConvNeXt+4cbam+res+no-norm+dataset1_kfold (Majority Vote from 5 folds):

                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    0.9886    0.9943        88
           brown_spot     0.9783    0.9677    0.9730        93
              healthy     0.9688    1.0000    0.9841        93
           leaf_blast     0.9889    0.9780    0.9834        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9890       543
            macro avg     0.9893    0.9891    0.9891       543
         weighted avg     0.9891    0.9890    0.9889       543

ğŸ”¢ Confusion Matrix:
 [[87  0  1  0  0  0]
 [ 0 90  2  1  0  0]
 [ 0  0 93  0  0  0]
 [ 0  2  0 89  0  0]
 [ 0  0  0  0 90  0]
 [ 0  0  0  0  0 88]]

ğŸ“Š Average Metrics Across All Folds:
   - Accuracy: 0.9831
   - Precision: 0.9835
   - Recall: 0.9833
   - F1 Score: 0.9833
ğŸš€ Starting training with 5-Fold Cross-Validation for model: ConvNeXt+4cbam+res+last-norm+dataset1_kfold
/media/data3/users/datlht/Rice_leaf_disease_detection/load_data.py:81: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/media/data3/users/datlht/Rice_leaf_disease_detection/load_data.py:84: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from font(s) DejaVu Sans.
  plt.savefig(plot_path)
âœ… Saved fold class distribution plot to: output/fold_class_distribution.png

ğŸ“‚ Fold 1/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7584 | Val Loss: 0.5423 | Val Acc: 0.9493
ğŸ’¾ Best model updated (val acc: 0.9493)
ğŸ•’ Epoch 2/100 | Train Loss: 0.5180 | Val Loss: 0.4933 | Val Acc: 0.9677
ğŸ’¾ Best model updated (val acc: 0.9677)
ğŸ•’ Epoch 3/100 | Train Loss: 0.5054 | Val Loss: 0.4569 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 4/100 | Train Loss: 0.4595 | Val Loss: 0.4892 | Val Acc: 0.9747
ğŸ•’ Epoch 5/100 | Train Loss: 0.4584 | Val Loss: 0.4793 | Val Acc: 0.9793
ğŸ•’ Epoch 6/100 | Train Loss: 0.4436 | Val Loss: 0.4531 | Val Acc: 0.9839
ğŸ’¾ Best model updated (val acc: 0.9839)
ğŸ•’ Epoch 7/100 | Train Loss: 0.4449 | Val Loss: 0.4570 | Val Acc: 0.9816
ğŸ•’ Epoch 8/100 | Train Loss: 0.4399 | Val Loss: 0.4414 | Val Acc: 0.9931
ğŸ’¾ Best model updated (val acc: 0.9931)
ğŸ•’ Epoch 9/100 | Train Loss: 0.4403 | Val Loss: 0.4395 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 10/100 | Train Loss: 0.4335 | Val Loss: 0.4369 | Val Acc: 0.9954
ğŸ’¾ Best model updated (val acc: 0.9954)
ğŸ•’ Epoch 11/100 | Train Loss: 0.4547 | Val Loss: 0.4494 | Val Acc: 0.9839
ğŸ•’ Epoch 12/100 | Train Loss: 0.4458 | Val Loss: 0.5108 | Val Acc: 0.9724
ğŸ•’ Epoch 13/100 | Train Loss: 0.4629 | Val Loss: 0.4494 | Val Acc: 0.9908
ğŸ•’ Epoch 14/100 | Train Loss: 0.4478 | Val Loss: 0.4510 | Val Acc: 0.9885
ğŸ•’ Epoch 15/100 | Train Loss: 0.4403 | Val Loss: 0.4591 | Val Acc: 0.9770
ğŸ•’ Epoch 16/100 | Train Loss: 0.4347 | Val Loss: 0.4379 | Val Acc: 0.9954
ğŸ•’ Epoch 17/100 | Train Loss: 0.4371 | Val Loss: 0.4423 | Val Acc: 0.9931
ğŸ•’ Epoch 18/100 | Train Loss: 0.4371 | Val Loss: 0.4507 | Val Acc: 0.9885
ğŸ•’ Epoch 19/100 | Train Loss: 0.4405 | Val Loss: 0.4487 | Val Acc: 0.9908
ğŸ•’ Epoch 20/100 | Train Loss: 0.4276 | Val Loss: 0.4354 | Val Acc: 0.9954
ğŸ’¾ Best model updated (val acc: 0.9954)
ğŸ•’ Epoch 21/100 | Train Loss: 0.4255 | Val Loss: 0.4351 | Val Acc: 0.9954
ğŸ’¾ Best model updated (val acc: 0.9954)
ğŸ•’ Epoch 22/100 | Train Loss: 0.4266 | Val Loss: 0.4423 | Val Acc: 0.9908
ğŸ•’ Epoch 23/100 | Train Loss: 0.4241 | Val Loss: 0.4421 | Val Acc: 0.9908
ğŸ•’ Epoch 24/100 | Train Loss: 0.4227 | Val Loss: 0.4390 | Val Acc: 0.9931
ğŸ•’ Epoch 25/100 | Train Loss: 0.4265 | Val Loss: 0.4372 | Val Acc: 0.9908
ğŸ•’ Epoch 26/100 | Train Loss: 0.4229 | Val Loss: 0.4390 | Val Acc: 0.9908
ğŸ•’ Epoch 27/100 | Train Loss: 0.4235 | Val Loss: 0.4388 | Val Acc: 0.9931
ğŸ•’ Epoch 28/100 | Train Loss: 0.4223 | Val Loss: 0.4411 | Val Acc: 0.9908
ğŸ•’ Epoch 29/100 | Train Loss: 0.4223 | Val Loss: 0.4336 | Val Acc: 0.9954
ğŸ’¾ Best model updated (val acc: 0.9954)
ğŸ•’ Epoch 30/100 | Train Loss: 0.4224 | Val Loss: 0.4357 | Val Acc: 0.9931
ğŸ•’ Epoch 31/100 | Train Loss: 0.4218 | Val Loss: 0.4359 | Val Acc: 0.9908
ğŸ•’ Epoch 32/100 | Train Loss: 0.4225 | Val Loss: 0.4362 | Val Acc: 0.9908
ğŸ•’ Epoch 33/100 | Train Loss: 0.4216 | Val Loss: 0.4380 | Val Acc: 0.9908
ğŸ•’ Epoch 34/100 | Train Loss: 0.4217 | Val Loss: 0.4347 | Val Acc: 0.9954
ğŸ•’ Epoch 35/100 | Train Loss: 0.4218 | Val Loss: 0.4351 | Val Acc: 0.9931
ğŸ•’ Epoch 36/100 | Train Loss: 0.4216 | Val Loss: 0.4342 | Val Acc: 0.9954
ğŸ•’ Epoch 37/100 | Train Loss: 0.4214 | Val Loss: 0.4343 | Val Acc: 0.9954
ğŸ•’ Epoch 38/100 | Train Loss: 0.4222 | Val Loss: 0.4338 | Val Acc: 0.9954
ğŸ•’ Epoch 39/100 | Train Loss: 0.4214 | Val Loss: 0.4338 | Val Acc: 0.9954
â¹ï¸ Early stopping.
âœ… Fold 1 complete. Saved: ./output/models/ConvNeXt+4cbam+res+last-norm+dataset1_kfold+dataset1_kfold_fold1.pth

ğŸ“‚ Fold 2/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7541 | Val Loss: 0.5487 | Val Acc: 0.9447
ğŸ’¾ Best model updated (val acc: 0.9447)
ğŸ•’ Epoch 2/100 | Train Loss: 0.5223 | Val Loss: 0.5040 | Val Acc: 0.9654
ğŸ’¾ Best model updated (val acc: 0.9654)
ğŸ•’ Epoch 3/100 | Train Loss: 0.4905 | Val Loss: 0.5081 | Val Acc: 0.9562
ğŸ•’ Epoch 4/100 | Train Loss: 0.4546 | Val Loss: 0.4749 | Val Acc: 0.9770
ğŸ’¾ Best model updated (val acc: 0.9770)
ğŸ•’ Epoch 5/100 | Train Loss: 0.4496 | Val Loss: 0.4543 | Val Acc: 0.9862
ğŸ’¾ Best model updated (val acc: 0.9862)
ğŸ•’ Epoch 6/100 | Train Loss: 0.4507 | Val Loss: 0.4541 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 7/100 | Train Loss: 0.4487 | Val Loss: 0.4559 | Val Acc: 0.9816
ğŸ•’ Epoch 8/100 | Train Loss: 0.4448 | Val Loss: 0.4529 | Val Acc: 0.9862
ğŸ’¾ Best model updated (val acc: 0.9862)
ğŸ•’ Epoch 9/100 | Train Loss: 0.4472 | Val Loss: 0.4902 | Val Acc: 0.9654
ğŸ•’ Epoch 10/100 | Train Loss: 0.4341 | Val Loss: 0.4668 | Val Acc: 0.9793
ğŸ•’ Epoch 11/100 | Train Loss: 0.4420 | Val Loss: 0.5036 | Val Acc: 0.9700
ğŸ•’ Epoch 12/100 | Train Loss: 0.4438 | Val Loss: 0.4585 | Val Acc: 0.9862
ğŸ•’ Epoch 13/100 | Train Loss: 0.4396 | Val Loss: 0.4491 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 14/100 | Train Loss: 0.4293 | Val Loss: 0.4623 | Val Acc: 0.9816
ğŸ•’ Epoch 15/100 | Train Loss: 0.4284 | Val Loss: 0.4448 | Val Acc: 0.9931
ğŸ’¾ Best model updated (val acc: 0.9931)
ğŸ•’ Epoch 16/100 | Train Loss: 0.4373 | Val Loss: 0.4651 | Val Acc: 0.9862
ğŸ•’ Epoch 17/100 | Train Loss: 0.4297 | Val Loss: 0.4624 | Val Acc: 0.9816
ğŸ•’ Epoch 18/100 | Train Loss: 0.4239 | Val Loss: 0.4470 | Val Acc: 0.9885
ğŸ•’ Epoch 19/100 | Train Loss: 0.4252 | Val Loss: 0.4506 | Val Acc: 0.9839
ğŸ•’ Epoch 20/100 | Train Loss: 0.4272 | Val Loss: 0.4683 | Val Acc: 0.9816
ğŸ•’ Epoch 21/100 | Train Loss: 0.4334 | Val Loss: 0.4684 | Val Acc: 0.9747
ğŸ•’ Epoch 22/100 | Train Loss: 0.4248 | Val Loss: 0.4544 | Val Acc: 0.9816
ğŸ•’ Epoch 23/100 | Train Loss: 0.4228 | Val Loss: 0.4687 | Val Acc: 0.9747
ğŸ•’ Epoch 24/100 | Train Loss: 0.4276 | Val Loss: 0.4600 | Val Acc: 0.9839
ğŸ•’ Epoch 25/100 | Train Loss: 0.4263 | Val Loss: 0.4372 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 26/100 | Train Loss: 0.4264 | Val Loss: 0.4492 | Val Acc: 0.9839
ğŸ•’ Epoch 27/100 | Train Loss: 0.4239 | Val Loss: 0.4443 | Val Acc: 0.9885
ğŸ•’ Epoch 28/100 | Train Loss: 0.4225 | Val Loss: 0.4495 | Val Acc: 0.9885
ğŸ•’ Epoch 29/100 | Train Loss: 0.4259 | Val Loss: 0.4507 | Val Acc: 0.9885
ğŸ•’ Epoch 30/100 | Train Loss: 0.4281 | Val Loss: 0.4419 | Val Acc: 0.9908
ğŸ•’ Epoch 31/100 | Train Loss: 0.4254 | Val Loss: 0.4499 | Val Acc: 0.9862
ğŸ•’ Epoch 32/100 | Train Loss: 0.4229 | Val Loss: 0.4396 | Val Acc: 0.9908
ğŸ•’ Epoch 33/100 | Train Loss: 0.4246 | Val Loss: 0.4602 | Val Acc: 0.9770
ğŸ•’ Epoch 34/100 | Train Loss: 0.4230 | Val Loss: 0.4476 | Val Acc: 0.9885
ğŸ•’ Epoch 35/100 | Train Loss: 0.4234 | Val Loss: 0.4440 | Val Acc: 0.9908
â¹ï¸ Early stopping.
âœ… Fold 2 complete. Saved: ./output/models/ConvNeXt+4cbam+res+last-norm+dataset1_kfold+dataset1_kfold_fold2.pth

ğŸ“‚ Fold 3/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7995 | Val Loss: 0.5602 | Val Acc: 0.9423
ğŸ’¾ Best model updated (val acc: 0.9423)
ğŸ•’ Epoch 2/100 | Train Loss: 0.5221 | Val Loss: 0.5088 | Val Acc: 0.9677
ğŸ’¾ Best model updated (val acc: 0.9677)
ğŸ•’ Epoch 3/100 | Train Loss: 0.4865 | Val Loss: 0.4721 | Val Acc: 0.9815
ğŸ’¾ Best model updated (val acc: 0.9815)
ğŸ•’ Epoch 4/100 | Train Loss: 0.4745 | Val Loss: 0.4907 | Val Acc: 0.9723
ğŸ•’ Epoch 5/100 | Train Loss: 0.4591 | Val Loss: 0.4541 | Val Acc: 0.9885
ğŸ’¾ Best model updated (val acc: 0.9885)
ğŸ•’ Epoch 6/100 | Train Loss: 0.4513 | Val Loss: 0.4822 | Val Acc: 0.9723
ğŸ•’ Epoch 7/100 | Train Loss: 0.4641 | Val Loss: 0.4566 | Val Acc: 0.9861
ğŸ•’ Epoch 8/100 | Train Loss: 0.4433 | Val Loss: 0.4463 | Val Acc: 0.9931
ğŸ’¾ Best model updated (val acc: 0.9931)
ğŸ•’ Epoch 9/100 | Train Loss: 0.4381 | Val Loss: 0.4736 | Val Acc: 0.9723
ğŸ•’ Epoch 10/100 | Train Loss: 0.4391 | Val Loss: 0.4659 | Val Acc: 0.9815
ğŸ•’ Epoch 11/100 | Train Loss: 0.4330 | Val Loss: 0.4472 | Val Acc: 0.9885
ğŸ•’ Epoch 12/100 | Train Loss: 0.4372 | Val Loss: 0.4711 | Val Acc: 0.9815
ğŸ•’ Epoch 13/100 | Train Loss: 0.4598 | Val Loss: 0.4422 | Val Acc: 0.9931
ğŸ’¾ Best model updated (val acc: 0.9931)
ğŸ•’ Epoch 14/100 | Train Loss: 0.4449 | Val Loss: 0.4588 | Val Acc: 0.9885
ğŸ•’ Epoch 15/100 | Train Loss: 0.4410 | Val Loss: 0.4545 | Val Acc: 0.9838
ğŸ•’ Epoch 16/100 | Train Loss: 0.4264 | Val Loss: 0.4450 | Val Acc: 0.9908
ğŸ•’ Epoch 17/100 | Train Loss: 0.4373 | Val Loss: 0.4521 | Val Acc: 0.9861
ğŸ•’ Epoch 18/100 | Train Loss: 0.4268 | Val Loss: 0.4609 | Val Acc: 0.9861
ğŸ•’ Epoch 19/100 | Train Loss: 0.4240 | Val Loss: 0.4543 | Val Acc: 0.9861
ğŸ•’ Epoch 20/100 | Train Loss: 0.4285 | Val Loss: 0.4662 | Val Acc: 0.9861
ğŸ•’ Epoch 21/100 | Train Loss: 0.4312 | Val Loss: 0.4503 | Val Acc: 0.9885
ğŸ•’ Epoch 22/100 | Train Loss: 0.4259 | Val Loss: 0.4440 | Val Acc: 0.9931
ğŸ•’ Epoch 23/100 | Train Loss: 0.4254 | Val Loss: 0.4408 | Val Acc: 0.9931
ğŸ’¾ Best model updated (val acc: 0.9931)
ğŸ•’ Epoch 24/100 | Train Loss: 0.4252 | Val Loss: 0.4453 | Val Acc: 0.9908
ğŸ•’ Epoch 25/100 | Train Loss: 0.4240 | Val Loss: 0.4428 | Val Acc: 0.9931
ğŸ•’ Epoch 26/100 | Train Loss: 0.4234 | Val Loss: 0.4396 | Val Acc: 0.9931
ğŸ’¾ Best model updated (val acc: 0.9931)
ğŸ•’ Epoch 27/100 | Train Loss: 0.4227 | Val Loss: 0.4407 | Val Acc: 0.9931
ğŸ•’ Epoch 28/100 | Train Loss: 0.4234 | Val Loss: 0.4362 | Val Acc: 0.9931
ğŸ’¾ Best model updated (val acc: 0.9931)
ğŸ•’ Epoch 29/100 | Train Loss: 0.4220 | Val Loss: 0.4351 | Val Acc: 0.9954
ğŸ’¾ Best model updated (val acc: 0.9954)
ğŸ•’ Epoch 30/100 | Train Loss: 0.4218 | Val Loss: 0.4355 | Val Acc: 0.9954
ğŸ•’ Epoch 31/100 | Train Loss: 0.4235 | Val Loss: 0.4336 | Val Acc: 0.9954
ğŸ’¾ Best model updated (val acc: 0.9954)
ğŸ•’ Epoch 32/100 | Train Loss: 0.4219 | Val Loss: 0.4383 | Val Acc: 0.9954
ğŸ•’ Epoch 33/100 | Train Loss: 0.4215 | Val Loss: 0.4366 | Val Acc: 0.9954
ğŸ•’ Epoch 34/100 | Train Loss: 0.4238 | Val Loss: 0.4360 | Val Acc: 0.9931
ğŸ•’ Epoch 35/100 | Train Loss: 0.4216 | Val Loss: 0.4372 | Val Acc: 0.9931
ğŸ•’ Epoch 36/100 | Train Loss: 0.4215 | Val Loss: 0.4372 | Val Acc: 0.9931
ğŸ•’ Epoch 37/100 | Train Loss: 0.4217 | Val Loss: 0.4364 | Val Acc: 0.9931
ğŸ•’ Epoch 38/100 | Train Loss: 0.4214 | Val Loss: 0.4365 | Val Acc: 0.9931
ğŸ•’ Epoch 39/100 | Train Loss: 0.4215 | Val Loss: 0.4359 | Val Acc: 0.9931
ğŸ•’ Epoch 40/100 | Train Loss: 0.4213 | Val Loss: 0.4358 | Val Acc: 0.9931
ğŸ•’ Epoch 41/100 | Train Loss: 0.4213 | Val Loss: 0.4358 | Val Acc: 0.9931
â¹ï¸ Early stopping.
âœ… Fold 3 complete. Saved: ./output/models/ConvNeXt+4cbam+res+last-norm+dataset1_kfold+dataset1_kfold_fold3.pth

ğŸ“‚ Fold 4/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.8030 | Val Loss: 0.5304 | Val Acc: 0.9492
ğŸ’¾ Best model updated (val acc: 0.9492)
ğŸ•’ Epoch 2/100 | Train Loss: 0.4992 | Val Loss: 0.4983 | Val Acc: 0.9700
ğŸ’¾ Best model updated (val acc: 0.9700)
ğŸ•’ Epoch 3/100 | Train Loss: 0.4801 | Val Loss: 0.4774 | Val Acc: 0.9815
ğŸ’¾ Best model updated (val acc: 0.9815)
ğŸ•’ Epoch 4/100 | Train Loss: 0.5030 | Val Loss: 0.5154 | Val Acc: 0.9584
ğŸ•’ Epoch 5/100 | Train Loss: 0.4503 | Val Loss: 0.4619 | Val Acc: 0.9792
ğŸ’¾ Best model updated (val acc: 0.9792)
ğŸ•’ Epoch 6/100 | Train Loss: 0.4568 | Val Loss: 0.4845 | Val Acc: 0.9746
ğŸ•’ Epoch 7/100 | Train Loss: 0.4534 | Val Loss: 0.4629 | Val Acc: 0.9838
ğŸ•’ Epoch 8/100 | Train Loss: 0.4429 | Val Loss: 0.4518 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 9/100 | Train Loss: 0.4501 | Val Loss: 0.4701 | Val Acc: 0.9769
ğŸ•’ Epoch 10/100 | Train Loss: 0.4442 | Val Loss: 0.4628 | Val Acc: 0.9861
ğŸ•’ Epoch 11/100 | Train Loss: 0.4473 | Val Loss: 0.4640 | Val Acc: 0.9861
ğŸ•’ Epoch 12/100 | Train Loss: 0.4459 | Val Loss: 0.4658 | Val Acc: 0.9861
ğŸ•’ Epoch 13/100 | Train Loss: 0.4414 | Val Loss: 0.4508 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 14/100 | Train Loss: 0.4315 | Val Loss: 0.4522 | Val Acc: 0.9931
ğŸ•’ Epoch 15/100 | Train Loss: 0.4346 | Val Loss: 0.4609 | Val Acc: 0.9908
ğŸ•’ Epoch 16/100 | Train Loss: 0.4271 | Val Loss: 0.4452 | Val Acc: 0.9931
ğŸ’¾ Best model updated (val acc: 0.9931)
ğŸ•’ Epoch 17/100 | Train Loss: 0.4320 | Val Loss: 0.4465 | Val Acc: 0.9908
ğŸ•’ Epoch 18/100 | Train Loss: 0.4271 | Val Loss: 0.4417 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 19/100 | Train Loss: 0.4234 | Val Loss: 0.4621 | Val Acc: 0.9838
ğŸ•’ Epoch 20/100 | Train Loss: 0.4365 | Val Loss: 0.4534 | Val Acc: 0.9861
ğŸ•’ Epoch 21/100 | Train Loss: 0.4423 | Val Loss: 0.4561 | Val Acc: 0.9885
ğŸ•’ Epoch 22/100 | Train Loss: 0.4323 | Val Loss: 0.4599 | Val Acc: 0.9815
ğŸ•’ Epoch 23/100 | Train Loss: 0.4282 | Val Loss: 0.4467 | Val Acc: 0.9931
ğŸ•’ Epoch 24/100 | Train Loss: 0.4226 | Val Loss: 0.4361 | Val Acc: 0.9954
ğŸ’¾ Best model updated (val acc: 0.9954)
ğŸ•’ Epoch 25/100 | Train Loss: 0.4263 | Val Loss: 0.4522 | Val Acc: 0.9861
ğŸ•’ Epoch 26/100 | Train Loss: 0.4229 | Val Loss: 0.4495 | Val Acc: 0.9861
ğŸ•’ Epoch 27/100 | Train Loss: 0.4222 | Val Loss: 0.4365 | Val Acc: 0.9954
ğŸ•’ Epoch 28/100 | Train Loss: 0.4215 | Val Loss: 0.4357 | Val Acc: 0.9954
ğŸ’¾ Best model updated (val acc: 0.9954)
ğŸ•’ Epoch 29/100 | Train Loss: 0.4249 | Val Loss: 0.4400 | Val Acc: 0.9908
ğŸ•’ Epoch 30/100 | Train Loss: 0.4252 | Val Loss: 0.4368 | Val Acc: 0.9954
ğŸ•’ Epoch 31/100 | Train Loss: 0.4232 | Val Loss: 0.4392 | Val Acc: 0.9931
ğŸ•’ Epoch 32/100 | Train Loss: 0.4218 | Val Loss: 0.4379 | Val Acc: 0.9931
ğŸ•’ Epoch 33/100 | Train Loss: 0.4253 | Val Loss: 0.4441 | Val Acc: 0.9908
ğŸ•’ Epoch 34/100 | Train Loss: 0.4224 | Val Loss: 0.4430 | Val Acc: 0.9931
ğŸ•’ Epoch 35/100 | Train Loss: 0.4217 | Val Loss: 0.4402 | Val Acc: 0.9931
ğŸ•’ Epoch 36/100 | Train Loss: 0.4215 | Val Loss: 0.4396 | Val Acc: 0.9931
ğŸ•’ Epoch 37/100 | Train Loss: 0.4214 | Val Loss: 0.4394 | Val Acc: 0.9931
ğŸ•’ Epoch 38/100 | Train Loss: 0.4215 | Val Loss: 0.4388 | Val Acc: 0.9931
â¹ï¸ Early stopping.
âœ… Fold 4 complete. Saved: ./output/models/ConvNeXt+4cbam+res+last-norm+dataset1_kfold+dataset1_kfold_fold4.pth

ğŸ“‚ Fold 5/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7856 | Val Loss: 0.5081 | Val Acc: 0.9677
ğŸ’¾ Best model updated (val acc: 0.9677)
ğŸ•’ Epoch 2/100 | Train Loss: 0.5197 | Val Loss: 0.5157 | Val Acc: 0.9630
ğŸ•’ Epoch 3/100 | Train Loss: 0.4955 | Val Loss: 0.4858 | Val Acc: 0.9792
ğŸ’¾ Best model updated (val acc: 0.9792)
ğŸ•’ Epoch 4/100 | Train Loss: 0.4623 | Val Loss: 0.5085 | Val Acc: 0.9584
ğŸ•’ Epoch 5/100 | Train Loss: 0.4561 | Val Loss: 0.4667 | Val Acc: 0.9815
ğŸ’¾ Best model updated (val acc: 0.9815)
ğŸ•’ Epoch 6/100 | Train Loss: 0.4580 | Val Loss: 0.4627 | Val Acc: 0.9792
ğŸ’¾ Best model updated (val acc: 0.9792)
ğŸ•’ Epoch 7/100 | Train Loss: 0.4434 | Val Loss: 0.4868 | Val Acc: 0.9654
ğŸ•’ Epoch 8/100 | Train Loss: 0.4669 | Val Loss: 0.4544 | Val Acc: 0.9861
ğŸ’¾ Best model updated (val acc: 0.9861)
ğŸ•’ Epoch 9/100 | Train Loss: 0.4462 | Val Loss: 0.4695 | Val Acc: 0.9815
ğŸ•’ Epoch 10/100 | Train Loss: 0.4566 | Val Loss: 0.4609 | Val Acc: 0.9838
ğŸ•’ Epoch 11/100 | Train Loss: 0.4397 | Val Loss: 0.4679 | Val Acc: 0.9792
ğŸ•’ Epoch 12/100 | Train Loss: 0.4416 | Val Loss: 0.4522 | Val Acc: 0.9861
ğŸ’¾ Best model updated (val acc: 0.9861)
ğŸ•’ Epoch 13/100 | Train Loss: 0.4278 | Val Loss: 0.4566 | Val Acc: 0.9838
ğŸ•’ Epoch 14/100 | Train Loss: 0.4296 | Val Loss: 0.4588 | Val Acc: 0.9792
ğŸ•’ Epoch 15/100 | Train Loss: 0.4278 | Val Loss: 0.4578 | Val Acc: 0.9861
ğŸ•’ Epoch 16/100 | Train Loss: 0.4383 | Val Loss: 0.4887 | Val Acc: 0.9677
ğŸ•’ Epoch 17/100 | Train Loss: 0.4332 | Val Loss: 0.4952 | Val Acc: 0.9700
ğŸ•’ Epoch 18/100 | Train Loss: 0.4326 | Val Loss: 0.4629 | Val Acc: 0.9792
ğŸ•’ Epoch 19/100 | Train Loss: 0.4292 | Val Loss: 0.4669 | Val Acc: 0.9769
ğŸ•’ Epoch 20/100 | Train Loss: 0.4381 | Val Loss: 0.4575 | Val Acc: 0.9861
ğŸ•’ Epoch 21/100 | Train Loss: 0.4244 | Val Loss: 0.4579 | Val Acc: 0.9861
ğŸ•’ Epoch 22/100 | Train Loss: 0.4224 | Val Loss: 0.4553 | Val Acc: 0.9838
â¹ï¸ Early stopping.
âœ… Fold 5 complete. Saved: ./output/models/ConvNeXt+4cbam+res+last-norm+dataset1_kfold+dataset1_kfold_fold5.pth
ğŸ“‚ Training metrics plot saved for Fold 1: output/test/fold_1/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 2: output/test/fold_2/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 3: output/test/fold_3/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 4: output/test/fold_4/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 5: output/test/fold_5/training_metrics.png
ğŸ‰ All folds completed.
ğŸš€ Evaluating 5 fold models on test set

ğŸ“‚ Evaluating Fold 1
ğŸ“Š Fold 1 Metrics:
   - Accuracy: 0.9926
   - Precision: 0.9929
   - Recall: 0.9928
   - F1 Score: 0.9928

ğŸ“‚ Evaluating Fold 2
ğŸ“Š Fold 2 Metrics:
   - Accuracy: 0.9890
   - Precision: 0.9892
   - Recall: 0.9892
   - F1 Score: 0.9891

ğŸ“‚ Evaluating Fold 3
ğŸ“Š Fold 3 Metrics:
   - Accuracy: 0.9853
   - Precision: 0.9855
   - Recall: 0.9854
   - F1 Score: 0.9854

ğŸ“‚ Evaluating Fold 4
ğŸ“Š Fold 4 Metrics:
   - Accuracy: 0.9816
   - Precision: 0.9819
   - Recall: 0.9820
   - F1 Score: 0.9819

ğŸ“‚ Evaluating Fold 5
ğŸ“Š Fold 5 Metrics:
   - Accuracy: 0.9853
   - Precision: 0.9856
   - Recall: 0.9855
   - F1 Score: 0.9855

ğŸ§¾ Classification Report for ConvNeXt+4cbam+res+last-norm+dataset1_kfold (Majority Vote from 5 folds):

                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    1.0000    1.0000        88
           brown_spot     0.9889    0.9570    0.9727        93
              healthy     0.9789    1.0000    0.9894        93
           leaf_blast     0.9783    0.9890    0.9836        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9908       543
            macro avg     0.9910    0.9910    0.9909       543
         weighted avg     0.9908    0.9908    0.9908       543

ğŸ”¢ Confusion Matrix:
 [[88  0  0  0  0  0]
 [ 0 89  2  2  0  0]
 [ 0  0 93  0  0  0]
 [ 0  1  0 90  0  0]
 [ 0  0  0  0 90  0]
 [ 0  0  0  0  0 88]]

ğŸ“Š Average Metrics Across All Folds:
   - Accuracy: 0.9867
   - Precision: 0.9870
   - Recall: 0.9870
   - F1 Score: 0.9869

âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: 4cbam+res+batchnormlast+dataset1]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
ğŸ•’ Epoch 1/100 | Time: 69.67s | Train Loss: 0.7302 | Val Loss: 0.5281 | Val Acc: 0.9577 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9577
ğŸ•’ Epoch 2/100 | Time: 68.88s | Train Loss: 0.5197 | Val Loss: 0.5112 | Val Acc: 0.9669 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9669
ğŸ•’ Epoch 3/100 | Time: 68.72s | Train Loss: 0.4955 | Val Loss: 0.4840 | Val Acc: 0.9743 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9743
ğŸ•’ Epoch 4/100 | Time: 68.63s | Train Loss: 0.4885 | Val Loss: 0.5000 | Val Acc: 0.9651 | LR: 0.000099 
ğŸ•’ Epoch 5/100 | Time: 69.69s | Train Loss: 0.4640 | Val Loss: 0.5023 | Val Acc: 0.9688 | LR: 0.000098 
ğŸ•’ Epoch 6/100 | Time: 70.73s | Train Loss: 0.4565 | Val Loss: 0.4693 | Val Acc: 0.9871 | LR: 0.000098 
ğŸ’¾ Saving best val acc: 0.9871
ğŸ•’ Epoch 7/100 | Time: 69.19s | Train Loss: 0.4577 | Val Loss: 0.4684 | Val Acc: 0.9835 | LR: 0.000097 
ğŸ’¾ Saving best val acc: 0.9835
ğŸ•’ Epoch 8/100 | Time: 69.48s | Train Loss: 0.4489 | Val Loss: 0.4826 | Val Acc: 0.9779 | LR: 0.000095 
ğŸ•’ Epoch 9/100 | Time: 69.57s | Train Loss: 0.4695 | Val Loss: 0.4990 | Val Acc: 0.9743 | LR: 0.000094 
ğŸ•’ Epoch 10/100 | Time: 69.82s | Train Loss: 0.4602 | Val Loss: 0.4816 | Val Acc: 0.9816 | LR: 0.000092 
ğŸ•’ Epoch 11/100 | Time: 69.58s | Train Loss: 0.4481 | Val Loss: 0.4796 | Val Acc: 0.9798 | LR: 0.000091 
ğŸ•’ Epoch 12/100 | Time: 69.91s | Train Loss: 0.4513 | Val Loss: 0.4625 | Val Acc: 0.9835 | LR: 0.000089 
ğŸ’¾ Saving best val acc: 0.9835
ğŸ•’ Epoch 13/100 | Time: 70.67s | Train Loss: 0.4449 | Val Loss: 0.4673 | Val Acc: 0.9835 | LR: 0.000087 
ğŸ•’ Epoch 14/100 | Time: 70.86s | Train Loss: 0.4455 | Val Loss: 0.4682 | Val Acc: 0.9835 | LR: 0.000084 
ğŸ•’ Epoch 15/100 | Time: 70.28s | Train Loss: 0.4422 | Val Loss: 0.4570 | Val Acc: 0.9871 | LR: 0.000082 
ğŸ’¾ Saving best val acc: 0.9871
ğŸ•’ Epoch 16/100 | Time: 71.70s | Train Loss: 0.4393 | Val Loss: 0.4661 | Val Acc: 0.9871 | LR: 0.000080 
ğŸ•’ Epoch 17/100 | Time: 72.11s | Train Loss: 0.4423 | Val Loss: 0.4648 | Val Acc: 0.9853 | LR: 0.000077 
ğŸ•’ Epoch 18/100 | Time: 71.31s | Train Loss: 0.4480 | Val Loss: 0.4742 | Val Acc: 0.9798 | LR: 0.000074 
ğŸ•’ Epoch 19/100 | Time: 71.16s | Train Loss: 0.4543 | Val Loss: 0.4778 | Val Acc: 0.9779 | LR: 0.000072 
ğŸ•’ Epoch 20/100 | Time: 71.67s | Train Loss: 0.4428 | Val Loss: 0.4757 | Val Acc: 0.9816 | LR: 0.000069 
ğŸ•’ Epoch 21/100 | Time: 71.05s | Train Loss: 0.4363 | Val Loss: 0.4666 | Val Acc: 0.9816 | LR: 0.000066 
ğŸ•’ Epoch 22/100 | Time: 71.16s | Train Loss: 0.4367 | Val Loss: 0.4983 | Val Acc: 0.9688 | LR: 0.000063 
ğŸ•’ Epoch 23/100 | Time: 71.19s | Train Loss: 0.4378 | Val Loss: 0.4728 | Val Acc: 0.9779 | LR: 0.000060 
ğŸ•’ Epoch 24/100 | Time: 70.08s | Train Loss: 0.4408 | Val Loss: 0.4704 | Val Acc: 0.9798 | LR: 0.000057 
ğŸ•’ Epoch 25/100 | Time: 71.43s | Train Loss: 0.4341 | Val Loss: 0.4662 | Val Acc: 0.9816 | LR: 0.000054 
â¹ï¸ Early stopping triggered.
âœ… Training complete in 1758.66 seconds. Best model loaded.
ğŸ“ Model saved to ./output/models/4cbam+res+batchnormlast+dataset1+dataset1.pth
ğŸ“‚ Training metrics plot saved to: output/test/4cbam+res+batchnormlast+dataset1/training metric.png
Evaluate model:4cbam+res+batchnormlast+dataset1

ğŸ”¥ Test Accuracy: 98.90%

ğŸ“Œ Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    0.9886    0.9943        88
           brown_spot     0.9783    0.9677    0.9730        93
              healthy     0.9894    1.0000    0.9947        93
           leaf_blast     0.9674    0.9780    0.9727        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9890       543
            macro avg     0.9892    0.9891    0.9891       543
         weighted avg     0.9890    0.9890    0.9890       543

ğŸ“‚ Confusion matrix saved to: output/test/4cbam+res+batchnormlast+dataset1/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/4cbam+res+batchnormlast+dataset1/grad_cam folder!
Saved misclassified images to output/test/4cbam+res+batchnormlast+dataset1/misclassified_images.png


ğŸ“‚ Fold 1/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7260 | Val Loss: 0.5301 | Val Acc: 0.9493
ğŸ’¾ Best model updated (val acc: 0.9493)
ğŸ•’ Epoch 2/100 | Train Loss: 0.5348 | Val Loss: 0.4882 | Val Acc: 0.9677
ğŸ’¾ Best model updated (val acc: 0.9677)
ğŸ•’ Epoch 3/100 | Train Loss: 0.5062 | Val Loss: 0.4733 | Val Acc: 0.9816
ğŸ’¾ Best model updated (val acc: 0.9816)
ğŸ•’ Epoch 4/100 | Train Loss: 0.4727 | Val Loss: 0.4742 | Val Acc: 0.9793
ğŸ•’ Epoch 5/100 | Train Loss: 0.4705 | Val Loss: 0.4671 | Val Acc: 0.9862
ğŸ’¾ Best model updated (val acc: 0.9862)
ğŸ•’ Epoch 6/100 | Train Loss: 0.5038 | Val Loss: 0.5000 | Val Acc: 0.9677
ğŸ•’ Epoch 7/100 | Train Loss: 0.4724 | Val Loss: 0.4833 | Val Acc: 0.9724
ğŸ•’ Epoch 8/100 | Train Loss: 0.4535 | Val Loss: 0.4649 | Val Acc: 0.9724
ğŸ’¾ Best model updated (val acc: 0.9724)
ğŸ•’ Epoch 9/100 | Train Loss: 0.4543 | Val Loss: 0.4538 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 10/100 | Train Loss: 0.4591 | Val Loss: 0.5104 | Val Acc: 0.9608
ğŸ•’ Epoch 11/100 | Train Loss: 0.4573 | Val Loss: 0.4491 | Val Acc: 0.9862
ğŸ’¾ Best model updated (val acc: 0.9862)
ğŸ•’ Epoch 12/100 | Train Loss: 0.4441 | Val Loss: 0.4669 | Val Acc: 0.9793
ğŸ•’ Epoch 13/100 | Train Loss: 0.4450 | Val Loss: 0.4494 | Val Acc: 0.9839
ğŸ•’ Epoch 14/100 | Train Loss: 0.4446 | Val Loss: 0.4479 | Val Acc: 0.9885
ğŸ’¾ Best model updated (val acc: 0.9885)
ğŸ•’ Epoch 15/100 | Train Loss: 0.4483 | Val Loss: 0.4410 | Val Acc: 0.9931
ğŸ’¾ Best model updated (val acc: 0.9931)
ğŸ•’ Epoch 16/100 | Train Loss: 0.4475 | Val Loss: 0.4575 | Val Acc: 0.9885
ğŸ•’ Epoch 17/100 | Train Loss: 0.4473 | Val Loss: 0.4387 | Val Acc: 0.9931
ğŸ’¾ Best model updated (val acc: 0.9931)
ğŸ•’ Epoch 18/100 | Train Loss: 0.4568 | Val Loss: 0.4702 | Val Acc: 0.9816
ğŸ•’ Epoch 19/100 | Train Loss: 0.4419 | Val Loss: 0.4466 | Val Acc: 0.9931
ğŸ•’ Epoch 20/100 | Train Loss: 0.4373 | Val Loss: 0.4405 | Val Acc: 0.9931
ğŸ•’ Epoch 21/100 | Train Loss: 0.4353 | Val Loss: 0.4393 | Val Acc: 0.9954
ğŸ•’ Epoch 22/100 | Train Loss: 0.4336 | Val Loss: 0.4393 | Val Acc: 0.9931
ğŸ•’ Epoch 23/100 | Train Loss: 0.4367 | Val Loss: 0.4495 | Val Acc: 0.9908
ğŸ•’ Epoch 24/100 | Train Loss: 0.4339 | Val Loss: 0.4587 | Val Acc: 0.9862
ğŸ•’ Epoch 25/100 | Train Loss: 0.4375 | Val Loss: 0.4364 | Val Acc: 0.9954
ğŸ’¾ Best model updated (val acc: 0.9954)
ğŸ•’ Epoch 26/100 | Train Loss: 0.4324 | Val Loss: 0.4372 | Val Acc: 0.9931
ğŸ•’ Epoch 27/100 | Train Loss: 0.4370 | Val Loss: 0.4375 | Val Acc: 0.9954
ğŸ•’ Epoch 28/100 | Train Loss: 0.4335 | Val Loss: 0.4358 | Val Acc: 0.9954
ğŸ’¾ Best model updated (val acc: 0.9954)
ğŸ•’ Epoch 29/100 | Train Loss: 0.4341 | Val Loss: 0.4338 | Val Acc: 0.9954
ğŸ’¾ Best model updated (val acc: 0.9954)
ğŸ•’ Epoch 30/100 | Train Loss: 0.4368 | Val Loss: 0.4367 | Val Acc: 0.9954
ğŸ•’ Epoch 31/100 | Train Loss: 0.4314 | Val Loss: 0.4335 | Val Acc: 0.9954
ğŸ’¾ Best model updated (val acc: 0.9954)
ğŸ•’ Epoch 32/100 | Train Loss: 0.4310 | Val Loss: 0.4346 | Val Acc: 0.9954
ğŸ•’ Epoch 33/100 | Train Loss: 0.4328 | Val Loss: 0.4334 | Val Acc: 0.9977
ğŸ’¾ Best model updated (val acc: 0.9977)
ğŸ•’ Epoch 34/100 | Train Loss: 0.4318 | Val Loss: 0.4376 | Val Acc: 0.9954
ğŸ•’ Epoch 35/100 | Train Loss: 0.4322 | Val Loss: 0.4415 | Val Acc: 0.9931
ğŸ•’ Epoch 36/100 | Train Loss: 0.4309 | Val Loss: 0.4509 | Val Acc: 0.9885
ğŸ•’ Epoch 37/100 | Train Loss: 0.4350 | Val Loss: 0.4376 | Val Acc: 0.9954
ğŸ•’ Epoch 38/100 | Train Loss: 0.4306 | Val Loss: 0.4364 | Val Acc: 0.9954
ğŸ•’ Epoch 39/100 | Train Loss: 0.4307 | Val Loss: 0.4375 | Val Acc: 0.9954
ğŸ•’ Epoch 40/100 | Train Loss: 0.4310 | Val Loss: 0.4375 | Val Acc: 0.9931
ğŸ•’ Epoch 41/100 | Train Loss: 0.4308 | Val Loss: 0.4363 | Val Acc: 0.9954
ğŸ•’ Epoch 42/100 | Train Loss: 0.4315 | Val Loss: 0.4363 | Val Acc: 0.9954
ğŸ•’ Epoch 43/100 | Train Loss: 0.4295 | Val Loss: 0.4363 | Val Acc: 0.9954
â¹ï¸ Early stopping.
âœ… Fold 1 complete. Saved: ./output/models/4cbam+res+batchnormlast+dataset1_kfold+dataset1_kfold_fold1.pth

ğŸ“‚ Fold 2/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7238 | Val Loss: 0.5464 | Val Acc: 0.9539
ğŸ’¾ Best model updated (val acc: 0.9539)
ğŸ•’ Epoch 2/100 | Train Loss: 0.5306 | Val Loss: 0.4787 | Val Acc: 0.9862
ğŸ’¾ Best model updated (val acc: 0.9862)
ğŸ•’ Epoch 3/100 | Train Loss: 0.4961 | Val Loss: 0.4798 | Val Acc: 0.9816
ğŸ•’ Epoch 4/100 | Train Loss: 0.4759 | Val Loss: 0.4813 | Val Acc: 0.9770
ğŸ•’ Epoch 5/100 | Train Loss: 0.4715 | Val Loss: 0.4671 | Val Acc: 0.9793
ğŸ’¾ Best model updated (val acc: 0.9793)
ğŸ•’ Epoch 6/100 | Train Loss: 0.4610 | Val Loss: 0.4679 | Val Acc: 0.9839
ğŸ•’ Epoch 7/100 | Train Loss: 0.4663 | Val Loss: 0.4634 | Val Acc: 0.9885
ğŸ’¾ Best model updated (val acc: 0.9885)
ğŸ•’ Epoch 8/100 | Train Loss: 0.4585 | Val Loss: 0.4697 | Val Acc: 0.9793
ğŸ•’ Epoch 9/100 | Train Loss: 0.4562 | Val Loss: 0.4990 | Val Acc: 0.9770
ğŸ•’ Epoch 10/100 | Train Loss: 0.4453 | Val Loss: 0.4592 | Val Acc: 0.9885
ğŸ’¾ Best model updated (val acc: 0.9885)
ğŸ•’ Epoch 11/100 | Train Loss: 0.4477 | Val Loss: 0.4628 | Val Acc: 0.9862
ğŸ•’ Epoch 12/100 | Train Loss: 0.4525 | Val Loss: 0.4797 | Val Acc: 0.9839
ğŸ•’ Epoch 13/100 | Train Loss: 0.4519 | Val Loss: 0.4565 | Val Acc: 0.9862
ğŸ’¾ Best model updated (val acc: 0.9862)
ğŸ•’ Epoch 14/100 | Train Loss: 0.4465 | Val Loss: 0.5139 | Val Acc: 0.9585
ğŸ•’ Epoch 15/100 | Train Loss: 0.4902 | Val Loss: 0.4704 | Val Acc: 0.9793
ğŸ•’ Epoch 16/100 | Train Loss: 0.4479 | Val Loss: 0.4767 | Val Acc: 0.9862
ğŸ•’ Epoch 17/100 | Train Loss: 0.4501 | Val Loss: 0.4595 | Val Acc: 0.9839
ğŸ•’ Epoch 18/100 | Train Loss: 0.4454 | Val Loss: 0.4468 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 19/100 | Train Loss: 0.4396 | Val Loss: 0.4666 | Val Acc: 0.9862
ğŸ•’ Epoch 20/100 | Train Loss: 0.4446 | Val Loss: 0.4493 | Val Acc: 0.9885
ğŸ•’ Epoch 21/100 | Train Loss: 0.4366 | Val Loss: 0.4864 | Val Acc: 0.9724
ğŸ•’ Epoch 22/100 | Train Loss: 0.4376 | Val Loss: 0.4532 | Val Acc: 0.9908
ğŸ•’ Epoch 23/100 | Train Loss: 0.4361 | Val Loss: 0.4522 | Val Acc: 0.9885
ğŸ•’ Epoch 24/100 | Train Loss: 0.4337 | Val Loss: 0.4490 | Val Acc: 0.9885
ğŸ•’ Epoch 25/100 | Train Loss: 0.4391 | Val Loss: 0.4585 | Val Acc: 0.9816
ğŸ•’ Epoch 26/100 | Train Loss: 0.4372 | Val Loss: 0.4576 | Val Acc: 0.9816
ğŸ•’ Epoch 27/100 | Train Loss: 0.4373 | Val Loss: 0.4630 | Val Acc: 0.9839
ğŸ•’ Epoch 28/100 | Train Loss: 0.4342 | Val Loss: 0.4625 | Val Acc: 0.9862
â¹ï¸ Early stopping.
âœ… Fold 2 complete. Saved: ./output/models/4cbam+res+batchnormlast+dataset1_kfold+dataset1_kfold_fold2.pth

ğŸ“‚ Fold 3/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7751 | Val Loss: 0.5521 | Val Acc: 0.9607
ğŸ’¾ Best model updated (val acc: 0.9607)
ğŸ•’ Epoch 2/100 | Train Loss: 0.5469 | Val Loss: 0.4839 | Val Acc: 0.9792
ğŸ’¾ Best model updated (val acc: 0.9792)
ğŸ•’ Epoch 3/100 | Train Loss: 0.5016 | Val Loss: 0.4806 | Val Acc: 0.9815
ğŸ’¾ Best model updated (val acc: 0.9815)
ğŸ•’ Epoch 4/100 | Train Loss: 0.4787 | Val Loss: 0.4610 | Val Acc: 0.9861
ğŸ’¾ Best model updated (val acc: 0.9861)
ğŸ•’ Epoch 5/100 | Train Loss: 0.4815 | Val Loss: 0.4754 | Val Acc: 0.9885
ğŸ•’ Epoch 6/100 | Train Loss: 0.4751 | Val Loss: 0.4885 | Val Acc: 0.9792
ğŸ•’ Epoch 7/100 | Train Loss: 0.4840 | Val Loss: 0.4679 | Val Acc: 0.9838
ğŸ•’ Epoch 8/100 | Train Loss: 0.4569 | Val Loss: 0.4567 | Val Acc: 0.9885
ğŸ’¾ Best model updated (val acc: 0.9885)
ğŸ•’ Epoch 9/100 | Train Loss: 0.4693 | Val Loss: 0.4508 | Val Acc: 0.9885
ğŸ’¾ Best model updated (val acc: 0.9885)
ğŸ•’ Epoch 10/100 | Train Loss: 0.4653 | Val Loss: 0.4531 | Val Acc: 0.9908
ğŸ•’ Epoch 11/100 | Train Loss: 0.4503 | Val Loss: 0.4460 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 12/100 | Train Loss: 0.4542 | Val Loss: 0.4524 | Val Acc: 0.9931
ğŸ•’ Epoch 13/100 | Train Loss: 0.4528 | Val Loss: 0.4375 | Val Acc: 0.9977
ğŸ’¾ Best model updated (val acc: 0.9977)
ğŸ•’ Epoch 14/100 | Train Loss: 0.4637 | Val Loss: 0.4467 | Val Acc: 0.9908
ğŸ•’ Epoch 15/100 | Train Loss: 0.4414 | Val Loss: 0.4490 | Val Acc: 0.9885
ğŸ•’ Epoch 16/100 | Train Loss: 0.4403 | Val Loss: 0.4334 | Val Acc: 0.9977
ğŸ’¾ Best model updated (val acc: 0.9977)
ğŸ•’ Epoch 17/100 | Train Loss: 0.4646 | Val Loss: 0.4494 | Val Acc: 0.9838
ğŸ•’ Epoch 18/100 | Train Loss: 0.4429 | Val Loss: 0.4463 | Val Acc: 0.9931
ğŸ•’ Epoch 19/100 | Train Loss: 0.4383 | Val Loss: 0.4446 | Val Acc: 0.9908
ğŸ•’ Epoch 20/100 | Train Loss: 0.4371 | Val Loss: 0.4417 | Val Acc: 0.9931
ğŸ•’ Epoch 21/100 | Train Loss: 0.4364 | Val Loss: 0.4372 | Val Acc: 0.9931
ğŸ•’ Epoch 22/100 | Train Loss: 0.4399 | Val Loss: 0.4350 | Val Acc: 0.9931
ğŸ•’ Epoch 23/100 | Train Loss: 0.4472 | Val Loss: 0.4607 | Val Acc: 0.9838
ğŸ•’ Epoch 24/100 | Train Loss: 0.4413 | Val Loss: 0.4409 | Val Acc: 0.9931
ğŸ•’ Epoch 25/100 | Train Loss: 0.4368 | Val Loss: 0.4399 | Val Acc: 0.9931
ğŸ•’ Epoch 26/100 | Train Loss: 0.4352 | Val Loss: 0.4304 | Val Acc: 0.9954
ğŸ’¾ Best model updated (val acc: 0.9954)
ğŸ•’ Epoch 27/100 | Train Loss: 0.4317 | Val Loss: 0.4300 | Val Acc: 0.9977
ğŸ’¾ Best model updated (val acc: 0.9977)
ğŸ•’ Epoch 28/100 | Train Loss: 0.4342 | Val Loss: 0.4355 | Val Acc: 0.9954
ğŸ•’ Epoch 29/100 | Train Loss: 0.4314 | Val Loss: 0.4309 | Val Acc: 0.9954
ğŸ•’ Epoch 30/100 | Train Loss: 0.4312 | Val Loss: 0.4309 | Val Acc: 0.9954
ğŸ•’ Epoch 31/100 | Train Loss: 0.4309 | Val Loss: 0.4292 | Val Acc: 0.9954
ğŸ’¾ Best model updated (val acc: 0.9954)
ğŸ•’ Epoch 32/100 | Train Loss: 0.4309 | Val Loss: 0.4296 | Val Acc: 0.9977
ğŸ•’ Epoch 33/100 | Train Loss: 0.4337 | Val Loss: 0.4386 | Val Acc: 0.9931
ğŸ•’ Epoch 34/100 | Train Loss: 0.4338 | Val Loss: 0.4329 | Val Acc: 0.9954
ğŸ•’ Epoch 35/100 | Train Loss: 0.4332 | Val Loss: 0.4321 | Val Acc: 0.9977
ğŸ•’ Epoch 36/100 | Train Loss: 0.4316 | Val Loss: 0.4418 | Val Acc: 0.9931
ğŸ•’ Epoch 37/100 | Train Loss: 0.4305 | Val Loss: 0.4330 | Val Acc: 0.9954
ğŸ•’ Epoch 38/100 | Train Loss: 0.4302 | Val Loss: 0.4298 | Val Acc: 0.9977
ğŸ•’ Epoch 39/100 | Train Loss: 0.4320 | Val Loss: 0.4289 | Val Acc: 0.9977
ğŸ’¾ Best model updated (val acc: 0.9977)
ğŸ•’ Epoch 40/100 | Train Loss: 0.4316 | Val Loss: 0.4286 | Val Acc: 0.9977
ğŸ’¾ Best model updated (val acc: 0.9977)
ğŸ•’ Epoch 41/100 | Train Loss: 0.4315 | Val Loss: 0.4279 | Val Acc: 0.9977
ğŸ’¾ Best model updated (val acc: 0.9977)
ğŸ•’ Epoch 42/100 | Train Loss: 0.4316 | Val Loss: 0.4282 | Val Acc: 0.9977
ğŸ•’ Epoch 43/100 | Train Loss: 0.4316 | Val Loss: 0.4286 | Val Acc: 0.9977
ğŸ•’ Epoch 44/100 | Train Loss: 0.4325 | Val Loss: 0.4283 | Val Acc: 0.9977
ğŸ•’ Epoch 45/100 | Train Loss: 0.4309 | Val Loss: 0.4284 | Val Acc: 0.9977
ğŸ•’ Epoch 46/100 | Train Loss: 0.4300 | Val Loss: 0.4287 | Val Acc: 0.9977
ğŸ•’ Epoch 47/100 | Train Loss: 0.4304 | Val Loss: 0.4288 | Val Acc: 0.9977
ğŸ•’ Epoch 48/100 | Train Loss: 0.4306 | Val Loss: 0.4285 | Val Acc: 0.9977
ğŸ•’ Epoch 49/100 | Train Loss: 0.4315 | Val Loss: 0.4283 | Val Acc: 0.9977
ğŸ•’ Epoch 50/100 | Train Loss: 0.4306 | Val Loss: 0.4287 | Val Acc: 0.9977
ğŸ•’ Epoch 51/100 | Train Loss: 0.4317 | Val Loss: 0.4296 | Val Acc: 0.9977
â¹ï¸ Early stopping.
âœ… Fold 3 complete. Saved: ./output/models/4cbam+res+batchnormlast+dataset1_kfold+dataset1_kfold_fold3.pth

ğŸ“‚ Fold 4/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7186 | Val Loss: 0.6140 | Val Acc: 0.9122
ğŸ’¾ Best model updated (val acc: 0.9122)
ğŸ•’ Epoch 2/100 | Train Loss: 0.5187 | Val Loss: 0.5432 | Val Acc: 0.9538
ğŸ’¾ Best model updated (val acc: 0.9538)
ğŸ•’ Epoch 3/100 | Train Loss: 0.4992 | Val Loss: 0.4814 | Val Acc: 0.9746
ğŸ’¾ Best model updated (val acc: 0.9746)
ğŸ•’ Epoch 4/100 | Train Loss: 0.4682 | Val Loss: 0.4768 | Val Acc: 0.9838
ğŸ’¾ Best model updated (val acc: 0.9838)
ğŸ•’ Epoch 5/100 | Train Loss: 0.4807 | Val Loss: 0.4821 | Val Acc: 0.9723
ğŸ•’ Epoch 6/100 | Train Loss: 0.4712 | Val Loss: 0.4671 | Val Acc: 0.9815
ğŸ’¾ Best model updated (val acc: 0.9815)
ğŸ•’ Epoch 7/100 | Train Loss: 0.4642 | Val Loss: 0.4672 | Val Acc: 0.9885
ğŸ•’ Epoch 8/100 | Train Loss: 0.4770 | Val Loss: 0.4641 | Val Acc: 0.9861
ğŸ’¾ Best model updated (val acc: 0.9861)
ğŸ•’ Epoch 9/100 | Train Loss: 0.4645 | Val Loss: 0.4733 | Val Acc: 0.9769
ğŸ•’ Epoch 10/100 | Train Loss: 0.4543 | Val Loss: 0.4594 | Val Acc: 0.9885
ğŸ’¾ Best model updated (val acc: 0.9885)
ğŸ•’ Epoch 11/100 | Train Loss: 0.4464 | Val Loss: 0.4619 | Val Acc: 0.9815
ğŸ•’ Epoch 12/100 | Train Loss: 0.4511 | Val Loss: 0.4558 | Val Acc: 0.9861
ğŸ’¾ Best model updated (val acc: 0.9861)
ğŸ•’ Epoch 13/100 | Train Loss: 0.4362 | Val Loss: 0.4677 | Val Acc: 0.9792
ğŸ•’ Epoch 14/100 | Train Loss: 0.4541 | Val Loss: 0.4592 | Val Acc: 0.9861
ğŸ•’ Epoch 15/100 | Train Loss: 0.4460 | Val Loss: 0.4641 | Val Acc: 0.9885
ğŸ•’ Epoch 16/100 | Train Loss: 0.4537 | Val Loss: 0.4584 | Val Acc: 0.9861
ğŸ•’ Epoch 17/100 | Train Loss: 0.4376 | Val Loss: 0.4540 | Val Acc: 0.9885
ğŸ’¾ Best model updated (val acc: 0.9885)
ğŸ•’ Epoch 18/100 | Train Loss: 0.4435 | Val Loss: 0.4693 | Val Acc: 0.9815
ğŸ•’ Epoch 19/100 | Train Loss: 0.4431 | Val Loss: 0.4516 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 20/100 | Train Loss: 0.4385 | Val Loss: 0.4536 | Val Acc: 0.9885
ğŸ•’ Epoch 21/100 | Train Loss: 0.4360 | Val Loss: 0.4494 | Val Acc: 0.9908
ğŸ’¾ Best model updated (val acc: 0.9908)
ğŸ•’ Epoch 22/100 | Train Loss: 0.4345 | Val Loss: 0.4504 | Val Acc: 0.9908
ğŸ•’ Epoch 23/100 | Train Loss: 0.4370 | Val Loss: 0.4432 | Val Acc: 0.9931
ğŸ’¾ Best model updated (val acc: 0.9931)
ğŸ•’ Epoch 24/100 | Train Loss: 0.4455 | Val Loss: 0.4455 | Val Acc: 0.9954
ğŸ•’ Epoch 25/100 | Train Loss: 0.4341 | Val Loss: 0.4436 | Val Acc: 0.9954
ğŸ•’ Epoch 26/100 | Train Loss: 0.4337 | Val Loss: 0.4428 | Val Acc: 0.9931
ğŸ’¾ Best model updated (val acc: 0.9931)
ğŸ•’ Epoch 27/100 | Train Loss: 0.4330 | Val Loss: 0.4431 | Val Acc: 0.9931
ğŸ•’ Epoch 28/100 | Train Loss: 0.4350 | Val Loss: 0.4442 | Val Acc: 0.9931
ğŸ•’ Epoch 29/100 | Train Loss: 0.4334 | Val Loss: 0.4528 | Val Acc: 0.9908
ğŸ•’ Epoch 30/100 | Train Loss: 0.4330 | Val Loss: 0.4530 | Val Acc: 0.9908
ğŸ•’ Epoch 31/100 | Train Loss: 0.4320 | Val Loss: 0.4495 | Val Acc: 0.9908
ğŸ•’ Epoch 32/100 | Train Loss: 0.4308 | Val Loss: 0.4503 | Val Acc: 0.9908
ğŸ•’ Epoch 33/100 | Train Loss: 0.4306 | Val Loss: 0.4454 | Val Acc: 0.9931
ğŸ•’ Epoch 34/100 | Train Loss: 0.4312 | Val Loss: 0.4453 | Val Acc: 0.9931
ğŸ•’ Epoch 35/100 | Train Loss: 0.4303 | Val Loss: 0.4463 | Val Acc: 0.9931
ğŸ•’ Epoch 36/100 | Train Loss: 0.4310 | Val Loss: 0.4467 | Val Acc: 0.9908
â¹ï¸ Early stopping.
âœ… Fold 4 complete. Saved: ./output/models/4cbam+res+batchnormlast+dataset1_kfold+dataset1_kfold_fold4.pth

ğŸ“‚ Fold 5/5
ğŸ•’ Epoch 1/100 | Train Loss: 0.7685 | Val Loss: 0.5031 | Val Acc: 0.9723
ğŸ’¾ Best model updated (val acc: 0.9723)
ğŸ•’ Epoch 2/100 | Train Loss: 0.5159 | Val Loss: 0.4825 | Val Acc: 0.9746
ğŸ’¾ Best model updated (val acc: 0.9746)
ğŸ•’ Epoch 3/100 | Train Loss: 0.4805 | Val Loss: 0.4754 | Val Acc: 0.9838
ğŸ’¾ Best model updated (val acc: 0.9838)
ğŸ•’ Epoch 4/100 | Train Loss: 0.4851 | Val Loss: 0.4686 | Val Acc: 0.9838
ğŸ’¾ Best model updated (val acc: 0.9838)
ğŸ•’ Epoch 5/100 | Train Loss: 0.4743 | Val Loss: 0.4772 | Val Acc: 0.9815
ğŸ•’ Epoch 6/100 | Train Loss: 0.4846 | Val Loss: 0.5164 | Val Acc: 0.9538
ğŸ•’ Epoch 7/100 | Train Loss: 0.4614 | Val Loss: 0.4720 | Val Acc: 0.9815
ğŸ•’ Epoch 8/100 | Train Loss: 0.4530 | Val Loss: 0.4712 | Val Acc: 0.9838
ğŸ•’ Epoch 9/100 | Train Loss: 0.4510 | Val Loss: 0.4672 | Val Acc: 0.9885
ğŸ’¾ Best model updated (val acc: 0.9885)
ğŸ•’ Epoch 10/100 | Train Loss: 0.4720 | Val Loss: 0.4881 | Val Acc: 0.9792
ğŸ•’ Epoch 11/100 | Train Loss: 0.4476 | Val Loss: 0.5155 | Val Acc: 0.9677
ğŸ•’ Epoch 12/100 | Train Loss: 0.4605 | Val Loss: 0.4790 | Val Acc: 0.9792
ğŸ•’ Epoch 13/100 | Train Loss: 0.4398 | Val Loss: 0.4616 | Val Acc: 0.9861
ğŸ’¾ Best model updated (val acc: 0.9861)
ğŸ•’ Epoch 14/100 | Train Loss: 0.4477 | Val Loss: 0.4799 | Val Acc: 0.9723
ğŸ•’ Epoch 15/100 | Train Loss: 0.4418 | Val Loss: 0.4655 | Val Acc: 0.9861
ğŸ•’ Epoch 16/100 | Train Loss: 0.4429 | Val Loss: 0.4616 | Val Acc: 0.9815
ğŸ•’ Epoch 17/100 | Train Loss: 0.4335 | Val Loss: 0.4638 | Val Acc: 0.9861
ğŸ•’ Epoch 18/100 | Train Loss: 0.4381 | Val Loss: 0.4599 | Val Acc: 0.9838
ğŸ’¾ Best model updated (val acc: 0.9838)
ğŸ•’ Epoch 19/100 | Train Loss: 0.4443 | Val Loss: 0.4688 | Val Acc: 0.9838
ğŸ•’ Epoch 20/100 | Train Loss: 0.4430 | Val Loss: 0.4692 | Val Acc: 0.9792
ğŸ•’ Epoch 21/100 | Train Loss: 0.4461 | Val Loss: 0.4573 | Val Acc: 0.9861
ğŸ’¾ Best model updated (val acc: 0.9861)
ğŸ•’ Epoch 22/100 | Train Loss: 0.4378 | Val Loss: 0.4559 | Val Acc: 0.9885
ğŸ’¾ Best model updated (val acc: 0.9885)
ğŸ•’ Epoch 23/100 | Train Loss: 0.4332 | Val Loss: 0.4549 | Val Acc: 0.9861
ğŸ’¾ Best model updated (val acc: 0.9861)
ğŸ•’ Epoch 24/100 | Train Loss: 0.4346 | Val Loss: 0.4631 | Val Acc: 0.9861
ğŸ•’ Epoch 25/100 | Train Loss: 0.4332 | Val Loss: 0.4577 | Val Acc: 0.9861
ğŸ•’ Epoch 26/100 | Train Loss: 0.4338 | Val Loss: 0.4530 | Val Acc: 0.9885
ğŸ’¾ Best model updated (val acc: 0.9885)
ğŸ•’ Epoch 27/100 | Train Loss: 0.4330 | Val Loss: 0.4605 | Val Acc: 0.9861
ğŸ•’ Epoch 28/100 | Train Loss: 0.4332 | Val Loss: 0.4571 | Val Acc: 0.9861
ğŸ•’ Epoch 29/100 | Train Loss: 0.4411 | Val Loss: 0.4641 | Val Acc: 0.9838
ğŸ•’ Epoch 30/100 | Train Loss: 0.4365 | Val Loss: 0.4568 | Val Acc: 0.9885
ğŸ•’ Epoch 31/100 | Train Loss: 0.4323 | Val Loss: 0.4527 | Val Acc: 0.9885
ğŸ’¾ Best model updated (val acc: 0.9885)
ğŸ•’ Epoch 32/100 | Train Loss: 0.4368 | Val Loss: 0.4624 | Val Acc: 0.9861
ğŸ•’ Epoch 33/100 | Train Loss: 0.4323 | Val Loss: 0.4612 | Val Acc: 0.9885
ğŸ•’ Epoch 34/100 | Train Loss: 0.4328 | Val Loss: 0.4593 | Val Acc: 0.9885
ğŸ•’ Epoch 35/100 | Train Loss: 0.4310 | Val Loss: 0.4654 | Val Acc: 0.9838
ğŸ•’ Epoch 36/100 | Train Loss: 0.4312 | Val Loss: 0.4620 | Val Acc: 0.9861
ğŸ•’ Epoch 37/100 | Train Loss: 0.4321 | Val Loss: 0.4592 | Val Acc: 0.9885
ğŸ•’ Epoch 38/100 | Train Loss: 0.4327 | Val Loss: 0.4604 | Val Acc: 0.9885
ğŸ•’ Epoch 39/100 | Train Loss: 0.4318 | Val Loss: 0.4605 | Val Acc: 0.9885
ğŸ•’ Epoch 40/100 | Train Loss: 0.4310 | Val Loss: 0.4595 | Val Acc: 0.9885
ğŸ•’ Epoch 41/100 | Train Loss: 0.4323 | Val Loss: 0.4579 | Val Acc: 0.9885
â¹ï¸ Early stopping.
âœ… Fold 5 complete. Saved: ./output/models/4cbam+res+batchnormlast+dataset1_kfold+dataset1_kfold_fold5.pth
ğŸ“‚ Training metrics plot saved for Fold 1: output/test/fold_1/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 2: output/test/fold_2/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 3: output/test/fold_3/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 4: output/test/fold_4/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 5: output/test/fold_5/training_metrics.png
ğŸ‰ All folds completed.
ğŸš€ Evaluating 5 fold models on test set

ğŸ“‚ Evaluating Fold 1
ğŸ“Š Fold 1 Metrics:
   - Accuracy: 0.9908
   - Precision: 0.9911
   - Recall: 0.9909
   - F1 Score: 0.9909

ğŸ“‚ Evaluating Fold 2
ğŸ“Š Fold 2 Metrics:
   - Accuracy: 0.9871
   - Precision: 0.9874
   - Recall: 0.9873
   - F1 Score: 0.9873

ğŸ“‚ Evaluating Fold 3
ğŸ“Š Fold 3 Metrics:
   - Accuracy: 0.9926
   - Precision: 0.9928
   - Recall: 0.9928
   - F1 Score: 0.9928

ğŸ“‚ Evaluating Fold 4
ğŸ“Š Fold 4 Metrics:
   - Accuracy: 0.9834
   - Precision: 0.9837
   - Recall: 0.9838
   - F1 Score: 0.9837

ğŸ“‚ Evaluating Fold 5
ğŸ“Š Fold 5 Metrics:
   - Accuracy: 0.9853
   - Precision: 0.9859
   - Recall: 0.9854
   - F1 Score: 0.9855

ğŸ§¾ Classification Report for 4cbam+res+batchnormlast+dataset1_kfold (Majority Vote from 5 folds):

                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    1.0000    1.0000        88
           brown_spot     0.9890    0.9677    0.9783        93
              healthy     0.9789    1.0000    0.9894        93
           leaf_blast     0.9890    0.9890    0.9890        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9926       543
            macro avg     0.9928    0.9928    0.9928       543
         weighted avg     0.9927    0.9926    0.9926       543

ğŸ”¢ Confusion Matrix:
 [[88  0  0  0  0  0]
 [ 0 90  2  1  0  0]
 [ 0  0 93  0  0  0]
 [ 0  1  0 90  0  0]
 [ 0  0  0  0 90  0]
 [ 0  0  0  0  0 88]]

ğŸ“Š Average Metrics Across All Folds:
   - Accuracy: 0.9878
   - Precision: 0.9882
   - Recall: 0.9880
   - F1 Score: 0.9880
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: last+cbam+dataset1]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
ğŸ•’ Epoch 1/100 | Time: 73.60s | Train Loss: 0.9049 | Val Loss: 0.5937 | Val Acc: 0.9449 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9449
ğŸ•’ Epoch 2/100 | Time: 68.31s | Train Loss: 0.5595 | Val Loss: 0.5329 | Val Acc: 0.9577 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9577
ğŸ•’ Epoch 3/100 | Time: 68.75s | Train Loss: 0.5045 | Val Loss: 0.5012 | Val Acc: 0.9706 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9706
ğŸ•’ Epoch 4/100 | Time: 69.37s | Train Loss: 0.4732 | Val Loss: 0.5145 | Val Acc: 0.9651 | LR: 0.000099 
ğŸ•’ Epoch 5/100 | Time: 70.02s | Train Loss: 0.4561 | Val Loss: 0.5092 | Val Acc: 0.9614 | LR: 0.000098 
ğŸ•’ Epoch 6/100 | Time: 69.57s | Train Loss: 0.4609 | Val Loss: 0.4919 | Val Acc: 0.9761 | LR: 0.000098 
ğŸ’¾ Saving best val acc: 0.9761
ğŸ•’ Epoch 7/100 | Time: 70.34s | Train Loss: 0.4483 | Val Loss: 0.4838 | Val Acc: 0.9779 | LR: 0.000097 
ğŸ’¾ Saving best val acc: 0.9779
ğŸ•’ Epoch 8/100 | Time: 69.26s | Train Loss: 0.4411 | Val Loss: 0.4614 | Val Acc: 0.9871 | LR: 0.000095 
ğŸ’¾ Saving best val acc: 0.9871
ğŸ•’ Epoch 9/100 | Time: 69.97s | Train Loss: 0.4367 | Val Loss: 0.4807 | Val Acc: 0.9798 | LR: 0.000094 
ğŸ•’ Epoch 10/100 | Time: 70.36s | Train Loss: 0.4586 | Val Loss: 0.4808 | Val Acc: 0.9743 | LR: 0.000092 
ğŸ•’ Epoch 11/100 | Time: 70.47s | Train Loss: 0.4382 | Val Loss: 0.4784 | Val Acc: 0.9798 | LR: 0.000091 
ğŸ•’ Epoch 12/100 | Time: 70.00s | Train Loss: 0.4368 | Val Loss: 0.4799 | Val Acc: 0.9779 | LR: 0.000089 
ğŸ•’ Epoch 13/100 | Time: 69.58s | Train Loss: 0.4451 | Val Loss: 0.4763 | Val Acc: 0.9798 | LR: 0.000087 
ğŸ•’ Epoch 14/100 | Time: 70.10s | Train Loss: 0.4548 | Val Loss: 0.4866 | Val Acc: 0.9743 | LR: 0.000084 
ğŸ•’ Epoch 15/100 | Time: 69.21s | Train Loss: 0.4625 | Val Loss: 0.5075 | Val Acc: 0.9688 | LR: 0.000082 
ğŸ•’ Epoch 16/100 | Time: 70.38s | Train Loss: 0.4424 | Val Loss: 0.4712 | Val Acc: 0.9816 | LR: 0.000080 
ğŸ•’ Epoch 17/100 | Time: 71.00s | Train Loss: 0.4336 | Val Loss: 0.4581 | Val Acc: 0.9853 | LR: 0.000077 
ğŸ’¾ Saving best val acc: 0.9853
ğŸ•’ Epoch 18/100 | Time: 70.34s | Train Loss: 0.4287 | Val Loss: 0.4739 | Val Acc: 0.9835 | LR: 0.000074 
ğŸ•’ Epoch 19/100 | Time: 71.02s | Train Loss: 0.4377 | Val Loss: 0.4768 | Val Acc: 0.9761 | LR: 0.000072 
ğŸ•’ Epoch 20/100 | Time: 70.54s | Train Loss: 0.4239 | Val Loss: 0.4648 | Val Acc: 0.9871 | LR: 0.000069 
ğŸ•’ Epoch 21/100 | Time: 70.18s | Train Loss: 0.4272 | Val Loss: 0.4663 | Val Acc: 0.9853 | LR: 0.000066 
ğŸ•’ Epoch 22/100 | Time: 70.60s | Train Loss: 0.4279 | Val Loss: 0.4773 | Val Acc: 0.9798 | LR: 0.000063 
ğŸ•’ Epoch 23/100 | Time: 71.02s | Train Loss: 0.4255 | Val Loss: 0.4616 | Val Acc: 0.9871 | LR: 0.000060 
ğŸ•’ Epoch 24/100 | Time: 70.95s | Train Loss: 0.4239 | Val Loss: 0.4530 | Val Acc: 0.9890 | LR: 0.000057 
ğŸ’¾ Saving best val acc: 0.9890
ğŸ•’ Epoch 25/100 | Time: 70.80s | Train Loss: 0.4230 | Val Loss: 0.4655 | Val Acc: 0.9835 | LR: 0.000054 
ğŸ•’ Epoch 26/100 | Time: 70.83s | Train Loss: 0.4235 | Val Loss: 0.4646 | Val Acc: 0.9835 | LR: 0.000050 
ğŸ•’ Epoch 27/100 | Time: 71.10s | Train Loss: 0.4225 | Val Loss: 0.4683 | Val Acc: 0.9835 | LR: 0.000047 
ğŸ•’ Epoch 28/100 | Time: 70.99s | Train Loss: 0.4223 | Val Loss: 0.4602 | Val Acc: 0.9871 | LR: 0.000044 
ğŸ•’ Epoch 29/100 | Time: 70.07s | Train Loss: 0.4245 | Val Loss: 0.4665 | Val Acc: 0.9835 | LR: 0.000041 
ğŸ•’ Epoch 30/100 | Time: 71.17s | Train Loss: 0.4229 | Val Loss: 0.4631 | Val Acc: 0.9835 | LR: 0.000038 
ğŸ•’ Epoch 31/100 | Time: 69.90s | Train Loss: 0.4252 | Val Loss: 0.4535 | Val Acc: 0.9890 | LR: 0.000035 
ğŸ•’ Epoch 32/100 | Time: 71.11s | Train Loss: 0.4225 | Val Loss: 0.4539 | Val Acc: 0.9890 | LR: 0.000032 
ğŸ•’ Epoch 33/100 | Time: 71.03s | Train Loss: 0.4223 | Val Loss: 0.4542 | Val Acc: 0.9890 | LR: 0.000029 
ğŸ•’ Epoch 34/100 | Time: 71.09s | Train Loss: 0.4225 | Val Loss: 0.4532 | Val Acc: 0.9890 | LR: 0.000027 
â¹ï¸ Early stopping triggered.
âœ… Training complete in 2393.17 seconds. Best model loaded.
ğŸ“ Model saved to ./output/models/last+cbam+dataset1+dataset1.pth
ğŸ“‚ Training metrics plot saved to: output/test/last+cbam+dataset1/training metric.png
Evaluate model:last+cbam+dataset1

ğŸ”¥ Test Accuracy: 98.53%

ğŸ“Œ Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    0.9773    0.9885        88
           brown_spot     0.9783    0.9677    0.9730        93
              healthy     0.9892    0.9892    0.9892        93
           leaf_blast     0.9780    0.9780    0.9780        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     0.9670    1.0000    0.9832        88

             accuracy                         0.9853       543
            macro avg     0.9854    0.9854    0.9853       543
         weighted avg     0.9854    0.9853    0.9853       543

ğŸ“‚ Confusion matrix saved to: output/test/last+cbam+dataset1/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/last+cbam+dataset1/grad_cam folder!
Saved misclassified images to output/test/last+cbam+dataset1/misclassified_images.png

ğŸ•’ Epoch 1/100 | Time: 69.65s | Train Loss: 0.9272 | Val Loss: 0.6689 | Val Acc: 0.9044 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9044
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: between_2_stage_+dataset1]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
ğŸ•’ Epoch 1/100 | Time: 72.20s | Train Loss: 0.8581 | Val Loss: 0.5569 | Val Acc: 0.9540 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9540
ğŸ•’ Epoch 2/100 | Time: 70.89s | Train Loss: 0.5263 | Val Loss: 0.5240 | Val Acc: 0.9596 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9596
ğŸ•’ Epoch 3/100 | Time: 70.71s | Train Loss: 0.4836 | Val Loss: 0.4912 | Val Acc: 0.9743 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 0.9743
ğŸ•’ Epoch 4/100 | Time: 70.18s | Train Loss: 0.4583 | Val Loss: 0.5176 | Val Acc: 0.9688 | LR: 0.000099 
ğŸ•’ Epoch 5/100 | Time: 70.33s | Train Loss: 0.4661 | Val Loss: 0.5018 | Val Acc: 0.9761 | LR: 0.000098 
ğŸ•’ Epoch 6/100 | Time: 70.91s | Train Loss: 0.4776 | Val Loss: 0.4815 | Val Acc: 0.9798 | LR: 0.000098 
ğŸ’¾ Saving best val acc: 0.9798
ğŸ•’ Epoch 7/100 | Time: 70.41s | Train Loss: 0.4712 | Val Loss: 0.4901 | Val Acc: 0.9761 | LR: 0.000097 
ğŸ•’ Epoch 8/100 | Time: 71.19s | Train Loss: 0.4536 | Val Loss: 0.4647 | Val Acc: 0.9816 | LR: 0.000095 
ğŸ’¾ Saving best val acc: 0.9816
ğŸ•’ Epoch 9/100 | Time: 70.79s | Train Loss: 0.4386 | Val Loss: 0.4597 | Val Acc: 0.9853 | LR: 0.000094 
ğŸ’¾ Saving best val acc: 0.9853
ğŸ•’ Epoch 10/100 | Time: 70.61s | Train Loss: 0.4336 | Val Loss: 0.4643 | Val Acc: 0.9816 | LR: 0.000092 
ğŸ•’ Epoch 11/100 | Time: 70.59s | Train Loss: 0.4369 | Val Loss: 0.4712 | Val Acc: 0.9835 | LR: 0.000091 
ğŸ•’ Epoch 12/100 | Time: 70.26s | Train Loss: 0.4370 | Val Loss: 0.4621 | Val Acc: 0.9835 | LR: 0.000089 
ğŸ•’ Epoch 13/100 | Time: 70.85s | Train Loss: 0.4671 | Val Loss: 0.4612 | Val Acc: 0.9853 | LR: 0.000087 
ğŸ•’ Epoch 14/100 | Time: 69.59s | Train Loss: 0.4332 | Val Loss: 0.4590 | Val Acc: 0.9871 | LR: 0.000084 
ğŸ’¾ Saving best val acc: 0.9871
ğŸ•’ Epoch 15/100 | Time: 72.48s | Train Loss: 0.4331 | Val Loss: 0.4570 | Val Acc: 0.9853 | LR: 0.000082 
ğŸ’¾ Saving best val acc: 0.9853
ğŸ•’ Epoch 16/100 | Time: 71.33s | Train Loss: 0.4420 | Val Loss: 0.4899 | Val Acc: 0.9688 | LR: 0.000080 
ğŸ•’ Epoch 17/100 | Time: 71.95s | Train Loss: 0.4490 | Val Loss: 0.4674 | Val Acc: 0.9816 | LR: 0.000077 
ğŸ•’ Epoch 18/100 | Time: 71.34s | Train Loss: 0.4375 | Val Loss: 0.4649 | Val Acc: 0.9835 | LR: 0.000074 
ğŸ•’ Epoch 19/100 | Time: 70.90s | Train Loss: 0.4293 | Val Loss: 0.4544 | Val Acc: 0.9871 | LR: 0.000072 
ğŸ’¾ Saving best val acc: 0.9871
ğŸ•’ Epoch 20/100 | Time: 71.04s | Train Loss: 0.4264 | Val Loss: 0.4569 | Val Acc: 0.9908 | LR: 0.000069 
ğŸ•’ Epoch 21/100 | Time: 71.17s | Train Loss: 0.4377 | Val Loss: 0.4679 | Val Acc: 0.9871 | LR: 0.000066 
ğŸ•’ Epoch 22/100 | Time: 71.41s | Train Loss: 0.4385 | Val Loss: 0.4690 | Val Acc: 0.9798 | LR: 0.000063 
ğŸ•’ Epoch 23/100 | Time: 71.25s | Train Loss: 0.4280 | Val Loss: 0.4628 | Val Acc: 0.9853 | LR: 0.000060 
ğŸ•’ Epoch 24/100 | Time: 71.01s | Train Loss: 0.4241 | Val Loss: 0.4534 | Val Acc: 0.9853 | LR: 0.000057 
ğŸ’¾ Saving best val acc: 0.9853
ğŸ•’ Epoch 25/100 | Time: 70.33s | Train Loss: 0.4242 | Val Loss: 0.4595 | Val Acc: 0.9835 | LR: 0.000054 
ğŸ•’ Epoch 26/100 | Time: 70.70s | Train Loss: 0.4239 | Val Loss: 0.4603 | Val Acc: 0.9853 | LR: 0.000050 
ğŸ•’ Epoch 27/100 | Time: 70.88s | Train Loss: 0.4269 | Val Loss: 0.4545 | Val Acc: 0.9853 | LR: 0.000047 
ğŸ•’ Epoch 28/100 | Time: 70.94s | Train Loss: 0.4238 | Val Loss: 0.4539 | Val Acc: 0.9853 | LR: 0.000044 
ğŸ•’ Epoch 29/100 | Time: 71.45s | Train Loss: 0.4224 | Val Loss: 0.4571 | Val Acc: 0.9853 | LR: 0.000041 
ğŸ•’ Epoch 30/100 | Time: 71.55s | Train Loss: 0.4222 | Val Loss: 0.4595 | Val Acc: 0.9835 | LR: 0.000038 
ğŸ•’ Epoch 31/100 | Time: 70.64s | Train Loss: 0.4240 | Val Loss: 0.4543 | Val Acc: 0.9871 | LR: 0.000035 
ğŸ•’ Epoch 32/100 | Time: 71.47s | Train Loss: 0.4229 | Val Loss: 0.4627 | Val Acc: 0.9835 | LR: 0.000032 
ğŸ•’ Epoch 33/100 | Time: 71.65s | Train Loss: 0.4221 | Val Loss: 0.4618 | Val Acc: 0.9853 | LR: 0.000029 
ğŸ•’ Epoch 34/100 | Time: 71.06s | Train Loss: 0.4222 | Val Loss: 0.4616 | Val Acc: 0.9853 | LR: 0.000027 
â¹ï¸ Early stopping triggered.
âœ… Training complete in 2414.24 seconds. Best model loaded.
ğŸ“ Model saved to ./output/models/between_2_stage_+dataset1+dataset1.pth
ğŸ“‚ Training metrics plot saved to: output/test/between_2_stage_+dataset1/training metric.png
Evaluate model:between_2_stage_+dataset1

ğŸ”¥ Test Accuracy: 98.90%

ğŸ“Œ Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    1.0000    1.0000        88
           brown_spot     0.9677    0.9677    0.9677        93
              healthy     0.9789    1.0000    0.9894        93
           leaf_blast     0.9888    0.9670    0.9778        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9890       543
            macro avg     0.9892    0.9891    0.9891       543
         weighted avg     0.9890    0.9890    0.9889       543

ğŸ“‚ Confusion matrix saved to: output/test/between_2_stage_+dataset1/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/between_2_stage_+dataset1/grad_cam folder!
Saved misclassified images to output/test/between_2_stage_+dataset1/misclassified_images.png
Evaluate model:ConvNeXt+dataset1

Evaluate model:4cbam+res+batchnormlast+dataset1

ğŸ”¥ Test Accuracy: 98.90%

ğŸ“Œ Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    0.9886    0.9943        88
           brown_spot     0.9783    0.9677    0.9730        93
              healthy     0.9894    1.0000    0.9947        93
           leaf_blast     0.9674    0.9780    0.9727        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9890       543
            macro avg     0.9892    0.9891    0.9891       543
         weighted avg     0.9890    0.9890    0.9890       543

ğŸ“‚ Confusion matrix saved to: output/test/4cbam+res+batchnormlast+dataset1/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/4cbam+res+batchnormlast+dataset1/grad_cam folder!
Saved misclassified images to output/test/4cbam+res+batchnormlast+dataset1/misclassified_images.png
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: 4cbam+res+batchnormlast+dataset3]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
ğŸ•’ Epoch 1/100 | Time: 121.88s | Train Loss: 0.4259 | Val Loss: 0.3586 | Val Acc: 1.0000 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 2/100 | Time: 111.33s | Train Loss: 0.3690 | Val Loss: 0.3616 | Val Acc: 0.9966 | LR: 0.000100 
ğŸ•’ Epoch 3/100 | Time: 115.53s | Train Loss: 0.3749 | Val Loss: 0.3549 | Val Acc: 1.0000 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 4/100 | Time: 117.13s | Train Loss: 0.3631 | Val Loss: 0.3526 | Val Acc: 1.0000 | LR: 0.000099 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 5/100 | Time: 117.38s | Train Loss: 0.3617 | Val Loss: 0.3502 | Val Acc: 1.0000 | LR: 0.000098 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 6/100 | Time: 116.23s | Train Loss: 0.3607 | Val Loss: 0.3509 | Val Acc: 1.0000 | LR: 0.000098 
ğŸ•’ Epoch 7/100 | Time: 114.37s | Train Loss: 0.3619 | Val Loss: 0.3505 | Val Acc: 1.0000 | LR: 0.000097 
ğŸ•’ Epoch 8/100 | Time: 114.32s | Train Loss: 0.3607 | Val Loss: 0.3504 | Val Acc: 1.0000 | LR: 0.000095 
ğŸ•’ Epoch 9/100 | Time: 115.07s | Train Loss: 0.3595 | Val Loss: 0.3495 | Val Acc: 1.0000 | LR: 0.000094 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 10/100 | Time: 114.64s | Train Loss: 0.3594 | Val Loss: 0.3509 | Val Acc: 1.0000 | LR: 0.000092 
ğŸ•’ Epoch 11/100 | Time: 114.59s | Train Loss: 0.3598 | Val Loss: 0.3514 | Val Acc: 1.0000 | LR: 0.000091 
ğŸ•’ Epoch 12/100 | Time: 114.27s | Train Loss: 0.3611 | Val Loss: 0.3506 | Val Acc: 1.0000 | LR: 0.000089 
ğŸ•’ Epoch 13/100 | Time: 114.41s | Train Loss: 0.3593 | Val Loss: 0.3508 | Val Acc: 1.0000 | LR: 0.000087 
ğŸ•’ Epoch 14/100 | Time: 114.23s | Train Loss: 0.3592 | Val Loss: 0.3511 | Val Acc: 1.0000 | LR: 0.000084 
ğŸ•’ Epoch 15/100 | Time: 114.39s | Train Loss: 0.3590 | Val Loss: 0.3497 | Val Acc: 1.0000 | LR: 0.000082 
ğŸ•’ Epoch 16/100 | Time: 114.25s | Train Loss: 0.3599 | Val Loss: 0.3517 | Val Acc: 1.0000 | LR: 0.000080 
ğŸ•’ Epoch 17/100 | Time: 114.30s | Train Loss: 0.3602 | Val Loss: 0.3516 | Val Acc: 1.0000 | LR: 0.000077 
ğŸ•’ Epoch 18/100 | Time: 114.39s | Train Loss: 0.3581 | Val Loss: 0.3493 | Val Acc: 1.0000 | LR: 0.000074 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 19/100 | Time: 114.40s | Train Loss: 0.3598 | Val Loss: 0.3496 | Val Acc: 1.0000 | LR: 0.000072 
ğŸ•’ Epoch 20/100 | Time: 114.22s | Train Loss: 0.3803 | Val Loss: 0.3509 | Val Acc: 1.0000 | LR: 0.000069 
ğŸ•’ Epoch 21/100 | Time: 114.28s | Train Loss: 0.3602 | Val Loss: 0.3517 | Val Acc: 1.0000 | LR: 0.000066 
ğŸ•’ Epoch 22/100 | Time: 114.45s | Train Loss: 0.3595 | Val Loss: 0.3492 | Val Acc: 1.0000 | LR: 0.000063 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 23/100 | Time: 114.38s | Train Loss: 0.3595 | Val Loss: 0.3520 | Val Acc: 1.0000 | LR: 0.000060 
ğŸ•’ Epoch 24/100 | Time: 114.43s | Train Loss: 0.3597 | Val Loss: 0.3523 | Val Acc: 1.0000 | LR: 0.000057 
ğŸ•’ Epoch 25/100 | Time: 114.33s | Train Loss: 0.3598 | Val Loss: 0.3490 | Val Acc: 1.0000 | LR: 0.000054 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 26/100 | Time: 114.36s | Train Loss: 0.3590 | Val Loss: 0.3494 | Val Acc: 1.0000 | LR: 0.000050 
ğŸ•’ Epoch 27/100 | Time: 114.43s | Train Loss: 0.3595 | Val Loss: 0.3494 | Val Acc: 1.0000 | LR: 0.000047 
ğŸ•’ Epoch 28/100 | Time: 114.31s | Train Loss: 0.3595 | Val Loss: 0.3510 | Val Acc: 1.0000 | LR: 0.000044 
ğŸ•’ Epoch 29/100 | Time: 114.14s | Train Loss: 0.3583 | Val Loss: 0.3498 | Val Acc: 1.0000 | LR: 0.000041 
ğŸ•’ Epoch 30/100 | Time: 114.55s | Train Loss: 0.3595 | Val Loss: 0.3506 | Val Acc: 1.0000 | LR: 0.000038 
ğŸ•’ Epoch 31/100 | Time: 114.48s | Train Loss: 0.3585 | Val Loss: 0.3495 | Val Acc: 1.0000 | LR: 0.000035 
ğŸ•’ Epoch 32/100 | Time: 114.43s | Train Loss: 0.3594 | Val Loss: 0.3499 | Val Acc: 1.0000 | LR: 0.000032 
ğŸ•’ Epoch 33/100 | Time: 114.29s | Train Loss: 0.3587 | Val Loss: 0.3492 | Val Acc: 1.0000 | LR: 0.000029 
ğŸ•’ Epoch 34/100 | Time: 114.22s | Train Loss: 0.3596 | Val Loss: 0.3509 | Val Acc: 1.0000 | LR: 0.000027 
ğŸ•’ Epoch 35/100 | Time: 114.28s | Train Loss: 0.3589 | Val Loss: 0.3500 | Val Acc: 1.0000 | LR: 0.000024 
â¹ï¸ Early stopping triggered.
âœ… Training complete in 4016.84 seconds. Best model loaded.
ğŸ“ Model saved to ./output/models/4cbam+res+batchnormlast+dataset3+dataset3.pth
ğŸ“‚ Training metrics plot saved to: output/test/4cbam+res+batchnormlast+dataset3/training metric.png
Evaluate model:4cbam+res+batchnormlast+dataset3

ğŸ”¥ Test Accuracy: 100.00%

ğŸ“Œ Classification Report:
                 precision    recall  f1-score   support

Bacterialblight     1.0000    1.0000    1.0000       160
          Blast     1.0000    1.0000    1.0000       145
      Brownspot     1.0000    1.0000    1.0000       160
         Tungro     1.0000    1.0000    1.0000       132

       accuracy                         1.0000       597
      macro avg     1.0000    1.0000    1.0000       597
   weighted avg     1.0000    1.0000    1.0000       597

ğŸ“‚ Confusion matrix saved to: output/test/4cbam+res+batchnormlast+dataset3/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/4cbam+res+batchnormlast+dataset3/grad_cam folder!

âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: ConvNeXt+dataset3]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
ğŸ•’ Epoch 1/100 | Time: 127.23s | Train Loss: 0.4253 | Val Loss: 0.3522 | Val Acc: 1.0000 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 2/100 | Time: 126.57s | Train Loss: 0.3510 | Val Loss: 0.3502 | Val Acc: 1.0000 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 3/100 | Time: 126.24s | Train Loss: 0.3496 | Val Loss: 0.3495 | Val Acc: 1.0000 | LR: 0.000100 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 4/100 | Time: 125.49s | Train Loss: 0.3493 | Val Loss: 0.3494 | Val Acc: 1.0000 | LR: 0.000099 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 5/100 | Time: 124.71s | Train Loss: 0.3491 | Val Loss: 0.3492 | Val Acc: 1.0000 | LR: 0.000098 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 6/100 | Time: 125.49s | Train Loss: 0.3491 | Val Loss: 0.3491 | Val Acc: 1.0000 | LR: 0.000098 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 7/100 | Time: 124.13s | Train Loss: 0.3490 | Val Loss: 0.3490 | Val Acc: 1.0000 | LR: 0.000097 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 8/100 | Time: 124.74s | Train Loss: 0.3490 | Val Loss: 0.3489 | Val Acc: 1.0000 | LR: 0.000095 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 9/100 | Time: 125.53s | Train Loss: 0.3489 | Val Loss: 0.3489 | Val Acc: 1.0000 | LR: 0.000094 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 10/100 | Time: 125.26s | Train Loss: 0.3489 | Val Loss: 0.3489 | Val Acc: 1.0000 | LR: 0.000092 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 11/100 | Time: 125.52s | Train Loss: 0.3489 | Val Loss: 0.3489 | Val Acc: 1.0000 | LR: 0.000091 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 12/100 | Time: 126.34s | Train Loss: 0.3489 | Val Loss: 0.3489 | Val Acc: 1.0000 | LR: 0.000089 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 13/100 | Time: 125.89s | Train Loss: 0.3489 | Val Loss: 0.3489 | Val Acc: 1.0000 | LR: 0.000087 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 14/100 | Time: 125.33s | Train Loss: 0.3489 | Val Loss: 0.3489 | Val Acc: 1.0000 | LR: 0.000084 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 15/100 | Time: 125.94s | Train Loss: 0.3489 | Val Loss: 0.3489 | Val Acc: 1.0000 | LR: 0.000082 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 16/100 | Time: 125.51s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000080 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 17/100 | Time: 125.32s | Train Loss: 0.3488 | Val Loss: 0.3489 | Val Acc: 1.0000 | LR: 0.000077 
ğŸ•’ Epoch 18/100 | Time: 125.94s | Train Loss: 0.3488 | Val Loss: 0.3489 | Val Acc: 1.0000 | LR: 0.000074 
ğŸ•’ Epoch 19/100 | Time: 125.73s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000072 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 20/100 | Time: 126.16s | Train Loss: 0.3488 | Val Loss: 0.3489 | Val Acc: 1.0000 | LR: 0.000069 
ğŸ•’ Epoch 21/100 | Time: 126.36s | Train Loss: 0.3488 | Val Loss: 0.3489 | Val Acc: 1.0000 | LR: 0.000066 
ğŸ•’ Epoch 22/100 | Time: 125.92s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000063 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 23/100 | Time: 125.98s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000060 
ğŸ•’ Epoch 24/100 | Time: 126.58s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000057 
ğŸ•’ Epoch 25/100 | Time: 126.52s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000054 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 26/100 | Time: 125.93s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000050 
ğŸ•’ Epoch 27/100 | Time: 126.21s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000047 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 28/100 | Time: 126.30s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000044 
ğŸ•’ Epoch 29/100 | Time: 126.57s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000041 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 30/100 | Time: 126.36s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000038 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 31/100 | Time: 126.83s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000035 
ğŸ•’ Epoch 32/100 | Time: 126.25s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000032 
ğŸ•’ Epoch 33/100 | Time: 126.15s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000029 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 34/100 | Time: 126.53s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000027 
ğŸ•’ Epoch 35/100 | Time: 126.80s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000024 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 36/100 | Time: 126.50s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000021 
ğŸ•’ Epoch 37/100 | Time: 126.36s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000019 
ğŸ•’ Epoch 38/100 | Time: 126.17s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000017 
ğŸ•’ Epoch 39/100 | Time: 125.94s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000014 
ğŸ•’ Epoch 40/100 | Time: 126.73s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000012 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 41/100 | Time: 126.19s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000010 
ğŸ•’ Epoch 42/100 | Time: 125.53s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000009 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 43/100 | Time: 126.40s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000007 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 44/100 | Time: 125.66s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000006 
ğŸ•’ Epoch 45/100 | Time: 125.55s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000004 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 46/100 | Time: 124.70s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000003 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 47/100 | Time: 125.31s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000003 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 48/100 | Time: 124.92s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000002 
ğŸ•’ Epoch 49/100 | Time: 125.32s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000001 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 50/100 | Time: 126.61s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000001 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 51/100 | Time: 126.34s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000001 
ğŸ•’ Epoch 52/100 | Time: 126.53s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000001 
ğŸ’¾ Saving best val acc: 1.0000
ğŸ•’ Epoch 53/100 | Time: 125.95s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000001 
ğŸ•’ Epoch 54/100 | Time: 126.20s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000002 
ğŸ•’ Epoch 55/100 | Time: 125.99s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000003 
ğŸ•’ Epoch 56/100 | Time: 126.05s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000003 
ğŸ•’ Epoch 57/100 | Time: 125.92s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000004 
ğŸ•’ Epoch 58/100 | Time: 125.14s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000006 
ğŸ•’ Epoch 59/100 | Time: 125.36s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000007 
ğŸ•’ Epoch 60/100 | Time: 125.77s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000009 
ğŸ•’ Epoch 61/100 | Time: 125.88s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000010 
ğŸ•’ Epoch 62/100 | Time: 125.74s | Train Loss: 0.3488 | Val Loss: 0.3488 | Val Acc: 1.0000 | LR: 0.000012 
â¹ï¸ Early stopping triggered.
âœ… Training complete in 7807.72 seconds. Best model loaded.
ğŸ“ Model saved to ./output/models/ConvNeXt+dataset3+dataset3.pth
ğŸ“‚ Training metrics plot saved to: output/test/ConvNeXt+dataset3/training metric.png
Evaluate model:ConvNeXt+dataset3

ğŸ”¥ Test Accuracy: 100.00%

ğŸ“Œ Classification Report:
                 precision    recall  f1-score   support

Bacterialblight     1.0000    1.0000    1.0000       160
          Blast     1.0000    1.0000    1.0000       145
      Brownspot     1.0000    1.0000    1.0000       160
         Tungro     1.0000    1.0000    1.0000       132

       accuracy                         1.0000       597
      macro avg     1.0000    1.0000    1.0000       597
   weighted avg     1.0000    1.0000    1.0000       597

ğŸ“‚ Confusion matrix saved to: output/test/ConvNeXt+dataset3/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+dataset3/grad_cam folder!

âœ… Saved fold class distribution plot to: output/fold_class_distribution.png

ğŸ“‚ Fold 1/5
ğŸ•’ Epoch 1/100 | Train Loss: 1.2069 | Val Loss: 1.1140 | Val Acc: 0.8916
ğŸ’¾ Best model updated (val acc: 0.8916)
ğŸ•’ Epoch 2/100 | Train Loss: 0.8396 | Val Loss: 1.0134 | Val Acc: 0.9252
ğŸ’¾ Best model updated (val acc: 0.9252)
ğŸ•’ Epoch 3/100 | Train Loss: 0.7962 | Val Loss: 0.9582 | Val Acc: 0.9383
ğŸ’¾ Best model updated (val acc: 0.9383)
ğŸ•’ Epoch 4/100 | Train Loss: 0.7594 | Val Loss: 0.9416 | Val Acc: 0.9551
ğŸ’¾ Best model updated (val acc: 0.9551)
ğŸ•’ Epoch 5/100 | Train Loss: 0.7830 | Val Loss: 0.9632 | Val Acc: 0.9458
ğŸ•’ Epoch 6/100 | Train Loss: 0.7332 | Val Loss: 0.9165 | Val Acc: 0.9589
ğŸ’¾ Best model updated (val acc: 0.9589)
ğŸ•’ Epoch 7/100 | Train Loss: 0.7187 | Val Loss: 0.9283 | Val Acc: 0.9607
ğŸ•’ Epoch 8/100 | Train Loss: 0.7170 | Val Loss: 0.9419 | Val Acc: 0.9439
ğŸ•’ Epoch 9/100 | Train Loss: 0.7171 | Val Loss: 0.9613 | Val Acc: 0.9402
ğŸ•’ Epoch 10/100 | Train Loss: 0.7268 | Val Loss: 0.9462 | Val Acc: 0.9533
ğŸ•’ Epoch 11/100 | Train Loss: 0.7139 | Val Loss: 0.9225 | Val Acc: 0.9551
ğŸ•’ Epoch 12/100 | Train Loss: 0.7012 | Val Loss: 0.8980 | Val Acc: 0.9664
ğŸ’¾ Best model updated (val acc: 0.9664)
ğŸ•’ Epoch 13/100 | Train Loss: 0.7021 | Val Loss: 0.8947 | Val Acc: 0.9701
ğŸ’¾ Best model updated (val acc: 0.9701)
ğŸ•’ Epoch 14/100 | Train Loss: 0.6959 | Val Loss: 0.9148 | Val Acc: 0.9533
ğŸ•’ Epoch 15/100 | Train Loss: 0.6982 | Val Loss: 0.8987 | Val Acc: 0.9682
ğŸ•’ Epoch 16/100 | Train Loss: 0.6960 | Val Loss: 0.8805 | Val Acc: 0.9738
ğŸ’¾ Best model updated (val acc: 0.9738)
ğŸ•’ Epoch 17/100 | Train Loss: 0.6949 | Val Loss: 0.8908 | Val Acc: 0.9682
ğŸ•’ Epoch 18/100 | Train Loss: 0.6886 | Val Loss: 0.8833 | Val Acc: 0.9757
ğŸ•’ Epoch 19/100 | Train Loss: 0.7030 | Val Loss: 0.8831 | Val Acc: 0.9701
ğŸ•’ Epoch 20/100 | Train Loss: 0.6938 | Val Loss: 0.8914 | Val Acc: 0.9701
ğŸ•’ Epoch 21/100 | Train Loss: 0.6963 | Val Loss: 0.9033 | Val Acc: 0.9626
ğŸ•’ Epoch 22/100 | Train Loss: 0.6963 | Val Loss: 0.9048 | Val Acc: 0.9607
ğŸ•’ Epoch 23/100 | Train Loss: 0.6873 | Val Loss: 0.8810 | Val Acc: 0.9720
ğŸ•’ Epoch 24/100 | Train Loss: 0.6755 | Val Loss: 0.8903 | Val Acc: 0.9682
ğŸ•’ Epoch 25/100 | Train Loss: 0.6757 | Val Loss: 0.8682 | Val Acc: 0.9813
ğŸ’¾ Best model updated (val acc: 0.9813)
ğŸ•’ Epoch 26/100 | Train Loss: 0.6820 | Val Loss: 0.8806 | Val Acc: 0.9720
ğŸ•’ Epoch 27/100 | Train Loss: 0.6777 | Val Loss: 0.8741 | Val Acc: 0.9776
ğŸ•’ Epoch 28/100 | Train Loss: 0.6721 | Val Loss: 0.8787 | Val Acc: 0.9757
ğŸ•’ Epoch 29/100 | Train Loss: 0.6757 | Val Loss: 0.9036 | Val Acc: 0.9701
ğŸ•’ Epoch 30/100 | Train Loss: 0.6798 | Val Loss: 0.8900 | Val Acc: 0.9664
ğŸ•’ Epoch 31/100 | Train Loss: 0.6775 | Val Loss: 0.8717 | Val Acc: 0.9813
ğŸ•’ Epoch 32/100 | Train Loss: 0.6758 | Val Loss: 0.8774 | Val Acc: 0.9757
ğŸ•’ Epoch 33/100 | Train Loss: 0.6744 | Val Loss: 0.8989 | Val Acc: 0.9664
ğŸ•’ Epoch 34/100 | Train Loss: 0.6776 | Val Loss: 0.8744 | Val Acc: 0.9757
ğŸ•’ Epoch 35/100 | Train Loss: 0.6770 | Val Loss: 0.8694 | Val Acc: 0.9832
â¹ï¸ Early stopping.
âœ… Fold 1 complete. Saved: ./output/models/ConvNeXt+cbam+batchnorm+dataset2+dataset2_fold1.pth

ğŸ“‚ Fold 2/5
ğŸ•’ Epoch 1/100 | Train Loss: 1.2037 | Val Loss: 1.0359 | Val Acc: 0.9028
ğŸ’¾ Best model updated (val acc: 0.9028)
ğŸ•’ Epoch 2/100 | Train Loss: 0.8561 | Val Loss: 0.9793 | Val Acc: 0.9439
ğŸ’¾ Best model updated (val acc: 0.9439)
ğŸ•’ Epoch 3/100 | Train Loss: 0.7746 | Val Loss: 1.0095 | Val Acc: 0.9271
ğŸ•’ Epoch 4/100 | Train Loss: 0.7611 | Val Loss: 0.9488 | Val Acc: 0.9570
ğŸ’¾ Best model updated (val acc: 0.9570)
ğŸ•’ Epoch 5/100 | Train Loss: 0.7550 | Val Loss: 0.9640 | Val Acc: 0.9477
ğŸ•’ Epoch 6/100 | Train Loss: 0.7261 | Val Loss: 0.9407 | Val Acc: 0.9533
ğŸ’¾ Best model updated (val acc: 0.9533)
ğŸ•’ Epoch 7/100 | Train Loss: 0.7274 | Val Loss: 0.9540 | Val Acc: 0.9458
ğŸ•’ Epoch 8/100 | Train Loss: 0.7234 | Val Loss: 0.9330 | Val Acc: 0.9514
ğŸ’¾ Best model updated (val acc: 0.9514)
ğŸ•’ Epoch 9/100 | Train Loss: 0.7221 | Val Loss: 0.9016 | Val Acc: 0.9626
ğŸ’¾ Best model updated (val acc: 0.9626)
ğŸ•’ Epoch 10/100 | Train Loss: 0.7232 | Val Loss: 0.9040 | Val Acc: 0.9701
ğŸ•’ Epoch 11/100 | Train Loss: 0.7064 | Val Loss: 0.9002 | Val Acc: 0.9720
ğŸ’¾ Best model updated (val acc: 0.9720)
ğŸ•’ Epoch 12/100 | Train Loss: 0.7013 | Val Loss: 0.9046 | Val Acc: 0.9720
ğŸ•’ Epoch 13/100 | Train Loss: 0.7036 | Val Loss: 0.9047 | Val Acc: 0.9701
ğŸ•’ Epoch 14/100 | Train Loss: 0.6991 | Val Loss: 0.8965 | Val Acc: 0.9738
ğŸ’¾ Best model updated (val acc: 0.9738)
ğŸ•’ Epoch 15/100 | Train Loss: 0.6993 | Val Loss: 0.8901 | Val Acc: 0.9701
ğŸ’¾ Best model updated (val acc: 0.9701)
ğŸ•’ Epoch 16/100 | Train Loss: 0.6915 | Val Loss: 0.8590 | Val Acc: 0.9757
ğŸ’¾ Best model updated (val acc: 0.9757)
ğŸ•’ Epoch 17/100 | Train Loss: 0.6854 | Val Loss: 0.8623 | Val Acc: 0.9757
ğŸ•’ Epoch 18/100 | Train Loss: 0.6913 | Val Loss: 0.9080 | Val Acc: 0.9626
ğŸ•’ Epoch 19/100 | Train Loss: 0.6854 | Val Loss: 0.9095 | Val Acc: 0.9514
ğŸ•’ Epoch 20/100 | Train Loss: 0.6922 | Val Loss: 0.9004 | Val Acc: 0.9589
ğŸ•’ Epoch 21/100 | Train Loss: 0.6791 | Val Loss: 0.8953 | Val Acc: 0.9607
ğŸ•’ Epoch 22/100 | Train Loss: 0.7046 | Val Loss: 0.9252 | Val Acc: 0.9495
ğŸ•’ Epoch 23/100 | Train Loss: 0.7232 | Val Loss: 0.9277 | Val Acc: 0.9514
ğŸ•’ Epoch 24/100 | Train Loss: 0.6787 | Val Loss: 0.8773 | Val Acc: 0.9776
ğŸ•’ Epoch 25/100 | Train Loss: 0.6799 | Val Loss: 0.8868 | Val Acc: 0.9738
ğŸ•’ Epoch 26/100 | Train Loss: 0.6780 | Val Loss: 0.8946 | Val Acc: 0.9720
â¹ï¸ Early stopping.
âœ… Fold 2 complete. Saved: ./output/models/ConvNeXt+cbam+batchnorm+dataset2+dataset2_fold2.pth

ğŸ“‚ Fold 3/5
ğŸ•’ Epoch 1/100 | Train Loss: 1.1765 | Val Loss: 1.0835 | Val Acc: 0.8897
ğŸ’¾ Best model updated (val acc: 0.8897)
ğŸ•’ Epoch 2/100 | Train Loss: 0.8545 | Val Loss: 0.9716 | Val Acc: 0.9402
ğŸ’¾ Best model updated (val acc: 0.9402)
ğŸ•’ Epoch 3/100 | Train Loss: 0.8157 | Val Loss: 0.9429 | Val Acc: 0.9533
ğŸ’¾ Best model updated (val acc: 0.9533)
ğŸ•’ Epoch 4/100 | Train Loss: 0.7780 | Val Loss: 0.9378 | Val Acc: 0.9607
ğŸ’¾ Best model updated (val acc: 0.9607)
ğŸ•’ Epoch 5/100 | Train Loss: 0.7536 | Val Loss: 0.8979 | Val Acc: 0.9720
ğŸ’¾ Best model updated (val acc: 0.9720)
ğŸ•’ Epoch 6/100 | Train Loss: 0.7235 | Val Loss: 0.9248 | Val Acc: 0.9589
ğŸ•’ Epoch 7/100 | Train Loss: 0.7258 | Val Loss: 0.9133 | Val Acc: 0.9682
ğŸ•’ Epoch 8/100 | Train Loss: 0.7257 | Val Loss: 0.9117 | Val Acc: 0.9701
ğŸ•’ Epoch 9/100 | Train Loss: 0.7425 | Val Loss: 0.9198 | Val Acc: 0.9682
ğŸ•’ Epoch 10/100 | Train Loss: 0.7153 | Val Loss: 0.8881 | Val Acc: 0.9776
ğŸ’¾ Best model updated (val acc: 0.9776)
ğŸ•’ Epoch 11/100 | Train Loss: 0.7110 | Val Loss: 0.8908 | Val Acc: 0.9701
ğŸ•’ Epoch 12/100 | Train Loss: 0.6989 | Val Loss: 0.8905 | Val Acc: 0.9757
ğŸ•’ Epoch 13/100 | Train Loss: 0.7142 | Val Loss: 0.8737 | Val Acc: 0.9794
ğŸ’¾ Best model updated (val acc: 0.9794)
ğŸ•’ Epoch 14/100 | Train Loss: 0.6888 | Val Loss: 0.9025 | Val Acc: 0.9551
ğŸ•’ Epoch 15/100 | Train Loss: 0.7048 | Val Loss: 0.9242 | Val Acc: 0.9589
ğŸ•’ Epoch 16/100 | Train Loss: 0.7084 | Val Loss: 0.8997 | Val Acc: 0.9720
ğŸ•’ Epoch 17/100 | Train Loss: 0.7046 | Val Loss: 0.8705 | Val Acc: 0.9776
ğŸ’¾ Best model updated (val acc: 0.9776)
ğŸ•’ Epoch 18/100 | Train Loss: 0.6865 | Val Loss: 0.8563 | Val Acc: 0.9888
ğŸ’¾ Best model updated (val acc: 0.9888)
ğŸ•’ Epoch 19/100 | Train Loss: 0.6747 | Val Loss: 0.8624 | Val Acc: 0.9832
ğŸ•’ Epoch 20/100 | Train Loss: 0.6809 | Val Loss: 0.8615 | Val Acc: 0.9813
ğŸ•’ Epoch 21/100 | Train Loss: 0.6886 | Val Loss: 0.8829 | Val Acc: 0.9720
ğŸ•’ Epoch 22/100 | Train Loss: 0.6857 | Val Loss: 0.8788 | Val Acc: 0.9794
ğŸ•’ Epoch 23/100 | Train Loss: 0.6751 | Val Loss: 0.8701 | Val Acc: 0.9757
ğŸ•’ Epoch 24/100 | Train Loss: 0.6830 | Val Loss: 0.8781 | Val Acc: 0.9757
ğŸ•’ Epoch 25/100 | Train Loss: 0.6752 | Val Loss: 0.8820 | Val Acc: 0.9757
ğŸ•’ Epoch 26/100 | Train Loss: 0.6834 | Val Loss: 0.8872 | Val Acc: 0.9720
ğŸ•’ Epoch 27/100 | Train Loss: 0.6804 | Val Loss: 0.8738 | Val Acc: 0.9776
ğŸ•’ Epoch 28/100 | Train Loss: 0.6749 | Val Loss: 0.8586 | Val Acc: 0.9813
â¹ï¸ Early stopping.
âœ… Fold 3 complete. Saved: ./output/models/ConvNeXt+cbam+batchnorm+dataset2+dataset2_fold3.pth

ğŸ“‚ Fold 4/5
ğŸ•’ Epoch 1/100 | Train Loss: 1.2042 | Val Loss: 1.0871 | Val Acc: 0.9028
ğŸ’¾ Best model updated (val acc: 0.9028)
ğŸ•’ Epoch 2/100 | Train Loss: 0.8454 | Val Loss: 0.9749 | Val Acc: 0.9477
ğŸ’¾ Best model updated (val acc: 0.9477)
ğŸ•’ Epoch 3/100 | Train Loss: 0.8001 | Val Loss: 0.9370 | Val Acc: 0.9570
ğŸ’¾ Best model updated (val acc: 0.9570)
ğŸ•’ Epoch 4/100 | Train Loss: 0.7651 | Val Loss: 0.9277 | Val Acc: 0.9645
ğŸ’¾ Best model updated (val acc: 0.9645)
ğŸ•’ Epoch 5/100 | Train Loss: 0.7492 | Val Loss: 0.9213 | Val Acc: 0.9645
ğŸ’¾ Best model updated (val acc: 0.9645)
ğŸ•’ Epoch 6/100 | Train Loss: 0.7480 | Val Loss: 0.9545 | Val Acc: 0.9551
ğŸ•’ Epoch 7/100 | Train Loss: 0.7437 | Val Loss: 0.9215 | Val Acc: 0.9645
ğŸ•’ Epoch 8/100 | Train Loss: 0.7158 | Val Loss: 0.9187 | Val Acc: 0.9626
ğŸ’¾ Best model updated (val acc: 0.9626)
ğŸ•’ Epoch 9/100 | Train Loss: 0.7102 | Val Loss: 0.8999 | Val Acc: 0.9664
ğŸ’¾ Best model updated (val acc: 0.9664)
ğŸ•’ Epoch 10/100 | Train Loss: 0.7247 | Val Loss: 0.8938 | Val Acc: 0.9682
ğŸ’¾ Best model updated (val acc: 0.9682)
ğŸ•’ Epoch 11/100 | Train Loss: 0.7052 | Val Loss: 0.8835 | Val Acc: 0.9738
ğŸ’¾ Best model updated (val acc: 0.9738)
ğŸ•’ Epoch 12/100 | Train Loss: 0.7094 | Val Loss: 0.9031 | Val Acc: 0.9720
ğŸ•’ Epoch 13/100 | Train Loss: 0.6951 | Val Loss: 0.8709 | Val Acc: 0.9813
ğŸ’¾ Best model updated (val acc: 0.9813)
ğŸ•’ Epoch 14/100 | Train Loss: 0.7096 | Val Loss: 0.8930 | Val Acc: 0.9682
ğŸ•’ Epoch 15/100 | Train Loss: 0.7066 | Val Loss: 0.8710 | Val Acc: 0.9776
ğŸ•’ Epoch 16/100 | Train Loss: 0.7062 | Val Loss: 0.9323 | Val Acc: 0.9533
ğŸ•’ Epoch 17/100 | Train Loss: 0.7136 | Val Loss: 0.8810 | Val Acc: 0.9664
ğŸ•’ Epoch 18/100 | Train Loss: 0.6898 | Val Loss: 0.8799 | Val Acc: 0.9776
ğŸ•’ Epoch 19/100 | Train Loss: 0.6799 | Val Loss: 0.8800 | Val Acc: 0.9757
ğŸ•’ Epoch 20/100 | Train Loss: 0.6962 | Val Loss: 0.8663 | Val Acc: 0.9776
ğŸ’¾ Best model updated (val acc: 0.9776)
ğŸ•’ Epoch 21/100 | Train Loss: 0.6831 | Val Loss: 0.8734 | Val Acc: 0.9738
ğŸ•’ Epoch 22/100 | Train Loss: 0.6862 | Val Loss: 0.8809 | Val Acc: 0.9757
ğŸ•’ Epoch 23/100 | Train Loss: 0.6782 | Val Loss: 0.8651 | Val Acc: 0.9813
ğŸ’¾ Best model updated (val acc: 0.9813)
ğŸ•’ Epoch 24/100 | Train Loss: 0.6889 | Val Loss: 0.8609 | Val Acc: 0.9738
ğŸ’¾ Best model updated (val acc: 0.9738)
ğŸ•’ Epoch 25/100 | Train Loss: 0.6772 | Val Loss: 0.8882 | Val Acc: 0.9701
ğŸ•’ Epoch 26/100 | Train Loss: 0.6867 | Val Loss: 0.8709 | Val Acc: 0.9738
ğŸ•’ Epoch 27/100 | Train Loss: 0.6812 | Val Loss: 0.8587 | Val Acc: 0.9850
ğŸ’¾ Best model updated (val acc: 0.9850)
ğŸ•’ Epoch 28/100 | Train Loss: 0.6769 | Val Loss: 0.8585 | Val Acc: 0.9794
ğŸ’¾ Best model updated (val acc: 0.9794)
ğŸ•’ Epoch 29/100 | Train Loss: 0.6773 | Val Loss: 0.8501 | Val Acc: 0.9907
ğŸ’¾ Best model updated (val acc: 0.9907)
ğŸ•’ Epoch 30/100 | Train Loss: 0.6765 | Val Loss: 0.8601 | Val Acc: 0.9832
ğŸ•’ Epoch 31/100 | Train Loss: 0.6810 | Val Loss: 0.8544 | Val Acc: 0.9832
ğŸ•’ Epoch 32/100 | Train Loss: 0.6756 | Val Loss: 0.8542 | Val Acc: 0.9850
ğŸ•’ Epoch 33/100 | Train Loss: 0.6718 | Val Loss: 0.8534 | Val Acc: 0.9869
ğŸ•’ Epoch 34/100 | Train Loss: 0.6710 | Val Loss: 0.8652 | Val Acc: 0.9813
ğŸ•’ Epoch 35/100 | Train Loss: 0.6809 | Val Loss: 0.8512 | Val Acc: 0.9869
ğŸ•’ Epoch 36/100 | Train Loss: 0.6763 | Val Loss: 0.8515 | Val Acc: 0.9888
ğŸ•’ Epoch 37/100 | Train Loss: 0.6727 | Val Loss: 0.8528 | Val Acc: 0.9888
ğŸ•’ Epoch 38/100 | Train Loss: 0.6742 | Val Loss: 0.8554 | Val Acc: 0.9869
ğŸ•’ Epoch 39/100 | Train Loss: 0.6706 | Val Loss: 0.8545 | Val Acc: 0.9869
â¹ï¸ Early stopping.
âœ… Fold 4 complete. Saved: ./output/models/ConvNeXt+cbam+batchnorm+dataset2+dataset2_fold4.pth

ğŸ“‚ Fold 5/5
ğŸ•’ Epoch 1/100 | Train Loss: 1.1370 | Val Loss: 1.1130 | Val Acc: 0.8822
ğŸ’¾ Best model updated (val acc: 0.8822)
ğŸ•’ Epoch 2/100 | Train Loss: 0.8594 | Val Loss: 1.0119 | Val Acc: 0.9178
ğŸ’¾ Best model updated (val acc: 0.9178)
ğŸ•’ Epoch 3/100 | Train Loss: 0.7888 | Val Loss: 0.9540 | Val Acc: 0.9458
ğŸ’¾ Best model updated (val acc: 0.9458)
ğŸ•’ Epoch 4/100 | Train Loss: 0.7625 | Val Loss: 1.0231 | Val Acc: 0.9234
ğŸ•’ Epoch 5/100 | Train Loss: 0.7722 | Val Loss: 1.0126 | Val Acc: 0.9159
ğŸ•’ Epoch 6/100 | Train Loss: 0.7354 | Val Loss: 0.9564 | Val Acc: 0.9421
ğŸ•’ Epoch 7/100 | Train Loss: 0.7272 | Val Loss: 0.9238 | Val Acc: 0.9551
ğŸ’¾ Best model updated (val acc: 0.9551)
ğŸ•’ Epoch 8/100 | Train Loss: 0.7235 | Val Loss: 0.9014 | Val Acc: 0.9682
ğŸ’¾ Best model updated (val acc: 0.9682)
ğŸ•’ Epoch 9/100 | Train Loss: 0.7160 | Val Loss: 0.9045 | Val Acc: 0.9682
ğŸ•’ Epoch 10/100 | Train Loss: 0.7043 | Val Loss: 0.9192 | Val Acc: 0.9645
ğŸ•’ Epoch 11/100 | Train Loss: 0.7107 | Val Loss: 0.9052 | Val Acc: 0.9701
ğŸ•’ Epoch 12/100 | Train Loss: 0.6985 | Val Loss: 0.9568 | Val Acc: 0.9402
ğŸ•’ Epoch 13/100 | Train Loss: 0.7099 | Val Loss: 0.9120 | Val Acc: 0.9645
ğŸ•’ Epoch 14/100 | Train Loss: 0.7139 | Val Loss: 0.9846 | Val Acc: 0.9308
ğŸ•’ Epoch 15/100 | Train Loss: 0.7426 | Val Loss: 0.8961 | Val Acc: 0.9664
ğŸ’¾ Best model updated (val acc: 0.9664)
ğŸ•’ Epoch 16/100 | Train Loss: 0.6895 | Val Loss: 0.8966 | Val Acc: 0.9645
ğŸ•’ Epoch 17/100 | Train Loss: 0.6825 | Val Loss: 0.8850 | Val Acc: 0.9701
ğŸ’¾ Best model updated (val acc: 0.9701)
ğŸ•’ Epoch 18/100 | Train Loss: 0.6899 | Val Loss: 0.9017 | Val Acc: 0.9682
ğŸ•’ Epoch 19/100 | Train Loss: 0.6888 | Val Loss: 0.9157 | Val Acc: 0.9551
ğŸ•’ Epoch 20/100 | Train Loss: 0.7037 | Val Loss: 0.8983 | Val Acc: 0.9626
ğŸ•’ Epoch 21/100 | Train Loss: 0.6852 | Val Loss: 0.8962 | Val Acc: 0.9738
ğŸ•’ Epoch 22/100 | Train Loss: 0.6724 | Val Loss: 0.8940 | Val Acc: 0.9701
ğŸ•’ Epoch 23/100 | Train Loss: 0.6894 | Val Loss: 0.9057 | Val Acc: 0.9607
ğŸ•’ Epoch 24/100 | Train Loss: 0.6729 | Val Loss: 0.8831 | Val Acc: 0.9701
ğŸ’¾ Best model updated (val acc: 0.9701)
ğŸ•’ Epoch 25/100 | Train Loss: 0.6847 | Val Loss: 0.9042 | Val Acc: 0.9645
ğŸ•’ Epoch 26/100 | Train Loss: 0.6846 | Val Loss: 0.8747 | Val Acc: 0.9794
ğŸ’¾ Best model updated (val acc: 0.9794)
ğŸ•’ Epoch 27/100 | Train Loss: 0.6828 | Val Loss: 0.9019 | Val Acc: 0.9664
ğŸ•’ Epoch 28/100 | Train Loss: 0.6857 | Val Loss: 0.8747 | Val Acc: 0.9776
ğŸ•’ Epoch 29/100 | Train Loss: 0.6729 | Val Loss: 0.8816 | Val Acc: 0.9738
ğŸ•’ Epoch 30/100 | Train Loss: 0.6771 | Val Loss: 0.8848 | Val Acc: 0.9738
ğŸ•’ Epoch 31/100 | Train Loss: 0.6793 | Val Loss: 0.8914 | Val Acc: 0.9813
ğŸ•’ Epoch 32/100 | Train Loss: 0.6718 | Val Loss: 0.8781 | Val Acc: 0.9720
ğŸ•’ Epoch 33/100 | Train Loss: 0.6715 | Val Loss: 0.9055 | Val Acc: 0.9607
ğŸ•’ Epoch 34/100 | Train Loss: 0.6736 | Val Loss: 0.8765 | Val Acc: 0.9832
ğŸ•’ Epoch 35/100 | Train Loss: 0.6761 | Val Loss: 0.8832 | Val Acc: 0.9757
ğŸ•’ Epoch 36/100 | Train Loss: 0.6757 | Val Loss: 0.8782 | Val Acc: 0.9757
â¹ï¸ Early stopping.
âœ… Fold 5 complete. Saved: ./output/models/ConvNeXt+cbam+batchnorm+dataset2+dataset2_fold5.pth
ğŸ“‚ Training metrics plot saved for Fold 1: output/test/fold_1/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 2: output/test/fold_2/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 3: output/test/fold_3/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 4: output/test/fold_4/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 5: output/test/fold_5/training_metrics.png
ğŸ‰ All folds completed.
ğŸš€ Evaluating 5 fold models on test set

ğŸ“‚ Evaluating Fold 1
ğŸ“Š Fold 1 Metrics:
   - Accuracy: 0.9735
   - Precision: 0.9645
   - Recall: 0.9675
   - F1 Score: 0.9647

ğŸ“‚ Evaluating Fold 2
ğŸ“Š Fold 2 Metrics:
   - Accuracy: 0.9735
   - Precision: 0.9666
   - Recall: 0.9674
   - F1 Score: 0.9656

ğŸ“‚ Evaluating Fold 3
ğŸ“Š Fold 3 Metrics:
   - Accuracy: 0.9749
   - Precision: 0.9674
   - Recall: 0.9684
   - F1 Score: 0.9665

ğŸ“‚ Evaluating Fold 4
ğŸ“Š Fold 4 Metrics:
   - Accuracy: 0.9735
   - Precision: 0.9693
   - Recall: 0.9692
   - F1 Score: 0.9681

ğŸ“‚ Evaluating Fold 5
ğŸ“Š Fold 5 Metrics:
   - Accuracy: 0.9735
   - Precision: 0.9666
   - Recall: 0.9660
   - F1 Score: 0.9647

ğŸ§¾ Classification Report for ConvNeXt+cbam+batchnorm+dataset2 (Majority Vote from 5 folds):

                       precision    recall  f1-score   support

     Bacterial Blight     1.0000    0.8980    0.9462        49
Bacterial Leaf Streak     0.8462    1.0000    0.9167        33
           Brown Spot     0.9742    0.9934    0.9837       152
              Healthy     0.9811    0.9873    0.9842       158
                Hispa     0.9924    0.9850    0.9887       133
           Leaf Blast     1.0000    0.9766    0.9881       128
        Sheath Blight     1.0000    0.9600    0.9796        25

             accuracy                         0.9794       678
            macro avg     0.9706    0.9715    0.9696       678
         weighted avg     0.9808    0.9794    0.9795       678

ğŸ”¢ Confusion Matrix:
 [[ 44   5   0   0   0   0   0]
 [  0  33   0   0   0   0   0]
 [  0   0 151   1   0   0   0]
 [  0   0   2 156   0   0   0]
 [  0   0   0   2 131   0   0]
 [  0   0   2   0   1 125   0]
 [  0   1   0   0   0   0  24]]

ğŸ“Š Average Metrics Across All Folds:
   - Accuracy: 0.9737
   - Precision: 0.9669
   - Recall: 0.9677
   - F1 Score: 0.9659
ğŸš€ Starting training with 5-Fold Cross-Validation for model: ConvNeXt+cbam+batchnorm+dataset3_kfold
/media/data3/users/datlht/Rice_leaf_disease_detection/load_data.py:81: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/media/data3/users/datlht/Rice_leaf_disease_detection/load_data.py:84: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from font(s) DejaVu Sans.
  plt.savefig(plot_path)
âœ… Saved fold class distribution plot to: output/fold_class_distribution.png

ğŸ“‚ Fold 1/5
ğŸ•’ Epoch 1/50 | Train Loss: 0.4287 | Val Loss: 0.3589 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 2/50 | Train Loss: 0.3687 | Val Loss: 0.3580 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 3/50 | Train Loss: 0.3671 | Val Loss: 0.3627 | Val Acc: 1.0000
ğŸ•’ Epoch 4/50 | Train Loss: 0.3631 | Val Loss: 0.3554 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 5/50 | Train Loss: 0.3627 | Val Loss: 0.3544 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 6/50 | Train Loss: 0.3623 | Val Loss: 0.3537 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 7/50 | Train Loss: 0.3635 | Val Loss: 0.3553 | Val Acc: 1.0000
ğŸ•’ Epoch 8/50 | Train Loss: 0.3621 | Val Loss: 0.3537 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 9/50 | Train Loss: 0.3628 | Val Loss: 0.3540 | Val Acc: 1.0000
ğŸ•’ Epoch 10/50 | Train Loss: 0.3622 | Val Loss: 0.3548 | Val Acc: 1.0000
ğŸ•’ Epoch 11/50 | Train Loss: 0.3622 | Val Loss: 0.3544 | Val Acc: 1.0000
ğŸ•’ Epoch 12/50 | Train Loss: 0.3725 | Val Loss: 0.4841 | Val Acc: 0.9353
ğŸ•’ Epoch 13/50 | Train Loss: 0.3903 | Val Loss: 0.3558 | Val Acc: 0.9991
ğŸ•’ Epoch 14/50 | Train Loss: 0.3621 | Val Loss: 0.3545 | Val Acc: 1.0000
ğŸ•’ Epoch 15/50 | Train Loss: 0.3618 | Val Loss: 0.3546 | Val Acc: 1.0000
ğŸ•’ Epoch 16/50 | Train Loss: 0.3617 | Val Loss: 0.3540 | Val Acc: 1.0000
ğŸ•’ Epoch 17/50 | Train Loss: 0.3613 | Val Loss: 0.3539 | Val Acc: 1.0000
ğŸ•’ Epoch 18/50 | Train Loss: 0.3616 | Val Loss: 0.3547 | Val Acc: 1.0000
â¹ï¸ Early stopping.
âœ… Fold 1 complete. Saved: ./output/models/ConvNeXt+cbam+batchnorm+dataset3_kfold+dataset3_kfold_fold1.pth

ğŸ“‚ Fold 2/5
ğŸ•’ Epoch 1/50 | Train Loss: 0.4261 | Val Loss: 0.3718 | Val Acc: 0.9972
ğŸ’¾ Best model updated (val acc: 0.9972)
ğŸ•’ Epoch 2/50 | Train Loss: 0.3746 | Val Loss: 0.3579 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 3/50 | Train Loss: 0.3634 | Val Loss: 0.3582 | Val Acc: 1.0000
ğŸ•’ Epoch 4/50 | Train Loss: 0.3632 | Val Loss: 0.3570 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 5/50 | Train Loss: 0.3626 | Val Loss: 0.3559 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 6/50 | Train Loss: 0.3629 | Val Loss: 0.3563 | Val Acc: 1.0000
ğŸ•’ Epoch 7/50 | Train Loss: 0.3623 | Val Loss: 0.3547 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 8/50 | Train Loss: 0.3616 | Val Loss: 0.3554 | Val Acc: 1.0000
ğŸ•’ Epoch 9/50 | Train Loss: 0.3624 | Val Loss: 0.3547 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 10/50 | Train Loss: 0.3619 | Val Loss: 0.3554 | Val Acc: 1.0000
ğŸ•’ Epoch 11/50 | Train Loss: 0.3618 | Val Loss: 0.3538 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 12/50 | Train Loss: 0.3624 | Val Loss: 0.3539 | Val Acc: 1.0000
ğŸ•’ Epoch 13/50 | Train Loss: 0.3618 | Val Loss: 0.3540 | Val Acc: 1.0000
ğŸ•’ Epoch 14/50 | Train Loss: 0.3621 | Val Loss: 0.3559 | Val Acc: 1.0000
ğŸ•’ Epoch 15/50 | Train Loss: 0.3611 | Val Loss: 0.3538 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 16/50 | Train Loss: 0.3620 | Val Loss: 0.3558 | Val Acc: 1.0000
ğŸ•’ Epoch 17/50 | Train Loss: 0.3626 | Val Loss: 0.3538 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 18/50 | Train Loss: 0.3619 | Val Loss: 0.3539 | Val Acc: 1.0000
ğŸ•’ Epoch 19/50 | Train Loss: 0.3604 | Val Loss: 0.3534 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 20/50 | Train Loss: 0.3611 | Val Loss: 0.3535 | Val Acc: 1.0000
ğŸ•’ Epoch 21/50 | Train Loss: 0.3612 | Val Loss: 0.3541 | Val Acc: 1.0000
ğŸ•’ Epoch 22/50 | Train Loss: 0.3618 | Val Loss: 0.3553 | Val Acc: 1.0000
ğŸ•’ Epoch 23/50 | Train Loss: 0.3620 | Val Loss: 0.3545 | Val Acc: 1.0000
ğŸ•’ Epoch 24/50 | Train Loss: 0.3626 | Val Loss: 0.3536 | Val Acc: 1.0000
ğŸ•’ Epoch 25/50 | Train Loss: 0.3608 | Val Loss: 0.3542 | Val Acc: 1.0000
ğŸ•’ Epoch 26/50 | Train Loss: 0.3608 | Val Loss: 0.3531 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 27/50 | Train Loss: 0.3606 | Val Loss: 0.3537 | Val Acc: 1.0000
ğŸ•’ Epoch 28/50 | Train Loss: 0.3703 | Val Loss: 0.3622 | Val Acc: 0.9972
ğŸ•’ Epoch 29/50 | Train Loss: 0.3632 | Val Loss: 0.3538 | Val Acc: 1.0000
ğŸ•’ Epoch 30/50 | Train Loss: 0.3622 | Val Loss: 0.3541 | Val Acc: 1.0000
ğŸ•’ Epoch 31/50 | Train Loss: 0.3609 | Val Loss: 0.3540 | Val Acc: 1.0000
ğŸ•’ Epoch 32/50 | Train Loss: 0.3604 | Val Loss: 0.3536 | Val Acc: 1.0000
ğŸ•’ Epoch 33/50 | Train Loss: 0.3611 | Val Loss: 0.3539 | Val Acc: 1.0000
ğŸ•’ Epoch 34/50 | Train Loss: 0.3616 | Val Loss: 0.3537 | Val Acc: 1.0000
ğŸ•’ Epoch 35/50 | Train Loss: 0.3619 | Val Loss: 0.3532 | Val Acc: 1.0000
ğŸ•’ Epoch 36/50 | Train Loss: 0.3607 | Val Loss: 0.3533 | Val Acc: 1.0000
â¹ï¸ Early stopping.
âœ… Fold 2 complete. Saved: ./output/models/ConvNeXt+cbam+batchnorm+dataset3_kfold+dataset3_kfold_fold2.pth

ğŸ“‚ Fold 3/5
ğŸ•’ Epoch 1/50 | Train Loss: 0.4291 | Val Loss: 0.3615 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 2/50 | Train Loss: 0.3706 | Val Loss: 0.3571 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 3/50 | Train Loss: 0.3677 | Val Loss: 0.3560 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 4/50 | Train Loss: 0.3644 | Val Loss: 0.3538 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 5/50 | Train Loss: 0.3647 | Val Loss: 0.4392 | Val Acc: 0.9569
ğŸ•’ Epoch 6/50 | Train Loss: 0.3827 | Val Loss: 0.3575 | Val Acc: 1.0000
ğŸ•’ Epoch 7/50 | Train Loss: 0.3641 | Val Loss: 0.3550 | Val Acc: 1.0000
ğŸ•’ Epoch 8/50 | Train Loss: 0.3621 | Val Loss: 0.3556 | Val Acc: 1.0000
ğŸ•’ Epoch 9/50 | Train Loss: 0.3618 | Val Loss: 0.3552 | Val Acc: 1.0000
ğŸ•’ Epoch 10/50 | Train Loss: 0.3635 | Val Loss: 0.3551 | Val Acc: 1.0000
ğŸ•’ Epoch 11/50 | Train Loss: 0.3619 | Val Loss: 0.3547 | Val Acc: 1.0000
ğŸ•’ Epoch 12/50 | Train Loss: 0.3618 | Val Loss: 0.3534 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 13/50 | Train Loss: 0.3621 | Val Loss: 0.3547 | Val Acc: 1.0000
ğŸ•’ Epoch 14/50 | Train Loss: 0.3628 | Val Loss: 0.3538 | Val Acc: 1.0000
ğŸ•’ Epoch 15/50 | Train Loss: 0.3625 | Val Loss: 0.3537 | Val Acc: 1.0000
ğŸ•’ Epoch 16/50 | Train Loss: 0.3616 | Val Loss: 0.3533 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 17/50 | Train Loss: 0.3619 | Val Loss: 0.3537 | Val Acc: 1.0000
ğŸ•’ Epoch 18/50 | Train Loss: 0.3618 | Val Loss: 0.3541 | Val Acc: 1.0000
ğŸ•’ Epoch 19/50 | Train Loss: 0.3616 | Val Loss: 0.3536 | Val Acc: 1.0000
ğŸ•’ Epoch 20/50 | Train Loss: 0.3614 | Val Loss: 0.3532 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 21/50 | Train Loss: 0.3620 | Val Loss: 0.3536 | Val Acc: 1.0000
ğŸ•’ Epoch 22/50 | Train Loss: 0.3615 | Val Loss: 0.3535 | Val Acc: 1.0000
ğŸ•’ Epoch 23/50 | Train Loss: 0.3605 | Val Loss: 0.3544 | Val Acc: 1.0000
ğŸ•’ Epoch 24/50 | Train Loss: 0.3691 | Val Loss: 0.3631 | Val Acc: 0.9981
ğŸ•’ Epoch 25/50 | Train Loss: 0.3617 | Val Loss: 0.3540 | Val Acc: 1.0000
ğŸ•’ Epoch 26/50 | Train Loss: 0.3627 | Val Loss: 0.3535 | Val Acc: 1.0000
ğŸ•’ Epoch 27/50 | Train Loss: 0.3614 | Val Loss: 0.3546 | Val Acc: 1.0000
ğŸ•’ Epoch 28/50 | Train Loss: 0.3606 | Val Loss: 0.3532 | Val Acc: 1.0000
ğŸ•’ Epoch 29/50 | Train Loss: 0.3610 | Val Loss: 0.3540 | Val Acc: 1.0000
ğŸ•’ Epoch 30/50 | Train Loss: 0.3609 | Val Loss: 0.3542 | Val Acc: 1.0000
â¹ï¸ Early stopping.
âœ… Fold 3 complete. Saved: ./output/models/ConvNeXt+cbam+batchnorm+dataset3_kfold+dataset3_kfold_fold3.pth

ğŸ“‚ Fold 4/5
ğŸ•’ Epoch 1/50 | Train Loss: 0.4181 | Val Loss: 0.3572 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 2/50 | Train Loss: 0.3691 | Val Loss: 0.3568 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 3/50 | Train Loss: 0.3654 | Val Loss: 0.3563 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 4/50 | Train Loss: 0.3638 | Val Loss: 0.3550 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 5/50 | Train Loss: 0.3632 | Val Loss: 0.3554 | Val Acc: 1.0000
ğŸ•’ Epoch 6/50 | Train Loss: 0.3627 | Val Loss: 0.3539 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 7/50 | Train Loss: 0.3617 | Val Loss: 0.3561 | Val Acc: 1.0000
ğŸ•’ Epoch 8/50 | Train Loss: 0.3617 | Val Loss: 0.3561 | Val Acc: 1.0000
ğŸ•’ Epoch 9/50 | Train Loss: 0.3754 | Val Loss: 0.4373 | Val Acc: 0.9634
ğŸ•’ Epoch 10/50 | Train Loss: 0.3827 | Val Loss: 0.3544 | Val Acc: 1.0000
ğŸ•’ Epoch 11/50 | Train Loss: 0.3636 | Val Loss: 0.3553 | Val Acc: 1.0000
ğŸ•’ Epoch 12/50 | Train Loss: 0.3629 | Val Loss: 0.3537 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 13/50 | Train Loss: 0.3631 | Val Loss: 0.3546 | Val Acc: 1.0000
ğŸ•’ Epoch 14/50 | Train Loss: 0.3620 | Val Loss: 0.3544 | Val Acc: 1.0000
ğŸ•’ Epoch 15/50 | Train Loss: 0.3620 | Val Loss: 0.3533 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 16/50 | Train Loss: 0.3634 | Val Loss: 0.3551 | Val Acc: 1.0000
ğŸ•’ Epoch 17/50 | Train Loss: 0.3618 | Val Loss: 0.3541 | Val Acc: 1.0000
ğŸ•’ Epoch 18/50 | Train Loss: 0.3620 | Val Loss: 0.3532 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 19/50 | Train Loss: 0.3624 | Val Loss: 0.3562 | Val Acc: 1.0000
ğŸ•’ Epoch 20/50 | Train Loss: 0.3626 | Val Loss: 0.3574 | Val Acc: 1.0000
ğŸ•’ Epoch 21/50 | Train Loss: 0.3620 | Val Loss: 0.3542 | Val Acc: 1.0000
ğŸ•’ Epoch 22/50 | Train Loss: 0.3643 | Val Loss: 0.3813 | Val Acc: 0.9897
ğŸ•’ Epoch 23/50 | Train Loss: 0.3662 | Val Loss: 0.3559 | Val Acc: 1.0000
ğŸ•’ Epoch 24/50 | Train Loss: 0.3615 | Val Loss: 0.3533 | Val Acc: 1.0000
ğŸ•’ Epoch 25/50 | Train Loss: 0.3617 | Val Loss: 0.3534 | Val Acc: 1.0000
ğŸ•’ Epoch 26/50 | Train Loss: 0.3613 | Val Loss: 0.3534 | Val Acc: 1.0000
ğŸ•’ Epoch 27/50 | Train Loss: 0.3624 | Val Loss: 0.3538 | Val Acc: 1.0000
ğŸ•’ Epoch 28/50 | Train Loss: 0.3618 | Val Loss: 0.3532 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 29/50 | Train Loss: 0.3619 | Val Loss: 0.3535 | Val Acc: 1.0000
ğŸ•’ Epoch 30/50 | Train Loss: 0.3612 | Val Loss: 0.3535 | Val Acc: 1.0000
ğŸ•’ Epoch 31/50 | Train Loss: 0.3606 | Val Loss: 0.3540 | Val Acc: 1.0000
ğŸ•’ Epoch 32/50 | Train Loss: 0.3615 | Val Loss: 0.3538 | Val Acc: 1.0000
ğŸ•’ Epoch 33/50 | Train Loss: 0.3620 | Val Loss: 0.3539 | Val Acc: 1.0000
ğŸ•’ Epoch 34/50 | Train Loss: 0.3612 | Val Loss: 0.3543 | Val Acc: 1.0000
ğŸ•’ Epoch 35/50 | Train Loss: 0.3614 | Val Loss: 0.3533 | Val Acc: 1.0000
ğŸ•’ Epoch 36/50 | Train Loss: 0.3618 | Val Loss: 0.3538 | Val Acc: 1.0000
ğŸ•’ Epoch 37/50 | Train Loss: 0.3605 | Val Loss: 0.3536 | Val Acc: 1.0000
ğŸ•’ Epoch 38/50 | Train Loss: 0.3598 | Val Loss: 0.3552 | Val Acc: 1.0000
â¹ï¸ Early stopping.
âœ… Fold 4 complete. Saved: ./output/models/ConvNeXt+cbam+batchnorm+dataset3_kfold+dataset3_kfold_fold4.pth

ğŸ“‚ Fold 5/5
ğŸ•’ Epoch 1/50 | Train Loss: 0.4232 | Val Loss: 0.3592 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 2/50 | Train Loss: 0.3709 | Val Loss: 0.3587 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 3/50 | Train Loss: 0.3671 | Val Loss: 0.3544 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 4/50 | Train Loss: 0.3649 | Val Loss: 0.3544 | Val Acc: 1.0000
ğŸ•’ Epoch 5/50 | Train Loss: 0.3631 | Val Loss: 0.3562 | Val Acc: 1.0000
ğŸ•’ Epoch 6/50 | Train Loss: 0.3629 | Val Loss: 0.3536 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 7/50 | Train Loss: 0.3626 | Val Loss: 0.3548 | Val Acc: 1.0000
ğŸ•’ Epoch 8/50 | Train Loss: 0.3614 | Val Loss: 0.3545 | Val Acc: 1.0000
ğŸ•’ Epoch 9/50 | Train Loss: 0.3627 | Val Loss: 0.3536 | Val Acc: 1.0000
ğŸ’¾ Best model updated (val acc: 1.0000)
ğŸ•’ Epoch 10/50 | Train Loss: 0.3623 | Val Loss: 0.3536 | Val Acc: 1.0000
ğŸ•’ Epoch 11/50 | Train Loss: 0.3625 | Val Loss: 0.3548 | Val Acc: 1.0000
ğŸ•’ Epoch 12/50 | Train Loss: 0.3949 | Val Loss: 0.3568 | Val Acc: 0.9991
ğŸ•’ Epoch 13/50 | Train Loss: 0.3633 | Val Loss: 0.3547 | Val Acc: 1.0000
ğŸ•’ Epoch 14/50 | Train Loss: 0.3622 | Val Loss: 0.3549 | Val Acc: 1.0000
ğŸ•’ Epoch 15/50 | Train Loss: 0.3609 | Val Loss: 0.3556 | Val Acc: 1.0000
ğŸ•’ Epoch 16/50 | Train Loss: 0.3623 | Val Loss: 0.3550 | Val Acc: 1.0000
ğŸ•’ Epoch 17/50 | Train Loss: 0.3612 | Val Loss: 0.3542 | Val Acc: 1.0000
ğŸ•’ Epoch 18/50 | Train Loss: 0.3620 | Val Loss: 0.3551 | Val Acc: 1.0000
ğŸ•’ Epoch 19/50 | Train Loss: 0.3615 | Val Loss: 0.3567 | Val Acc: 1.0000
â¹ï¸ Early stopping.
âœ… Fold 5 complete. Saved: ./output/models/ConvNeXt+cbam+batchnorm+dataset3_kfold+dataset3_kfold_fold5.pth
ğŸ“‚ Training metrics plot saved for Fold 1: output/test/fold_1/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 2: output/test/fold_2/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 3: output/test/fold_3/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 4: output/test/fold_4/training_metrics.png
ğŸ“‚ Training metrics plot saved for Fold 5: output/test/fold_5/training_metrics.png
ğŸ‰ All folds completed.
ğŸš€ Evaluating 5 fold models on test set

ğŸ“‚ Evaluating Fold 1
ğŸ“Š Fold 1 Metrics:
   - Accuracy: 1.0000
   - Precision: 1.0000
   - Recall: 1.0000
   - F1 Score: 1.0000

ğŸ“‚ Evaluating Fold 2
ğŸ“Š Fold 2 Metrics:
   - Accuracy: 1.0000
   - Precision: 1.0000
   - Recall: 1.0000
   - F1 Score: 1.0000

ğŸ“‚ Evaluating Fold 3
ğŸ“Š Fold 3 Metrics:
   - Accuracy: 1.0000
   - Precision: 1.0000
   - Recall: 1.0000
   - F1 Score: 1.0000

ğŸ“‚ Evaluating Fold 4
ğŸ“Š Fold 4 Metrics:
   - Accuracy: 1.0000
   - Precision: 1.0000
   - Recall: 1.0000
   - F1 Score: 1.0000

ğŸ“‚ Evaluating Fold 5
ğŸ“Š Fold 5 Metrics:
   - Accuracy: 1.0000
   - Precision: 1.0000
   - Recall: 1.0000
   - F1 Score: 1.0000

ğŸ§¾ Classification Report for ConvNeXt+cbam+batchnorm+dataset3_kfold (Majority Vote from 5 folds):

                 precision    recall  f1-score   support

Bacterialblight     1.0000    1.0000    1.0000       160
          Blast     1.0000    1.0000    1.0000       145
      Brownspot     1.0000    1.0000    1.0000       160
         Tungro     1.0000    1.0000    1.0000       132

       accuracy                         1.0000       597
      macro avg     1.0000    1.0000    1.0000       597
   weighted avg     1.0000    1.0000    1.0000       597

ğŸ”¢ Confusion Matrix:
 [[160   0   0   0]
 [  0 145   0   0]
 [  0   0 160   0]
 [  0   0   0 132]]

ğŸ“Š Average Metrics Across All Folds:
   - Accuracy: 1.0000
   - Precision: 1.0000
   - Recall: 1.0000
   - F1 Score: 1.0000
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: set_name_for_the_model_here+PlantVillageSplited]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
Epoch 1/50 | Time: 1136.87s | Train Loss: 0.8067 | Val Loss: 0.7181 | Val Acc: 0.9881 | LR: 0.000100 
Saving best val acc: 0.9881
Epoch 2/50 | Time: 1042.17s | Train Loss: 0.7137 | Val Loss: 0.6990 | Val Acc: 0.9944 | LR: 0.000100 
Saving best val acc: 0.9944
Epoch 3/50 | Time: 1042.30s | Train Loss: 0.7013 | Val Loss: 0.6935 | Val Acc: 0.9946 | LR: 0.000100 
Saving best val acc: 0.9946
Epoch 4/50 | Time: 1043.00s | Train Loss: 0.6992 | Val Loss: 0.6913 | Val Acc: 0.9952 | LR: 0.000099 
Saving best val acc: 0.9952
Epoch 5/50 | Time: 1042.10s | Train Loss: 0.6925 | Val Loss: 0.6892 | Val Acc: 0.9950 | LR: 0.000098 
Saving best val acc: 0.9950
Epoch 6/50 | Time: 1042.29s | Train Loss: 0.6938 | Val Loss: 0.6884 | Val Acc: 0.9973 | LR: 0.000098 
Saving best val acc: 0.9973
Epoch 7/50 | Time: 1042.07s | Train Loss: 0.6918 | Val Loss: 0.6901 | Val Acc: 0.9949 | LR: 0.000097 
Epoch 8/50 | Time: 1042.21s | Train Loss: 0.6892 | Val Loss: 0.6893 | Val Acc: 0.9957 | LR: 0.000095 
Epoch 9/50 | Time: 1042.19s | Train Loss: 0.6883 | Val Loss: 0.6826 | Val Acc: 0.9974 | LR: 0.000094 
Saving best val acc: 0.9974
Epoch 10/50 | Time: 1042.19s | Train Loss: 0.6855 | Val Loss: 0.7135 | Val Acc: 0.9864 | LR: 0.000092 
Epoch 11/50 | Time: 1042.40s | Train Loss: 0.6854 | Val Loss: 0.6942 | Val Acc: 0.9948 | LR: 0.000091 
Epoch 12/50 | Time: 1042.20s | Train Loss: 0.6847 | Val Loss: 0.6800 | Val Acc: 0.9981 | LR: 0.000089 
Saving best val acc: 0.9981
Epoch 13/50 | Time: 1042.28s | Train Loss: 0.6862 | Val Loss: 0.6844 | Val Acc: 0.9966 | LR: 0.000087 
Epoch 14/50 | Time: 1042.21s | Train Loss: 0.6824 | Val Loss: 0.6975 | Val Acc: 0.9914 | LR: 0.000084 
Epoch 15/50 | Time: 1042.09s | Train Loss: 0.6811 | Val Loss: 0.7113 | Val Acc: 0.9893 | LR: 0.000082 
Epoch 16/50 | Time: 1042.20s | Train Loss: 0.6813 | Val Loss: 0.6804 | Val Acc: 0.9982 | LR: 0.000080 
Epoch 17/50 | Time: 1042.20s | Train Loss: 0.6835 | Val Loss: 0.6813 | Val Acc: 0.9974 | LR: 0.000077 
Epoch 18/50 | Time: 1041.89s | Train Loss: 0.6805 | Val Loss: 0.6803 | Val Acc: 0.9975 | LR: 0.000074 
Epoch 19/50 | Time: 1042.12s | Train Loss: 0.6780 | Val Loss: 0.6842 | Val Acc: 0.9969 | LR: 0.000072 
Epoch 20/50 | Time: 1042.18s | Train Loss: 0.6808 | Val Loss: 0.6827 | Val Acc: 0.9969 | LR: 0.000069 
Epoch 21/50 | Time: 1042.83s | Train Loss: 0.6783 | Val Loss: 0.6895 | Val Acc: 0.9950 | LR: 0.000066 
Epoch 22/50 | Time: 1043.33s | Train Loss: 0.6780 | Val Loss: 0.6791 | Val Acc: 0.9983 | LR: 0.000063 
Saving best val acc: 0.9983
Epoch 23/50 | Time: 1042.06s | Train Loss: 0.6768 | Val Loss: 0.6862 | Val Acc: 0.9957 | LR: 0.000060 
Epoch 24/50 | Time: 1042.67s | Train Loss: 0.6770 | Val Loss: 0.6807 | Val Acc: 0.9976 | LR: 0.000057 
Epoch 25/50 | Time: 1042.15s | Train Loss: 0.6763 | Val Loss: 0.6830 | Val Acc: 0.9969 | LR: 0.000054 
Epoch 26/50 | Time: 1042.30s | Train Loss: 0.6762 | Val Loss: 0.6817 | Val Acc: 0.9975 | LR: 0.000050 
Epoch 27/50 | Time: 1042.20s | Train Loss: 0.6763 | Val Loss: 0.6827 | Val Acc: 0.9971 | LR: 0.000047 
Epoch 28/50 | Time: 1042.20s | Train Loss: 0.6751 | Val Loss: 0.6798 | Val Acc: 0.9983 | LR: 0.000044 
Epoch 29/50 | Time: 1042.09s | Train Loss: 0.6763 | Val Loss: 0.6808 | Val Acc: 0.9977 | LR: 0.000041 
Epoch 30/50 | Time: 1042.50s | Train Loss: 0.6748 | Val Loss: 0.6811 | Val Acc: 0.9977 | LR: 0.000038 
Epoch 31/50 | Time: 1042.21s | Train Loss: 0.6751 | Val Loss: 0.6817 | Val Acc: 0.9977 | LR: 0.000035 
Epoch 32/50 | Time: 1042.20s | Train Loss: 0.6750 | Val Loss: 0.6815 | Val Acc: 0.9981 | LR: 0.000032 
Early stopping triggered.
Training complete in 33448.06 seconds. Best model loaded.
Model saved to ./output/models/set_name_for_the_model_here+PlantVillageSplited+PlantVillageSplited.pth
 Training metrics plot saved to: output/test/set_name_for_the_model_here+PlantVillageSplited/training metric.png
Evaluate model:set_name_for_the_model_here+PlantVillageSplited

 Test Accuracy: 99.72%

 Classification Report:
                                                    precision    recall  f1-score   support

                                Apple___Apple_scab     1.0000    1.0000    1.0000        63
                                 Apple___Black_rot     1.0000    1.0000    1.0000        62
                          Apple___Cedar_apple_rust     1.0000    1.0000    1.0000        28
                                   Apple___healthy     0.9940    1.0000    0.9970       165
                               Blueberry___healthy     1.0000    1.0000    1.0000       151
          Cherry_(including_sour)___Powdery_mildew     1.0000    1.0000    1.0000       106
                 Cherry_(including_sour)___healthy     1.0000    1.0000    1.0000        86
Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot     0.9444    0.9808    0.9623        52
                       Corn_(maize)___Common_rust_     1.0000    0.9917    0.9958       120
               Corn_(maize)___Northern_Leaf_Blight     0.9796    0.9697    0.9746        99
                            Corn_(maize)___healthy     1.0000    1.0000    1.0000       117
                                 Grape___Black_rot     1.0000    1.0000    1.0000       118
                      Grape___Esca_(Black_Measles)     1.0000    1.0000    1.0000       139
        Grape___Leaf_blight_(Isariopsis_Leaf_Spot)     1.0000    1.0000    1.0000       108
                                   Grape___healthy     1.0000    1.0000    1.0000        43
          Orange___Haunglongbing_(Citrus_greening)     1.0000    1.0000    1.0000       551
                            Peach___Bacterial_spot     0.9957    1.0000    0.9978       230
                                   Peach___healthy     1.0000    0.9722    0.9859        36
                     Pepper,_bell___Bacterial_spot     0.9804    1.0000    0.9901       100
                            Pepper,_bell___healthy     1.0000    0.9797    0.9898       148
                             Potato___Early_blight     1.0000    1.0000    1.0000       100
                              Potato___Late_blight     1.0000    1.0000    1.0000       100
                                  Potato___healthy     1.0000    1.0000    1.0000        16
                               Raspberry___healthy     1.0000    1.0000    1.0000        38
                                 Soybean___healthy     1.0000    1.0000    1.0000       509
                           Squash___Powdery_mildew     1.0000    1.0000    1.0000       184
                          Strawberry___Leaf_scorch     1.0000    1.0000    1.0000       111
                              Strawberry___healthy     1.0000    1.0000    1.0000        46
                           Tomato___Bacterial_spot     0.9953    0.9953    0.9953       213
                             Tomato___Early_blight     0.9802    0.9900    0.9851       100
                              Tomato___Late_blight     1.0000    0.9895    0.9947       191
                                Tomato___Leaf_Mold     1.0000    1.0000    1.0000        96
                       Tomato___Septoria_leaf_spot     0.9888    0.9944    0.9916       178
     Tomato___Spider_mites_Two-spotted_spider_mite     1.0000    1.0000    1.0000       168
                              Tomato___Target_Spot     1.0000    0.9929    0.9964       141
            Tomato___Tomato_Yellow_Leaf_Curl_Virus     0.9981    1.0000    0.9991       536
                      Tomato___Tomato_mosaic_virus     1.0000    1.0000    1.0000        38
                                  Tomato___healthy     1.0000    1.0000    1.0000       160

                                          accuracy                         0.9972      5447
                                         macro avg     0.9962    0.9962    0.9962      5447
                                      weighted avg     0.9973    0.9972    0.9972      5447


âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: Convnext2+PlantDocSplited]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
Epoch 1/100 | Time: 202.60s | Train Loss: 1.7608 | Val Loss: 1.2701 | Val Acc: 0.7508 | LR: 0.000100 
Saving best val acc: 0.7508
Epoch 2/100 | Time: 158.95s | Train Loss: 1.1514 | Val Loss: 1.2034 | Val Acc: 0.7778 | LR: 0.000100 
Saving best val acc: 0.7778
Epoch 3/100 | Time: 158.21s | Train Loss: 1.0023 | Val Loss: 1.2673 | Val Acc: 0.7568 | LR: 0.000100 
Epoch 4/100 | Time: 158.05s | Train Loss: 0.8879 | Val Loss: 1.2340 | Val Acc: 0.7868 | LR: 0.000099 
Epoch 5/100 | Time: 157.98s | Train Loss: 0.8120 | Val Loss: 1.2172 | Val Acc: 0.8048 | LR: 0.000098 
Epoch 6/100 | Time: 157.34s | Train Loss: 0.7710 | Val Loss: 1.2373 | Val Acc: 0.7958 | LR: 0.000098 
Epoch 7/100 | Time: 158.19s | Train Loss: 0.7537 | Val Loss: 1.1785 | Val Acc: 0.8288 | LR: 0.000097 
Saving best val acc: 0.8288
Epoch 8/100 | Time: 158.32s | Train Loss: 0.7362 | Val Loss: 1.2897 | Val Acc: 0.7838 | LR: 0.000095 
Epoch 9/100 | Time: 159.69s | Train Loss: 0.7293 | Val Loss: 1.2240 | Val Acc: 0.8048 | LR: 0.000094 
Epoch 10/100 | Time: 158.14s | Train Loss: 0.7250 | Val Loss: 1.1956 | Val Acc: 0.8228 | LR: 0.000092 
Epoch 11/100 | Time: 158.30s | Train Loss: 0.7106 | Val Loss: 1.2112 | Val Acc: 0.8168 | LR: 0.000091 
Epoch 12/100 | Time: 153.40s | Train Loss: 0.7023 | Val Loss: 1.1697 | Val Acc: 0.8228 | LR: 0.000089 
Saving best val acc: 0.8228
Epoch 13/100 | Time: 158.59s | Train Loss: 0.6935 | Val Loss: 1.2092 | Val Acc: 0.8288 | LR: 0.000087 
Epoch 14/100 | Time: 158.07s | Train Loss: 0.6972 | Val Loss: 1.2332 | Val Acc: 0.8108 | LR: 0.000084 
Epoch 15/100 | Time: 158.24s | Train Loss: 0.6878 | Val Loss: 1.1707 | Val Acc: 0.8468 | LR: 0.000082 
Epoch 16/100 | Time: 158.75s | Train Loss: 0.6910 | Val Loss: 1.2134 | Val Acc: 0.8258 | LR: 0.000080 
Epoch 17/100 | Time: 157.92s | Train Loss: 0.6929 | Val Loss: 1.2081 | Val Acc: 0.7988 | LR: 0.000077 
Epoch 18/100 | Time: 157.32s | Train Loss: 0.6855 | Val Loss: 1.1677 | Val Acc: 0.8348 | LR: 0.000074 
Saving best val acc: 0.8348
Epoch 19/100 | Time: 157.68s | Train Loss: 0.6798 | Val Loss: 1.1577 | Val Acc: 0.8438 | LR: 0.000072 
Saving best val acc: 0.8438
Epoch 20/100 | Time: 157.19s | Train Loss: 0.6847 | Val Loss: 1.1344 | Val Acc: 0.8438 | LR: 0.000069 
Saving best val acc: 0.8438
Epoch 21/100 | Time: 158.12s | Train Loss: 0.6786 | Val Loss: 1.1734 | Val Acc: 0.8378 | LR: 0.000066 
Epoch 22/100 | Time: 157.88s | Train Loss: 0.6761 | Val Loss: 1.1845 | Val Acc: 0.8408 | LR: 0.000063 
Epoch 23/100 | Time: 157.60s | Train Loss: 0.6780 | Val Loss: 1.1868 | Val Acc: 0.8378 | LR: 0.000060 
Epoch 24/100 | Time: 157.98s | Train Loss: 0.6799 | Val Loss: 1.1807 | Val Acc: 0.8378 | LR: 0.000057 
Epoch 25/100 | Time: 157.86s | Train Loss: 0.6781 | Val Loss: 1.2083 | Val Acc: 0.8108 | LR: 0.000054 
Epoch 26/100 | Time: 158.79s | Train Loss: 0.6759 | Val Loss: 1.1763 | Val Acc: 0.8138 | LR: 0.000050 
Epoch 27/100 | Time: 159.18s | Train Loss: 0.6753 | Val Loss: 1.1900 | Val Acc: 0.8228 | LR: 0.000047 
Epoch 28/100 | Time: 158.28s | Train Loss: 0.6748 | Val Loss: 1.1762 | Val Acc: 0.8168 | LR: 0.000044 
Epoch 29/100 | Time: 158.43s | Train Loss: 0.6743 | Val Loss: 1.2026 | Val Acc: 0.8258 | LR: 0.000041 
Epoch 30/100 | Time: 158.87s | Train Loss: 0.6710 | Val Loss: 1.1887 | Val Acc: 0.8198 | LR: 0.000038 
Epoch 31/100 | Time: 157.96s | Train Loss: 0.6710 | Val Loss: 1.1894 | Val Acc: 0.8378 | LR: 0.000035 
Epoch 32/100 | Time: 158.09s | Train Loss: 0.6687 | Val Loss: 1.1833 | Val Acc: 0.8348 | LR: 0.000032 
Epoch 33/100 | Time: 158.07s | Train Loss: 0.6691 | Val Loss: 1.1964 | Val Acc: 0.8408 | LR: 0.000029 
Epoch 34/100 | Time: 155.93s | Train Loss: 0.6699 | Val Loss: 1.1525 | Val Acc: 0.8468 | LR: 0.000027 
Epoch 35/100 | Time: 159.11s | Train Loss: 0.6701 | Val Loss: 1.1695 | Val Acc: 0.8318 | LR: 0.000024 
Epoch 36/100 | Time: 157.89s | Train Loss: 0.6679 | Val Loss: 1.1836 | Val Acc: 0.8318 | LR: 0.000021 
Epoch 37/100 | Time: 158.67s | Train Loss: 0.6672 | Val Loss: 1.1803 | Val Acc: 0.8318 | LR: 0.000019 
Epoch 38/100 | Time: 159.11s | Train Loss: 0.6675 | Val Loss: 1.1706 | Val Acc: 0.8258 | LR: 0.000017 
Epoch 39/100 | Time: 158.47s | Train Loss: 0.6651 | Val Loss: 1.1861 | Val Acc: 0.8318 | LR: 0.000014 
Epoch 40/100 | Time: 157.79s | Train Loss: 0.6645 | Val Loss: 1.1767 | Val Acc: 0.8288 | LR: 0.000012 
Early stopping triggered.
Training complete in 6367.16 seconds. Best model loaded.
Model saved to ./output/models/Convnext2+PlantDocSplited+PlantDocSplited.pth
 Training metrics plot saved to: output/test/Convnext2+PlantDocSplited/training metric.png
Evaluate model:Convnext2+PlantDocSplited

 Test Accuracy: 68.25%

 Classification Report:
/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
                                      precision    recall  f1-score   support

                     Apple_Scab_Leaf     0.7273    0.8000    0.7619        10
                          Apple_leaf     0.7500    0.6667    0.7059         9
                     Apple_rust_leaf     0.9000    0.9000    0.9000        10
                    Bell_pepper_leaf     0.8750    0.8750    0.8750         8
               Bell_pepper_leaf_spot     0.8000    0.8889    0.8421         9
                      Blueberry_leaf     0.8333    0.9091    0.8696        11
                         Cherry_leaf     1.0000    0.8000    0.8889        10
                 Corn_Gray_leaf_spot     0.1111    0.2500    0.1538         4
                    Corn_leaf_blight     0.6250    0.4167    0.5000        12
                      Corn_rust_leaf     0.9000    0.9000    0.9000        10
                          Peach_leaf     1.0000    1.0000    1.0000         9
            Potato_leaf_early_blight     0.3333    0.2143    0.2609        14
             Potato_leaf_late_blight     0.2353    0.5000    0.3200         8
                      Raspberry_leaf     0.8750    1.0000    0.9333         7
                       Soyabean_leaf     0.7500    0.7500    0.7500         8
          Squash_Powdery_mildew_leaf     1.0000    1.0000    1.0000         6
                     Strawberry_leaf     1.0000    1.0000    1.0000         8
            Tomato_Early_blight_leaf     0.7000    0.7778    0.7368         9
           Tomato_Septoria_leaf_spot     0.8333    0.8333    0.8333        12
                         Tomato_leaf     1.0000    0.5000    0.6667         8
          Tomato_leaf_bacterial_spot     0.6250    0.5556    0.5882         9
             Tomato_leaf_late_blight     0.8750    0.7000    0.7778        10
            Tomato_leaf_mosaic_virus     0.8333    0.5000    0.6250        10
            Tomato_leaf_yellow_virus     0.8824    1.0000    0.9375        15
                    Tomato_mold_leaf     0.6250    0.8333    0.7143         6
Tomato_two_spotted_spider_mites_leaf     0.0000    0.0000    0.0000        12
                          grape_leaf     0.0000    0.0000    0.0000         8
                grape_leaf_black_rot     0.0000    0.0000    0.0000         0

                            accuracy                         0.6825       252
                           macro avg     0.6818    0.6632    0.6622       252
                        weighted avg     0.7103    0.6825    0.6865       252

 Confusion matrix saved to: output/test/Convnext2+PlantDocSplited/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/Convnext2+PlantDocSplited/grad_cam folder!
Traceback (most recent call last):
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/wrong_test.py", line 41, in <module>
    predicted_labels.append(class_names[preds[i].cpu().item()])
                            ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
IndexError: list index out of range
Evaluate model:Convnext2+PlantDocSplited

 Test Accuracy: 76.28%

 Classification Report:
                                      precision    recall  f1-score   support

                     Apple_Scab_Leaf     0.7273    0.8000    0.7619        10
                          Apple_leaf     0.7500    0.6667    0.7059         9
                     Apple_rust_leaf     0.9000    0.9000    0.9000        10
                    Bell_pepper_leaf     0.8750    0.8750    0.8750         8
               Bell_pepper_leaf_spot     0.8000    0.8889    0.8421         9
                      Blueberry_leaf     0.8333    0.9091    0.8696        11
                         Cherry_leaf     1.0000    0.8000    0.8889        10
                 Corn_Gray_leaf_spot     0.1111    0.2500    0.1538         4
                    Corn_leaf_blight     0.6250    0.4167    0.5000        12
                      Corn_rust_leaf     0.9000    0.9000    0.9000        10
                          Peach_leaf     1.0000    1.0000    1.0000         9
            Potato_leaf_early_blight     0.3333    0.2143    0.2609        14
             Potato_leaf_late_blight     0.2353    0.5000    0.3200         8
                      Raspberry_leaf     0.8750    1.0000    0.9333         7
                       Soyabean_leaf     0.7500    0.7500    0.7500         8
          Squash_Powdery_mildew_leaf     1.0000    1.0000    1.0000         6
                     Strawberry_leaf     1.0000    1.0000    1.0000         8
            Tomato_Early_blight_leaf     0.7000    0.7778    0.7368         9
           Tomato_Septoria_leaf_spot     0.8333    0.8333    0.8333        12
                         Tomato_leaf     1.0000    0.5000    0.6667         8
          Tomato_leaf_bacterial_spot     0.6250    0.5556    0.5882         9
             Tomato_leaf_late_blight     0.8750    0.7000    0.7778        10
            Tomato_leaf_mosaic_virus     0.8333    0.5000    0.6250        10
            Tomato_leaf_yellow_virus     0.8824    1.0000    0.9375        15
                    Tomato_mold_leaf     0.6250    0.8333    0.7143         6
Tomato_two_spotted_spider_mites_leaf     1.0000    1.0000    1.0000         1
                          grape_leaf     1.0000    1.0000    1.0000        12
                grape_leaf_black_rot     1.0000    1.0000    1.0000         8

                            accuracy                         0.7628       253
                           macro avg     0.7889    0.7704    0.7693       253
                        weighted avg     0.7905    0.7628    0.7668       253

 Confusion matrix saved to: output/test/Convnext2+PlantDocSplited/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/Convnext2+PlantDocSplited/grad_cam folder!
Saved misclassified images to output/test/Convnext2+PlantDocSplited/misclassified_images.png
Evaluate model:Convnext2+PlantDocSplited

 Test Accuracy: 77.20%

 Classification Report:
                                      precision    recall  f1-score   support

                     Apple_Scab_Leaf     0.7273    0.8000    0.7619        10
                          Apple_leaf     0.7500    0.6667    0.7059         9
                     Apple_rust_leaf     0.9000    0.9000    0.9000        10
                    Bell_pepper_leaf     0.8750    0.8750    0.8750         8
               Bell_pepper_leaf_spot     0.8000    0.8889    0.8421         9
                      Blueberry_leaf     0.9091    0.9091    0.9091        11
                         Cherry_leaf     1.0000    0.8000    0.8889        10
                 Corn_Gray_leaf_spot     0.1111    0.2500    0.1538         4
                    Corn_leaf_blight     0.6250    0.4167    0.5000        12
                      Corn_rust_leaf     0.9000    0.9000    0.9000        10
                          Peach_leaf     1.0000    1.0000    1.0000         9
            Potato_leaf_early_blight     0.3333    0.2143    0.2609        14
             Potato_leaf_late_blight     0.2353    0.5000    0.3200         8
                      Raspberry_leaf     0.8750    1.0000    0.9333         7
                       Soyabean_leaf     0.7500    0.8571    0.8000         7
          Squash_Powdery_mildew_leaf     1.0000    1.0000    1.0000         6
                     Strawberry_leaf     1.0000    1.0000    1.0000         8
            Tomato_Early_blight_leaf     0.7778    0.7778    0.7778         9
           Tomato_Septoria_leaf_spot     0.8333    0.8333    0.8333        12
                         Tomato_leaf     1.0000    0.5000    0.6667         8
          Tomato_leaf_bacterial_spot     0.7143    0.6250    0.6667         8
             Tomato_leaf_late_blight     0.8750    0.7000    0.7778        10
            Tomato_leaf_mosaic_virus     0.8333    0.5000    0.6250        10
            Tomato_leaf_yellow_virus     0.8824    1.0000    0.9375        15
                    Tomato_mold_leaf     0.6250    1.0000    0.7692         5
Tomato_two_spotted_spider_mites_leaf     1.0000    1.0000    1.0000         1
                          grape_leaf     1.0000    1.0000    1.0000        12
                grape_leaf_black_rot     1.0000    1.0000    1.0000         8

                            accuracy                         0.7720       250
                           macro avg     0.7976    0.7826    0.7787       250
                        weighted avg     0.8010    0.7720    0.7760       250

 Confusion matrix saved to: output/test/Convnext2+PlantDocSplited/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/Convnext2+PlantDocSplited/grad_cam folder!
Saved misclassified images to output/test/Convnext2+PlantDocSplited/misclassified_images.png
----------------------------------------DEPTH---------------------------
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: Convnext+depth+CBAM+dataset1]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Epoch 1/100 | Time: 213.10s | Train Loss: 1.0960 | Val Loss: 0.8843 | Val Acc: 0.7983 | LR: 0.000100 
Saving best val acc: 0.7983
Epoch 2/100 | Time: 179.90s | Train Loss: 0.6933 | Val Loss: 0.5607 | Val Acc: 0.9479 | LR: 0.000100 
Saving best val acc: 0.9479
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: Convnext+depth+CBAM+dataset1]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Epoch 1/100 | Time: 171.71s | Train Loss: 1.0551 | Val Loss: 0.8208 | Val Acc: 0.8373 | LR: 0.000100 
Saving best val acc: 0.8373
Epoch 2/100 | Time: 169.81s | Train Loss: 0.6604 | Val Loss: 0.5919 | Val Acc: 0.9306 | LR: 0.000100 
Saving best val acc: 0.9306
Epoch 3/100 | Time: 166.40s | Train Loss: 0.5838 | Val Loss: 0.5350 | Val Acc: 0.9436 | LR: 0.000100 
Saving best val acc: 0.9436
Epoch 4/100 | Time: 169.49s | Train Loss: 0.5431 | Val Loss: 0.5373 | Val Acc: 0.9610 | LR: 0.000099 
Epoch 5/100 | Time: 170.61s | Train Loss: 0.5102 | Val Loss: 0.5336 | Val Acc: 0.9544 | LR: 0.000098 
Saving best val acc: 0.9544
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: Convnext+depth+CBAM+dataset1]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Epoch 1/100 | Time: 175.94s | Train Loss: 0.9318 | Val Loss: 0.6438 | Val Acc: 0.9349 | LR: 0.000100 
Saving best val acc: 0.9349
Epoch 2/100 | Time: 172.18s | Train Loss: 0.6077 | Val Loss: 0.5926 | Val Acc: 0.9328 | LR: 0.000100 
Saving best val acc: 0.9328
Epoch 3/100 | Time: 171.23s | Train Loss: 0.5436 | Val Loss: 0.5472 | Val Acc: 0.9566 | LR: 0.000100 
Saving best val acc: 0.9566
Epoch 4/100 | Time: 174.08s | Train Loss: 0.5304 | Val Loss: 0.5403 | Val Acc: 0.9479 | LR: 0.000099 
Saving best val acc: 0.9479
Epoch 5/100 | Time: 174.00s | Train Loss: 0.5117 | Val Loss: 0.6408 | Val Acc: 0.9046 | LR: 0.000098 
Epoch 6/100 | Time: 174.54s | Train Loss: 0.5041 | Val Loss: 0.5192 | Val Acc: 0.9588 | LR: 0.000098 
Saving best val acc: 0.9588
Epoch 7/100 | Time: 174.74s | Train Loss: 0.5079 | Val Loss: 0.5286 | Val Acc: 0.9566 | LR: 0.000097 
Epoch 8/100 | Time: 175.84s | Train Loss: 0.4847 | Val Loss: 0.5099 | Val Acc: 0.9653 | LR: 0.000095 
Saving best val acc: 0.9653
Epoch 9/100 | Time: 173.56s | Train Loss: 0.4808 | Val Loss: 0.4955 | Val Acc: 0.9740 | LR: 0.000094 
Saving best val acc: 0.9740
Epoch 10/100 | Time: 168.37s | Train Loss: 0.4802 | Val Loss: 0.4881 | Val Acc: 0.9761 | LR: 0.000092 
Saving best val acc: 0.9761
Epoch 11/100 | Time: 173.73s | Train Loss: 0.4663 | Val Loss: 0.5110 | Val Acc: 0.9696 | LR: 0.000091 
Epoch 12/100 | Time: 180.50s | Train Loss: 0.4710 | Val Loss: 0.5994 | Val Acc: 0.9349 | LR: 0.000089 
Epoch 13/100 | Time: 176.61s | Train Loss: 0.4992 | Val Loss: 0.5497 | Val Acc: 0.9501 | LR: 0.000087 
Epoch 14/100 | Time: 179.80s | Train Loss: 0.4699 | Val Loss: 0.4886 | Val Acc: 0.9740 | LR: 0.000084 
Epoch 15/100 | Time: 177.04s | Train Loss: 0.4622 | Val Loss: 0.4952 | Val Acc: 0.9718 | LR: 0.000082 
Epoch 16/100 | Time: 171.40s | Train Loss: 0.4532 | Val Loss: 0.4945 | Val Acc: 0.9740 | LR: 0.000080 
Epoch 17/100 | Time: 171.49s | Train Loss: 0.4567 | Val Loss: 0.4774 | Val Acc: 0.9761 | LR: 0.000077 
Saving best val acc: 0.9761
Epoch 18/100 | Time: 173.53s | Train Loss: 0.4584 | Val Loss: 0.4863 | Val Acc: 0.9805 | LR: 0.000074 
Epoch 19/100 | Time: 174.44s | Train Loss: 0.4644 | Val Loss: 0.5116 | Val Acc: 0.9696 | LR: 0.000072 
Epoch 20/100 | Time: 172.69s | Train Loss: 0.4632 | Val Loss: 0.5082 | Val Acc: 0.9610 | LR: 0.000069 
Epoch 21/100 | Time: 173.63s | Train Loss: 0.4623 | Val Loss: 0.5018 | Val Acc: 0.9696 | LR: 0.000066 
Epoch 22/100 | Time: 178.46s | Train Loss: 0.4564 | Val Loss: 0.4940 | Val Acc: 0.9761 | LR: 0.000063 
Epoch 23/100 | Time: 182.06s | Train Loss: 0.4499 | Val Loss: 0.4949 | Val Acc: 0.9761 | LR: 0.000060 
Epoch 24/100 | Time: 187.25s | Train Loss: 0.4538 | Val Loss: 0.5123 | Val Acc: 0.9631 | LR: 0.000057 
Epoch 25/100 | Time: 201.12s | Train Loss: 0.4534 | Val Loss: 0.4997 | Val Acc: 0.9675 | LR: 0.000054 
Epoch 26/100 | Time: 191.66s | Train Loss: 0.4531 | Val Loss: 0.4817 | Val Acc: 0.9761 | LR: 0.000050 
Epoch 27/100 | Time: 187.24s | Train Loss: 0.4501 | Val Loss: 0.4953 | Val Acc: 0.9761 | LR: 0.000047 
Early stopping triggered.
Training complete in 4787.33 seconds. Best model loaded.
Model saved to ./output/models/Convnext+depth+CBAM+dataset1+dataset1.pth
 Training metrics plot saved to: output/test/Convnext+depth+CBAM+dataset1/training metric.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Evaluate model:Convnext+depth+CBAM+dataset1
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset

 Test Accuracy: 97.18%

 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     0.9048    1.0000    0.9500        19
           brown_spot     0.9176    0.9750    0.9455        80
              healthy     0.9688    1.0000    0.9841        93
           leaf_blast     0.9877    0.8791    0.9302        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9718       461
            macro avg     0.9631    0.9757    0.9683       461
         weighted avg     0.9730    0.9718    0.9715       461
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: Convnext+depth+dataset1]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Epoch 1/100 | Time: 158.63s | Train Loss: 0.7284 | Val Loss: 0.6033 | Val Acc: 0.9136 | LR: 0.000100 
Saving best val acc: 0.9136
Epoch 2/100 | Time: 154.38s | Train Loss: 0.5302 | Val Loss: 0.4975 | Val Acc: 0.9743 | LR: 0.000100 
Saving best val acc: 0.9743
Epoch 3/100 | Time: 153.99s | Train Loss: 0.4912 | Val Loss: 0.4699 | Val Acc: 0.9835 | LR: 0.000100 
Saving best val acc: 0.9835
Epoch 4/100 | Time: 155.09s | Train Loss: 0.4830 | Val Loss: 0.5198 | Val Acc: 0.9577 | LR: 0.000099 
Epoch 5/100 | Time: 155.14s | Train Loss: 0.4906 | Val Loss: 0.4816 | Val Acc: 0.9816 | LR: 0.000098 
Epoch 6/100 | Time: 155.26s | Train Loss: 0.4739 | Val Loss: 0.4833 | Val Acc: 0.9724 | LR: 0.000098 
Epoch 7/100 | Time: 155.08s | Train Loss: 0.4624 | Val Loss: 0.4677 | Val Acc: 0.9816 | LR: 0.000097 
Saving best val acc: 0.9816
Epoch 8/100 | Time: 155.57s | Train Loss: 0.4600 | Val Loss: 0.5025 | Val Acc: 0.9706 | LR: 0.000095 
Epoch 9/100 | Time: 155.56s | Train Loss: 0.4521 | Val Loss: 0.4905 | Val Acc: 0.9743 | LR: 0.000094 
Epoch 10/100 | Time: 155.98s | Train Loss: 0.4602 | Val Loss: 0.5062 | Val Acc: 0.9669 | LR: 0.000092 
Epoch 11/100 | Time: 155.70s | Train Loss: 0.4588 | Val Loss: 0.4726 | Val Acc: 0.9871 | LR: 0.000091 
Epoch 12/100 | Time: 156.36s | Train Loss: 0.4542 | Val Loss: 0.4768 | Val Acc: 0.9835 | LR: 0.000089 
Epoch 13/100 | Time: 157.41s | Train Loss: 0.4537 | Val Loss: 0.4840 | Val Acc: 0.9798 | LR: 0.000087 
Epoch 14/100 | Time: 156.23s | Train Loss: 0.4544 | Val Loss: 0.4802 | Val Acc: 0.9779 | LR: 0.000084 
Epoch 15/100 | Time: 156.47s | Train Loss: 0.4393 | Val Loss: 0.4545 | Val Acc: 0.9890 | LR: 0.000082 
Saving best val acc: 0.9890
Epoch 16/100 | Time: 156.01s | Train Loss: 0.4414 | Val Loss: 0.4683 | Val Acc: 0.9835 | LR: 0.000080 
Epoch 17/100 | Time: 156.77s | Train Loss: 0.4350 | Val Loss: 0.4621 | Val Acc: 0.9871 | LR: 0.000077 
Epoch 18/100 | Time: 155.51s | Train Loss: 0.4431 | Val Loss: 0.4634 | Val Acc: 0.9835 | LR: 0.000074 
Epoch 19/100 | Time: 155.32s | Train Loss: 0.4397 | Val Loss: 0.4697 | Val Acc: 0.9816 | LR: 0.000072 
Epoch 20/100 | Time: 155.52s | Train Loss: 0.4412 | Val Loss: 0.4773 | Val Acc: 0.9798 | LR: 0.000069 
Epoch 21/100 | Time: 171.64s | Train Loss: 0.4417 | Val Loss: 0.4569 | Val Acc: 0.9871 | LR: 0.000066 
Epoch 22/100 | Time: 155.78s | Train Loss: 0.4368 | Val Loss: 0.4658 | Val Acc: 0.9835 | LR: 0.000063 
Epoch 23/100 | Time: 155.51s | Train Loss: 0.4381 | Val Loss: 0.4580 | Val Acc: 0.9890 | LR: 0.000060 
Epoch 24/100 | Time: 155.40s | Train Loss: 0.4367 | Val Loss: 0.4641 | Val Acc: 0.9835 | LR: 0.000057 
Epoch 25/100 | Time: 155.50s | Train Loss: 0.4373 | Val Loss: 0.4678 | Val Acc: 0.9798 | LR: 0.000054 
Early stopping triggered.
Training complete in 3909.92 seconds. Best model loaded.
Model saved to ./output/models/Convnext+depth+dataset1+dataset1.pth
 Training metrics plot saved to: output/test/Convnext+depth+dataset1/training metric.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Evaluate model:Convnext+depth+dataset1
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset

 Test Accuracy: 98.90%

 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    0.9886    0.9943        88
           brown_spot     0.9783    0.9677    0.9730        93
              healthy     0.9789    1.0000    0.9894        93
           leaf_blast     0.9780    0.9780    0.9780        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9890       543
            macro avg     0.9892    0.9891    0.9891       543
         weighted avg     0.9890    0.9890    0.9889       543

 Saved misclassified images to output/test/Convnext+depth+dataset1/misclassified_images.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: Convnext+depth+PlantDocSplited]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Epoch 1/100 | Time: 218.24s | Train Loss: 1.8033 | Val Loss: 1.3808 | Val Acc: 0.7327 | LR: 0.000100 
Saving best val acc: 0.7327
Epoch 2/100 | Time: 214.66s | Train Loss: 1.1614 | Val Loss: 1.1612 | Val Acc: 0.8018 | LR: 0.000100 
Saving best val acc: 0.8018
Epoch 3/100 | Time: 180.64s | Train Loss: 0.9991 | Val Loss: 1.2304 | Val Acc: 0.7808 | LR: 0.000100 
Epoch 4/100 | Time: 179.85s | Train Loss: 0.8898 | Val Loss: 1.2229 | Val Acc: 0.7808 | LR: 0.000099 
Epoch 5/100 | Time: 179.65s | Train Loss: 0.8374 | Val Loss: 1.2389 | Val Acc: 0.8018 | LR: 0.000098 
Epoch 6/100 | Time: 179.27s | Train Loss: 0.7945 | Val Loss: 1.1467 | Val Acc: 0.8078 | LR: 0.000098 
Saving best val acc: 0.8078
Epoch 7/100 | Time: 180.57s | Train Loss: 0.7525 | Val Loss: 1.1681 | Val Acc: 0.8198 | LR: 0.000097 
Epoch 8/100 | Time: 184.85s | Train Loss: 0.7248 | Val Loss: 1.1781 | Val Acc: 0.8078 | LR: 0.000095 
Epoch 9/100 | Time: 182.47s | Train Loss: 0.7265 | Val Loss: 1.1821 | Val Acc: 0.8018 | LR: 0.000094 
Epoch 10/100 | Time: 180.71s | Train Loss: 0.7030 | Val Loss: 1.1818 | Val Acc: 0.8138 | LR: 0.000092 
Epoch 11/100 | Time: 180.02s | Train Loss: 0.7093 | Val Loss: 1.1726 | Val Acc: 0.8258 | LR: 0.000091 
Epoch 12/100 | Time: 179.44s | Train Loss: 0.7009 | Val Loss: 1.2777 | Val Acc: 0.7868 | LR: 0.000089 
Epoch 13/100 | Time: 179.99s | Train Loss: 0.7018 | Val Loss: 1.1660 | Val Acc: 0.8198 | LR: 0.000087 
Epoch 14/100 | Time: 181.04s | Train Loss: 0.7228 | Val Loss: 1.2137 | Val Acc: 0.7898 | LR: 0.000084 
Epoch 15/100 | Time: 179.72s | Train Loss: 0.6972 | Val Loss: 1.1877 | Val Acc: 0.8318 | LR: 0.000082 
Epoch 16/100 | Time: 180.97s | Train Loss: 0.6928 | Val Loss: 1.2986 | Val Acc: 0.7808 | LR: 0.000080 
Early stopping triggered.
Training complete in 2962.16 seconds. Best model loaded.
Model saved to ./output/models/Convnext+depth+PlantDocSplited+PlantDocSplited.pth
 Training metrics plot saved to: output/test/Convnext+depth+PlantDocSplited/training metric.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Evaluate model:Convnext+depth+PlantDocSplited
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset

 Test Accuracy: 75.20%

 Classification Report:
                                      precision    recall  f1-score   support

                     Apple_Scab_Leaf     0.8000    0.8000    0.8000        10
                          Apple_leaf     0.7778    0.7778    0.7778         9
                     Apple_rust_leaf     0.8889    0.8000    0.8421        10
                    Bell_pepper_leaf     0.7778    0.8750    0.8235         8
               Bell_pepper_leaf_spot     0.6667    0.8889    0.7619         9
                      Blueberry_leaf     1.0000    0.9091    0.9524        11
                         Cherry_leaf     0.9000    0.9000    0.9000        10
                 Corn_Gray_leaf_spot     0.0000    0.0000    0.0000         4
                    Corn_leaf_blight     0.6000    0.5000    0.5455        12
                      Corn_rust_leaf     1.0000    0.9000    0.9474        10
                          Peach_leaf     1.0000    0.8889    0.9412         9
            Potato_leaf_early_blight     0.4286    0.2143    0.2857        14
             Potato_leaf_late_blight     0.2353    0.5000    0.3200         8
                      Raspberry_leaf     0.8750    1.0000    0.9333         7
                       Soyabean_leaf     1.0000    0.7143    0.8333         7
          Squash_Powdery_mildew_leaf     1.0000    0.8333    0.9091         6
                     Strawberry_leaf     1.0000    1.0000    1.0000         8
            Tomato_Early_blight_leaf     0.7778    0.7778    0.7778         9
           Tomato_Septoria_leaf_spot     0.7059    1.0000    0.8276        12
                         Tomato_leaf     0.8333    0.6250    0.7143         8
          Tomato_leaf_bacterial_spot     0.7500    0.3750    0.5000         8
             Tomato_leaf_late_blight     0.7500    0.6000    0.6667        10
            Tomato_leaf_mosaic_virus     0.8000    0.4000    0.5333        10
            Tomato_leaf_yellow_virus     0.8750    0.9333    0.9032        15
                    Tomato_mold_leaf     0.3636    0.8000    0.5000         5
Tomato_two_spotted_spider_mites_leaf     1.0000    1.0000    1.0000         1
                          grape_leaf     1.0000    1.0000    1.0000        12
                grape_leaf_black_rot     1.0000    1.0000    1.0000         8

                            accuracy                         0.7520       250
                           macro avg     0.7788    0.7505    0.7499       250
                        weighted avg     0.7876    0.7520    0.7556       250

 Confusion matrix saved to: output/test/Convnext+depth+PlantDocSplited/confusion_matrix.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Device set to use cuda:0
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Saved 8 merged gradCAM images in the output/test/Convnext+depth+PlantDocSplited/grad_cam folder!
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Saved misclassified images to output/test/Convnext+depth+PlantDocSplited/misclassified_images.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Corn_Gray_leaf_spot
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Evaluate model:Convnext+depth+PlantDocSplited
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset

 Test Accuracy: 75.20%

 Classification Report:
                                      precision    recall  f1-score   support

                     Apple_Scab_Leaf     0.8000    0.8000    0.8000        10
                          Apple_leaf     0.7778    0.7778    0.7778         9
                     Apple_rust_leaf     0.8889    0.8000    0.8421        10
                    Bell_pepper_leaf     0.7778    0.8750    0.8235         8
               Bell_pepper_leaf_spot     0.6667    0.8889    0.7619         9
                      Blueberry_leaf     1.0000    0.9091    0.9524        11
                         Cherry_leaf     0.9000    0.9000    0.9000        10
                 Corn_Gray_leaf_spot     0.0000    0.0000    0.0000         4
                    Corn_leaf_blight     0.6000    0.5000    0.5455        12
                      Corn_rust_leaf     1.0000    0.9000    0.9474        10
                          Peach_leaf     1.0000    0.8889    0.9412         9
            Potato_leaf_early_blight     0.4286    0.2143    0.2857        14
             Potato_leaf_late_blight     0.2353    0.5000    0.3200         8
                      Raspberry_leaf     0.8750    1.0000    0.9333         7
                       Soyabean_leaf     1.0000    0.7143    0.8333         7
          Squash_Powdery_mildew_leaf     1.0000    0.8333    0.9091         6
                     Strawberry_leaf     1.0000    1.0000    1.0000         8
            Tomato_Early_blight_leaf     0.7778    0.7778    0.7778         9
           Tomato_Septoria_leaf_spot     0.7059    1.0000    0.8276        12
                         Tomato_leaf     0.8333    0.6250    0.7143         8
          Tomato_leaf_bacterial_spot     0.7500    0.3750    0.5000         8
             Tomato_leaf_late_blight     0.7500    0.6000    0.6667        10
            Tomato_leaf_mosaic_virus     0.8000    0.4000    0.5333        10
            Tomato_leaf_yellow_virus     0.8750    0.9333    0.9032        15
                    Tomato_mold_leaf     0.3636    0.8000    0.5000         5
Tomato_two_spotted_spider_mites_leaf     1.0000    1.0000    1.0000         1
                          grape_leaf     1.0000    1.0000    1.0000        12
                grape_leaf_black_rot     1.0000    1.0000    1.0000         8

                            accuracy                         0.7520       250
                           macro avg     0.7788    0.7505    0.7499       250
                        weighted avg     0.7876    0.7520    0.7556       250

 Confusion matrix saved to: output/test/Convnext+depth+PlantDocSplited/confusion_matrix.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Device set to use cuda:0
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Saved 8 merged gradCAM images in the output/test/Convnext+depth+PlantDocSplited/grad_cam folder!
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Saved misclassified images to output/test/Convnext+depth+PlantDocSplited/misclassified_images.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: Convnext+depth+PlantVillageSplited]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Epoch 1/100 | Time: 2827.63s | Train Loss: 0.8197 | Val Loss: 0.7349 | Val Acc: 0.9820 | LR: 0.000100 
Saving best val acc: 0.9820
Epoch 2/100 | Time: 2607.53s | Train Loss: 0.7180 | Val Loss: 0.7055 | Val Acc: 0.9923 | LR: 0.000100 
Saving best val acc: 0.9923
Epoch 3/100 | Time: 2471.16s | Train Loss: 0.7059 | Val Loss: 0.6963 | Val Acc: 0.9926 | LR: 0.000100 
Saving best val acc: 0.9926

Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: Convnext+depth+dataset1]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Epoch 1/100 | Time: 186.26s | Train Loss: 0.7406 | Val Loss: 0.5770 | Val Acc: 0.9485 | LR: 0.000100 
Saving best val acc: 0.9485
Epoch 2/100 | Time: 155.71s | Train Loss: 0.5349 | Val Loss: 0.5521 | Val Acc: 0.9393 | LR: 0.000100 
Saving best val acc: 0.9393
Epoch 3/100 | Time: 155.40s | Train Loss: 0.5071 | Val Loss: 0.5148 | Val Acc: 0.9724 | LR: 0.000100 
Saving best val acc: 0.9724
Epoch 4/100 | Time: 155.43s | Train Loss: 0.4875 | Val Loss: 0.5511 | Val Acc: 0.9522 | LR: 0.000099 
Epoch 5/100 | Time: 155.74s | Train Loss: 0.4740 | Val Loss: 0.4933 | Val Acc: 0.9669 | LR: 0.000098 
Saving best val acc: 0.9669
Epoch 6/100 | Time: 155.36s | Train Loss: 0.4701 | Val Loss: 0.5026 | Val Acc: 0.9669 | LR: 0.000098 
Epoch 7/100 | Time: 155.69s | Train Loss: 0.4694 | Val Loss: 0.5027 | Val Acc: 0.9540 | LR: 0.000097 
Epoch 8/100 | Time: 155.21s | Train Loss: 0.4583 | Val Loss: 0.4672 | Val Acc: 0.9779 | LR: 0.000095 
Saving best val acc: 0.9779
Epoch 9/100 | Time: 155.10s | Train Loss: 0.4498 | Val Loss: 0.4834 | Val Acc: 0.9779 | LR: 0.000094 
Epoch 10/100 | Time: 156.11s | Train Loss: 0.4605 | Val Loss: 0.4762 | Val Acc: 0.9761 | LR: 0.000092 
Epoch 11/100 | Time: 155.44s | Train Loss: 0.4517 | Val Loss: 0.4703 | Val Acc: 0.9853 | LR: 0.000091 
Epoch 12/100 | Time: 154.88s | Train Loss: 0.4591 | Val Loss: 0.4659 | Val Acc: 0.9835 | LR: 0.000089 
Saving best val acc: 0.9835
Epoch 13/100 | Time: 155.57s | Train Loss: 0.4457 | Val Loss: 0.4639 | Val Acc: 0.9853 | LR: 0.000087 
Saving best val acc: 0.9853
Epoch 14/100 | Time: 155.85s | Train Loss: 0.4400 | Val Loss: 0.4610 | Val Acc: 0.9835 | LR: 0.000084 
Saving best val acc: 0.9835
Epoch 15/100 | Time: 156.03s | Train Loss: 0.4399 | Val Loss: 0.4538 | Val Acc: 0.9871 | LR: 0.000082 
Saving best val acc: 0.9871
Epoch 16/100 | Time: 155.71s | Train Loss: 0.4369 | Val Loss: 0.4656 | Val Acc: 0.9835 | LR: 0.000080 
Epoch 17/100 | Time: 156.14s | Train Loss: 0.4422 | Val Loss: 0.4615 | Val Acc: 0.9835 | LR: 0.000077 
Epoch 18/100 | Time: 155.64s | Train Loss: 0.4445 | Val Loss: 0.4678 | Val Acc: 0.9816 | LR: 0.000074 
Epoch 19/100 | Time: 156.20s | Train Loss: 0.4418 | Val Loss: 0.4657 | Val Acc: 0.9871 | LR: 0.000072 
Epoch 20/100 | Time: 156.59s | Train Loss: 0.4340 | Val Loss: 0.4557 | Val Acc: 0.9835 | LR: 0.000069 
Epoch 21/100 | Time: 156.37s | Train Loss: 0.4344 | Val Loss: 0.4594 | Val Acc: 0.9816 | LR: 0.000066 
Epoch 22/100 | Time: 155.44s | Train Loss: 0.4338 | Val Loss: 0.4558 | Val Acc: 0.9890 | LR: 0.000063 
Epoch 23/100 | Time: 154.89s | Train Loss: 0.4367 | Val Loss: 0.4626 | Val Acc: 0.9853 | LR: 0.000060 
Epoch 24/100 | Time: 154.90s | Train Loss: 0.4418 | Val Loss: 0.4646 | Val Acc: 0.9816 | LR: 0.000057 
Epoch 25/100 | Time: 155.47s | Train Loss: 0.4350 | Val Loss: 0.4646 | Val Acc: 0.9853 | LR: 0.000054 
Early stopping triggered.
Training complete in 3921.31 seconds. Best model loaded.
Model saved to ./output/models/Convnext+depth+dataset1+dataset1.pth
 Training metrics plot saved to: output/test/Convnext+depth+dataset1/training metric.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Evaluate model:Convnext+depth+dataset1
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset

 Test Accuracy: 98.71%

 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    0.9886    0.9943        88
           brown_spot     0.9579    0.9785    0.9681        93
              healthy     0.9789    1.0000    0.9894        93
           leaf_blast     0.9886    0.9560    0.9721        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9871       543
            macro avg     0.9876    0.9872    0.9873       543
         weighted avg     0.9873    0.9871    0.9871       543

 Confusion matrix saved to: output/test/Convnext+depth+dataset1/confusion_matrix.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Device set to use cuda:0
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Saved 8 merged gradCAM images in the output/test/Convnext+depth+dataset1/grad_cam folder!
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Saved misclassified images to output/test/Convnext+depth+dataset1/misclassified_images.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: Convnext+depth+dataset3]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Epoch 1/100 | Time: 288.76s | Train Loss: 0.4345 | Val Loss: 0.3534 | Val Acc: 1.0000 | LR: 0.000100 
Saving best val acc: 1.0000
Epoch 2/100 | Time: 272.37s | Train Loss: 0.3674 | Val Loss: 0.3560 | Val Acc: 1.0000 | LR: 0.000100 
Epoch 3/100 | Time: 273.01s | Train Loss: 0.3638 | Val Loss: 0.3495 | Val Acc: 1.0000 | LR: 0.000100 
Saving best val acc: 1.0000
Epoch 4/100 | Time: 269.28s | Train Loss: 0.3609 | Val Loss: 0.3509 | Val Acc: 1.0000 | LR: 0.000099 
Epoch 5/100 | Time: 270.82s | Train Loss: 0.3615 | Val Loss: 0.3504 | Val Acc: 1.0000 | LR: 0.000098 
Epoch 6/100 | Time: 268.88s | Train Loss: 0.3617 | Val Loss: 0.3506 | Val Acc: 1.0000 | LR: 0.000098 
Epoch 7/100 | Time: 270.57s | Train Loss: 0.3602 | Val Loss: 0.3496 | Val Acc: 1.0000 | LR: 0.000097 
Epoch 8/100 | Time: 270.24s | Train Loss: 0.3619 | Val Loss: 0.3495 | Val Acc: 1.0000 | LR: 0.000095 
Epoch 9/100 | Time: 268.11s | Train Loss: 0.3608 | Val Loss: 0.3499 | Val Acc: 1.0000 | LR: 0.000094 
Epoch 10/100 | Time: 271.31s | Train Loss: 0.3606 | Val Loss: 0.3513 | Val Acc: 1.0000 | LR: 0.000092 
Epoch 11/100 | Time: 269.66s | Train Loss: 0.3599 | Val Loss: 0.3492 | Val Acc: 1.0000 | LR: 0.000091 
Saving best val acc: 1.0000
Epoch 12/100 | Time: 270.60s | Train Loss: 0.3943 | Val Loss: 0.4251 | Val Acc: 0.9629 | LR: 0.000089 
Epoch 13/100 | Time: 269.19s | Train Loss: 0.3761 | Val Loss: 0.3535 | Val Acc: 0.9992 | LR: 0.000087 
Epoch 14/100 | Time: 268.38s | Train Loss: 0.3617 | Val Loss: 0.3502 | Val Acc: 1.0000 | LR: 0.000084 
Epoch 15/100 | Time: 270.32s | Train Loss: 0.3605 | Val Loss: 0.3501 | Val Acc: 1.0000 | LR: 0.000082 
Epoch 16/100 | Time: 268.01s | Train Loss: 0.3605 | Val Loss: 0.3501 | Val Acc: 1.0000 | LR: 0.000080 
Epoch 17/100 | Time: 272.10s | Train Loss: 0.3607 | Val Loss: 0.3530 | Val Acc: 1.0000 | LR: 0.000077 
Epoch 18/100 | Time: 273.27s | Train Loss: 0.3603 | Val Loss: 0.3494 | Val Acc: 1.0000 | LR: 0.000074 
Epoch 19/100 | Time: 270.61s | Train Loss: 0.3592 | Val Loss: 0.3518 | Val Acc: 1.0000 | LR: 0.000072 
Epoch 20/100 | Time: 271.69s | Train Loss: 0.3594 | Val Loss: 0.3498 | Val Acc: 1.0000 | LR: 0.000069 
Epoch 21/100 | Time: 271.98s | Train Loss: 0.3587 | Val Loss: 0.3497 | Val Acc: 1.0000 | LR: 0.000066 
Early stopping triggered.
Training complete in 5699.22 seconds. Best model loaded.
Model saved to ./output/models/Convnext+depth+dataset3+dataset3.pth
 Training metrics plot saved to: output/test/Convnext+depth+dataset3/training metric.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Evaluate model:Convnext+depth+dataset3
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset

 Test Accuracy: 100.00%

 Classification Report:
                 precision    recall  f1-score   support

Bacterialblight     1.0000    1.0000    1.0000       160
          Blast     1.0000    1.0000    1.0000       145
      Brownspot     1.0000    1.0000    1.0000       160
         Tungro     1.0000    1.0000    1.0000       132

       accuracy                         1.0000       597
      macro avg     1.0000    1.0000    1.0000       597
   weighted avg     1.0000    1.0000    1.0000       597

=========================================================================================================


Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: Convnext+depth4channel+dataset1]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Epoch 1/100 | Time: 323.39s | Train Loss: 1.2867 | Val Loss: 2.3658 | Val Acc: 0.2500 | LR: 0.000100 
Saving best val acc: 0.2500
Epoch 2/100 | Time: 292.59s | Train Loss: 0.9587 | Val Loss: 1.1345 | Val Acc: 0.7096 | LR: 0.000100 
Saving best val acc: 0.7096
Epoch 3/100 | Time: 291.12s | Train Loss: 0.8225 | Val Loss: 1.6049 | Val Acc: 0.5165 | LR: 0.000100 
Epoch 4/100 | Time: 293.33s | Train Loss: 0.7669 | Val Loss: 0.7846 | Val Acc: 0.8456 | LR: 0.000099 
Saving best val acc: 0.8456
Epoch 5/100 | Time: 291.80s | Train Loss: 0.7098 | Val Loss: 0.8122 | Val Acc: 0.8456 | LR: 0.000098 
Epoch 6/100 | Time: 292.72s | Train Loss: 0.6711 | Val Loss: 0.7137 | Val Acc: 0.8952 | LR: 0.000098 
Saving best val acc: 0.8952
Epoch 7/100 | Time: 292.06s | Train Loss: 0.6112 | Val Loss: 0.6468 | Val Acc: 0.9099 | LR: 0.000097 
Saving best val acc: 0.9099
Epoch 8/100 | Time: 291.75s | Train Loss: 0.5746 | Val Loss: 0.7196 | Val Acc: 0.8915 | LR: 0.000095 
Epoch 9/100 | Time: 293.08s | Train Loss: 0.5685 | Val Loss: 0.8548 | Val Acc: 0.8438 | LR: 0.000094 
Epoch 10/100 | Time: 293.88s | Train Loss: 0.5470 | Val Loss: 0.7761 | Val Acc: 0.8768 | LR: 0.000092 
Epoch 11/100 | Time: 293.75s | Train Loss: 0.5348 | Val Loss: 0.5457 | Val Acc: 0.9430 | LR: 0.000091 
Saving best val acc: 0.9430
Epoch 12/100 | Time: 293.15s | Train Loss: 0.5261 | Val Loss: 0.5458 | Val Acc: 0.9485 | LR: 0.000089 
Epoch 13/100 | Time: 292.52s | Train Loss: 0.5079 | Val Loss: 0.5388 | Val Acc: 0.9632 | LR: 0.000087 
Saving best val acc: 0.9632
Epoch 14/100 | Time: 291.01s | Train Loss: 0.5037 | Val Loss: 0.5341 | Val Acc: 0.9596 | LR: 0.000084 
Saving best val acc: 0.9596
Epoch 15/100 | Time: 290.22s | Train Loss: 0.5041 | Val Loss: 0.5672 | Val Acc: 0.9375 | LR: 0.000082 
Epoch 16/100 | Time: 290.44s | Train Loss: 0.4864 | Val Loss: 0.5214 | Val Acc: 0.9614 | LR: 0.000080 
Saving best val acc: 0.9614
Epoch 17/100 | Time: 289.07s | Train Loss: 0.4820 | Val Loss: 0.4947 | Val Acc: 0.9651 | LR: 0.000077 
Saving best val acc: 0.9651
Epoch 18/100 | Time: 292.59s | Train Loss: 0.4698 | Val Loss: 0.5329 | Val Acc: 0.9540 | LR: 0.000074 
Epoch 19/100 | Time: 290.36s | Train Loss: 0.4712 | Val Loss: 0.5178 | Val Acc: 0.9596 | LR: 0.000072 
Epoch 20/100 | Time: 288.71s | Train Loss: 0.4656 | Val Loss: 0.5084 | Val Acc: 0.9706 | LR: 0.000069 
Epoch 21/100 | Time: 290.90s | Train Loss: 0.4646 | Val Loss: 0.4975 | Val Acc: 0.9743 | LR: 0.000066 
Epoch 22/100 | Time: 290.29s | Train Loss: 0.4617 | Val Loss: 0.5192 | Val Acc: 0.9596 | LR: 0.000063 
Epoch 23/100 | Time: 287.05s | Train Loss: 0.4622 | Val Loss: 0.5191 | Val Acc: 0.9688 | LR: 0.000060 
Epoch 24/100 | Time: 289.15s | Train Loss: 0.4454 | Val Loss: 0.4987 | Val Acc: 0.9669 | LR: 0.000057 
Epoch 25/100 | Time: 287.66s | Train Loss: 0.4420 | Val Loss: 0.4977 | Val Acc: 0.9706 | LR: 0.000054 
Epoch 26/100 | Time: 289.01s | Train Loss: 0.4614 | Val Loss: 0.5177 | Val Acc: 0.9632 | LR: 0.000050 
Epoch 27/100 | Time: 287.79s | Train Loss: 0.4564 | Val Loss: 0.5085 | Val Acc: 0.9669 | LR: 0.000047 
Early stopping triggered.
Training complete in 7889.58 seconds. Best model loaded.
Model saved to ./output/models/Convnext+depth4channel+dataset1+dataset1.pth
 Training metrics plot saved to: output/test/Convnext+depth4channel+dataset1/training metric.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Evaluate model:Convnext+depth4channel+dataset1
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset

 Test Accuracy: 96.87%

 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     0.9884    0.9659    0.9770        88
           brown_spot     0.9247    0.9247    0.9247        93
              healthy     0.9789    1.0000    0.9894        93
           leaf_blast     0.9231    0.9231    0.9231        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9687       543
            macro avg     0.9692    0.9690    0.9690       543
         weighted avg     0.9687    0.9687    0.9687       543

 Confusion matrix saved to: output/test/Convnext+depth4channel+dataset1/confusion_matrix.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Device set to use cuda:0
Traceback (most recent call last):
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/grad_cam.py", line 117, in <module>
    output = model(input_tensor)
             ^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/models/convnext_cbam.py", line 31, in forward
    x = self.model.stem(x)  # Initial Conv + LayerNorm
        ^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 554, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 549, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
RuntimeError: Given groups=1, weight of size [128, 4, 4, 4], expected input[1, 3, 224, 224] to have 4 channels, but got 3 channels instead
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Traceback (most recent call last):
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/wrong_test.py", line 32, in <module>
    outputs = model(images)
              ^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/models/convnext_cbam.py", line 31, in forward
    x = self.model.stem(x)  # Initial Conv + LayerNorm
        ^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 554, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 549, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
RuntimeError: Given groups=1, weight of size [128, 4, 4, 4], expected input[16, 3, 224, 224] to have 4 channels, but got 3 channels instead
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Evaluate model:Convnext+depth4channel+dataset1
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset

 Test Accuracy: 96.87%

 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     0.9884    0.9659    0.9770        88
           brown_spot     0.9247    0.9247    0.9247        93
              healthy     0.9789    1.0000    0.9894        93
           leaf_blast     0.9231    0.9231    0.9231        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9687       543
            macro avg     0.9692    0.9690    0.9690       543
         weighted avg     0.9687    0.9687    0.9687       543

 Confusion matrix saved to: output/test/Convnext+depth4channel+dataset1/confusion_matrix.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Device set to use cuda:0
Traceback (most recent call last):
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/grad_cam.py", line 117, in <module>
    output = model(input_tensor)
             ^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/models/convnext_cbam.py", line 101, in forward
    x = self.model.stem(x)  # First conv + norm
        ^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 554, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 549, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
RuntimeError: Given groups=1, weight of size [128, 4, 4, 4], expected input[1, 3, 224, 224] to have 4 channels, but got 3 channels instead
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Traceback (most recent call last):
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/wrong_test.py", line 32, in <module>
    outputs = model(images)
              ^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/models/convnext_cbam.py", line 101, in forward
    x = self.model.stem(x)  # First conv + norm
        ^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 554, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 549, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
RuntimeError: Given groups=1, weight of size [128, 4, 4, 4], expected input[16, 3, 224, 224] to have 4 channels, but got 3 channels instead
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: Convnext+depth4channel_v2+dataset1]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Epoch 1/100 | Time: 281.68s | Train Loss: 0.7531 | Val Loss: 0.5296 | Val Acc: 0.9614 | LR: 0.000100 
Saving best val acc: 0.9614
Epoch 2/100 | Time: 267.75s | Train Loss: 0.5266 | Val Loss: 0.4945 | Val Acc: 0.9724 | LR: 0.000100 
Saving best val acc: 0.9724
Epoch 3/100 | Time: 264.61s | Train Loss: 0.4998 | Val Loss: 0.4843 | Val Acc: 0.9779 | LR: 0.000100 
Saving best val acc: 0.9779
Epoch 4/100 | Time: 267.28s | Train Loss: 0.4831 | Val Loss: 0.4753 | Val Acc: 0.9761 | LR: 0.000099 
Saving best val acc: 0.9761
Epoch 5/100 | Time: 268.15s | Train Loss: 0.4671 | Val Loss: 0.4804 | Val Acc: 0.9761 | LR: 0.000098 
Epoch 6/100 | Time: 267.49s | Train Loss: 0.4546 | Val Loss: 0.4742 | Val Acc: 0.9835 | LR: 0.000098 
Saving best val acc: 0.9835
Epoch 7/100 | Time: 266.68s | Train Loss: 0.4525 | Val Loss: 0.4632 | Val Acc: 0.9798 | LR: 0.000097 
Saving best val acc: 0.9798
Epoch 8/100 | Time: 266.44s | Train Loss: 0.4583 | Val Loss: 0.4671 | Val Acc: 0.9835 | LR: 0.000095 
Epoch 9/100 | Time: 266.59s | Train Loss: 0.4482 | Val Loss: 0.4702 | Val Acc: 0.9853 | LR: 0.000094 
Epoch 10/100 | Time: 266.15s | Train Loss: 0.4410 | Val Loss: 0.4634 | Val Acc: 0.9890 | LR: 0.000092 
Epoch 11/100 | Time: 266.49s | Train Loss: 0.4578 | Val Loss: 0.5618 | Val Acc: 0.9375 | LR: 0.000091 
Epoch 12/100 | Time: 265.72s | Train Loss: 0.4602 | Val Loss: 0.5006 | Val Acc: 0.9724 | LR: 0.000089 
Epoch 13/100 | Time: 267.95s | Train Loss: 0.4464 | Val Loss: 0.4585 | Val Acc: 0.9835 | LR: 0.000087 
Saving best val acc: 0.9835
Epoch 14/100 | Time: 265.95s | Train Loss: 0.4391 | Val Loss: 0.4542 | Val Acc: 0.9871 | LR: 0.000084 
Saving best val acc: 0.9871
Epoch 15/100 | Time: 266.01s | Train Loss: 0.4404 | Val Loss: 0.4559 | Val Acc: 0.9835 | LR: 0.000082 
Epoch 16/100 | Time: 265.94s | Train Loss: 0.4436 | Val Loss: 0.5139 | Val Acc: 0.9688 | LR: 0.000080 
Epoch 17/100 | Time: 267.54s | Train Loss: 0.4408 | Val Loss: 0.4788 | Val Acc: 0.9761 | LR: 0.000077 
Epoch 18/100 | Time: 265.71s | Train Loss: 0.4424 | Val Loss: 0.4654 | Val Acc: 0.9835 | LR: 0.000074 
Epoch 19/100 | Time: 266.27s | Train Loss: 0.4420 | Val Loss: 0.5173 | Val Acc: 0.9632 | LR: 0.000072 
Epoch 20/100 | Time: 264.83s | Train Loss: 0.4435 | Val Loss: 0.4850 | Val Acc: 0.9688 | LR: 0.000069 
Epoch 21/100 | Time: 266.42s | Train Loss: 0.4320 | Val Loss: 0.4793 | Val Acc: 0.9798 | LR: 0.000066 
Epoch 22/100 | Time: 265.28s | Train Loss: 0.4343 | Val Loss: 0.4679 | Val Acc: 0.9835 | LR: 0.000063 
Epoch 23/100 | Time: 265.53s | Train Loss: 0.4326 | Val Loss: 0.4606 | Val Acc: 0.9835 | LR: 0.000060 
Epoch 24/100 | Time: 265.04s | Train Loss: 0.4381 | Val Loss: 0.5075 | Val Acc: 0.9706 | LR: 0.000057 
Early stopping triggered.
Training complete in 6407.64 seconds. Best model loaded.
Model saved to ./output/models/Convnext+depth4channel_v2+dataset1+dataset1.pth
 Training metrics plot saved to: output/test/Convnext+depth4channel_v2+dataset1/training metric.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Evaluate model:Convnext+depth4channel_v2+dataset1
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset

 Test Accuracy: 98.16%

 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     0.9886    0.9886    0.9886        88
           brown_spot     0.9474    0.9677    0.9574        93
              healthy     0.9789    1.0000    0.9894        93
           leaf_blast     0.9770    0.9341    0.9551        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9816       543
            macro avg     0.9820    0.9817    0.9818       543
         weighted avg     0.9817    0.9816    0.9815       543

 Confusion matrix saved to: output/test/Convnext+depth4channel_v2+dataset1/confusion_matrix.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Device set to use cuda:0
Traceback (most recent call last):
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/grad_cam.py", line 117, in <module>
    output = model(input_tensor)
             ^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/models/convnext_cbam.py", line 101, in forward
    x = self.model.stem(x)  # First conv + norm
        ^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 554, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 549, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
RuntimeError: Given groups=1, weight of size [128, 4, 4, 4], expected input[1, 3, 224, 224] to have 4 channels, but got 3 channels instead
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Traceback (most recent call last):
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/wrong_test.py", line 32, in <module>
    outputs = model(images)
              ^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/models/convnext_cbam.py", line 101, in forward
    x = self.model.stem(x)  # First conv + norm
        ^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 554, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/data3/users/datlht/Rice_leaf_disease_detection/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 549, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
RuntimeError: Given groups=1, weight of size [128, 4, 4, 4], expected input[16, 3, 224, 224] to have 4 channels, but got 3 channels instead
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Evaluate model:Convnext+depth4channel_v2+dataset1
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset

 Test Accuracy: 98.16%

 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     0.9886    0.9886    0.9886        88
           brown_spot     0.9474    0.9677    0.9574        93
              healthy     0.9789    1.0000    0.9894        93
           leaf_blast     0.9770    0.9341    0.9551        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9816       543
            macro avg     0.9820    0.9817    0.9818       543
         weighted avg     0.9817    0.9816    0.9815       543

 Confusion matrix saved to: output/test/Convnext+depth4channel_v2+dataset1/confusion_matrix.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.

âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: Convnext+depth4channel+dataset2_splited]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: Convnext+depth4channel+dataset2_splited]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”

âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: Convnext+depth4channel+dataset2_splited]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Epoch 1/100 | Time: 487.65s | Train Loss: 0.9429 | Val Loss: 0.6933 | Val Acc: 0.9071 | LR: 0.000100 
Saving best val acc: 0.9071
Epoch 2/100 | Time: 473.89s | Train Loss: 0.6417 | Val Loss: 0.5984 | Val Acc: 0.9412 | LR: 0.000100 
Saving best val acc: 0.9412
Epoch 3/100 | Time: 470.32s | Train Loss: 0.5696 | Val Loss: 0.5621 | Val Acc: 0.9505 | LR: 0.000100 
Saving best val acc: 0.9505
Epoch 4/100 | Time: 645.40s | Train Loss: 0.5429 | Val Loss: 0.5919 | Val Acc: 0.9381 | LR: 0.000099 
Epoch 5/100 | Time: 627.21s | Train Loss: 0.5405 | Val Loss: 0.5619 | Val Acc: 0.9567 | LR: 0.000098 
Saving best val acc: 0.9567
Epoch 6/100 | Time: 634.55s | Train Loss: 0.5385 | Val Loss: 0.5993 | Val Acc: 0.9505 | LR: 0.000098 
Epoch 7/100 | Time: 628.48s | Train Loss: 0.5153 | Val Loss: 0.5756 | Val Acc: 0.9567 | LR: 0.000097 
Epoch 8/100 | Time: 618.07s | Train Loss: 0.4967 | Val Loss: 0.5388 | Val Acc: 0.9628 | LR: 0.000095 
Saving best val acc: 0.9628
Epoch 9/100 | Time: 626.62s | Train Loss: 0.4974 | Val Loss: 0.5485 | Val Acc: 0.9505 | LR: 0.000094 
Epoch 10/100 | Time: 622.57s | Train Loss: 0.4950 | Val Loss: 0.5554 | Val Acc: 0.9536 | LR: 0.000092 
Epoch 11/100 | Time: 623.11s | Train Loss: 0.4996 | Val Loss: 0.5396 | Val Acc: 0.9598 | LR: 0.000091 
Epoch 12/100 | Time: 558.40s | Train Loss: 0.4868 | Val Loss: 0.5507 | Val Acc: 0.9567 | LR: 0.000089 
Epoch 13/100 | Time: 452.26s | Train Loss: 0.4830 | Val Loss: 0.5418 | Val Acc: 0.9659 | LR: 0.000087 
Epoch 14/100 | Time: 479.66s | Train Loss: 0.4861 | Val Loss: 0.5798 | Val Acc: 0.9505 | LR: 0.000084 
Epoch 15/100 | Time: 460.29s | Train Loss: 0.4835 | Val Loss: 0.5453 | Val Acc: 0.9598 | LR: 0.000082 
Epoch 16/100 | Time: 895.98s | Train Loss: 0.4692 | Val Loss: 0.5266 | Val Acc: 0.9659 | LR: 0.000080 
Saving best val acc: 0.9659
Epoch 17/100 | Time: 1365.39s | Train Loss: 0.4754 | Val Loss: 0.5502 | Val Acc: 0.9598 | LR: 0.000077 
Epoch 18/100 | Time: 1360.35s | Train Loss: 0.4716 | Val Loss: 0.5173 | Val Acc: 0.9659 | LR: 0.000074 
Saving best val acc: 0.9659
Epoch 19/100 | Time: 1475.96s | Train Loss: 0.4691 | Val Loss: 0.5348 | Val Acc: 0.9628 | LR: 0.000072 
Epoch 20/100 | Time: 1325.68s | Train Loss: 0.4744 | Val Loss: 0.5264 | Val Acc: 0.9536 | LR: 0.000069 
Epoch 21/100 | Time: 602.10s | Train Loss: 0.4733 | Val Loss: 0.5353 | Val Acc: 0.9598 | LR: 0.000066 
Epoch 22/100 | Time: 1455.35s | Train Loss: 0.4628 | Val Loss: 0.5298 | Val Acc: 0.9598 | LR: 0.000063 
Epoch 23/100 | Time: 1402.63s | Train Loss: 0.4760 | Val Loss: 0.5306 | Val Acc: 0.9690 | LR: 0.000060 
Epoch 24/100 | Time: 1365.60s | Train Loss: 0.4628 | Val Loss: 0.5433 | Val Acc: 0.9598 | LR: 0.000057 
Epoch 25/100 | Time: 719.94s | Train Loss: 0.4633 | Val Loss: 0.5698 | Val Acc: 0.9505 | LR: 0.000054 
Epoch 26/100 | Time: 1193.59s | Train Loss: 0.4678 | Val Loss: 0.5322 | Val Acc: 0.9721 | LR: 0.000050 
Epoch 27/100 | Time: 1384.50s | Train Loss: 0.4637 | Val Loss: 0.5412 | Val Acc: 0.9659 | LR: 0.000047 
Epoch 28/100 | Time: 1420.73s | Train Loss: 0.4625 | Val Loss: 0.5303 | Val Acc: 0.9598 | LR: 0.000044 
Early stopping triggered.
Training complete in 24378.81 seconds. Best model loaded.
Model saved to ./output/models/Convnext+depth4channel+dataset2_splited+dataset2_splited.pth
 Training metrics plot saved to: output/test/Convnext+depth4channel+dataset2_splited/training metric.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Evaluate model:Convnext+depth4channel+dataset2_splited
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset

 Test Accuracy: 96.76%

 Classification Report:
                       precision    recall  f1-score   support

     Bacterial Blight     0.9783    0.9184    0.9474        49
Bacterial Leaf Streak     0.8684    1.0000    0.9296        33
           Brown Spot     0.9359    0.9605    0.9481       152
              Healthy     0.9872    0.9747    0.9809       158
                Hispa     0.9925    0.9925    0.9925       133
           Leaf Blast     0.9760    0.9531    0.9644       128
        Sheath Blight     1.0000    0.9600    0.9796        25

             accuracy                         0.9676       678
            macro avg     0.9626    0.9656    0.9632       678
         weighted avg     0.9687    0.9676    0.9677       678

 Confusion matrix saved to: output/test/Convnext+depth4channel+dataset2_splited/confusion_matrix.png
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Device set to use cuda:0
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Saved 8 merged gradCAM images in the output/test/Convnext+depth4channel+dataset2_splited/grad_cam folder!
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Evaluate model:Convnext+depth4channel+dataset2_splited
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset

 Test Accuracy: 96.76%

 Classification Report:
                       precision    recall  f1-score   support

     Bacterial Blight     0.9783    0.9184    0.9474        49
Bacterial Leaf Streak     0.8684    1.0000    0.9296        33
           Brown Spot     0.9359    0.9605    0.9481       152
              Healthy     0.9872    0.9747    0.9809       158
                Hispa     0.9925    0.9925    0.9925       133
           Leaf Blast     0.9760    0.9531    0.9644       128
        Sheath Blight     1.0000    0.9600    0.9796        25

             accuracy                         0.9676       678
            macro avg     0.9626    0.9656    0.9632       678
         weighted avg     0.9687    0.9676    0.9677       678


Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: ConvNext+depth4channel_v3+dataset1]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Epoch 1/100 | Time: 977.27s | Train Loss: 0.7750 | Val Loss: 0.5327 | Val Acc: 0.9485 | LR: 0.000100 
Saving best val acc: 0.9485
Epoch 2/100 | Time: 712.61s | Train Loss: 0.5234 | Val Loss: 0.5244 | Val Acc: 0.9522 | LR: 0.000100 
Saving best val acc: 0.9522
Epoch 3/100 | Time: 349.10s | Train Loss: 0.4820 | Val Loss: 0.4990 | Val Acc: 0.9706 | LR: 0.000100 
Saving best val acc: 0.9706
Epoch 4/100 | Time: 316.76s | Train Loss: 0.4989 | Val Loss: 0.4866 | Val Acc: 0.9798 | LR: 0.000099 
Saving best val acc: 0.9798
Epoch 5/100 | Time: 262.94s | Train Loss: 0.4830 | Val Loss: 0.4939 | Val Acc: 0.9761 | LR: 0.000098 
Epoch 6/100 | Time: 261.88s | Train Loss: 0.4637 | Val Loss: 0.4934 | Val Acc: 0.9798 | LR: 0.000098 
Epoch 7/100 | Time: 263.33s | Train Loss: 0.4751 | Val Loss: 0.4920 | Val Acc: 0.9688 | LR: 0.000097 
Epoch 8/100 | Time: 262.37s | Train Loss: 0.4658 | Val Loss: 0.5052 | Val Acc: 0.9596 | LR: 0.000095 
Epoch 9/100 | Time: 262.21s | Train Loss: 0.4665 | Val Loss: 0.4959 | Val Acc: 0.9688 | LR: 0.000094 
Epoch 10/100 | Time: 261.99s | Train Loss: 0.4492 | Val Loss: 0.4843 | Val Acc: 0.9743 | LR: 0.000092 
Saving best val acc: 0.9743
Epoch 11/100 | Time: 263.37s | Train Loss: 0.4511 | Val Loss: 0.4627 | Val Acc: 0.9853 | LR: 0.000091 
Saving best val acc: 0.9853
Epoch 12/100 | Time: 262.32s | Train Loss: 0.4562 | Val Loss: 0.4571 | Val Acc: 0.9853 | LR: 0.000089 
Saving best val acc: 0.9853
Epoch 13/100 | Time: 263.25s | Train Loss: 0.4478 | Val Loss: 0.4874 | Val Acc: 0.9816 | LR: 0.000087 
Epoch 14/100 | Time: 262.71s | Train Loss: 0.4452 | Val Loss: 0.4709 | Val Acc: 0.9853 | LR: 0.000084 
Epoch 15/100 | Time: 264.35s | Train Loss: 0.4367 | Val Loss: 0.4609 | Val Acc: 0.9890 | LR: 0.000082 
Epoch 16/100 | Time: 262.41s | Train Loss: 0.4387 | Val Loss: 0.4636 | Val Acc: 0.9890 | LR: 0.000080 
Epoch 17/100 | Time: 262.90s | Train Loss: 0.4440 | Val Loss: 0.4672 | Val Acc: 0.9835 | LR: 0.000077 
Epoch 18/100 | Time: 263.46s | Train Loss: 0.4420 | Val Loss: 0.4647 | Val Acc: 0.9853 | LR: 0.000074 
Epoch 19/100 | Time: 266.24s | Train Loss: 0.4400 | Val Loss: 0.4622 | Val Acc: 0.9871 | LR: 0.000072 
Epoch 20/100 | Time: 263.12s | Train Loss: 0.4411 | Val Loss: 0.4661 | Val Acc: 0.9816 | LR: 0.000069 
Epoch 21/100 | Time: 262.19s | Train Loss: 0.4460 | Val Loss: 0.4718 | Val Acc: 0.9816 | LR: 0.000066 
Epoch 22/100 | Time: 279.77s | Train Loss: 0.4385 | Val Loss: 0.4668 | Val Acc: 0.9853 | LR: 0.000063 
Early stopping triggered.
Training complete in 7106.78 seconds. Best model loaded.
Model saved to ./output/models/ConvNext+depth4channel_v3+dataset1+dataset1.pth
 Training metrics plot saved to: output/test/ConvNext+depth4channel_v3+dataset1/training metric.png
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: convnext+cbam+depth+precompute+dataset_2_depth_AUG]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
Epoch 1/50 | Time: 232.74s | Train Loss: 0.8145 | Val Loss: 0.6098 | Val Acc: 0.9319 | LR: 0.000100 
Saving best val acc: 0.9319
Epoch 2/50 | Time: 234.48s | Train Loss: 0.5851 | Val Loss: 0.6294 | Val Acc: 0.9350 | LR: 0.000100 
Epoch 3/50 | Time: 233.78s | Train Loss: 0.5484 | Val Loss: 0.5721 | Val Acc: 0.9536 | LR: 0.000100 
Saving best val acc: 0.9536
Epoch 4/50 | Time: 236.23s | Train Loss: 0.5256 | Val Loss: 0.6376 | Val Acc: 0.9164 | LR: 0.000099 
Epoch 5/50 | Time: 246.28s | Train Loss: 0.5181 | Val Loss: 0.5713 | Val Acc: 0.9412 | LR: 0.000098 
Saving best val acc: 0.9412
Epoch 6/50 | Time: 245.87s | Train Loss: 0.4994 | Val Loss: 0.5791 | Val Acc: 0.9536 | LR: 0.000098 
Epoch 7/50 | Time: 246.45s | Train Loss: 0.4891 | Val Loss: 0.5550 | Val Acc: 0.9567 | LR: 0.000097 
Saving best val acc: 0.9567
Epoch 8/50 | Time: 246.48s | Train Loss: 0.4997 | Val Loss: 0.5449 | Val Acc: 0.9659 | LR: 0.000095 
Saving best val acc: 0.9659
Epoch 9/50 | Time: 247.53s | Train Loss: 0.4777 | Val Loss: 0.5253 | Val Acc: 0.9690 | LR: 0.000094 
Saving best val acc: 0.9690
Epoch 10/50 | Time: 244.88s | Train Loss: 0.4928 | Val Loss: 0.5300 | Val Acc: 0.9628 | LR: 0.000092 
Epoch 11/50 | Time: 233.00s | Train Loss: 0.4752 | Val Loss: 0.5548 | Val Acc: 0.9567 | LR: 0.000091 
Epoch 12/50 | Time: 237.90s | Train Loss: 0.4826 | Val Loss: 0.6422 | Val Acc: 0.9257 | LR: 0.000089 
Epoch 13/50 | Time: 241.03s | Train Loss: 0.4805 | Val Loss: 0.5146 | Val Acc: 0.9721 | LR: 0.000087 
Saving best val acc: 0.9721
Epoch 14/50 | Time: 234.08s | Train Loss: 0.4785 | Val Loss: 0.5398 | Val Acc: 0.9598 | LR: 0.000084 
Epoch 15/50 | Time: 233.66s | Train Loss: 0.4760 | Val Loss: 0.5238 | Val Acc: 0.9598 | LR: 0.000082 
Epoch 16/50 | Time: 234.23s | Train Loss: 0.4767 | Val Loss: 0.5353 | Val Acc: 0.9659 | LR: 0.000080 
Epoch 17/50 | Time: 234.14s | Train Loss: 0.4679 | Val Loss: 0.5175 | Val Acc: 0.9721 | LR: 0.000077 
Epoch 18/50 | Time: 234.05s | Train Loss: 0.4620 | Val Loss: 0.5009 | Val Acc: 0.9814 | LR: 0.000074 
Saving best val acc: 0.9814
Epoch 19/50 | Time: 247.43s | Train Loss: 0.4723 | Val Loss: 0.5836 | Val Acc: 0.9598 | LR: 0.000072 
Epoch 20/50 | Time: 251.22s | Train Loss: 0.4755 | Val Loss: 0.5292 | Val Acc: 0.9690 | LR: 0.000069 
Epoch 21/50 | Time: 241.33s | Train Loss: 0.4700 | Val Loss: 0.5500 | Val Acc: 0.9598 | LR: 0.000066 
Epoch 22/50 | Time: 232.52s | Train Loss: 0.4621 | Val Loss: 0.5028 | Val Acc: 0.9752 | LR: 0.000063 
Epoch 23/50 | Time: 233.74s | Train Loss: 0.4604 | Val Loss: 0.5132 | Val Acc: 0.9690 | LR: 0.000060 
Epoch 24/50 | Time: 233.89s | Train Loss: 0.4631 | Val Loss: 0.5257 | Val Acc: 0.9721 | LR: 0.000057 
Epoch 25/50 | Time: 231.97s | Train Loss: 0.4646 | Val Loss: 0.4755 | Val Acc: 0.9876 | LR: 0.000054 
Saving best val acc: 0.9876
Epoch 26/50 | Time: 234.88s | Train Loss: 0.4586 | Val Loss: 0.5412 | Val Acc: 0.9567 | LR: 0.000050 
Epoch 27/50 | Time: 245.00s | Train Loss: 0.4598 | Val Loss: 0.5120 | Val Acc: 0.9721 | LR: 0.000047 
Epoch 28/50 | Time: 260.20s | Train Loss: 0.4603 | Val Loss: 0.5189 | Val Acc: 0.9690 | LR: 0.000044 
Epoch 29/50 | Time: 260.37s | Train Loss: 0.4595 | Val Loss: 0.4689 | Val Acc: 0.9907 | LR: 0.000041 
Saving best val acc: 0.9907
Epoch 30/50 | Time: 235.89s | Train Loss: 0.4606 | Val Loss: 0.5225 | Val Acc: 0.9752 | LR: 0.000038 
Epoch 31/50 | Time: 233.76s | Train Loss: 0.4638 | Val Loss: 0.5002 | Val Acc: 0.9783 | LR: 0.000035 
Epoch 32/50 | Time: 233.20s | Train Loss: 0.4571 | Val Loss: 0.5073 | Val Acc: 0.9721 | LR: 0.000032 
Epoch 33/50 | Time: 232.91s | Train Loss: 0.4575 | Val Loss: 0.4996 | Val Acc: 0.9783 | LR: 0.000029 
Epoch 34/50 | Time: 233.30s | Train Loss: 0.4577 | Val Loss: 0.4899 | Val Acc: 0.9814 | LR: 0.000027 
Epoch 35/50 | Time: 240.50s | Train Loss: 0.4563 | Val Loss: 0.4800 | Val Acc: 0.9814 | LR: 0.000024 
Epoch 36/50 | Time: 247.77s | Train Loss: 0.4555 | Val Loss: 0.4830 | Val Acc: 0.9907 | LR: 0.000021 
Epoch 37/50 | Time: 250.74s | Train Loss: 0.4561 | Val Loss: 0.4787 | Val Acc: 0.9876 | LR: 0.000019 
Epoch 38/50 | Time: 248.77s | Train Loss: 0.4555 | Val Loss: 0.5007 | Val Acc: 0.9783 | LR: 0.000017 
Epoch 39/50 | Time: 232.29s | Train Loss: 0.4544 | Val Loss: 0.4959 | Val Acc: 0.9783 | LR: 0.000014 
Early stopping triggered.
Training complete in 9358.68 seconds. Best model loaded.
Model saved to ./output/models/convnext+cbam+depth+precompute+dataset_2_depth_AUG+dataset_2_depth_AUG.pth
 Training metrics plot saved to: output/test/convnext+cbam+depth+precompute+dataset_2_depth_AUG/training metric.png
Evaluate model:convnext+cbam+depth+precompute+dataset_2_depth_AUG

 Test Accuracy: 97.49%

 Classification Report:
                       precision    recall  f1-score   support

     Bacterial Blight     0.9783    0.9184    0.9474        49
Bacterial Leaf Streak     0.9167    1.0000    0.9565        33
           Brown Spot     0.9737    0.9737    0.9737       152
              Healthy     0.9809    0.9747    0.9778       158
                Hispa     0.9706    0.9925    0.9814       133
           Leaf Blast     0.9843    0.9766    0.9804       128
        Sheath Blight     1.0000    0.9600    0.9796        25

             accuracy                         0.9749       678
            macro avg     0.9720    0.9708    0.9710       678
         weighted avg     0.9753    0.9749    0.9749       678

 Confusion matrix saved to: output/test/convnext+cbam+depth+precompute+dataset_2_depth_AUG/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/convnext+cbam+depth+precompute+dataset_2_depth_AUG/grad_cam folder!
Saved misclassified images to output/test/convnext+cbam+depth+precompute+dataset_2_depth_AUG/misclassified_images.png



âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: convnext+cbam+depth+precompute+dataset_1_depth_AUG]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
Epoch 1/50 | Time: 204.31s | Train Loss: 0.6640 | Val Loss: 0.5533 | Val Acc: 0.9375 | LR: 0.000100 
Saving best val acc: 0.9375
Epoch 2/50 | Time: 131.21s | Train Loss: 0.5032 | Val Loss: 0.6440 | Val Acc: 0.8989 | LR: 0.000100 
Epoch 3/50 | Time: 131.48s | Train Loss: 0.4759 | Val Loss: 0.4705 | Val Acc: 0.9798 | LR: 0.000100 
Saving best val acc: 0.9798
Epoch 4/50 | Time: 148.96s | Train Loss: 0.4606 | Val Loss: 0.5585 | Val Acc: 0.9577 | LR: 0.000099 
Epoch 5/50 | Time: 140.12s | Train Loss: 0.4600 | Val Loss: 0.4905 | Val Acc: 0.9761 | LR: 0.000098 
Epoch 6/50 | Time: 133.00s | Train Loss: 0.4585 | Val Loss: 0.5114 | Val Acc: 0.9688 | LR: 0.000098 
Epoch 7/50 | Time: 134.18s | Train Loss: 0.4581 | Val Loss: 0.4808 | Val Acc: 0.9761 | LR: 0.000097 
Epoch 8/50 | Time: 141.85s | Train Loss: 0.4520 | Val Loss: 0.4779 | Val Acc: 0.9761 | LR: 0.000095 
Epoch 9/50 | Time: 142.19s | Train Loss: 0.4565 | Val Loss: 0.4700 | Val Acc: 0.9816 | LR: 0.000094 
Saving best val acc: 0.9816
Epoch 10/50 | Time: 142.57s | Train Loss: 0.4491 | Val Loss: 0.4604 | Val Acc: 0.9835 | LR: 0.000092 
Saving best val acc: 0.9835
Epoch 11/50 | Time: 141.86s | Train Loss: 0.4456 | Val Loss: 0.4850 | Val Acc: 0.9724 | LR: 0.000091 
Epoch 12/50 | Time: 142.45s | Train Loss: 0.4481 | Val Loss: 0.4679 | Val Acc: 0.9835 | LR: 0.000089 
Epoch 13/50 | Time: 142.88s | Train Loss: 0.4363 | Val Loss: 0.4794 | Val Acc: 0.9798 | LR: 0.000087 
Epoch 14/50 | Time: 143.31s | Train Loss: 0.4434 | Val Loss: 0.4755 | Val Acc: 0.9798 | LR: 0.000084 
Epoch 15/50 | Time: 141.78s | Train Loss: 0.4413 | Val Loss: 0.4861 | Val Acc: 0.9724 | LR: 0.000082 
Epoch 16/50 | Time: 143.22s | Train Loss: 0.4359 | Val Loss: 0.4597 | Val Acc: 0.9890 | LR: 0.000080 
Saving best val acc: 0.9890
Epoch 17/50 | Time: 142.23s | Train Loss: 0.4359 | Val Loss: 0.4723 | Val Acc: 0.9798 | LR: 0.000077 
Epoch 18/50 | Time: 142.23s | Train Loss: 0.4371 | Val Loss: 0.4717 | Val Acc: 0.9816 | LR: 0.000074 
Epoch 19/50 | Time: 142.70s | Train Loss: 0.4431 | Val Loss: 0.4652 | Val Acc: 0.9853 | LR: 0.000072 
Epoch 20/50 | Time: 142.02s | Train Loss: 0.4389 | Val Loss: 0.4875 | Val Acc: 0.9743 | LR: 0.000069 
Epoch 21/50 | Time: 142.99s | Train Loss: 0.4492 | Val Loss: 0.5011 | Val Acc: 0.9614 | LR: 0.000066 
Epoch 22/50 | Time: 141.39s | Train Loss: 0.4403 | Val Loss: 0.4709 | Val Acc: 0.9835 | LR: 0.000063 
Epoch 23/50 | Time: 141.35s | Train Loss: 0.4384 | Val Loss: 0.4635 | Val Acc: 0.9853 | LR: 0.000060 
Epoch 24/50 | Time: 141.99s | Train Loss: 0.4348 | Val Loss: 0.4699 | Val Acc: 0.9835 | LR: 0.000057 
Epoch 25/50 | Time: 141.05s | Train Loss: 0.4326 | Val Loss: 0.4723 | Val Acc: 0.9835 | LR: 0.000054 
Epoch 26/50 | Time: 142.73s | Train Loss: 0.4316 | Val Loss: 0.4729 | Val Acc: 0.9816 | LR: 0.000050 
Early stopping triggered.
Training complete in 3726.18 seconds. Best model loaded.
Model saved to ./output/models/convnext+cbam+depth+precompute+dataset_1_depth_AUG+dataset_1_depth_AUG.pth
 Training metrics plot saved to: output/test/convnext+cbam+depth+precompute+dataset_1_depth_AUG/training metric.png
Evaluate model:convnext+cbam+depth+precompute+dataset_1_depth_AUG

 Test Accuracy: 98.53%

 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    0.9886    0.9943        88
           brown_spot     0.9778    0.9462    0.9617        93
              healthy     0.9688    1.0000    0.9841        93
           leaf_blast     0.9674    0.9780    0.9727        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9853       543
            macro avg     0.9857    0.9855    0.9855       543
         weighted avg     0.9854    0.9853    0.9852       543

 Confusion matrix saved to: output/test/convnext+cbam+depth+precompute+dataset_1_depth_AUG/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/convnext+cbam+depth+precompute+dataset_1_depth_AUG/grad_cam folder!


Evaluate model:convnext+cbam+depth+precompute+dataset_1_depth_AUG

 Test Accuracy: 98.53%

 Classification Report:
                       precision    recall  f1-score   support

bacterial_leaf_blight     1.0000    0.9886    0.9943        88
           brown_spot     0.9778    0.9462    0.9617        93
              healthy     0.9688    1.0000    0.9841        93
           leaf_blast     0.9674    0.9780    0.9727        91
           leaf_scald     1.0000    1.0000    1.0000        90
    narrow_brown_spot     1.0000    1.0000    1.0000        88

             accuracy                         0.9853       543
            macro avg     0.9857    0.9855    0.9855       543
         weighted avg     0.9854    0.9853    0.9852       543

 Confusion matrix saved to: output/test/convnext+cbam+depth+precompute+dataset_1_depth_AUG/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/convnext+cbam+depth+precompute+dataset_1_depth_AUG/grad_cam folder!
Saved misclassified images to output/test/convnext+cbam+depth+precompute+dataset_1_depth_AUG/misclassified_images.png
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: convnext_only+dataset2_splited]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
Epoch 1/50 | Time: 172.06s | Train Loss: 0.9638 | Val Loss: 0.6279 | Val Acc: 0.9257 | LR: 0.000100 
Saving best val acc: 0.9257
Epoch 2/50 | Time: 129.45s | Train Loss: 0.6259 | Val Loss: 0.5639 | Val Acc: 0.9536 | LR: 0.000100 
Saving best val acc: 0.9536
Epoch 3/50 | Time: 130.28s | Train Loss: 0.5569 | Val Loss: 0.5349 | Val Acc: 0.9659 | LR: 0.000100 
Saving best val acc: 0.9659
Epoch 4/50 | Time: 128.64s | Train Loss: 0.5240 | Val Loss: 0.5740 | Val Acc: 0.9536 | LR: 0.000099 
Epoch 5/50 | Time: 129.97s | Train Loss: 0.5284 | Val Loss: 0.5492 | Val Acc: 0.9690 | LR: 0.000098 
Epoch 6/50 | Time: 129.61s | Train Loss: 0.4973 | Val Loss: 0.5369 | Val Acc: 0.9598 | LR: 0.000098 
Epoch 7/50 | Time: 129.39s | Train Loss: 0.4876 | Val Loss: 0.5778 | Val Acc: 0.9443 | LR: 0.000097 
Epoch 8/50 | Time: 130.60s | Train Loss: 0.4855 | Val Loss: 0.5197 | Val Acc: 0.9659 | LR: 0.000095 
Saving best val acc: 0.9659
Epoch 9/50 | Time: 130.85s | Train Loss: 0.4804 | Val Loss: 0.5378 | Val Acc: 0.9690 | LR: 0.000094 
Epoch 10/50 | Time: 129.03s | Train Loss: 0.4812 | Val Loss: 0.5244 | Val Acc: 0.9721 | LR: 0.000092 
Epoch 11/50 | Time: 130.85s | Train Loss: 0.4802 | Val Loss: 0.5450 | Val Acc: 0.9598 | LR: 0.000091 
Epoch 12/50 | Time: 128.92s | Train Loss: 0.4756 | Val Loss: 0.5589 | Val Acc: 0.9628 | LR: 0.000089 
Epoch 13/50 | Time: 129.87s | Train Loss: 0.4849 | Val Loss: 0.5273 | Val Acc: 0.9752 | LR: 0.000087 
Epoch 14/50 | Time: 129.98s | Train Loss: 0.4669 | Val Loss: 0.5342 | Val Acc: 0.9567 | LR: 0.000084 
Epoch 15/50 | Time: 129.75s | Train Loss: 0.4604 | Val Loss: 0.5357 | Val Acc: 0.9598 | LR: 0.000082 
Epoch 16/50 | Time: 128.79s | Train Loss: 0.4719 | Val Loss: 0.5491 | Val Acc: 0.9598 | LR: 0.000080 
Epoch 17/50 | Time: 128.80s | Train Loss: 0.4691 | Val Loss: 0.5559 | Val Acc: 0.9505 | LR: 0.000077 
Epoch 18/50 | Time: 128.83s | Train Loss: 0.4654 | Val Loss: 0.5238 | Val Acc: 0.9628 | LR: 0.000074 
Early stopping triggered.
Training complete in 2375.76 seconds. Best model loaded.
Model saved to ./output/models/convnext_only+dataset2_splited+dataset2_splited.pth
 Training metrics plot saved to: output/test/convnext_only+dataset2_splited/training metric.png
Evaluate model:convnext_only+dataset2_splited

 Test Accuracy: 96.31%

 Classification Report:
                       precision    recall  f1-score   support

     Bacterial Blight     0.9565    0.8980    0.9263        49
Bacterial Leaf Streak     0.8378    0.9394    0.8857        33
           Brown Spot     0.9545    0.9671    0.9608       152
              Healthy     0.9742    0.9557    0.9649       158
                Hispa     0.9706    0.9925    0.9814       133
           Leaf Blast     0.9841    0.9688    0.9764       128
        Sheath Blight     1.0000    0.9600    0.9796        25

             accuracy                         0.9631       678
            macro avg     0.9540    0.9545    0.9536       678
         weighted avg     0.9640    0.9631    0.9633       678

 Confusion matrix saved to: output/test/convnext_only+dataset2_splited/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/convnext_only+dataset2_splited/grad_cam folder!
Saved misclassified images to output/test/convnext_only+dataset2_splited/misclassified_images.png
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: convnext_only+dataset2_splited]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: convnext+CBAM+dataset2_splited]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
Epoch 1/50 | Time: 157.63s | Train Loss: 0.9238 | Val Loss: 0.6559 | Val Acc: 0.9102 | LR: 0.000100 
Saving best val acc: 0.9102
Epoch 2/50 | Time: 128.87s | Train Loss: 0.6725 | Val Loss: 0.6111 | Val Acc: 0.9319 | LR: 0.000100 
Saving best val acc: 0.9319
Epoch 3/50 | Time: 128.21s | Train Loss: 0.5949 | Val Loss: 0.5760 | Val Acc: 0.9381 | LR: 0.000100 
Saving best val acc: 0.9381
Epoch 4/50 | Time: 131.92s | Train Loss: 0.5641 | Val Loss: 0.5566 | Val Acc: 0.9567 | LR: 0.000099 
Saving best val acc: 0.9567
Epoch 5/50 | Time: 130.37s | Train Loss: 0.5448 | Val Loss: 0.5562 | Val Acc: 0.9567 | LR: 0.000098 
Saving best val acc: 0.9567
Epoch 6/50 | Time: 131.07s | Train Loss: 0.5193 | Val Loss: 0.5327 | Val Acc: 0.9628 | LR: 0.000098 
Saving best val acc: 0.9628
Epoch 7/50 | Time: 131.60s | Train Loss: 0.5229 | Val Loss: 0.5669 | Val Acc: 0.9567 | LR: 0.000097 
Epoch 8/50 | Time: 131.55s | Train Loss: 0.5066 | Val Loss: 0.5479 | Val Acc: 0.9721 | LR: 0.000095 
Epoch 9/50 | Time: 131.84s | Train Loss: 0.4955 | Val Loss: 0.5215 | Val Acc: 0.9783 | LR: 0.000094 
Saving best val acc: 0.9783
Epoch 10/50 | Time: 130.93s | Train Loss: 0.4937 | Val Loss: 0.5304 | Val Acc: 0.9752 | LR: 0.000092 
Epoch 11/50 | Time: 131.12s | Train Loss: 0.4816 | Val Loss: 0.5577 | Val Acc: 0.9598 | LR: 0.000091 
Epoch 12/50 | Time: 130.69s | Train Loss: 0.5016 | Val Loss: 0.5509 | Val Acc: 0.9659 | LR: 0.000089 
Epoch 13/50 | Time: 131.06s | Train Loss: 0.4839 | Val Loss: 0.5572 | Val Acc: 0.9690 | LR: 0.000087 
Epoch 14/50 | Time: 128.51s | Train Loss: 0.4901 | Val Loss: 0.5502 | Val Acc: 0.9598 | LR: 0.000084 
Epoch 15/50 | Time: 131.06s | Train Loss: 0.4835 | Val Loss: 0.5482 | Val Acc: 0.9598 | LR: 0.000082 
Epoch 16/50 | Time: 131.36s | Train Loss: 0.4833 | Val Loss: 0.5669 | Val Acc: 0.9505 | LR: 0.000080 
Epoch 17/50 | Time: 131.76s | Train Loss: 0.4860 | Val Loss: 0.5574 | Val Acc: 0.9628 | LR: 0.000077 
Epoch 18/50 | Time: 129.43s | Train Loss: 0.4676 | Val Loss: 0.5318 | Val Acc: 0.9690 | LR: 0.000074 
Epoch 19/50 | Time: 129.27s | Train Loss: 0.4703 | Val Loss: 0.5476 | Val Acc: 0.9628 | LR: 0.000072 
Early stopping triggered.
Training complete in 2508.37 seconds. Best model loaded.
Model saved to ./output/models/convnext+CBAM+dataset2_splited+dataset2_splited.pth
 Training metrics plot saved to: output/test/convnext+CBAM+dataset2_splited/training metric.png
Evaluate model:convnext+CBAM+dataset2_splited

 Test Accuracy: 97.35%

 Classification Report:
                       precision    recall  f1-score   support

     Bacterial Blight     1.0000    0.8571    0.9231        49
Bacterial Leaf Streak     0.8684    1.0000    0.9296        33
           Brown Spot     0.9737    0.9737    0.9737       152
              Healthy     0.9693    1.0000    0.9844       158
                Hispa     1.0000    0.9850    0.9924       133
           Leaf Blast     0.9841    0.9688    0.9764       128
        Sheath Blight     0.9231    0.9600    0.9412        25

             accuracy                         0.9735       678
            macro avg     0.9598    0.9635    0.9601       678
         weighted avg     0.9747    0.9735    0.9734       678

 Confusion matrix saved to: output/test/convnext+CBAM+dataset2_splited/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/convnext+CBAM+dataset2_splited/grad_cam folder!
Saved misclassified images to output/test/convnext+CBAM+dataset2_splited/misclassified_images.png

âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: convnext+CBAM+PlantVillageSplited_depth_AUG]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
Epoch 1/50 | Time: 2636.27s | Train Loss: 0.7706 | Val Loss: 0.7008 | Val Acc: 0.9931 | LR: 0.000100 
Saving best val acc: 0.9931
Epoch 2/50 | Time: 2105.60s | Train Loss: 0.7050 | Val Loss: 0.7091 | Val Acc: 0.9889 | LR: 0.000100 
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: convnext+CBAM+PlantDocSplited_depth_AUG]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
Epoch 1/50 | Time: 159.67s | Train Loss: 1.4471 | Val Loss: 1.1405 | Val Acc: 0.8048 | LR: 0.000100 
Saving best val acc: 0.8048
Epoch 2/50 | Time: 160.03s | Train Loss: 0.9513 | Val Loss: 1.1624 | Val Acc: 0.8018 | LR: 0.000100 
Epoch 3/50 | Time: 160.37s | Train Loss: 0.8123 | Val Loss: 1.2513 | Val Acc: 0.7868 | LR: 0.000100 
Epoch 4/50 | Time: 161.41s | Train Loss: 0.7619 | Val Loss: 1.1818 | Val Acc: 0.8168 | LR: 0.000099 
Epoch 5/50 | Time: 161.92s | Train Loss: 0.7155 | Val Loss: 1.2052 | Val Acc: 0.8048 | LR: 0.000098 
Epoch 6/50 | Time: 161.51s | Train Loss: 0.7053 | Val Loss: 1.1428 | Val Acc: 0.8468 | LR: 0.000098 
Epoch 7/50 | Time: 162.12s | Train Loss: 0.6833 | Val Loss: 1.1575 | Val Acc: 0.8198 | LR: 0.000097 
Epoch 8/50 | Time: 161.74s | Train Loss: 0.6817 | Val Loss: 1.1172 | Val Acc: 0.8288 | LR: 0.000095 
Saving best val acc: 0.8288
Epoch 9/50 | Time: 161.11s | Train Loss: 0.6825 | Val Loss: 1.1577 | Val Acc: 0.8198 | LR: 0.000094 
Epoch 10/50 | Time: 161.62s | Train Loss: 0.6976 | Val Loss: 1.1588 | Val Acc: 0.8108 | LR: 0.000092 
Epoch 11/50 | Time: 161.82s | Train Loss: 0.6905 | Val Loss: 1.2292 | Val Acc: 0.8048 | LR: 0.000091 
Epoch 12/50 | Time: 160.85s | Train Loss: 0.6914 | Val Loss: 1.2299 | Val Acc: 0.8078 | LR: 0.000089 
Epoch 13/50 | Time: 162.32s | Train Loss: 0.6761 | Val Loss: 1.1723 | Val Acc: 0.8198 | LR: 0.000087 
Epoch 14/50 | Time: 161.79s | Train Loss: 0.6652 | Val Loss: 1.1648 | Val Acc: 0.8408 | LR: 0.000084 
Epoch 15/50 | Time: 162.22s | Train Loss: 0.6686 | Val Loss: 1.3086 | Val Acc: 0.7808 | LR: 0.000082 
Epoch 16/50 | Time: 161.93s | Train Loss: 0.6690 | Val Loss: 1.1664 | Val Acc: 0.8318 | LR: 0.000080 
Epoch 17/50 | Time: 161.55s | Train Loss: 0.6616 | Val Loss: 1.1864 | Val Acc: 0.8318 | LR: 0.000077 
Epoch 18/50 | Time: 162.46s | Train Loss: 0.6603 | Val Loss: 1.2098 | Val Acc: 0.8198 | LR: 0.000074 
Early stopping triggered.
Training complete in 2906.48 seconds. Best model loaded.
Model saved to ./output/models/convnext+CBAM+PlantDocSplited_depth_AUG+PlantDocSplited_depth_AUG.pth
 Training metrics plot saved to: output/test/convnext+CBAM+PlantDocSplited_depth_AUG/training metric.png
Evaluate model:convnext+CBAM+PlantDocSplited_depth_AUG

 Test Accuracy: 77.20%

 Classification Report:
                                      precision    recall  f1-score   support

                     Apple_Scab_Leaf     0.8889    0.8000    0.8421        10
                          Apple_leaf     0.7778    0.7778    0.7778         9
                     Apple_rust_leaf     0.9000    0.9000    0.9000        10
                    Bell_pepper_leaf     0.7778    0.8750    0.8235         8
               Bell_pepper_leaf_spot     0.5833    0.7778    0.6667         9
                      Blueberry_leaf     0.9000    0.8182    0.8571        11
                         Cherry_leaf     0.8889    0.8000    0.8421        10
                 Corn_Gray_leaf_spot     0.1667    0.2500    0.2000         4
                    Corn_leaf_blight     0.7000    0.5833    0.6364        12
                      Corn_rust_leaf     1.0000    1.0000    1.0000        10
                          Peach_leaf     0.8750    0.7778    0.8235         9
            Potato_leaf_early_blight     0.3333    0.1429    0.2000        14
             Potato_leaf_late_blight     0.2500    0.5000    0.3333         8
                      Raspberry_leaf     0.8750    1.0000    0.9333         7
                       Soyabean_leaf     1.0000    0.7143    0.8333         7
          Squash_Powdery_mildew_leaf     1.0000    1.0000    1.0000         6
                     Strawberry_leaf     1.0000    1.0000    1.0000         8
            Tomato_Early_blight_leaf     0.7273    0.8889    0.8000         9
           Tomato_Septoria_leaf_spot     0.7857    0.9167    0.8462        12
                         Tomato_leaf     0.7500    0.3750    0.5000         8
          Tomato_leaf_bacterial_spot     0.5714    0.5000    0.5333         8
             Tomato_leaf_late_blight     0.8889    0.8000    0.8421        10
            Tomato_leaf_mosaic_virus     0.6667    0.8000    0.7273        10
            Tomato_leaf_yellow_virus     0.9333    0.9333    0.9333        15
                    Tomato_mold_leaf     0.6667    0.8000    0.7273         5
Tomato_two_spotted_spider_mites_leaf     1.0000    1.0000    1.0000         1
                          grape_leaf     1.0000    1.0000    1.0000        12
                grape_leaf_black_rot     1.0000    1.0000    1.0000         8

                            accuracy                         0.7720       250
                           macro avg     0.7824    0.7761    0.7707       250
                        weighted avg     0.7853    0.7720    0.7700       250

 Confusion matrix saved to: output/test/convnext+CBAM+PlantDocSplited_depth_AUG/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/convnext+CBAM+PlantDocSplited_depth_AUG/grad_cam folder!
Saved misclassified images to output/test/convnext+CBAM+PlantDocSplited_depth_AUG/misclassified_images.png
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: ConvNeXt+CBAM_Potato_splited_depth_AUG]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
Epoch 1/50 | Time: 174.06s | Train Loss: 0.8846 | Val Loss: 0.7589 | Val Acc: 0.8480 | LR: 0.000100 
Saving best val acc: 0.8480
Epoch 2/50 | Time: 162.82s | Train Loss: 0.6136 | Val Loss: 0.7119 | Val Acc: 0.8856 | LR: 0.000100 
Saving best val acc: 0.8856
Epoch 3/50 | Time: 155.26s | Train Loss: 0.5435 | Val Loss: 0.7106 | Val Acc: 0.8856 | LR: 0.000100 
Saving best val acc: 0.8856
Epoch 4/50 | Time: 148.72s | Train Loss: 0.5210 | Val Loss: 0.7521 | Val Acc: 0.8824 | LR: 0.000099 
Epoch 5/50 | Time: 148.79s | Train Loss: 0.4981 | Val Loss: 0.7209 | Val Acc: 0.8922 | LR: 0.000098 
Epoch 6/50 | Time: 149.16s | Train Loss: 0.4862 | Val Loss: 0.6761 | Val Acc: 0.9118 | LR: 0.000098 
Saving best val acc: 0.9118
Epoch 7/50 | Time: 151.18s | Train Loss: 0.4972 | Val Loss: 0.6967 | Val Acc: 0.8987 | LR: 0.000097 
Epoch 8/50 | Time: 150.22s | Train Loss: 0.4967 | Val Loss: 0.7620 | Val Acc: 0.8709 | LR: 0.000095 
Epoch 9/50 | Time: 150.82s | Train Loss: 0.5006 | Val Loss: 0.7086 | Val Acc: 0.9020 | LR: 0.000094 
Epoch 10/50 | Time: 149.98s | Train Loss: 0.4717 | Val Loss: 0.7727 | Val Acc: 0.8807 | LR: 0.000092 
Epoch 11/50 | Time: 151.33s | Train Loss: 0.4727 | Val Loss: 0.7805 | Val Acc: 0.8775 | LR: 0.000091 
Epoch 12/50 | Time: 150.50s | Train Loss: 0.4759 | Val Loss: 0.6771 | Val Acc: 0.9118 | LR: 0.000089 
Epoch 13/50 | Time: 150.41s | Train Loss: 0.4710 | Val Loss: 0.6954 | Val Acc: 0.9036 | LR: 0.000087 
Epoch 14/50 | Time: 149.97s | Train Loss: 0.4650 | Val Loss: 0.6892 | Val Acc: 0.9101 | LR: 0.000084 
Epoch 15/50 | Time: 147.30s | Train Loss: 0.4686 | Val Loss: 0.7670 | Val Acc: 0.8758 | LR: 0.000082 
Epoch 16/50 | Time: 150.35s | Train Loss: 0.4711 | Val Loss: 0.7465 | Val Acc: 0.8938 | LR: 0.000080 
Early stopping triggered.
Training complete in 2440.95 seconds. Best model loaded.
Model saved to ./output/models/ConvNeXt+CBAM_Potato_splited_depth_AUG.pth
 Training metrics plot saved to: output/test/ConvNeXt+CBAM_Potato_splited_depth_AUG/training metric.png
Evaluate model:ConvNeXt+CBAM_Potato_splited_depth_AUG

 Test Accuracy: 88.75%

 Classification Report:
              precision    recall  f1-score   support

    Bacteria     0.9741    0.9826    0.9784       115
       Fungi     0.8741    0.8278    0.8503       151
     Healthy     0.7917    0.9268    0.8539        41
    Nematode     0.8824    1.0000    0.9375        15
        Pest     0.8387    0.8455    0.8421       123
 Phytopthora     0.9077    0.8429    0.8741        70
       Virus     0.8991    0.9159    0.9074       107

    accuracy                         0.8875       622
   macro avg     0.8811    0.9059    0.8920       622
weighted avg     0.8884    0.8875    0.8872       622

 Confusion matrix saved to: output/test/ConvNeXt+CBAM_Potato_splited_depth_AUG/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+CBAM_Potato_splited_depth_AUG/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+CBAM_Potato_splited_depth_AUG/misclassified_images.png
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: ConvNeXt+CBAM_Potato_splited_depth_AUG+v2]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
Epoch 1/50 | Time: 167.38s | Train Loss: 0.8577 | Val Loss: 0.8265 | Val Acc: 0.8562 | LR: 0.000100 
Saving best val acc: 0.8562
Epoch 2/50 | Time: 168.84s | Train Loss: 0.6096 | Val Loss: 0.8174 | Val Acc: 0.8333 | LR: 0.000100 
Saving best val acc: 0.8333
Epoch 3/50 | Time: 170.32s | Train Loss: 0.5500 | Val Loss: 0.7067 | Val Acc: 0.9069 | LR: 0.000100 
Saving best val acc: 0.9069
Epoch 4/50 | Time: 170.32s | Train Loss: 0.5160 | Val Loss: 0.7766 | Val Acc: 0.8758 | LR: 0.000099 
Epoch 5/50 | Time: 172.06s | Train Loss: 0.5045 | Val Loss: 0.7002 | Val Acc: 0.8987 | LR: 0.000098 
Saving best val acc: 0.8987
Epoch 6/50 | Time: 172.15s | Train Loss: 0.4889 | Val Loss: 0.8079 | Val Acc: 0.8611 | LR: 0.000098 
Epoch 7/50 | Time: 171.42s | Train Loss: 0.4907 | Val Loss: 0.7147 | Val Acc: 0.8840 | LR: 0.000097 
Epoch 8/50 | Time: 172.23s | Train Loss: 0.4742 | Val Loss: 0.7531 | Val Acc: 0.8856 | LR: 0.000095 
Epoch 9/50 | Time: 172.91s | Train Loss: 0.4750 | Val Loss: 0.8666 | Val Acc: 0.8562 | LR: 0.000094 
Epoch 10/50 | Time: 169.11s | Train Loss: 0.4832 | Val Loss: 0.8338 | Val Acc: 0.8464 | LR: 0.000092 
Epoch 11/50 | Time: 172.47s | Train Loss: 0.4886 | Val Loss: 0.7185 | Val Acc: 0.8938 | LR: 0.000091 
Epoch 12/50 | Time: 172.73s | Train Loss: 0.4705 | Val Loss: 0.7797 | Val Acc: 0.8775 | LR: 0.000089 
Epoch 13/50 | Time: 171.77s | Train Loss: 0.4699 | Val Loss: 0.7717 | Val Acc: 0.8742 | LR: 0.000087 
Epoch 14/50 | Time: 172.87s | Train Loss: 0.4770 | Val Loss: 0.7424 | Val Acc: 0.8873 | LR: 0.000084 
Epoch 15/50 | Time: 171.39s | Train Loss: 0.4717 | Val Loss: 0.7897 | Val Acc: 0.8725 | LR: 0.000082 
Early stopping triggered.
Training complete in 2568.04 seconds. Best model loaded.
Model saved to ./output/models/ConvNeXt+CBAM_Potato_splited_depth_AUG+v2.pth
 Training metrics plot saved to: output/test/ConvNeXt+CBAM_Potato_splited_depth_AUG+v2/training metric.png
Evaluate model:ConvNeXt+CBAM_Potato_splited_depth_AUG+v2

 Test Accuracy: 90.48%

 Classification Report:
              precision    recall  f1-score   support

    Bacteria     0.9355    1.0000    0.9667        58
       Fungi     0.8889    0.8421    0.8649        76
     Healthy     1.0000    0.9048    0.9500        21
    Nematode     0.8750    0.8750    0.8750         8
        Pest     0.8438    0.8710    0.8571        62
 Phytopthora     0.8889    0.8889    0.8889        36
       Virus     0.9444    0.9444    0.9444        54

    accuracy                         0.9048       315
   macro avg     0.9109    0.9037    0.9067       315
weighted avg     0.9052    0.9048    0.9044       315

 Confusion matrix saved to: output/test/ConvNeXt+CBAM_Potato_splited_depth_AUG+v2/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+CBAM_Potato_splited_depth_AUG+v2/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+CBAM_Potato_splited_depth_AUG+v2/misclassified_images.png
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: ConvNeXt+CBAM_PlantVillageSplited_depth_AUG]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
Epoch 1/50 | Time: 4514.90s | Train Loss: 0.7695 | Val Loss: 0.7345 | Val Acc: 0.9828 | LR: 0.000100 
Saving best val acc: 0.9828
Epoch 2/50 | Time: 2199.09s | Train Loss: 0.7054 | Val Loss: 0.7234 | Val Acc: 0.9840 | LR: 0.000100 
Saving best val acc: 0.9840
Epoch 3/50 | Time: 2015.85s | Train Loss: 0.6969 | Val Loss: 0.6956 | Val Acc: 0.9925 | LR: 0.000100 
Saving best val acc: 0.9925
Epoch 4/50 | Time: 2015.27s | Train Loss: 0.6920 | Val Loss: 0.6851 | Val Acc: 0.9969 | LR: 0.000099 
Saving best val acc: 0.9969
Epoch 5/50 | Time: 2015.16s | Train Loss: 0.6877 | Val Loss: 0.6891 | Val Acc: 0.9954 | LR: 0.000098 
Epoch 6/50 | Time: 2017.75s | Train Loss: 0.6893 | Val Loss: 0.6838 | Val Acc: 0.9968 | LR: 0.000098 
Saving best val acc: 0.9968
Epoch 7/50 | Time: 2015.78s | Train Loss: 0.6848 | Val Loss: 0.6863 | Val Acc: 0.9954 | LR: 0.000097 
Epoch 8/50 | Time: 2089.54s | Train Loss: 0.6854 | Val Loss: 0.7014 | Val Acc: 0.9909 | LR: 0.000095 
Epoch 9/50 | Time: 3351.00s | Train Loss: 0.6836 | Val Loss: 0.6830 | Val Acc: 0.9970 | LR: 0.000094 
Saving best val acc: 0.9970
Epoch 10/50 | Time: 2925.68s | Train Loss: 0.6840 | Val Loss: 0.6859 | Val Acc: 0.9963 | LR: 0.000092 
Epoch 11/50 | Time: 2432.79s | Train Loss: 0.6819 | Val Loss: 0.6825 | Val Acc: 0.9975 | LR: 0.000091 
Saving best val acc: 0.9975
Epoch 12/50 | Time: 2281.63s | Train Loss: 0.6816 | Val Loss: 0.6925 | Val Acc: 0.9940 | LR: 0.000089 
Epoch 13/50 | Time: 2015.58s | Train Loss: 0.6811 | Val Loss: 0.6880 | Val Acc: 0.9961 | LR: 0.000087 
Epoch 14/50 | Time: 2015.01s | Train Loss: 0.6802 | Val Loss: 0.6834 | Val Acc: 0.9970 | LR: 0.000084 
Epoch 15/50 | Time: 2014.85s | Train Loss: 0.6789 | Val Loss: 0.6838 | Val Acc: 0.9970 | LR: 0.000082 
Epoch 16/50 | Time: 2015.08s | Train Loss: 0.6790 | Val Loss: 0.6917 | Val Acc: 0.9955 | LR: 0.000080 
Epoch 17/50 | Time: 2015.08s | Train Loss: 0.6785 | Val Loss: 0.6850 | Val Acc: 0.9962 | LR: 0.000077 
Epoch 18/50 | Time: 2015.10s | Train Loss: 0.6771 | Val Loss: 0.6885 | Val Acc: 0.9958 | LR: 0.000074 
Epoch 19/50 | Time: 2014.84s | Train Loss: 0.6779 | Val Loss: 0.6839 | Val Acc: 0.9972 | LR: 0.000072 
Epoch 20/50 | Time: 2015.09s | Train Loss: 0.6776 | Val Loss: 0.6865 | Val Acc: 0.9971 | LR: 0.000069 
Epoch 21/50 | Time: 2015.08s | Train Loss: 0.6763 | Val Loss: 0.6983 | Val Acc: 0.9929 | LR: 0.000066 
Early stopping triggered.
Training complete in 48010.48 seconds. Best model loaded.
Model saved to ./output/models/ConvNeXt+CBAM_PlantVillageSplited_depth_AUG.pth
 Training metrics plot saved to: output/test/ConvNeXt+CBAM_PlantVillageSplited_depth_AUG/training metric.png
Evaluate model:ConvNeXt+CBAM_PlantVillageSplited_depth_AUG

 Test Accuracy: 99.69%

 Classification Report:
                                                    precision    recall  f1-score   support

                                Apple___Apple_scab     1.0000    1.0000    1.0000        63
                                 Apple___Black_rot     1.0000    1.0000    1.0000        62
                          Apple___Cedar_apple_rust     1.0000    1.0000    1.0000        28
                                   Apple___healthy     1.0000    1.0000    1.0000       165
                               Blueberry___healthy     1.0000    1.0000    1.0000       151
          Cherry_(including_sour)___Powdery_mildew     1.0000    1.0000    1.0000       106
                 Cherry_(including_sour)___healthy     1.0000    1.0000    1.0000        86
Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot     0.9600    0.9231    0.9412        52
                       Corn_(maize)___Common_rust_     0.9756    1.0000    0.9877       120
               Corn_(maize)___Northern_Leaf_Blight     0.9796    0.9697    0.9746        99
                            Corn_(maize)___healthy     1.0000    1.0000    1.0000       117
                                 Grape___Black_rot     1.0000    1.0000    1.0000       118
                      Grape___Esca_(Black_Measles)     1.0000    1.0000    1.0000       139
        Grape___Leaf_blight_(Isariopsis_Leaf_Spot)     1.0000    1.0000    1.0000       108
                                   Grape___healthy     1.0000    1.0000    1.0000        43
          Orange___Haunglongbing_(Citrus_greening)     1.0000    1.0000    1.0000       551
                            Peach___Bacterial_spot     0.9957    1.0000    0.9978       230
                                   Peach___healthy     1.0000    0.9722    0.9859        36
                     Pepper,_bell___Bacterial_spot     1.0000    1.0000    1.0000       100
                            Pepper,_bell___healthy     1.0000    1.0000    1.0000       148
                             Potato___Early_blight     1.0000    0.9900    0.9950       100
                              Potato___Late_blight     1.0000    1.0000    1.0000       100
                                  Potato___healthy     1.0000    1.0000    1.0000        16
                               Raspberry___healthy     1.0000    1.0000    1.0000        38
                                 Soybean___healthy     1.0000    1.0000    1.0000       509
                           Squash___Powdery_mildew     1.0000    1.0000    1.0000       184
                          Strawberry___Leaf_scorch     1.0000    1.0000    1.0000       111
                              Strawberry___healthy     1.0000    1.0000    1.0000        46
                           Tomato___Bacterial_spot     0.9816    1.0000    0.9907       213
                             Tomato___Early_blight     1.0000    0.9900    0.9950       100
                              Tomato___Late_blight     1.0000    0.9895    0.9947       191
                                Tomato___Leaf_Mold     1.0000    1.0000    1.0000        96
                       Tomato___Septoria_leaf_spot     0.9780    1.0000    0.9889       178
     Tomato___Spider_mites_Two-spotted_spider_mite     0.9941    1.0000    0.9970       168
                              Tomato___Target_Spot     1.0000    0.9858    0.9929       141
            Tomato___Tomato_Yellow_Leaf_Curl_Virus     1.0000    0.9944    0.9972       536
                      Tomato___Tomato_mosaic_virus     1.0000    1.0000    1.0000        38
                                  Tomato___healthy     1.0000    1.0000    1.0000       160

                                          accuracy                         0.9969      5447
                                         macro avg     0.9964    0.9951    0.9958      5447
                                      weighted avg     0.9969    0.9969    0.9969      5447

 Confusion matrix saved to: output/test/ConvNeXt+CBAM_PlantVillageSplited_depth_AUG/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+CBAM_PlantVillageSplited_depth_AUG/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+CBAM_PlantVillageSplited_depth_AUG/misclassified_images.png

âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: ConvNeXt+CBAM_Citrus_splited_depth_AUG]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
Epoch 1/50 | Time: 21.50s | Train Loss: 0.7235 | Val Loss: 0.5767 | Val Acc: 0.9060 | LR: 0.000100 
Saving best val acc: 0.9060
Epoch 2/50 | Time: 22.26s | Train Loss: 0.5019 | Val Loss: 0.7220 | Val Acc: 0.8462 | LR: 0.000100 
Epoch 3/50 | Time: 22.44s | Train Loss: 0.4563 | Val Loss: 0.5740 | Val Acc: 0.9231 | LR: 0.000100 
Saving best val acc: 0.9231
Epoch 4/50 | Time: 22.66s | Train Loss: 0.4250 | Val Loss: 0.5388 | Val Acc: 0.9060 | LR: 0.000099 
Saving best val acc: 0.9060
Epoch 5/50 | Time: 22.83s | Train Loss: 0.4062 | Val Loss: 0.5955 | Val Acc: 0.9060 | LR: 0.000098 
Epoch 6/50 | Time: 22.96s | Train Loss: 0.4095 | Val Loss: 0.5340 | Val Acc: 0.9316 | LR: 0.000098 
Saving best val acc: 0.9316
Epoch 7/50 | Time: 23.14s | Train Loss: 0.4014 | Val Loss: 0.5685 | Val Acc: 0.9145 | LR: 0.000097 
Epoch 8/50 | Time: 23.28s | Train Loss: 0.4017 | Val Loss: 0.5901 | Val Acc: 0.9145 | LR: 0.000095 
Epoch 9/50 | Time: 23.36s | Train Loss: 0.3877 | Val Loss: 0.5528 | Val Acc: 0.9060 | LR: 0.000094 
Epoch 10/50 | Time: 23.37s | Train Loss: 0.3943 | Val Loss: 0.5428 | Val Acc: 0.9316 | LR: 0.000092 
Epoch 11/50 | Time: 23.18s | Train Loss: 0.3944 | Val Loss: 0.5915 | Val Acc: 0.9060 | LR: 0.000091 
Epoch 12/50 | Time: 22.73s | Train Loss: 0.3949 | Val Loss: 0.5758 | Val Acc: 0.9145 | LR: 0.000089 
Epoch 13/50 | Time: 22.50s | Train Loss: 0.3838 | Val Loss: 0.5640 | Val Acc: 0.9145 | LR: 0.000087 
Epoch 14/50 | Time: 22.35s | Train Loss: 0.3913 | Val Loss: 0.5743 | Val Acc: 0.9145 | LR: 0.000084 
Epoch 15/50 | Time: 22.34s | Train Loss: 0.3739 | Val Loss: 0.5710 | Val Acc: 0.9145 | LR: 0.000082 
Epoch 16/50 | Time: 22.53s | Train Loss: 0.3907 | Val Loss: 0.6162 | Val Acc: 0.9145 | LR: 0.000080 
Early stopping triggered.
Training complete in 363.50 seconds. Best model loaded.
Model saved to ./output/models/ConvNeXt+CBAM_Citrus_splited_depth_AUG.pth
 Training metrics plot saved to: output/test/ConvNeXt+CBAM_Citrus_splited_depth_AUG/training metric.png
Evaluate model:ConvNeXt+CBAM_Citrus_splited_depth_AUG

 Test Accuracy: 98.44%

 Classification Report:
              precision    recall  f1-score   support

  Black spot     0.9474    1.0000    0.9730        18
      canker     1.0000    1.0000    1.0000        17
    greening     1.0000    0.9545    0.9767        22
     healthy     1.0000    1.0000    1.0000         7

    accuracy                         0.9844        64
   macro avg     0.9868    0.9886    0.9874        64
weighted avg     0.9852    0.9844    0.9844        64

 Confusion matrix saved to: output/test/ConvNeXt+CBAM_Citrus_splited_depth_AUG/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+CBAM_Citrus_splited_depth_AUG/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+CBAM_Citrus_splited_depth_AUG/misclassified_images.png
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: ConvNeXt+Potato_splited]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
Epoch 1/50 | Time: 154.32s | Train Loss: 1.1286 | Val Loss: 0.9526 | Val Acc: 0.7892 | LR: 0.000100 
Saving best val acc: 0.7892
Epoch 2/50 | Time: 93.29s | Train Loss: 0.7054 | Val Loss: 0.7752 | Val Acc: 0.8562 | LR: 0.000100 
Saving best val acc: 0.8562
Epoch 3/50 | Time: 92.91s | Train Loss: 0.5897 | Val Loss: 0.7659 | Val Acc: 0.8644 | LR: 0.000100 
Saving best val acc: 0.8644
Epoch 4/50 | Time: 94.57s | Train Loss: 0.5383 | Val Loss: 0.6954 | Val Acc: 0.8856 | LR: 0.000099 
Saving best val acc: 0.8856
Epoch 5/50 | Time: 92.32s | Train Loss: 0.5120 | Val Loss: 0.6998 | Val Acc: 0.8824 | LR: 0.000098 
Epoch 6/50 | Time: 92.54s | Train Loss: 0.4869 | Val Loss: 0.6786 | Val Acc: 0.8971 | LR: 0.000098 
Saving best val acc: 0.8971
Epoch 7/50 | Time: 94.08s | Train Loss: 0.4722 | Val Loss: 0.7286 | Val Acc: 0.8807 | LR: 0.000097 
Epoch 8/50 | Time: 93.21s | Train Loss: 0.4781 | Val Loss: 0.7263 | Val Acc: 0.8856 | LR: 0.000095 
Epoch 9/50 | Time: 93.76s | Train Loss: 0.4799 | Val Loss: 0.7564 | Val Acc: 0.8725 | LR: 0.000094 
Epoch 10/50 | Time: 93.62s | Train Loss: 0.4651 | Val Loss: 0.7239 | Val Acc: 0.8987 | LR: 0.000092 
Epoch 11/50 | Time: 93.60s | Train Loss: 0.4666 | Val Loss: 0.7188 | Val Acc: 0.8873 | LR: 0.000091 
Epoch 12/50 | Time: 93.80s | Train Loss: 0.4702 | Val Loss: 0.7946 | Val Acc: 0.8513 | LR: 0.000089 
Epoch 13/50 | Time: 94.35s | Train Loss: 0.4847 | Val Loss: 0.7300 | Val Acc: 0.8938 | LR: 0.000087 
Epoch 14/50 | Time: 94.19s | Train Loss: 0.4726 | Val Loss: 0.7528 | Val Acc: 0.8775 | LR: 0.000084 
Epoch 15/50 | Time: 94.08s | Train Loss: 0.4856 | Val Loss: 0.7486 | Val Acc: 0.8758 | LR: 0.000082 
Epoch 16/50 | Time: 94.42s | Train Loss: 0.4605 | Val Loss: 0.7412 | Val Acc: 0.8824 | LR: 0.000080 
Early stopping triggered.
Training complete in 1559.15 seconds. Best model loaded.
Model saved to ./output/models/ConvNeXt+Potato_splited.pth
 Training metrics plot saved to: output/test/ConvNeXt+Potato_splited/training metric.png
Evaluate model:ConvNeXt+Potato_splited

 Test Accuracy: 88.57%

 Classification Report:
              precision    recall  f1-score   support

    Bacteria     0.9500    0.9828    0.9661        58
       Fungi     0.9143    0.8421    0.8767        76
     Healthy     0.9500    0.9048    0.9268        21
    Nematode     0.8000    1.0000    0.8889         8
        Pest     0.7971    0.8871    0.8397        62
 Phytopthora     0.8710    0.7500    0.8060        36
       Virus     0.8909    0.9074    0.8991        54

    accuracy                         0.8857       315
   macro avg     0.8819    0.8963    0.8862       315
weighted avg     0.8883    0.8857    0.8853       315

 Confusion matrix saved to: output/test/ConvNeXt+Potato_splited/confusion_matrix.png
Saved 8 merged gradCAM images in the output/test/ConvNeXt+Potato_splited/grad_cam folder!
Saved misclassified images to output/test/ConvNeXt+Potato_splited/misclassified_images.png
âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”[NEW LOG: ConvNeXt+CBAM+Potato_splited]âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”âœ”
Epoch 1/50 | Time: 141.29s | Train Loss: 0.9998 | Val Loss: 0.9248 | Val Acc: 0.8007 | LR: 0.000100 
Saving best model: 0.8007
Epoch 2/50 | Time: 102.85s | Train Loss: 0.6977 | Val Loss: 0.8287 | Val Acc: 0.8333 | LR: 0.000100 
Saving best model: 0.8333
Epoch 3/50 | Time: 102.70s | Train Loss: 0.6137 | Val Loss: 0.7582 | Val Acc: 0.8676 | LR: 0.000100 
Saving best model: 0.8676
Epoch 4/50 | Time: 103.28s | Train Loss: 0.5628 | Val Loss: 0.7409 | Val Acc: 0.8709 | LR: 0.000099 
Saving best model: 0.8709
Epoch 5/50 | Time: 103.72s | Train Loss: 0.5329 | Val Loss: 0.7150 | Val Acc: 0.8905 | LR: 0.000098 
Saving best model: 0.8905
Epoch 6/50 | Time: 103.64s | Train Loss: 0.5311 | Val Loss: 0.6873 | Val Acc: 0.8938 | LR: 0.000098 
Saving best model: 0.8938
Epoch 7/50 | Time: 103.42s | Train Loss: 0.5075 | Val Loss: 0.8023 | Val Acc: 0.8725 | LR: 0.000097 
Epoch 8/50 | Time: 103.21s | Train Loss: 0.5086 | Val Loss: 0.7226 | Val Acc: 0.8840 | LR: 0.000095 
Epoch 9/50 | Time: 103.14s | Train Loss: 0.4907 | Val Loss: 0.7537 | Val Acc: 0.8709 | LR: 0.000094 
Epoch 10/50 | Time: 103.94s | Train Loss: 0.4963 | Val Loss: 0.7451 | Val Acc: 0.8824 | LR: 0.000092 
Epoch 11/50 | Time: 103.25s | Train Loss: 0.4935 | Val Loss: 0.7687 | Val Acc: 0.8775 | LR: 0.000091 
Epoch 12/50 | Time: 103.43s | Train Loss: 0.4889 | Val Loss: 0.8965 | Val Acc: 0.8235 | LR: 0.000089 
Epoch 13/50 | Time: 104.21s | Train Loss: 0.4817 | Val Loss: 0.7754 | Val Acc: 0.8627 | LR: 0.000087 
Epoch 14/50 | Time: 103.41s | Train Loss: 0.4768 | Val Loss: 0.7417 | Val Acc: 0.8791 | LR: 0.000084 
Epoch 15/50 | Time: 104.08s | Train Loss: 0.4804 | Val Loss: 0.8960 | Val Acc: 0.8448 | LR: 0.000082 
Epoch 16/50 | Time: 102.94s | Train Loss: 0.4907 | Val Loss: 0.7850 | Val Acc: 0.8693 | LR: 0.000080 
Early stopping triggered.
Training complete in 1692.63 seconds.
Model saved

Evaluate model:ConvNeXt+CBAM+Potato_splited

 Test Accuracy: 88.89%

 Classification Report:
              precision    recall  f1-score   support

    Bacteria     0.9333    0.9655    0.9492        58
       Fungi     0.8293    0.8947    0.8608        76
     Healthy     1.0000    0.7619    0.8649        21
    Nematode     0.8000    1.0000    0.8889         8
        Pest     0.8462    0.8871    0.8661        62
 Phytopthora     0.9643    0.7500    0.8438        36
       Virus     0.9259    0.9259    0.9259        54

    accuracy                         0.8889       315
   macro avg     0.8999    0.8836    0.8856       315
weighted avg     0.8944    0.8889    0.8883       315

 Confusion matrix saved
Saved gradCAM images
Saved misclassified images
